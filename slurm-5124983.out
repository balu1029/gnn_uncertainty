wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_221815-hpbu9lw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/hpbu9lw1
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
80
Uncertainty Slope: 0.6297221779823303, Uncertainty Bias: 0.03318367898464203
1.5258789e-05 0.002626419
0.5307545 3.203376
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 13.237398026524605, Test Loss Force: 20.395767180075097, time: 15.065272569656372

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.047 MB uploadedwandb: | 0.039 MB of 0.047 MB uploadedwandb: / 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.2374
wandb:   test_error_force 20.39577
wandb:          test_loss 9.85373
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_81 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/hpbu9lw1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_221815-hpbu9lw1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 3725 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1884 steps.
Found uncertainty sample 3 after 63 steps.
Found uncertainty sample 4 after 1198 steps.
Found uncertainty sample 5 after 3661 steps.
Found uncertainty sample 6 after 75 steps.
Found uncertainty sample 7 after 805 steps.
Found uncertainty sample 8 after 1538 steps.
Found uncertainty sample 9 after 1401 steps.
Found uncertainty sample 10 after 452 steps.
Found uncertainty sample 11 after 726 steps.
Found uncertainty sample 12 after 150 steps.
Found uncertainty sample 13 after 297 steps.
Found uncertainty sample 14 after 86 steps.
Found uncertainty sample 15 after 245 steps.
Found uncertainty sample 16 after 1225 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 96 steps.
Found uncertainty sample 20 after 1149 steps.
Found uncertainty sample 21 after 768 steps.
Found uncertainty sample 22 after 423 steps.
Found uncertainty sample 23 after 635 steps.
Found uncertainty sample 24 after 730 steps.
Found uncertainty sample 25 after 2211 steps.
Found uncertainty sample 26 after 284 steps.
Found uncertainty sample 27 after 665 steps.
Found uncertainty sample 28 after 2072 steps.
Found uncertainty sample 29 after 1897 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 56 steps.
Found uncertainty sample 32 after 3100 steps.
Found uncertainty sample 33 after 3158 steps.
Found uncertainty sample 34 after 97 steps.
Found uncertainty sample 35 after 1055 steps.
Found uncertainty sample 36 after 1212 steps.
Found uncertainty sample 37 after 1835 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 34 steps.
Found uncertainty sample 42 after 1018 steps.
Found uncertainty sample 43 after 1892 steps.
Found uncertainty sample 44 after 394 steps.
Found uncertainty sample 45 after 1972 steps.
Found uncertainty sample 46 after 39 steps.
Found uncertainty sample 47 after 2 steps.
Found uncertainty sample 48 after 25 steps.
Found uncertainty sample 49 after 642 steps.
Found uncertainty sample 50 after 91 steps.
Found uncertainty sample 51 after 179 steps.
Found uncertainty sample 52 after 2902 steps.
Found uncertainty sample 53 after 1576 steps.
Found uncertainty sample 54 after 1370 steps.
Found uncertainty sample 55 after 107 steps.
Found uncertainty sample 56 after 3312 steps.
Found uncertainty sample 57 after 3624 steps.
Found uncertainty sample 58 after 963 steps.
Found uncertainty sample 59 after 232 steps.
Found uncertainty sample 60 after 51 steps.
Found uncertainty sample 61 after 1532 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 896 steps.
Found uncertainty sample 64 after 2092 steps.
Found uncertainty sample 65 after 111 steps.
Found uncertainty sample 66 after 445 steps.
Found uncertainty sample 67 after 99 steps.
Found uncertainty sample 68 after 2870 steps.
Found uncertainty sample 69 after 112 steps.
Found uncertainty sample 70 after 508 steps.
Found uncertainty sample 71 after 81 steps.
Found uncertainty sample 72 after 3138 steps.
Found uncertainty sample 73 after 380 steps.
Found uncertainty sample 74 after 2671 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2428 steps.
Found uncertainty sample 78 after 970 steps.
Found uncertainty sample 79 after 548 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 868 steps.
Found uncertainty sample 82 after 562 steps.
Found uncertainty sample 83 after 328 steps.
Found uncertainty sample 84 after 1125 steps.
Found uncertainty sample 85 after 2454 steps.
Found uncertainty sample 86 after 594 steps.
Found uncertainty sample 87 after 136 steps.
Found uncertainty sample 88 after 3183 steps.
Found uncertainty sample 89 after 1653 steps.
Found uncertainty sample 90 after 1042 steps.
Found uncertainty sample 91 after 168 steps.
Found uncertainty sample 92 after 996 steps.
Found uncertainty sample 93 after 36 steps.
Found uncertainty sample 94 after 3888 steps.
Found uncertainty sample 95 after 74 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2047 steps.
Found uncertainty sample 98 after 767 steps.
Found uncertainty sample 99 after 30 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_232737-f418fp4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/f418fp4u
Training model 0. Added 88 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.6472659996925705, Training Loss Force: 2.903248048297524, time: 1.1119143962860107
Validation Loss Energy: 0.9651334720684958, Validation Loss Force: 2.6048391136805984, time: 0.06851720809936523
Test Loss Energy: 12.68317415391532, Test Loss Force: 19.75592184467329, time: 15.959530353546143


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8319147776276377, Training Loss Force: 2.4588071926247324, time: 1.014493465423584
Validation Loss Energy: 0.9572507616335062, Validation Loss Force: 2.504951293501414, time: 0.08110976219177246
Test Loss Energy: 12.676012974285433, Test Loss Force: 19.600348512950596, time: 16.153993129730225


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2061493349166654, Training Loss Force: 2.4303909594208473, time: 1.006728172302246
Validation Loss Energy: 1.7172045245065393, Validation Loss Force: 2.5215677558471294, time: 0.06714677810668945
Test Loss Energy: 13.383231035708539, Test Loss Force: 19.590026615908492, time: 16.044584274291992


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5843817149294106, Training Loss Force: 2.387686420888843, time: 1.0048556327819824
Validation Loss Energy: 1.9564588477650395, Validation Loss Force: 2.497491431774541, time: 0.07317972183227539
Test Loss Energy: 13.256666564668047, Test Loss Force: 19.076289473321996, time: 16.182856798171997


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6380863796542111, Training Loss Force: 2.4294178157284483, time: 0.9683780670166016
Validation Loss Energy: 1.1040565295436968, Validation Loss Force: 2.486160466945714, time: 0.06917285919189453
Test Loss Energy: 13.090622746800303, Test Loss Force: 19.501078821154696, time: 16.05542778968811


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3489432449910317, Training Loss Force: 2.41435809700167, time: 0.9583890438079834
Validation Loss Energy: 2.2353149899613696, Validation Loss Force: 2.489955862538053, time: 0.07143068313598633
Test Loss Energy: 13.705854528594633, Test Loss Force: 19.429065427644403, time: 16.233219385147095


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5912191209637814, Training Loss Force: 2.4253460797735427, time: 1.0304491519927979
Validation Loss Energy: 1.0580868183706238, Validation Loss Force: 2.51794515151203, time: 0.07143735885620117
Test Loss Energy: 12.997818126583454, Test Loss Force: 19.803701802958532, time: 16.23851728439331


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2704961175861917, Training Loss Force: 2.39689310616058, time: 0.9739830493927002
Validation Loss Energy: 1.108046092631285, Validation Loss Force: 2.4754373888852697, time: 0.0702366828918457
Test Loss Energy: 12.68446611993743, Test Loss Force: 19.71368228644989, time: 16.114315032958984


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2736295893799132, Training Loss Force: 2.4037254146620026, time: 1.002326488494873
Validation Loss Energy: 1.657625386468933, Validation Loss Force: 2.4794113651326426, time: 0.07120633125305176
Test Loss Energy: 12.603145431257817, Test Loss Force: 19.560388452582465, time: 16.3042471408844


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.1883918999622776, Training Loss Force: 2.4045623564093193, time: 0.9821016788482666
Validation Loss Energy: 1.1541989491768834, Validation Loss Force: 2.488282058568114, time: 0.06840229034423828
Test Loss Energy: 13.048120261782046, Test Loss Force: 19.40139322536326, time: 16.168537616729736


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.167465046063922, Training Loss Force: 2.3831952557877045, time: 0.9674839973449707
Validation Loss Energy: 1.0086176389001498, Validation Loss Force: 2.4800078957745835, time: 0.07440662384033203
Test Loss Energy: 12.826043630290918, Test Loss Force: 18.956221979667802, time: 17.553380966186523


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.0963054881461758, Training Loss Force: 2.380212499195898, time: 1.0285260677337646
Validation Loss Energy: 1.3706866882791429, Validation Loss Force: 2.4956305857220227, time: 0.07439661026000977
Test Loss Energy: 12.860134015391688, Test Loss Force: 19.588754636482395, time: 17.67972683906555


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2615632756015984, Training Loss Force: 2.3711528709901066, time: 1.2624773979187012
Validation Loss Energy: 1.1845670126368069, Validation Loss Force: 2.4845772893181675, time: 0.07906627655029297
Test Loss Energy: 12.610607650246537, Test Loss Force: 19.308231467152485, time: 18.051936626434326


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.303193081619609, Training Loss Force: 2.3889236660932514, time: 1.0852012634277344
Validation Loss Energy: 2.42255235338169, Validation Loss Force: 2.466160769596772, time: 0.07518553733825684
Test Loss Energy: 13.898576805490416, Test Loss Force: 19.006056966656303, time: 17.924347639083862


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6931951781201762, Training Loss Force: 2.388580143268371, time: 1.092027187347412
Validation Loss Energy: 1.2000274881114381, Validation Loss Force: 2.5358395120862247, time: 0.07399249076843262
Test Loss Energy: 12.982273176147313, Test Loss Force: 19.76331058051224, time: 17.851300477981567


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.336130691356253, Training Loss Force: 2.4034078725549706, time: 1.0084984302520752
Validation Loss Energy: 1.8999743655175376, Validation Loss Force: 2.4861117024027557, time: 0.07326197624206543
Test Loss Energy: 13.442956072166433, Test Loss Force: 18.81995869348264, time: 17.956010580062866


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.546095809012375, Training Loss Force: 2.362268061921278, time: 1.029738426208496
Validation Loss Energy: 1.0081556004223495, Validation Loss Force: 2.4584744533484906, time: 0.07435727119445801
Test Loss Energy: 13.371224925205382, Test Loss Force: 19.243473431828534, time: 17.923254251480103


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9132969706647072, Training Loss Force: 2.421391921080157, time: 1.0157649517059326
Validation Loss Energy: 1.0802524185020055, Validation Loss Force: 2.4902079240112434, time: 0.0800628662109375
Test Loss Energy: 13.462407819218878, Test Loss Force: 19.421869404373503, time: 17.82245707511902


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.451121153716327, Training Loss Force: 2.354431109995777, time: 1.05698561668396
Validation Loss Energy: 0.9564701949424563, Validation Loss Force: 2.4710646121975395, time: 0.07654881477355957
Test Loss Energy: 13.264505064202401, Test Loss Force: 19.53934138252466, time: 17.994498014450073


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.911190904250884, Training Loss Force: 2.3784409196134884, time: 1.1039280891418457
Validation Loss Energy: 1.043368944497662, Validation Loss Force: 2.5254036772240274, time: 0.07528114318847656
Test Loss Energy: 12.729247258766657, Test Loss Force: 19.368714264201074, time: 17.56738805770874

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–…â–…â–„â–‡â–ƒâ–â–â–ƒâ–‚â–‚â–â–ˆâ–ƒâ–†â–…â–†â–…â–‚
wandb:   test_error_force â–ˆâ–‡â–†â–ƒâ–†â–…â–ˆâ–‡â–†â–…â–‚â–†â–„â–‚â–ˆâ–â–„â–…â–†â–…
wandb:          test_loss â–ˆâ–†â–‡â–„â–†â–†â–ˆâ–‡â–…â–…â–‚â–†â–„â–ƒâ–‡â–â–„â–…â–†â–„
wandb: train_error_energy â–ˆâ–„â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–â–â–‚â–‚â–„â–‚â–ƒâ–…â–ƒâ–…
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–â–‚
wandb: valid_error_energy â–â–â–…â–†â–‚â–‡â–â–‚â–„â–‚â–â–ƒâ–‚â–ˆâ–‚â–†â–â–‚â–â–
wandb:  valid_error_force â–ˆâ–ƒâ–„â–ƒâ–‚â–ƒâ–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–…â–‚â–â–ƒâ–‚â–„
wandb:         valid_loss â–ˆâ–ƒâ–ƒâ–†â–‚â–…â–‚â–„â–ƒâ–â–â–â–â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 879
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.72925
wandb:   test_error_force 19.36871
wandb:          test_loss 9.37192
wandb: train_error_energy 1.91119
wandb:  train_error_force 2.37844
wandb:         train_loss 1.14009
wandb: valid_error_energy 1.04337
wandb:  valid_error_force 2.5254
wandb:         valid_loss 1.2547
wandb: 
wandb: ğŸš€ View run al_81_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/f418fp4u
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_232737-f418fp4u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6252325773239136, Uncertainty Bias: 0.03469109535217285
0.00018310547 0.00944519
0.6204446 3.326611
(48745, 22, 3)
Found uncertainty sample 0 after 1704 steps.
Found uncertainty sample 1 after 2278 steps.
Found uncertainty sample 2 after 1835 steps.
Found uncertainty sample 3 after 1034 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 486 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 382 steps.
Found uncertainty sample 8 after 3745 steps.
Found uncertainty sample 9 after 1527 steps.
Found uncertainty sample 10 after 926 steps.
Found uncertainty sample 11 after 2781 steps.
Found uncertainty sample 12 after 5 steps.
Found uncertainty sample 13 after 342 steps.
Found uncertainty sample 14 after 1446 steps.
Found uncertainty sample 15 after 70 steps.
Found uncertainty sample 16 after 2154 steps.
Found uncertainty sample 17 after 611 steps.
Found uncertainty sample 18 after 1761 steps.
Found uncertainty sample 19 after 3038 steps.
Found uncertainty sample 20 after 359 steps.
Found uncertainty sample 21 after 378 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 593 steps.
Found uncertainty sample 24 after 1469 steps.
Found uncertainty sample 25 after 3289 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3603 steps.
Found uncertainty sample 28 after 125 steps.
Found uncertainty sample 29 after 547 steps.
Found uncertainty sample 30 after 175 steps.
Found uncertainty sample 31 after 696 steps.
Found uncertainty sample 32 after 2232 steps.
Found uncertainty sample 33 after 1959 steps.
Found uncertainty sample 34 after 3396 steps.
Found uncertainty sample 35 after 2959 steps.
Found uncertainty sample 36 after 273 steps.
Found uncertainty sample 37 after 1044 steps.
Found uncertainty sample 38 after 428 steps.
Found uncertainty sample 39 after 7 steps.
Found uncertainty sample 40 after 437 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1445 steps.
Found uncertainty sample 43 after 112 steps.
Found uncertainty sample 44 after 3351 steps.
Found uncertainty sample 45 after 1458 steps.
Found uncertainty sample 46 after 505 steps.
Found uncertainty sample 47 after 281 steps.
Found uncertainty sample 48 after 749 steps.
Found uncertainty sample 49 after 2429 steps.
Found uncertainty sample 50 after 655 steps.
Found uncertainty sample 51 after 2845 steps.
Found uncertainty sample 52 after 3161 steps.
Found uncertainty sample 53 after 2041 steps.
Found uncertainty sample 54 after 668 steps.
Found uncertainty sample 55 after 3158 steps.
Found uncertainty sample 56 after 59 steps.
Found uncertainty sample 57 after 1365 steps.
Found uncertainty sample 58 after 2964 steps.
Found uncertainty sample 59 after 262 steps.
Found uncertainty sample 60 after 376 steps.
Found uncertainty sample 61 after 1136 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 43 steps.
Found uncertainty sample 65 after 204 steps.
Found uncertainty sample 66 after 1995 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3532 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 817 steps.
Found uncertainty sample 72 after 90 steps.
Found uncertainty sample 73 after 1840 steps.
Found uncertainty sample 74 after 491 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3751 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 915 steps.
Found uncertainty sample 80 after 90 steps.
Found uncertainty sample 81 after 45 steps.
Found uncertainty sample 82 after 116 steps.
Found uncertainty sample 83 after 1068 steps.
Found uncertainty sample 84 after 137 steps.
Found uncertainty sample 85 after 270 steps.
Found uncertainty sample 86 after 1295 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 437 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 438 steps.
Found uncertainty sample 91 after 85 steps.
Found uncertainty sample 92 after 633 steps.
Found uncertainty sample 93 after 748 steps.
Found uncertainty sample 94 after 3812 steps.
Found uncertainty sample 95 after 1398 steps.
Found uncertainty sample 96 after 8 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 103 steps.
Found uncertainty sample 99 after 857 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_005241-tp7lhjkg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/tp7lhjkg
Training model 1. Added 84 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.146358736017404, Training Loss Force: 3.0139659321696306, time: 1.055237054824829
Validation Loss Energy: 1.198902563586211, Validation Loss Force: 3.0285929718756637, time: 0.07507467269897461
Test Loss Energy: 12.926441053875413, Test Loss Force: 19.415503892716252, time: 16.742932558059692


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.456965549199, Training Loss Force: 2.6506605049355683, time: 1.074657917022705
Validation Loss Energy: 2.2019437877303183, Validation Loss Force: 2.5617622087168463, time: 0.07531595230102539
Test Loss Energy: 13.238434093236734, Test Loss Force: 18.58960423972966, time: 16.891799926757812


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.335203227974058, Training Loss Force: 2.5348857013773385, time: 1.0772228240966797
Validation Loss Energy: 1.0679867999331463, Validation Loss Force: 2.532836595984243, time: 0.07269573211669922
Test Loss Energy: 12.794833017093788, Test Loss Force: 19.030607249583745, time: 16.75556755065918


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2116158658952625, Training Loss Force: 2.536593380746679, time: 1.064633846282959
Validation Loss Energy: 1.8988948654980797, Validation Loss Force: 2.550033334124246, time: 0.0802767276763916
Test Loss Energy: 13.244525267179746, Test Loss Force: 19.017285591113534, time: 16.89476227760315


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6064313153041394, Training Loss Force: 2.5346234936133984, time: 1.0423638820648193
Validation Loss Energy: 1.2137362254150552, Validation Loss Force: 2.5490266469155065, time: 0.07968568801879883
Test Loss Energy: 12.507635882214974, Test Loss Force: 18.483502144543976, time: 16.860679149627686


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.422282701374827, Training Loss Force: 2.524457630246028, time: 1.03529953956604
Validation Loss Energy: 1.0793576225390946, Validation Loss Force: 2.5637072237065253, time: 0.07886552810668945
Test Loss Energy: 12.296716080119912, Test Loss Force: 18.870513487047624, time: 16.69761371612549


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3510706944024637, Training Loss Force: 2.5217575590271175, time: 1.0664176940917969
Validation Loss Energy: 1.510472477360241, Validation Loss Force: 2.5475200674741587, time: 0.07541084289550781
Test Loss Energy: 12.289190268688408, Test Loss Force: 19.0155405831466, time: 16.984361171722412


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3843888679764125, Training Loss Force: 2.55902282154907, time: 1.0440120697021484
Validation Loss Energy: 1.0877879877384937, Validation Loss Force: 2.5503243626979732, time: 0.07827043533325195
Test Loss Energy: 12.27817466049476, Test Loss Force: 18.64000438199506, time: 16.804295778274536


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.407675169341554, Training Loss Force: 2.5300223474496053, time: 1.0627474784851074
Validation Loss Energy: 1.025613195466807, Validation Loss Force: 2.5321572324200172, time: 0.07647323608398438
Test Loss Energy: 12.579726242306494, Test Loss Force: 19.172205464670387, time: 16.88787055015564


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4818564489635258, Training Loss Force: 2.5176570473264186, time: 1.1048543453216553
Validation Loss Energy: 1.0241140754418483, Validation Loss Force: 2.535301988767955, time: 0.07393145561218262
Test Loss Energy: 12.630124258139837, Test Loss Force: 19.17888630381764, time: 16.849314212799072


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9598958109776028, Training Loss Force: 2.5267205202861294, time: 1.241008996963501
Validation Loss Energy: 3.3156059302256207, Validation Loss Force: 2.556240013897837, time: 0.07519841194152832
Test Loss Energy: 13.312222236783334, Test Loss Force: 18.23809662285214, time: 17.245811700820923


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.201902488170477, Training Loss Force: 2.5818910987042556, time: 1.0186238288879395
Validation Loss Energy: 1.1738994905282714, Validation Loss Force: 2.5629013840674126, time: 0.07706308364868164
Test Loss Energy: 12.56210340868575, Test Loss Force: 19.082194547154522, time: 17.15945315361023


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9983838017359774, Training Loss Force: 2.529378714860996, time: 1.0774986743927002
Validation Loss Energy: 1.1119794317595264, Validation Loss Force: 2.5444015860854403, time: 0.07620835304260254
Test Loss Energy: 12.01644328883782, Test Loss Force: 18.212363591369957, time: 17.276517868041992


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3729747881777152, Training Loss Force: 2.5333320645231514, time: 1.0791947841644287
Validation Loss Energy: 1.1421731452781885, Validation Loss Force: 2.5556775516352235, time: 0.07556462287902832
Test Loss Energy: 12.482630850601193, Test Loss Force: 18.75373682419852, time: 17.39463710784912


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5566406925101797, Training Loss Force: 2.518796155876242, time: 1.0952072143554688
Validation Loss Energy: 1.0330828546361006, Validation Loss Force: 2.5275820494786387, time: 0.0747215747833252
Test Loss Energy: 12.731601829932506, Test Loss Force: 19.118366872448416, time: 17.488747358322144


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4304359937892195, Training Loss Force: 2.506334744327368, time: 1.0837554931640625
Validation Loss Energy: 1.044814289923879, Validation Loss Force: 2.538959329489819, time: 0.07810831069946289
Test Loss Energy: 12.415780685930537, Test Loss Force: 18.74603475673123, time: 17.4498131275177


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.361569067749871, Training Loss Force: 2.4976299468279177, time: 1.0485072135925293
Validation Loss Energy: 1.0214453857279038, Validation Loss Force: 2.530236265698098, time: 0.07551956176757812
Test Loss Energy: 12.739456081851676, Test Loss Force: 19.294829423954784, time: 17.51519274711609


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.666786520260471, Training Loss Force: 2.507050492030038, time: 1.0475430488586426
Validation Loss Energy: 1.0274722601661581, Validation Loss Force: 2.545672581570396, time: 0.07972931861877441
Test Loss Energy: 12.362533708142191, Test Loss Force: 18.80431938262413, time: 17.503848791122437


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.420544061716323, Training Loss Force: 2.519474235381726, time: 1.0345337390899658
Validation Loss Energy: 1.0507496473431572, Validation Loss Force: 2.526818962315544, time: 0.07775473594665527
Test Loss Energy: 12.604440171900702, Test Loss Force: 19.019631511991097, time: 17.90863561630249


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6278683902350266, Training Loss Force: 2.51788667859431, time: 1.0494933128356934
Validation Loss Energy: 2.778983531320365, Validation Loss Force: 2.544581057417058, time: 0.07811164855957031
Test Loss Energy: 12.652925410806628, Test Loss Force: 19.348983931233512, time: 17.68871784210205

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–ˆâ–…â–ˆâ–„â–ƒâ–‚â–‚â–„â–„â–ˆâ–„â–â–„â–…â–ƒâ–…â–ƒâ–„â–„
wandb:   test_error_force â–ˆâ–ƒâ–†â–†â–ƒâ–…â–†â–ƒâ–‡â–‡â–â–†â–â–„â–†â–„â–‡â–„â–†â–ˆ
wandb:          test_loss â–ˆâ–„â–†â–†â–ƒâ–„â–…â–ƒâ–†â–†â–‚â–†â–â–„â–‡â–„â–‡â–„â–…â–‡
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–‚â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–…â–â–„â–‚â–â–‚â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–†
wandb:  valid_error_force â–ˆâ–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–
wandb:         valid_loss â–ˆâ–ƒâ–â–ƒâ–„â–‚â–‚â–â–â–â–…â–ƒâ–…â–â–„â–‚â–ƒâ–ƒâ–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 954
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.65293
wandb:   test_error_force 19.34898
wandb:          test_loss 9.31532
wandb: train_error_energy 1.62787
wandb:  train_error_force 2.51789
wandb:         train_loss 1.1671
wandb: valid_error_energy 2.77898
wandb:  valid_error_force 2.54458
wandb:         valid_loss 1.35436
wandb: 
wandb: ğŸš€ View run al_81_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/tp7lhjkg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_005241-tp7lhjkg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7069069147109985, Uncertainty Bias: 0.018866464495658875
0.00030899048 0.09194565
0.4481535 3.6843932
(48745, 22, 3)
Found uncertainty sample 0 after 1369 steps.
Found uncertainty sample 1 after 1485 steps.
Found uncertainty sample 2 after 2454 steps.
Found uncertainty sample 3 after 3136 steps.
Found uncertainty sample 4 after 868 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 202 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3766 steps.
Found uncertainty sample 9 after 2119 steps.
Found uncertainty sample 10 after 799 steps.
Found uncertainty sample 11 after 85 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 256 steps.
Found uncertainty sample 14 after 848 steps.
Found uncertainty sample 15 after 832 steps.
Found uncertainty sample 16 after 1863 steps.
Found uncertainty sample 17 after 55 steps.
Found uncertainty sample 18 after 1400 steps.
Found uncertainty sample 19 after 2993 steps.
Found uncertainty sample 20 after 8 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2198 steps.
Found uncertainty sample 23 after 497 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 410 steps.
Found uncertainty sample 26 after 1080 steps.
Found uncertainty sample 27 after 2179 steps.
Found uncertainty sample 28 after 1234 steps.
Found uncertainty sample 29 after 25 steps.
Found uncertainty sample 30 after 1669 steps.
Found uncertainty sample 31 after 637 steps.
Found uncertainty sample 32 after 3091 steps.
Found uncertainty sample 33 after 668 steps.
Found uncertainty sample 34 after 3753 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2987 steps.
Found uncertainty sample 37 after 2470 steps.
Found uncertainty sample 38 after 282 steps.
Found uncertainty sample 39 after 727 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 874 steps.
Found uncertainty sample 42 after 74 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 717 steps.
Found uncertainty sample 47 after 296 steps.
Found uncertainty sample 48 after 283 steps.
Found uncertainty sample 49 after 1045 steps.
Found uncertainty sample 50 after 281 steps.
Found uncertainty sample 51 after 1357 steps.
Found uncertainty sample 52 after 3298 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 32 steps.
Found uncertainty sample 55 after 1885 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 152 steps.
Found uncertainty sample 58 after 16 steps.
Found uncertainty sample 59 after 307 steps.
Found uncertainty sample 60 after 394 steps.
Found uncertainty sample 61 after 633 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 662 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 255 steps.
Found uncertainty sample 66 after 567 steps.
Found uncertainty sample 67 after 664 steps.
Found uncertainty sample 68 after 3061 steps.
Found uncertainty sample 69 after 3483 steps.
Found uncertainty sample 70 after 1779 steps.
Found uncertainty sample 71 after 305 steps.
Found uncertainty sample 72 after 1081 steps.
Found uncertainty sample 73 after 28 steps.
Found uncertainty sample 74 after 147 steps.
Found uncertainty sample 75 after 10 steps.
Found uncertainty sample 76 after 2147 steps.
Found uncertainty sample 77 after 1535 steps.
Found uncertainty sample 78 after 113 steps.
Found uncertainty sample 79 after 638 steps.
Found uncertainty sample 80 after 261 steps.
Found uncertainty sample 81 after 2184 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 146 steps.
Found uncertainty sample 84 after 2275 steps.
Found uncertainty sample 85 after 6 steps.
Found uncertainty sample 86 after 977 steps.
Found uncertainty sample 87 after 1233 steps.
Found uncertainty sample 88 after 1076 steps.
Found uncertainty sample 89 after 2957 steps.
Found uncertainty sample 90 after 2969 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 493 steps.
Found uncertainty sample 93 after 338 steps.
Found uncertainty sample 94 after 1280 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3389 steps.
Found uncertainty sample 97 after 2337 steps.
Found uncertainty sample 98 after 307 steps.
Found uncertainty sample 99 after 2 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_021620-0mt8hf5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/0mt8hf5r
Training model 2. Added 84 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.42529579568382, Training Loss Force: 3.113134117382661, time: 1.176816701889038
Validation Loss Energy: 1.8444246483446405, Validation Loss Force: 2.6648228415563553, time: 0.08081650733947754
Test Loss Energy: 11.893104298122601, Test Loss Force: 18.251840051658952, time: 16.92882013320923


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7517249441292613, Training Loss Force: 2.682963426973097, time: 1.1808032989501953
Validation Loss Energy: 1.2520860870799064, Validation Loss Force: 2.591423074969303, time: 0.08079195022583008
Test Loss Energy: 12.620632341103368, Test Loss Force: 18.697837989784176, time: 17.059688329696655


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2267422290154495, Training Loss Force: 2.612774893595367, time: 1.1929857730865479
Validation Loss Energy: 1.094777460894594, Validation Loss Force: 2.59944918433427, time: 0.07839679718017578
Test Loss Energy: 12.524812174430993, Test Loss Force: 18.631609955712392, time: 16.95496368408203


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3041951644690013, Training Loss Force: 2.621733912458723, time: 1.1692867279052734
Validation Loss Energy: 1.1278920369349639, Validation Loss Force: 2.5795817524580094, time: 0.07729840278625488
Test Loss Energy: 12.347065383871612, Test Loss Force: 18.525946203976282, time: 17.06494426727295


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5151571612279042, Training Loss Force: 2.605178198304547, time: 1.1668732166290283
Validation Loss Energy: 1.411561618058815, Validation Loss Force: 2.5882019431043117, time: 0.07705831527709961
Test Loss Energy: 12.496037286559849, Test Loss Force: 18.37162448269897, time: 17.111619234085083


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6789424737688947, Training Loss Force: 2.655199897522891, time: 1.2102694511413574
Validation Loss Energy: 1.9370365315114881, Validation Loss Force: 2.5881629760037743, time: 0.08450102806091309
Test Loss Energy: 12.480309313743824, Test Loss Force: 19.038841867036442, time: 16.987019777297974


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.463284431955224, Training Loss Force: 2.6614491813264034, time: 1.1661479473114014
Validation Loss Energy: 1.1195915991822136, Validation Loss Force: 2.5809008444784856, time: 0.0791923999786377
Test Loss Energy: 12.403575017240343, Test Loss Force: 18.95114572936031, time: 17.405218601226807


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5496815264804165, Training Loss Force: 2.6377118204218664, time: 1.172898769378662
Validation Loss Energy: 1.0951329521860678, Validation Loss Force: 2.58302599880722, time: 0.0781700611114502
Test Loss Energy: 12.374649474456165, Test Loss Force: 18.976042741956366, time: 16.947710752487183


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.769767857074652, Training Loss Force: 2.6524807361358698, time: 1.1434190273284912
Validation Loss Energy: 1.1058283079378441, Validation Loss Force: 2.5745993076487292, time: 0.0799710750579834
Test Loss Energy: 12.013211722999761, Test Loss Force: 18.007278411055978, time: 17.0299870967865


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7387425518927733, Training Loss Force: 2.6271268916975954, time: 1.166921615600586
Validation Loss Energy: 2.0694667793605808, Validation Loss Force: 2.5637047743459203, time: 0.07784628868103027
Test Loss Energy: 12.055072804297044, Test Loss Force: 18.60307719197517, time: 17.19185471534729


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4951119280386198, Training Loss Force: 2.629542838435812, time: 1.1605405807495117
Validation Loss Energy: 2.4523610719470432, Validation Loss Force: 2.6173537876891775, time: 0.07950735092163086
Test Loss Energy: 12.023222046450549, Test Loss Force: 18.502008352133092, time: 17.08911967277527


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.867379613972111, Training Loss Force: 2.6660534529552997, time: 1.1838288307189941
Validation Loss Energy: 1.1490007379651992, Validation Loss Force: 2.5770092558151054, time: 0.0797569751739502
Test Loss Energy: 12.325734169330694, Test Loss Force: 18.903299543908354, time: 17.32139754295349


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4058978832598192, Training Loss Force: 2.6596760804124804, time: 1.1292986869812012
Validation Loss Energy: 1.1215367255064659, Validation Loss Force: 2.582681084300178, time: 0.08086466789245605
Test Loss Energy: 12.340591391537048, Test Loss Force: 19.152675678494234, time: 17.48456645011902


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6670012116094912, Training Loss Force: 2.6252504115720128, time: 1.1978721618652344
Validation Loss Energy: 1.9333872068788778, Validation Loss Force: 2.5688003350813315, time: 0.08034586906433105
Test Loss Energy: 12.07813460810335, Test Loss Force: 18.514113225146023, time: 17.577364206314087


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9839431264898273, Training Loss Force: 2.6309167273088363, time: 1.1517610549926758
Validation Loss Energy: 2.4260785419766027, Validation Loss Force: 2.579163134463665, time: 0.07904434204101562
Test Loss Energy: 12.926687356261795, Test Loss Force: 18.5942265993848, time: 17.939427375793457


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9013950334669685, Training Loss Force: 2.615886276561616, time: 1.1629786491394043
Validation Loss Energy: 1.3165323273092022, Validation Loss Force: 2.601355677561704, time: 0.0785980224609375
Test Loss Energy: 11.95326890445908, Test Loss Force: 18.562475965710707, time: 17.559565544128418


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3926575743637353, Training Loss Force: 2.6164030309213655, time: 1.1565120220184326
Validation Loss Energy: 1.0895310418128163, Validation Loss Force: 2.5901108856923507, time: 0.07958674430847168
Test Loss Energy: 12.137488265068429, Test Loss Force: 18.631747409026435, time: 17.80287790298462


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4868324464888991, Training Loss Force: 2.6279403965533676, time: 1.174309492111206
Validation Loss Energy: 1.1550678041842937, Validation Loss Force: 2.564753768692386, time: 0.08455705642700195
Test Loss Energy: 12.17235582844206, Test Loss Force: 18.85871138811442, time: 17.9010591506958


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.28648271109193, Training Loss Force: 2.646007926247596, time: 1.1483757495880127
Validation Loss Energy: 1.1648830601367905, Validation Loss Force: 2.5976417788767745, time: 0.08240389823913574
Test Loss Energy: 12.234687628109386, Test Loss Force: 18.49008940202798, time: 17.689947605133057


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6383449408253121, Training Loss Force: 2.6388509013067347, time: 1.1704747676849365
Validation Loss Energy: 1.3915798455761201, Validation Loss Force: 2.579258882196414, time: 0.08275866508483887
Test Loss Energy: 12.11464446717987, Test Loss Force: 18.43163718904049, time: 17.82242751121521

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–…â–„â–…â–…â–„â–„â–‚â–‚â–‚â–„â–„â–‚â–ˆâ–â–ƒâ–ƒâ–ƒâ–ƒ
wandb:   test_error_force â–‚â–…â–…â–„â–ƒâ–‡â–‡â–‡â–â–…â–„â–†â–ˆâ–„â–…â–„â–…â–†â–„â–„
wandb:          test_loss â–‚â–†â–…â–„â–ƒâ–ˆâ–‡â–‡â–â–„â–„â–†â–ˆâ–„â–†â–„â–…â–†â–ƒâ–„
wandb: train_error_energy â–ˆâ–‚â–â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–‚â–‚â–â–‚â–â–â–‚â–‚â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚
wandb: valid_error_energy â–…â–‚â–â–â–ƒâ–…â–â–â–â–†â–ˆâ–â–â–…â–ˆâ–‚â–â–â–â–ƒ
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–…â–‚â–‚â–â–‚â–„â–ƒâ–â–ƒâ–‚
wandb:         valid_loss â–ˆâ–‚â–â–ƒâ–ƒâ–†â–‚â–‚â–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–†â–â–‚â–ƒâ–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1029
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.11464
wandb:   test_error_force 18.43164
wandb:          test_loss 8.94261
wandb: train_error_energy 1.63834
wandb:  train_error_force 2.63885
wandb:         train_loss 1.22612
wandb: valid_error_energy 1.39158
wandb:  valid_error_force 2.57926
wandb:         valid_loss 1.33368
wandb: 
wandb: ğŸš€ View run al_81_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/0mt8hf5r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_021620-0mt8hf5r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7174990177154541, Uncertainty Bias: 0.013746976852416992
0.00017642975 0.0060124397
0.47666788 5.7962594
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 150 steps.
Found uncertainty sample 2 after 665 steps.
Found uncertainty sample 3 after 172 steps.
Found uncertainty sample 4 after 6 steps.
Found uncertainty sample 5 after 3665 steps.
Found uncertainty sample 6 after 3493 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 45 steps.
Found uncertainty sample 9 after 84 steps.
Found uncertainty sample 10 after 10 steps.
Found uncertainty sample 11 after 21 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1494 steps.
Found uncertainty sample 14 after 90 steps.
Found uncertainty sample 15 after 13 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1959 steps.
Found uncertainty sample 18 after 2802 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 407 steps.
Found uncertainty sample 21 after 665 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 75 steps.
Found uncertainty sample 24 after 621 steps.
Found uncertainty sample 25 after 1541 steps.
Found uncertainty sample 26 after 836 steps.
Found uncertainty sample 27 after 165 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 316 steps.
Found uncertainty sample 30 after 53 steps.
Found uncertainty sample 31 after 2799 steps.
Found uncertainty sample 32 after 1245 steps.
Found uncertainty sample 33 after 957 steps.
Found uncertainty sample 34 after 631 steps.
Found uncertainty sample 35 after 203 steps.
Found uncertainty sample 36 after 912 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2926 steps.
Found uncertainty sample 39 after 3050 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3650 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 24 steps.
Found uncertainty sample 44 after 313 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 505 steps.
Found uncertainty sample 47 after 56 steps.
Found uncertainty sample 48 after 142 steps.
Found uncertainty sample 49 after 3867 steps.
Found uncertainty sample 50 after 1441 steps.
Found uncertainty sample 51 after 102 steps.
Found uncertainty sample 52 after 180 steps.
Found uncertainty sample 53 after 33 steps.
Found uncertainty sample 54 after 1931 steps.
Found uncertainty sample 55 after 522 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1010 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3519 steps.
Found uncertainty sample 60 after 3720 steps.
Found uncertainty sample 61 after 696 steps.
Found uncertainty sample 62 after 2000 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 107 steps.
Found uncertainty sample 65 after 149 steps.
Found uncertainty sample 66 after 5 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 536 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 669 steps.
Found uncertainty sample 72 after 1181 steps.
Found uncertainty sample 73 after 754 steps.
Found uncertainty sample 74 after 138 steps.
Found uncertainty sample 75 after 2555 steps.
Found uncertainty sample 76 after 1613 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1553 steps.
Found uncertainty sample 79 after 1340 steps.
Found uncertainty sample 80 after 920 steps.
Found uncertainty sample 81 after 132 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1673 steps.
Found uncertainty sample 85 after 2879 steps.
Found uncertainty sample 86 after 3547 steps.
Found uncertainty sample 87 after 150 steps.
Found uncertainty sample 88 after 277 steps.
Found uncertainty sample 89 after 1822 steps.
Found uncertainty sample 90 after 1407 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3594 steps.
Found uncertainty sample 93 after 17 steps.
Found uncertainty sample 94 after 871 steps.
Found uncertainty sample 95 after 2313 steps.
Found uncertainty sample 96 after 164 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 778 steps.
Found uncertainty sample 99 after 193 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_034503-y5goa4ln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/y5goa4ln
Training model 3. Added 78 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2585722822445047, Training Loss Force: 3.012710108936146, time: 1.3077349662780762
Validation Loss Energy: 1.1971954705789556, Validation Loss Force: 2.653441330831402, time: 0.08651924133300781
Test Loss Energy: 11.990086275455164, Test Loss Force: 18.11778342370478, time: 17.266275882720947


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5809900145224038, Training Loss Force: 2.727213330248714, time: 1.2451038360595703
Validation Loss Energy: 1.92760738385803, Validation Loss Force: 2.5923190956125164, time: 0.08288812637329102
Test Loss Energy: 12.093867495961879, Test Loss Force: 18.870175291086593, time: 17.779711723327637


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8300716528581469, Training Loss Force: 2.715950343129151, time: 1.2473852634429932
Validation Loss Energy: 1.384487944612893, Validation Loss Force: 2.60977991935959, time: 0.08378887176513672
Test Loss Energy: 12.089998686002387, Test Loss Force: 18.67043483711651, time: 17.320866346359253


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7625345151758312, Training Loss Force: 2.691530198809324, time: 1.2971413135528564
Validation Loss Energy: 1.1114852175901395, Validation Loss Force: 2.6059891998193154, time: 0.1045694351196289
Test Loss Energy: 12.02310650098253, Test Loss Force: 18.43562064912819, time: 17.334187269210815


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.354385846723829, Training Loss Force: 2.694760008409031, time: 1.1991424560546875
Validation Loss Energy: 2.82974719787069, Validation Loss Force: 2.6100241874126726, time: 0.08461689949035645
Test Loss Energy: 12.912557453092532, Test Loss Force: 18.22268349255039, time: 17.425493717193604


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5882518040915048, Training Loss Force: 2.708537827224678, time: 1.244330644607544
Validation Loss Energy: 1.1262411678870552, Validation Loss Force: 2.598916559737211, time: 0.08857107162475586
Test Loss Energy: 12.200408993149939, Test Loss Force: 18.36608686658435, time: 17.287529945373535


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4339225356125351, Training Loss Force: 2.6997325667082315, time: 1.2420377731323242
Validation Loss Energy: 1.1342513564080885, Validation Loss Force: 2.592861072313705, time: 0.08444070816040039
Test Loss Energy: 11.719546396842244, Test Loss Force: 17.75166420151274, time: 17.415435075759888


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5098910754962724, Training Loss Force: 2.732152602691587, time: 1.1934983730316162
Validation Loss Energy: 1.173583634344773, Validation Loss Force: 2.6202943564303, time: 0.08320307731628418
Test Loss Energy: 11.789037007219532, Test Loss Force: 17.66161172530727, time: 17.43409037590027


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5597440045633322, Training Loss Force: 2.7269169385295573, time: 1.2584104537963867
Validation Loss Energy: 1.1360272541814356, Validation Loss Force: 2.6177116170066834, time: 0.08432269096374512
Test Loss Energy: 11.799535029727021, Test Loss Force: 17.667220819383548, time: 17.46866226196289


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5846444287354928, Training Loss Force: 2.7144246205032294, time: 1.3355767726898193
Validation Loss Energy: 1.549217465424541, Validation Loss Force: 2.580771919042993, time: 0.08536553382873535
Test Loss Energy: 12.09794578279476, Test Loss Force: 18.803188671032725, time: 18.18630361557007


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6200967890530318, Training Loss Force: 2.6919800159320006, time: 1.3544116020202637
Validation Loss Energy: 1.3185032832543822, Validation Loss Force: 2.5997932081647286, time: 0.08637714385986328
Test Loss Energy: 11.774100673346982, Test Loss Force: 17.980806598321813, time: 18.152660369873047


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3768760030403393, Training Loss Force: 2.697248374286627, time: 1.3257977962493896
Validation Loss Energy: 1.1581576725877605, Validation Loss Force: 2.6094051671869933, time: 0.08677363395690918
Test Loss Energy: 11.65389628596613, Test Loss Force: 17.731717970406574, time: 18.51889204978943


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.473969452677642, Training Loss Force: 2.701951986429401, time: 1.3511478900909424
Validation Loss Energy: 1.8185386921230973, Validation Loss Force: 2.5952643404057034, time: 0.08871746063232422
Test Loss Energy: 12.413911053190303, Test Loss Force: 17.758656077980067, time: 18.550777673721313


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.381234206032468, Training Loss Force: 2.7095304926392, time: 1.289264440536499
Validation Loss Energy: 1.0973115471098251, Validation Loss Force: 2.592183044764355, time: 0.08853745460510254
Test Loss Energy: 11.606731183643792, Test Loss Force: 17.702731260058265, time: 18.55564546585083


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.634980866357502, Training Loss Force: 2.691053082449356, time: 1.356708288192749
Validation Loss Energy: 1.1133770146539421, Validation Loss Force: 2.6072595272968333, time: 0.08786916732788086
Test Loss Energy: 11.831568590781675, Test Loss Force: 18.090578798650718, time: 18.727046012878418


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4922899049770146, Training Loss Force: 2.6970947834717416, time: 1.3263189792633057
Validation Loss Energy: 1.0992475439990943, Validation Loss Force: 2.5866673073505773, time: 0.08789539337158203
Test Loss Energy: 11.796723042508312, Test Loss Force: 17.83204845335044, time: 19.12533140182495


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3697005645660298, Training Loss Force: 2.695272077462933, time: 1.3101904392242432
Validation Loss Energy: 1.690091772625507, Validation Loss Force: 2.5823927277562015, time: 0.09089446067810059
Test Loss Energy: 12.14160806395863, Test Loss Force: 17.700170350371597, time: 18.601398468017578


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5951945548988133, Training Loss Force: 2.695487258563582, time: 1.330063819885254
Validation Loss Energy: 1.1062375738280594, Validation Loss Force: 2.612416544716521, time: 0.08870053291320801
Test Loss Energy: 11.846552498908189, Test Loss Force: 17.973986944197886, time: 18.725199460983276


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5902746244522528, Training Loss Force: 2.7170213689971123, time: 1.3208975791931152
Validation Loss Energy: 1.7633576037212837, Validation Loss Force: 2.6504246092423727, time: 0.08729076385498047
Test Loss Energy: 11.88323126010964, Test Loss Force: 18.08005725948348, time: 18.746260166168213


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7951576985829918, Training Loss Force: 2.7078076950951804, time: 1.2797772884368896
Validation Loss Energy: 2.258403553702622, Validation Loss Force: 2.628438035104317, time: 0.08412981033325195
Test Loss Energy: 11.883209972472967, Test Loss Force: 17.968492537555644, time: 18.561806440353394

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–„â–ƒâ–ˆâ–„â–‚â–‚â–‚â–„â–‚â–â–…â–â–‚â–‚â–„â–‚â–‚â–‚
wandb:   test_error_force â–„â–ˆâ–‡â–…â–„â–…â–‚â–â–â–ˆâ–ƒâ–â–‚â–â–ƒâ–‚â–â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–„â–ˆâ–‡â–…â–…â–†â–‚â–â–â–ˆâ–ƒâ–â–‚â–â–ƒâ–‚â–â–ƒâ–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–‚
wandb: valid_error_energy â–â–„â–‚â–â–ˆâ–â–â–â–â–ƒâ–‚â–â–„â–â–â–â–ƒâ–â–„â–†
wandb:  valid_error_force â–ˆâ–‚â–„â–ƒâ–„â–ƒâ–‚â–…â–…â–â–ƒâ–„â–‚â–‚â–„â–‚â–â–„â–ˆâ–†
wandb:         valid_loss â–†â–…â–…â–‚â–ˆâ–‚â–…â–†â–‡â–„â–‚â–‚â–„â–‚â–†â–â–„â–‚â–„â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1099
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.88321
wandb:   test_error_force 17.96849
wandb:          test_loss 8.67372
wandb: train_error_energy 1.79516
wandb:  train_error_force 2.70781
wandb:         train_loss 1.25095
wandb: valid_error_energy 2.2584
wandb:  valid_error_force 2.62844
wandb:         valid_loss 1.36757
wandb: 
wandb: ğŸš€ View run al_81_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/y5goa4ln
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_034503-y5goa4ln/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6655176281929016, Uncertainty Bias: 0.029559344053268433
0.0001449585 0.0033569336
0.67532766 3.8487043
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1033 steps.
Found uncertainty sample 2 after 697 steps.
Found uncertainty sample 3 after 643 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1368 steps.
Found uncertainty sample 6 after 185 steps.
Found uncertainty sample 7 after 2287 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1690 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 220 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 265 steps.
Found uncertainty sample 16 after 221 steps.
Found uncertainty sample 17 after 3609 steps.
Found uncertainty sample 18 after 1702 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2649 steps.
Found uncertainty sample 21 after 65 steps.
Found uncertainty sample 22 after 720 steps.
Found uncertainty sample 23 after 193 steps.
Found uncertainty sample 24 after 2246 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 727 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1565 steps.
Found uncertainty sample 29 after 1556 steps.
Found uncertainty sample 30 after 1100 steps.
Found uncertainty sample 31 after 447 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1425 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 791 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1328 steps.
Found uncertainty sample 39 after 444 steps.
Found uncertainty sample 40 after 461 steps.
Found uncertainty sample 41 after 2295 steps.
Found uncertainty sample 42 after 1749 steps.
Found uncertainty sample 43 after 1243 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1015 steps.
Found uncertainty sample 46 after 644 steps.
Found uncertainty sample 47 after 6 steps.
Found uncertainty sample 48 after 536 steps.
Found uncertainty sample 49 after 194 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 852 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1867 steps.
Found uncertainty sample 54 after 20 steps.
Found uncertainty sample 55 after 272 steps.
Found uncertainty sample 56 after 961 steps.
Found uncertainty sample 57 after 2191 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 166 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 700 steps.
Found uncertainty sample 64 after 1363 steps.
Found uncertainty sample 65 after 3620 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1449 steps.
Found uncertainty sample 68 after 17 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 392 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 219 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1489 steps.
Found uncertainty sample 75 after 656 steps.
Found uncertainty sample 76 after 1423 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 903 steps.
Found uncertainty sample 80 after 557 steps.
Found uncertainty sample 81 after 166 steps.
Found uncertainty sample 82 after 576 steps.
Found uncertainty sample 83 after 1125 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3491 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 530 steps.
Found uncertainty sample 88 after 108 steps.
Found uncertainty sample 89 after 1260 steps.
Found uncertainty sample 90 after 263 steps.
Found uncertainty sample 91 after 119 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1438 steps.
Found uncertainty sample 94 after 574 steps.
Found uncertainty sample 95 after 2203 steps.
Found uncertainty sample 96 after 1429 steps.
Found uncertainty sample 97 after 399 steps.
Found uncertainty sample 98 after 2773 steps.
Found uncertainty sample 99 after 1545 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_052303-07qc7cjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/07qc7cjp
Training model 4. Added 70 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.023316347947043, Training Loss Force: 3.2101266952134697, time: 1.3194303512573242
Validation Loss Energy: 1.2833732174396468, Validation Loss Force: 2.6916248586442455, time: 0.0909881591796875
Test Loss Energy: 11.403797341684815, Test Loss Force: 17.611847022494004, time: 17.905039310455322


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5533386831491802, Training Loss Force: 2.811559383434503, time: 1.3203530311584473
Validation Loss Energy: 1.3513204846503655, Validation Loss Force: 2.6190002033541675, time: 0.0874941349029541
Test Loss Energy: 11.26517398638777, Test Loss Force: 17.137148514365258, time: 17.664878129959106


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6676138188361116, Training Loss Force: 2.7599739895005984, time: 1.3627254962921143
Validation Loss Energy: 1.1626755182240625, Validation Loss Force: 2.6014028834206404, time: 0.08938956260681152
Test Loss Energy: 11.474953563905922, Test Loss Force: 17.41886466337255, time: 17.571557760238647


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8117065377276378, Training Loss Force: 2.776846786159872, time: 1.5148272514343262
Validation Loss Energy: 1.7112150584848007, Validation Loss Force: 2.649082582299866, time: 0.08775043487548828
Test Loss Energy: 11.76746575300768, Test Loss Force: 17.26106757336111, time: 17.537355422973633


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.688583616445883, Training Loss Force: 2.760980472094447, time: 1.272564172744751
Validation Loss Energy: 1.1274062841931223, Validation Loss Force: 2.5977533361188843, time: 0.08773422241210938
Test Loss Energy: 11.535200532178642, Test Loss Force: 17.43592760650103, time: 17.67895245552063


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4602385572578118, Training Loss Force: 2.7399070821780964, time: 1.3137214183807373
Validation Loss Energy: 1.5109616814738445, Validation Loss Force: 2.6391018831719446, time: 0.09255051612854004
Test Loss Energy: 11.8868227385624, Test Loss Force: 17.424490465795415, time: 17.56140375137329


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6227585938197897, Training Loss Force: 2.792582664250463, time: 1.3036024570465088
Validation Loss Energy: 1.2254920429743128, Validation Loss Force: 2.6296945570947874, time: 0.09217047691345215
Test Loss Energy: 11.731675775119298, Test Loss Force: 17.925608348657367, time: 17.726107120513916


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7245390310268611, Training Loss Force: 2.7575589500342907, time: 1.2806994915008545
Validation Loss Energy: 2.968922984826519, Validation Loss Force: 2.6641920198659417, time: 0.0924537181854248
Test Loss Energy: 12.296818092899734, Test Loss Force: 16.89658001471169, time: 17.694483757019043


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0639151861962244, Training Loss Force: 2.7826281498104852, time: 1.3036973476409912
Validation Loss Energy: 1.6805938202059572, Validation Loss Force: 2.662869587808277, time: 0.08704590797424316
Test Loss Energy: 11.7423680910292, Test Loss Force: 18.09608227993501, time: 18.014620542526245


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6458037160142887, Training Loss Force: 2.7691784760219855, time: 1.2841005325317383
Validation Loss Energy: 2.065041230085266, Validation Loss Force: 2.6149890413594243, time: 0.08711719512939453
Test Loss Energy: 11.916635162062548, Test Loss Force: 17.026499725064994, time: 17.705106019973755


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.61567866583672, Training Loss Force: 2.739540719216025, time: 1.3076167106628418
Validation Loss Energy: 1.7878995289780066, Validation Loss Force: 2.630623310102452, time: 0.08786797523498535
Test Loss Energy: 11.64731256787232, Test Loss Force: 17.804033587735667, time: 17.60107111930847


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.845991474835174, Training Loss Force: 2.7588944052279505, time: 1.5339577198028564
Validation Loss Energy: 1.52931585383438, Validation Loss Force: 2.6216005336403123, time: 0.08782291412353516
Test Loss Energy: 11.296889132895362, Test Loss Force: 17.520749423587276, time: 17.766053199768066


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5957919881245488, Training Loss Force: 2.773585068329471, time: 1.320389986038208
Validation Loss Energy: 1.2098733610715, Validation Loss Force: 2.615745671117287, time: 0.09416341781616211
Test Loss Energy: 11.509391051733557, Test Loss Force: 17.238349925121465, time: 18.286558628082275


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6600598101871062, Training Loss Force: 2.7743709640348104, time: 1.2992026805877686
Validation Loss Energy: 1.0972362849385016, Validation Loss Force: 2.6500979536052967, time: 0.08631348609924316
Test Loss Energy: 11.587145993653548, Test Loss Force: 17.4759321773822, time: 18.017910718917847


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6389892246983775, Training Loss Force: 2.7622925410096992, time: 1.3257627487182617
Validation Loss Energy: 1.7969217487672817, Validation Loss Force: 2.5890171348475532, time: 0.08902311325073242
Test Loss Energy: 11.95637716988065, Test Loss Force: 17.144008468107174, time: 18.250874757766724


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7223098646301165, Training Loss Force: 2.748828514088413, time: 1.337275505065918
Validation Loss Energy: 1.1190721120647642, Validation Loss Force: 2.597287734934749, time: 0.09428048133850098
Test Loss Energy: 11.628048930781713, Test Loss Force: 17.588652657100035, time: 18.266314029693604


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5195339922356876, Training Loss Force: 2.7450712791732186, time: 1.3423264026641846
Validation Loss Energy: 1.6907237076616501, Validation Loss Force: 2.604467256206899, time: 0.0880742073059082
Test Loss Energy: 11.71522469416123, Test Loss Force: 16.890291026628987, time: 18.140897035598755


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8089291267941516, Training Loss Force: 2.7717240176620614, time: 1.3363206386566162
Validation Loss Energy: 1.3243395529037223, Validation Loss Force: 2.624676930560451, time: 0.08830547332763672
Test Loss Energy: 11.596304825627076, Test Loss Force: 17.2336722222742, time: 18.213680267333984


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.57323831779841, Training Loss Force: 2.751644628831218, time: 1.336942195892334
Validation Loss Energy: 1.784445151182656, Validation Loss Force: 2.6212391416164715, time: 0.08812761306762695
Test Loss Energy: 11.382846138272077, Test Loss Force: 17.670410640002874, time: 18.3222918510437


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5393936126375858, Training Loss Force: 2.7683346743025345, time: 1.3151180744171143
Validation Loss Energy: 1.0890764627514047, Validation Loss Force: 2.608043990697937, time: 0.0895698070526123
Test Loss Energy: 11.383470106182862, Test Loss Force: 17.27207795407596, time: 18.108476638793945

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–„â–ƒâ–…â–„â–ˆâ–„â–…â–„â–â–ƒâ–ƒâ–†â–ƒâ–„â–ƒâ–‚â–‚
wandb:   test_error_force â–…â–‚â–„â–ƒâ–„â–„â–‡â–â–ˆâ–‚â–†â–…â–ƒâ–„â–‚â–…â–â–ƒâ–†â–ƒ
wandb:          test_loss â–…â–‚â–„â–ƒâ–„â–„â–‡â–‚â–ˆâ–‚â–†â–„â–ƒâ–…â–ƒâ–…â–â–ƒâ–…â–ƒ
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–â–â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–â–‚â–â–â–‚â–â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–â–ƒâ–â–ƒâ–‚â–ˆâ–ƒâ–…â–„â–ƒâ–â–â–„â–â–ƒâ–‚â–„â–
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–…â–‚â–„â–„â–†â–†â–ƒâ–„â–ƒâ–ƒâ–…â–â–‚â–‚â–ƒâ–ƒâ–‚
wandb:         valid_loss â–†â–‚â–â–…â–‚â–ƒâ–„â–ˆâ–†â–†â–„â–ƒâ–‚â–‚â–ƒâ–â–„â–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1162
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.38347
wandb:   test_error_force 17.27208
wandb:          test_loss 8.34022
wandb: train_error_energy 1.53939
wandb:  train_error_force 2.76833
wandb:         train_loss 1.25706
wandb: valid_error_energy 1.08908
wandb:  valid_error_force 2.60804
wandb:         valid_loss 1.30289
wandb: 
wandb: ğŸš€ View run al_81_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/07qc7cjp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_052303-07qc7cjp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7135140895843506, Uncertainty Bias: 0.01856134831905365
0.00016784668 0.011176109
0.5120072 3.4644969
(48745, 22, 3)
Found uncertainty sample 0 after 2932 steps.
Found uncertainty sample 1 after 2270 steps.
Found uncertainty sample 2 after 1965 steps.
Found uncertainty sample 3 after 398 steps.
Found uncertainty sample 4 after 668 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2422 steps.
Found uncertainty sample 8 after 276 steps.
Found uncertainty sample 9 after 1466 steps.
Found uncertainty sample 10 after 715 steps.
Found uncertainty sample 11 after 555 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1323 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1529 steps.
Found uncertainty sample 17 after 3427 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2305 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 136 steps.
Found uncertainty sample 22 after 1515 steps.
Found uncertainty sample 23 after 174 steps.
Found uncertainty sample 24 after 1901 steps.
Found uncertainty sample 25 after 3347 steps.
Found uncertainty sample 26 after 2227 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3523 steps.
Found uncertainty sample 29 after 2073 steps.
Found uncertainty sample 30 after 1323 steps.
Found uncertainty sample 31 after 2614 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 47 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2511 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 108 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3945 steps.
Found uncertainty sample 43 after 10 steps.
Found uncertainty sample 44 after 8 steps.
Found uncertainty sample 45 after 694 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1996 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1421 steps.
Found uncertainty sample 52 after 237 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 240 steps.
Found uncertainty sample 55 after 842 steps.
Found uncertainty sample 56 after 2232 steps.
Found uncertainty sample 57 after 295 steps.
Did not find any uncertainty samples for sample 58.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 476 steps.
Found uncertainty sample 61 after 285 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1250 steps.
Found uncertainty sample 64 after 153 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 523 steps.
Found uncertainty sample 68 after 189 steps.
Found uncertainty sample 69 after 764 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1080 steps.
Found uncertainty sample 72 after 1617 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 9 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 597 steps.
Found uncertainty sample 77 after 378 steps.
Found uncertainty sample 78 after 57 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 884 steps.
Found uncertainty sample 81 after 1114 steps.
Found uncertainty sample 82 after 2244 steps.
Found uncertainty sample 83 after 353 steps.
Found uncertainty sample 84 after 85 steps.
Found uncertainty sample 85 after 3697 steps.
Found uncertainty sample 86 after 1695 steps.
Found uncertainty sample 87 after 937 steps.
Found uncertainty sample 88 after 996 steps.
Found uncertainty sample 89 after 651 steps.
Found uncertainty sample 90 after 305 steps.
Found uncertainty sample 91 after 1521 steps.
Found uncertainty sample 92 after 1066 steps.
Found uncertainty sample 93 after 1673 steps.
Found uncertainty sample 94 after 71 steps.
Found uncertainty sample 95 after 832 steps.
Found uncertainty sample 96 after 1453 steps.
Found uncertainty sample 97 after 1108 steps.
Found uncertainty sample 98 after 103 steps.
Found uncertainty sample 99 after 933 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_070249-5g6gj6s0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/5g6gj6s0
Training model 5. Added 72 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4925494503305297, Training Loss Force: 3.115465192400445, time: 1.4234545230865479
Validation Loss Energy: 1.2191433002856198, Validation Loss Force: 2.737401849671518, time: 0.09014177322387695
Test Loss Energy: 11.036376174162347, Test Loss Force: 16.873269049960133, time: 18.041638612747192


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5612518021190973, Training Loss Force: 2.864022299807042, time: 1.4421792030334473
Validation Loss Energy: 1.54237484257018, Validation Loss Force: 2.6305398091727294, time: 0.0917809009552002
Test Loss Energy: 11.077601279736264, Test Loss Force: 17.026664089868902, time: 18.12526273727417


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8394115836730625, Training Loss Force: 2.826522657454926, time: 1.4012365341186523
Validation Loss Energy: 1.2780514248519728, Validation Loss Force: 2.618913807725548, time: 0.0919046401977539
Test Loss Energy: 11.333964067973898, Test Loss Force: 17.029168649106154, time: 18.160649061203003


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5357714206184654, Training Loss Force: 2.812041455191492, time: 1.4485747814178467
Validation Loss Energy: 1.3969345931973915, Validation Loss Force: 2.622092855121959, time: 0.09374642372131348
Test Loss Energy: 11.82901099665025, Test Loss Force: 16.944324649043416, time: 18.02660870552063


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6629003528771114, Training Loss Force: 2.8143943144145314, time: 1.4531877040863037
Validation Loss Energy: 1.1095045755371118, Validation Loss Force: 2.6582017745021926, time: 0.0949242115020752
Test Loss Energy: 11.25289709621348, Test Loss Force: 16.908854330784024, time: 18.16358256340027


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6588349366885433, Training Loss Force: 2.815421926813523, time: 1.407832145690918
Validation Loss Energy: 1.4658827582190557, Validation Loss Force: 2.6518708453451736, time: 0.09071779251098633
Test Loss Energy: 11.354455010764578, Test Loss Force: 17.1906265271309, time: 18.059717416763306


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.648306097491664, Training Loss Force: 2.807537086747984, time: 1.6599175930023193
Validation Loss Energy: 1.2030022365664603, Validation Loss Force: 2.6035719035711233, time: 0.09070873260498047
Test Loss Energy: 11.415417350883779, Test Loss Force: 17.28434370379811, time: 18.468409299850464


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0033830016848055, Training Loss Force: 2.826040390341639, time: 1.450216293334961
Validation Loss Energy: 1.0988917187039018, Validation Loss Force: 2.631962665015208, time: 0.0930635929107666
Test Loss Energy: 11.225239056156344, Test Loss Force: 16.79783612054679, time: 17.93337368965149


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7189462525575505, Training Loss Force: 2.8180964801483106, time: 1.481727123260498
Validation Loss Energy: 1.436119130155753, Validation Loss Force: 2.646920910231199, time: 0.09268760681152344
Test Loss Energy: 11.125461958501425, Test Loss Force: 16.823781930467923, time: 18.29197120666504


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8574767186358874, Training Loss Force: 2.8331720434568797, time: 1.4705555438995361
Validation Loss Energy: 1.2043463788658535, Validation Loss Force: 2.6341230010689993, time: 0.09309601783752441
Test Loss Energy: 11.177423349563817, Test Loss Force: 16.794034628949404, time: 18.376256942749023


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5555094874304078, Training Loss Force: 2.822211012011951, time: 1.4746391773223877
Validation Loss Energy: 1.1330564024364669, Validation Loss Force: 2.6196134341820527, time: 0.09695816040039062
Test Loss Energy: 11.14716410486525, Test Loss Force: 16.7858366225012, time: 18.513452529907227


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5248781748000773, Training Loss Force: 2.816325678072726, time: 1.4993743896484375
Validation Loss Energy: 1.422449582621819, Validation Loss Force: 2.6388097412524876, time: 0.09340095520019531
Test Loss Energy: 11.337749322210733, Test Loss Force: 16.456421314963457, time: 18.631146907806396


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.631285462098763, Training Loss Force: 2.8260950641811613, time: 1.5164029598236084
Validation Loss Energy: 1.128939695266554, Validation Loss Force: 2.6191761119794505, time: 0.09741878509521484
Test Loss Energy: 11.069697289825246, Test Loss Force: 16.502059718346434, time: 18.809932470321655


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.770699152481254, Training Loss Force: 2.8229934999380686, time: 1.448805332183838
Validation Loss Energy: 1.2191353955309394, Validation Loss Force: 2.6424537218255955, time: 0.09754443168640137
Test Loss Energy: 11.264583775585828, Test Loss Force: 17.4276916273857, time: 18.928728342056274


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6026294132051664, Training Loss Force: 2.8206651000642884, time: 1.4513850212097168
Validation Loss Energy: 1.3506670620416403, Validation Loss Force: 2.6320931491347217, time: 0.09499621391296387
Test Loss Energy: 11.086586420449512, Test Loss Force: 16.95813357289012, time: 19.040735960006714


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.871349624476805, Training Loss Force: 2.8077464128735516, time: 1.5490953922271729
Validation Loss Energy: 1.1550338471395396, Validation Loss Force: 2.6313592316297436, time: 0.09898519515991211
Test Loss Energy: 11.290068527472886, Test Loss Force: 16.80537898074055, time: 19.05850315093994


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6055021934650169, Training Loss Force: 2.8010330865699262, time: 1.4355037212371826
Validation Loss Energy: 1.6435295388551203, Validation Loss Force: 2.6057885749188343, time: 0.09363842010498047
Test Loss Energy: 10.999237301562143, Test Loss Force: 16.573247906996762, time: 18.99286437034607


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5989758178925266, Training Loss Force: 2.7991248234082557, time: 1.4376204013824463
Validation Loss Energy: 1.856793919400929, Validation Loss Force: 2.6304019769714, time: 0.09649491310119629
Test Loss Energy: 11.071109767653397, Test Loss Force: 16.580787405002997, time: 18.89543890953064


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8954303391281928, Training Loss Force: 2.8075129185814527, time: 1.5035157203674316
Validation Loss Energy: 1.5408927567348847, Validation Loss Force: 2.6077952692619353, time: 0.09783720970153809
Test Loss Energy: 11.356770984390725, Test Loss Force: 16.746749802906592, time: 18.49863362312317


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9163565542291434, Training Loss Force: 2.8140230393062913, time: 1.4863061904907227
Validation Loss Energy: 1.5728491192127112, Validation Loss Force: 2.62675755106, time: 0.09752702713012695
Test Loss Energy: 11.102350649864688, Test Loss Force: 16.270418078380242, time: 18.89128589630127

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–„â–ˆâ–ƒâ–„â–…â–ƒâ–‚â–ƒâ–‚â–„â–‚â–ƒâ–‚â–ƒâ–â–‚â–„â–‚
wandb:   test_error_force â–…â–†â–†â–…â–…â–‡â–‡â–„â–„â–„â–„â–‚â–‚â–ˆâ–…â–„â–ƒâ–ƒâ–„â–
wandb:          test_loss â–…â–†â–†â–†â–…â–‡â–ˆâ–…â–…â–…â–„â–ƒâ–ƒâ–ˆâ–…â–…â–ƒâ–ƒâ–„â–
wandb: train_error_energy â–ˆâ–â–‚â–â–â–â–â–ƒâ–‚â–‚â–â–â–â–‚â–â–‚â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–â–‚
wandb: valid_error_energy â–‚â–…â–ƒâ–„â–â–„â–‚â–â–„â–‚â–â–„â–â–‚â–ƒâ–‚â–†â–ˆâ–…â–…
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–„â–„â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–‚
wandb:         valid_loss â–‡â–ƒâ–ƒâ–‚â–‡â–ƒâ–‚â–„â–†â–â–â–„â–ˆâ–‡â–„â–„â–†â–ˆâ–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1226
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.10235
wandb:   test_error_force 16.27042
wandb:          test_loss 7.92786
wandb: train_error_energy 1.91636
wandb:  train_error_force 2.81402
wandb:         train_loss 1.3318
wandb: valid_error_energy 1.57285
wandb:  valid_error_force 2.62676
wandb:         valid_loss 1.3509
wandb: 
wandb: ğŸš€ View run al_81_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/5g6gj6s0
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_070249-5g6gj6s0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6901485919952393, Uncertainty Bias: 0.02372974157333374
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:1004: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
9.918213e-05 0.0048234463
0.69157624 3.8319695
(48745, 22, 3)
Found uncertainty sample 0 after 691 steps.
Found uncertainty sample 1 after 904 steps.
Found uncertainty sample 2 after 1559 steps.
Found uncertainty sample 3 after 2382 steps.
Found uncertainty sample 4 after 1779 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2473 steps.
Found uncertainty sample 7 after 1814 steps.
Found uncertainty sample 8 after 1252 steps.
Found uncertainty sample 9 after 411 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 484 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 780 steps.
Found uncertainty sample 17 after 67 steps.
Found uncertainty sample 18 after 2380 steps.
Found uncertainty sample 19 after 3179 steps.
Found uncertainty sample 20 after 1095 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3183 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 283 steps.
Found uncertainty sample 25 after 1763 steps.
Found uncertainty sample 26 after 1685 steps.
Found uncertainty sample 27 after 2869 steps.
Found uncertainty sample 28 after 3730 steps.
Found uncertainty sample 29 after 1247 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2161 steps.
Found uncertainty sample 32 after 9 steps.
Found uncertainty sample 33 after 2253 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3817 steps.
Found uncertainty sample 36 after 1335 steps.
Found uncertainty sample 37 after 3286 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3621 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3126 steps.
Found uncertainty sample 45 after 52 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 849 steps.
Found uncertainty sample 48 after 256 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3408 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1011 steps.
Found uncertainty sample 53 after 3778 steps.
Found uncertainty sample 54 after 1072 steps.
Found uncertainty sample 55 after 2181 steps.
Found uncertainty sample 56 after 1553 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 302 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 474 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1682 steps.
Found uncertainty sample 64 after 869 steps.
Found uncertainty sample 65 after 2238 steps.
Found uncertainty sample 66 after 1647 steps.
Found uncertainty sample 67 after 436 steps.
Found uncertainty sample 68 after 1734 steps.
Found uncertainty sample 69 after 606 steps.
Found uncertainty sample 70 after 301 steps.
Found uncertainty sample 71 after 10 steps.
Found uncertainty sample 72 after 3718 steps.
Found uncertainty sample 73 after 1369 steps.
Found uncertainty sample 74 after 478 steps.
Found uncertainty sample 75 after 300 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3730 steps.
Found uncertainty sample 78 after 866 steps.
Found uncertainty sample 79 after 472 steps.
Found uncertainty sample 80 after 1880 steps.
Found uncertainty sample 81 after 597 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2232 steps.
Found uncertainty sample 84 after 55 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1989 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1933 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1005 steps.
Found uncertainty sample 91 after 82 steps.
Found uncertainty sample 92 after 2349 steps.
Found uncertainty sample 93 after 3006 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 729 steps.
Found uncertainty sample 96 after 2163 steps.
Found uncertainty sample 97 after 3457 steps.
Found uncertainty sample 98 after 557 steps.
Found uncertainty sample 99 after 1134 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_085251-vb0saaue
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/vb0saaue
Training model 6. Added 74 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0185900044754113, Training Loss Force: 3.1896067746325314, time: 1.4627325534820557
Validation Loss Energy: 1.838662972859186, Validation Loss Force: 3.166768974366277, time: 0.12876582145690918
Test Loss Energy: 11.068834093645243, Test Loss Force: 16.87900341233519, time: 17.39943790435791


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8375392594368745, Training Loss Force: 2.8954821819451584, time: 1.4443790912628174
Validation Loss Energy: 1.649316542955924, Validation Loss Force: 2.6056063202228925, time: 0.12233901023864746
Test Loss Energy: 11.170831951133186, Test Loss Force: 16.555521894789152, time: 17.555959224700928


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7404329407642984, Training Loss Force: 2.865910361627254, time: 1.4192278385162354
Validation Loss Energy: 1.5893468989036468, Validation Loss Force: 2.7872576941138956, time: 0.11858415603637695
Test Loss Energy: 11.030767201330006, Test Loss Force: 16.730866511949348, time: 17.390379190444946


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7193583692116314, Training Loss Force: 2.891412615462725, time: 1.652259349822998
Validation Loss Energy: 1.7767941836612908, Validation Loss Force: 2.4652159844106003, time: 0.12601351737976074
Test Loss Energy: 11.171023092193346, Test Loss Force: 16.55285374484387, time: 18.168633460998535


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5712126652765241, Training Loss Force: 2.8738302523786583, time: 1.5316648483276367
Validation Loss Energy: 0.8312897204810537, Validation Loss Force: 2.8159223386074714, time: 0.13259315490722656
Test Loss Energy: 11.199005720911659, Test Loss Force: 16.41976836473002, time: 17.57369613647461


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5590222206259732, Training Loss Force: 2.8775033863170187, time: 1.4212260246276855
Validation Loss Energy: 1.016711551020052, Validation Loss Force: 2.198535001442596, time: 0.11694025993347168
Test Loss Energy: 10.908497628734905, Test Loss Force: 15.96401473872916, time: 17.850311517715454


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6078030727413595, Training Loss Force: 2.8872102621359517, time: 1.4575467109680176
Validation Loss Energy: 1.1134584002267787, Validation Loss Force: 3.387301053166023, time: 0.1267249584197998
Test Loss Energy: 11.131747906159351, Test Loss Force: 16.42443902143949, time: 17.51356840133667


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7460284480418657, Training Loss Force: 2.8807336041693548, time: 1.465125560760498
Validation Loss Energy: 2.1613728013348377, Validation Loss Force: 2.436105444952304, time: 0.1391773223876953
Test Loss Energy: 10.870424748834674, Test Loss Force: 16.493472346334308, time: 17.553598880767822


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6069081247117145, Training Loss Force: 2.8863440682963826, time: 1.4949951171875
Validation Loss Energy: 0.8346983954342028, Validation Loss Force: 2.587235781680131, time: 0.12964344024658203
Test Loss Energy: 10.99959134783578, Test Loss Force: 16.507969567324626, time: 18.20476722717285


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5339377266939909, Training Loss Force: 2.8877926451406934, time: 1.6036460399627686
Validation Loss Energy: 0.9714355099038305, Validation Loss Force: 2.416021244662482, time: 0.12960076332092285
Test Loss Energy: 11.093415466315006, Test Loss Force: 15.847297937740292, time: 18.352488040924072


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.918680213923815, Training Loss Force: 2.8836810267754083, time: 1.4351389408111572
Validation Loss Energy: 0.8419310511312994, Validation Loss Force: 2.669726016149685, time: 0.1201472282409668
Test Loss Energy: 10.942200830662532, Test Loss Force: 16.29239347126291, time: 17.996101140975952


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5875373875934355, Training Loss Force: 2.862522662379199, time: 1.4371061325073242
Validation Loss Energy: 1.130543692459245, Validation Loss Force: 2.211110853799019, time: 0.12019872665405273
Test Loss Energy: 11.175391963427465, Test Loss Force: 16.599951561446698, time: 18.13050079345703


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6645819575432448, Training Loss Force: 2.8625896477754393, time: 1.4932942390441895
Validation Loss Energy: 1.2524556621948602, Validation Loss Force: 2.584215942723058, time: 0.12261199951171875
Test Loss Energy: 10.90733346780771, Test Loss Force: 16.272581172733503, time: 18.46528196334839


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7726561993682937, Training Loss Force: 2.8546143667162465, time: 1.4766595363616943
Validation Loss Energy: 1.0644303561680308, Validation Loss Force: 2.3561128902926214, time: 0.1278846263885498
Test Loss Energy: 10.741657783825962, Test Loss Force: 16.167604286529965, time: 18.425156593322754


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4298275604857542, Training Loss Force: 2.84970324120512, time: 1.4789047241210938
Validation Loss Energy: 1.2340131458506776, Validation Loss Force: 2.249008752764923, time: 0.12869954109191895
Test Loss Energy: 10.919744299885217, Test Loss Force: 16.102601492348168, time: 18.303898334503174


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7658667292683519, Training Loss Force: 2.8836219325564607, time: 1.4592208862304688
Validation Loss Energy: 0.9021246725107368, Validation Loss Force: 2.5470120478177245, time: 0.12867426872253418
Test Loss Energy: 11.299364472344797, Test Loss Force: 16.079816474450904, time: 18.528968811035156


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5262427996669081, Training Loss Force: 2.873043480821774, time: 1.4515676498413086
Validation Loss Energy: 1.6112265918516573, Validation Loss Force: 2.4401946524826945, time: 0.13469290733337402
Test Loss Energy: 10.985622106867243, Test Loss Force: 16.10033228623751, time: 18.411131381988525


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.844712681746808, Training Loss Force: 2.8559123540464526, time: 1.493196964263916
Validation Loss Energy: 1.5832936938388864, Validation Loss Force: 2.6308723655421726, time: 0.13113141059875488
Test Loss Energy: 11.282599896545408, Test Loss Force: 16.94472265556918, time: 18.45320463180542


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7317157559811258, Training Loss Force: 2.8572540714245367, time: 1.485757827758789
Validation Loss Energy: 1.503627405145275, Validation Loss Force: 2.9753646918836365, time: 0.13074278831481934
Test Loss Energy: 10.994720512729927, Test Loss Force: 15.810338660047252, time: 18.875319004058838


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4313781890435733, Training Loss Force: 2.865087104916166, time: 1.4827089309692383
Validation Loss Energy: 1.3567865668446006, Validation Loss Force: 2.9816250349213966, time: 0.12356209754943848
Test Loss Energy: 11.057847630627764, Test Loss Force: 16.305595168188013, time: 18.577382802963257

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–†â–…â–†â–‡â–ƒâ–†â–ƒâ–„â–…â–„â–†â–ƒâ–â–ƒâ–ˆâ–„â–ˆâ–„â–…
wandb:   test_error_force â–ˆâ–†â–‡â–†â–…â–‚â–…â–…â–…â–â–„â–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–â–„
wandb:          test_loss â–ˆâ–†â–‡â–†â–…â–‚â–…â–…â–†â–‚â–„â–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–â–„
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–
wandb: valid_error_energy â–†â–…â–…â–†â–â–‚â–‚â–ˆâ–â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–â–…â–…â–…â–„
wandb:  valid_error_force â–‡â–ƒâ–„â–ƒâ–…â–â–ˆâ–‚â–ƒâ–‚â–„â–â–ƒâ–‚â–â–ƒâ–‚â–„â–†â–†
wandb:         valid_loss â–‡â–ƒâ–„â–ƒâ–…â–â–ˆâ–‚â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–„â–‚â–ƒâ–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1292
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.05785
wandb:   test_error_force 16.3056
wandb:          test_loss 7.93323
wandb: train_error_energy 1.43138
wandb:  train_error_force 2.86509
wandb:         train_loss 1.28475
wandb: valid_error_energy 1.35679
wandb:  valid_error_force 2.98163
wandb:         valid_loss 1.51817
wandb: 
wandb: ğŸš€ View run al_81_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/vb0saaue
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_085251-vb0saaue/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.701116144657135, Uncertainty Bias: 0.021909266710281372
0.00030517578 0.00084781647
0.3547379 4.4112887
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1037 steps.
Found uncertainty sample 3 after 109 steps.
Found uncertainty sample 4 after 10 steps.
Found uncertainty sample 5 after 2671 steps.
Found uncertainty sample 6 after 1558 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1061 steps.
Found uncertainty sample 10 after 896 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 563 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 390 steps.
Found uncertainty sample 15 after 797 steps.
Found uncertainty sample 16 after 1866 steps.
Found uncertainty sample 17 after 1024 steps.
Found uncertainty sample 18 after 3563 steps.
Found uncertainty sample 19 after 2374 steps.
Found uncertainty sample 20 after 547 steps.
Found uncertainty sample 21 after 734 steps.
Found uncertainty sample 22 after 55 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 802 steps.
Found uncertainty sample 25 after 344 steps.
Found uncertainty sample 26 after 786 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 847 steps.
Found uncertainty sample 29 after 3748 steps.
Found uncertainty sample 30 after 223 steps.
Found uncertainty sample 31 after 637 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 429 steps.
Found uncertainty sample 34 after 3130 steps.
Found uncertainty sample 35 after 1011 steps.
Found uncertainty sample 36 after 1690 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 494 steps.
Found uncertainty sample 40 after 1024 steps.
Found uncertainty sample 41 after 729 steps.
Found uncertainty sample 42 after 3982 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1854 steps.
Found uncertainty sample 45 after 1904 steps.
Found uncertainty sample 46 after 284 steps.
Found uncertainty sample 47 after 729 steps.
Found uncertainty sample 48 after 1141 steps.
Found uncertainty sample 49 after 802 steps.
Found uncertainty sample 50 after 2897 steps.
Found uncertainty sample 51 after 700 steps.
Found uncertainty sample 52 after 69 steps.
Found uncertainty sample 53 after 1227 steps.
Found uncertainty sample 54 after 1061 steps.
Found uncertainty sample 55 after 1732 steps.
Found uncertainty sample 56 after 104 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 238 steps.
Found uncertainty sample 59 after 284 steps.
Found uncertainty sample 60 after 731 steps.
Found uncertainty sample 61 after 1599 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1981 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 153 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1089 steps.
Found uncertainty sample 69 after 57 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 279 steps.
Found uncertainty sample 72 after 344 steps.
Found uncertainty sample 73 after 1448 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 278 steps.
Found uncertainty sample 76 after 3954 steps.
Found uncertainty sample 77 after 268 steps.
Found uncertainty sample 78 after 3954 steps.
Found uncertainty sample 79 after 628 steps.
Found uncertainty sample 80 after 997 steps.
Found uncertainty sample 81 after 3005 steps.
Found uncertainty sample 82 after 1620 steps.
Found uncertainty sample 83 after 685 steps.
Found uncertainty sample 84 after 2615 steps.
Found uncertainty sample 85 after 232 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 103 steps.
Found uncertainty sample 89 after 3147 steps.
Found uncertainty sample 90 after 193 steps.
Found uncertainty sample 91 after 874 steps.
Found uncertainty sample 92 after 324 steps.
Found uncertainty sample 93 after 1704 steps.
Found uncertainty sample 94 after 1803 steps.
Found uncertainty sample 95 after 2385 steps.
Found uncertainty sample 96 after 3808 steps.
Found uncertainty sample 97 after 2766 steps.
Found uncertainty sample 98 after 323 steps.
Found uncertainty sample 99 after 893 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_102635-co8qmiwr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/co8qmiwr
Training model 7. Added 79 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.730562056786651, Training Loss Force: 3.1769210614179832, time: 1.5785470008850098
Validation Loss Energy: 1.3839509223002016, Validation Loss Force: 2.573905025251726, time: 0.12925410270690918
Test Loss Energy: 10.782213459677498, Test Loss Force: 16.412292897510017, time: 17.705939769744873


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4868083112875892, Training Loss Force: 2.9323813934039866, time: 1.5536677837371826
Validation Loss Energy: 1.2711322594786991, Validation Loss Force: 2.758985169986298, time: 0.12709975242614746
Test Loss Energy: 10.81039014397359, Test Loss Force: 15.88931113820426, time: 17.899009704589844


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.738607710660616, Training Loss Force: 2.9345939272482653, time: 1.5075252056121826
Validation Loss Energy: 1.6898396554850303, Validation Loss Force: 2.5578334343060964, time: 0.12328219413757324
Test Loss Energy: 11.273551284633307, Test Loss Force: 16.061577796262874, time: 17.81099033355713


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9423885475519578, Training Loss Force: 2.955049930639088, time: 1.5304007530212402
Validation Loss Energy: 2.024579240236717, Validation Loss Force: 2.9471450516781976, time: 0.12502813339233398
Test Loss Energy: 11.049815569817822, Test Loss Force: 16.744543154002066, time: 17.71877670288086


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7309019548780604, Training Loss Force: 2.9306128204098694, time: 1.5287258625030518
Validation Loss Energy: 2.318042923744202, Validation Loss Force: 2.950063798843019, time: 0.12687039375305176
Test Loss Energy: 10.882676354985735, Test Loss Force: 16.331148539477837, time: 17.805498123168945


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9369648851246097, Training Loss Force: 2.9227644113800575, time: 1.5597453117370605
Validation Loss Energy: 3.634325861609965, Validation Loss Force: 2.641888142194939, time: 0.12539410591125488
Test Loss Energy: 11.039347214768055, Test Loss Force: 16.14801381310218, time: 17.778459310531616


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9830393427120208, Training Loss Force: 2.9286995487193654, time: 1.5323283672332764
Validation Loss Energy: 1.3350146457632195, Validation Loss Force: 2.8216894694870014, time: 0.13614153861999512
Test Loss Energy: 10.915178556483497, Test Loss Force: 16.495186861452122, time: 17.886375427246094


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6829656194514486, Training Loss Force: 2.896655972433267, time: 1.5699448585510254
Validation Loss Energy: 1.4197006206807676, Validation Loss Force: 2.7331154686124077, time: 0.12703752517700195
Test Loss Energy: 10.729048489420046, Test Loss Force: 16.106329053125876, time: 17.85551691055298


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6592254351680475, Training Loss Force: 2.9132586862538097, time: 1.5592873096466064
Validation Loss Energy: 1.9826034341995777, Validation Loss Force: 2.724813583510209, time: 0.1251072883605957
Test Loss Energy: 11.140706419839654, Test Loss Force: 16.13995863667012, time: 17.838622331619263


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7253033508827087, Training Loss Force: 2.902038077289374, time: 1.5432419776916504
Validation Loss Energy: 1.5773982498640158, Validation Loss Force: 2.5411417097890574, time: 0.13174152374267578
Test Loss Energy: 10.797209105149356, Test Loss Force: 15.58920555350488, time: 18.313344955444336


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8480333617498803, Training Loss Force: 2.9176488570266828, time: 1.5465843677520752
Validation Loss Energy: 1.765587913554183, Validation Loss Force: 2.585651268037709, time: 0.12874269485473633
Test Loss Energy: 10.737905368042014, Test Loss Force: 15.804588787775241, time: 17.8502299785614


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7255135816265776, Training Loss Force: 2.8990511622957853, time: 1.569399356842041
Validation Loss Energy: 1.3120294005056776, Validation Loss Force: 2.6510479715163977, time: 0.12392067909240723
Test Loss Energy: 10.719020417722783, Test Loss Force: 15.93530123759387, time: 17.98904824256897


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4989726335192841, Training Loss Force: 2.898807738314116, time: 1.5652341842651367
Validation Loss Energy: 1.134167911145652, Validation Loss Force: 2.430628785973637, time: 0.13026690483093262
Test Loss Energy: 10.824993663250435, Test Loss Force: 15.761800852569971, time: 18.14094567298889


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8138852357985729, Training Loss Force: 2.907627994598858, time: 1.5394060611724854
Validation Loss Energy: 1.1358503713786392, Validation Loss Force: 2.7925109046046237, time: 0.1288316249847412
Test Loss Energy: 10.610234700000689, Test Loss Force: 15.601151163285543, time: 18.984086751937866


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7264058893912415, Training Loss Force: 2.915904321943622, time: 1.6501314640045166
Validation Loss Energy: 1.4333190099784245, Validation Loss Force: 2.8480680811939094, time: 0.12593603134155273
Test Loss Energy: 10.755989441562733, Test Loss Force: 15.77001990883021, time: 18.98535919189453


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9200609323143285, Training Loss Force: 2.9059628540122016, time: 1.657364845275879
Validation Loss Energy: 1.211071710747597, Validation Loss Force: 2.4801970532140487, time: 0.14046669006347656
Test Loss Energy: 10.715960533293654, Test Loss Force: 15.871616677398565, time: 19.128607988357544


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4775128712779084, Training Loss Force: 2.900874170128553, time: 1.6709787845611572
Validation Loss Energy: 1.9577931926220118, Validation Loss Force: 2.63227451315408, time: 0.1370861530303955
Test Loss Energy: 10.770846687085228, Test Loss Force: 16.22804126269839, time: 19.24104905128479


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7355667181346803, Training Loss Force: 2.9068144443932744, time: 1.643068552017212
Validation Loss Energy: 1.110226969913788, Validation Loss Force: 2.7539606407084376, time: 0.12391304969787598
Test Loss Energy: 10.775660640133658, Test Loss Force: 15.910561515684561, time: 19.012521505355835


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.49967510548034, Training Loss Force: 2.896186627300469, time: 1.6668360233306885
Validation Loss Energy: 1.5121227340679981, Validation Loss Force: 2.8794855843385907, time: 0.12907910346984863
Test Loss Energy: 10.599542388754017, Test Loss Force: 15.567317768690161, time: 19.487463235855103


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5781489089817562, Training Loss Force: 2.897028383990655, time: 1.674088478088379
Validation Loss Energy: 1.4747994328331608, Validation Loss Force: 2.9314517756114986, time: 0.13493609428405762
Test Loss Energy: 10.685557292771904, Test Loss Force: 15.850037808135088, time: 19.108328580856323

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.039 MB uploadedwandb: - 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: \ 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: | 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.7%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ˆâ–†â–„â–†â–„â–‚â–‡â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–â–‚
wandb:   test_error_force â–†â–ƒâ–„â–ˆâ–†â–„â–‡â–„â–„â–â–‚â–ƒâ–‚â–â–‚â–ƒâ–…â–ƒâ–â–ƒ
wandb:          test_loss â–†â–ƒâ–„â–ˆâ–†â–…â–‡â–„â–…â–â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–…â–ƒâ–â–‚
wandb: train_error_energy â–ˆâ–â–‚â–„â–‚â–„â–„â–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–‚â–â–ƒâ–„â–„â–ˆâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–â–‚â–â–ƒâ–â–‚â–‚
wandb:  valid_error_force â–ƒâ–…â–ƒâ–ˆâ–ˆâ–„â–†â–…â–…â–‚â–ƒâ–„â–â–†â–‡â–‚â–„â–…â–‡â–ˆ
wandb:         valid_loss â–„â–„â–ƒâ–†â–ˆâ–…â–„â–…â–„â–ƒâ–ƒâ–ƒâ–â–„â–†â–â–ƒâ–„â–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1363
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.68556
wandb:   test_error_force 15.85004
wandb:          test_loss 7.69639
wandb: train_error_energy 1.57815
wandb:  train_error_force 2.89703
wandb:         train_loss 1.31604
wandb: valid_error_energy 1.4748
wandb:  valid_error_force 2.93145
wandb:         valid_loss 1.48012
wandb: 
wandb: ğŸš€ View run al_81_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/co8qmiwr
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_102635-co8qmiwr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6881451606750488, Uncertainty Bias: 0.021305590867996216
3.8146973e-06 0.018044472
0.5104404 3.6409712
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 823 steps.
Found uncertainty sample 4 after 250 steps.
Found uncertainty sample 5 after 25 steps.
Found uncertainty sample 6 after 1448 steps.
Found uncertainty sample 7 after 3504 steps.
Found uncertainty sample 8 after 634 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2764 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3461 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 15 steps.
Found uncertainty sample 16 after 1191 steps.
Found uncertainty sample 17 after 2440 steps.
Found uncertainty sample 18 after 174 steps.
Found uncertainty sample 19 after 588 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 289 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 961 steps.
Found uncertainty sample 24 after 380 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1594 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 32 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3652 steps.
Found uncertainty sample 32 after 1144 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3490 steps.
Found uncertainty sample 37 after 1107 steps.
Found uncertainty sample 38 after 2291 steps.
Found uncertainty sample 39 after 750 steps.
Found uncertainty sample 40 after 2003 steps.
Found uncertainty sample 41 after 506 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1178 steps.
Found uncertainty sample 44 after 1988 steps.
Found uncertainty sample 45 after 3868 steps.
Found uncertainty sample 46 after 811 steps.
Found uncertainty sample 47 after 3405 steps.
Found uncertainty sample 48 after 1901 steps.
Found uncertainty sample 49 after 3825 steps.
Found uncertainty sample 50 after 360 steps.
Found uncertainty sample 51 after 395 steps.
Found uncertainty sample 52 after 2489 steps.
Found uncertainty sample 53 after 204 steps.
Found uncertainty sample 54 after 805 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1826 steps.
Found uncertainty sample 60 after 2578 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1929 steps.
Found uncertainty sample 63 after 1573 steps.
Found uncertainty sample 64 after 3002 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 6 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1021 steps.
Found uncertainty sample 73 after 2157 steps.
Found uncertainty sample 74 after 2102 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1940 steps.
Found uncertainty sample 81 after 960 steps.
Found uncertainty sample 82 after 3047 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2122 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1606 steps.
Found uncertainty sample 88 after 1295 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1597 steps.
Found uncertainty sample 91 after 3981 steps.
Found uncertainty sample 92 after 2765 steps.
Found uncertainty sample 93 after 1562 steps.
Found uncertainty sample 94 after 1408 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 4 steps.
Found uncertainty sample 97 after 13 steps.
Found uncertainty sample 98 after 1431 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_123148-q7jc3ymf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/q7jc3ymf
Training model 8. Added 61 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.6305728421405274, Training Loss Force: 3.160798497074483, time: 1.668825387954712
Validation Loss Energy: 1.049498469412189, Validation Loss Force: 2.589541520686213, time: 0.1291038990020752
Test Loss Energy: 10.520200610903967, Test Loss Force: 15.537993706425123, time: 18.774603366851807


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5594841756481015, Training Loss Force: 2.963569503945278, time: 1.7332580089569092
Validation Loss Energy: 1.3292615987071696, Validation Loss Force: 2.5122179897441947, time: 0.12753796577453613
Test Loss Energy: 10.866156491411912, Test Loss Force: 15.890235152206282, time: 18.8514723777771


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.693851311063047, Training Loss Force: 2.9410847447047326, time: 1.7229416370391846
Validation Loss Energy: 1.3824113321579707, Validation Loss Force: 2.656347385854906, time: 0.13261079788208008
Test Loss Energy: 10.453368241112067, Test Loss Force: 15.501173313657173, time: 18.815097093582153


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6527880897794764, Training Loss Force: 2.948553681436353, time: 1.688962459564209
Validation Loss Energy: 1.8688409325357735, Validation Loss Force: 2.6650158957058747, time: 0.13526368141174316
Test Loss Energy: 10.332063681621204, Test Loss Force: 15.211874424528665, time: 19.219237565994263


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6967437127567526, Training Loss Force: 2.94924171425266, time: 1.6843810081481934
Validation Loss Energy: 2.334515319152502, Validation Loss Force: 2.791297135090171, time: 0.1336686611175537
Test Loss Energy: 10.502054171369476, Test Loss Force: 15.513378669911077, time: 18.819463968276978


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.622141801221716, Training Loss Force: 2.950778210530814, time: 1.7269108295440674
Validation Loss Energy: 1.0130753917006943, Validation Loss Force: 2.5763694160242823, time: 0.13247394561767578
Test Loss Energy: 10.612672467820625, Test Loss Force: 15.340179179685942, time: 18.87718629837036


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.645901190402499, Training Loss Force: 2.944544800563304, time: 1.7990052700042725
Validation Loss Energy: 1.5242216847811307, Validation Loss Force: 2.5875759088005355, time: 0.12992262840270996
Test Loss Energy: 10.840338887623327, Test Loss Force: 15.635044923369806, time: 18.848778009414673


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8511809609268874, Training Loss Force: 2.9473990132614327, time: 1.7398838996887207
Validation Loss Energy: 1.2750220111216253, Validation Loss Force: 2.7772669748744074, time: 0.13270807266235352
Test Loss Energy: 10.387433948447011, Test Loss Force: 15.246499010397615, time: 18.86558437347412


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5684802305756795, Training Loss Force: 2.9615612212289357, time: 1.7144322395324707
Validation Loss Energy: 1.3161904745029167, Validation Loss Force: 2.752021081112834, time: 0.13011765480041504
Test Loss Energy: 10.577780161358229, Test Loss Force: 15.338909979543837, time: 18.49872326850891


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5053182643347411, Training Loss Force: 2.9360793600252184, time: 1.7503376007080078
Validation Loss Energy: 1.9321800061042302, Validation Loss Force: 2.74310184580355, time: 0.13004827499389648
Test Loss Energy: 10.621272071480288, Test Loss Force: 15.878460454401905, time: 18.36567187309265


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8082069501384177, Training Loss Force: 2.9432532947759076, time: 1.5967698097229004
Validation Loss Energy: 1.3622937314962598, Validation Loss Force: 2.7861306542317816, time: 0.12143468856811523
Test Loss Energy: 10.67694867975538, Test Loss Force: 15.358058490856969, time: 17.674747467041016


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9147701933843873, Training Loss Force: 2.9614021760803046, time: 1.599250078201294
Validation Loss Energy: 1.16965474859945, Validation Loss Force: 2.7196959785293506, time: 0.1240684986114502
Test Loss Energy: 10.373738863326814, Test Loss Force: 15.262310147225127, time: 17.63980484008789


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.491615978251102, Training Loss Force: 2.9402069186048436, time: 1.5909144878387451
Validation Loss Energy: 1.1247888640500276, Validation Loss Force: 2.6228491508761023, time: 0.1263713836669922
Test Loss Energy: 10.480588590571575, Test Loss Force: 15.303227269893434, time: 17.73572015762329


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5037224254921473, Training Loss Force: 2.9360562024340426, time: 1.5976927280426025
Validation Loss Energy: 1.4533100232306755, Validation Loss Force: 2.586773186529466, time: 0.13341426849365234
Test Loss Energy: 10.214579849544, Test Loss Force: 15.258479389207638, time: 17.92409586906433


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5938416772534814, Training Loss Force: 2.936198141644063, time: 1.6041557788848877
Validation Loss Energy: 1.404600813555253, Validation Loss Force: 2.759950106730176, time: 0.12350893020629883
Test Loss Energy: 10.46885650068314, Test Loss Force: 15.802288477932576, time: 18.133772611618042


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4212669422539674, Training Loss Force: 2.936867217893747, time: 1.609424114227295
Validation Loss Energy: 1.2349294293861703, Validation Loss Force: 2.9049889949674297, time: 0.12561321258544922
Test Loss Energy: 10.505145667822482, Test Loss Force: 15.253645831947914, time: 18.432292222976685


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5229351729678564, Training Loss Force: 2.9175278731121717, time: 1.768200159072876
Validation Loss Energy: 1.302823590005585, Validation Loss Force: 2.62600214598244, time: 0.1284472942352295
Test Loss Energy: 10.426484642012854, Test Loss Force: 14.915973980458535, time: 18.427969932556152


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.650620272042382, Training Loss Force: 2.9431645190615274, time: 1.592538833618164
Validation Loss Energy: 1.4224842076740107, Validation Loss Force: 2.6402091055000705, time: 0.1214895248413086
Test Loss Energy: 10.238484485212814, Test Loss Force: 15.362971961858134, time: 18.538001537322998


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6672731915125398, Training Loss Force: 2.9250769608399194, time: 1.5435421466827393
Validation Loss Energy: 2.08411618247117, Validation Loss Force: 2.8783150126384482, time: 0.1328294277191162
Test Loss Energy: 10.690476797990343, Test Loss Force: 14.96815241681366, time: 18.112945556640625


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6965244603451641, Training Loss Force: 2.9388145981245763, time: 1.577789545059204
Validation Loss Energy: 3.0108852080457567, Validation Loss Force: 2.807232118514775, time: 0.12488389015197754
Test Loss Energy: 11.375581131866614, Test Loss Force: 15.065906559448795, time: 18.298924922943115

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–…â–‚â–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–â–„â–ˆ
wandb:   test_error_force â–…â–ˆâ–…â–ƒâ–…â–„â–†â–ƒâ–„â–ˆâ–„â–ƒâ–„â–ƒâ–‡â–ƒâ–â–„â–â–‚
wandb:          test_loss â–†â–ˆâ–…â–ƒâ–…â–„â–†â–ƒâ–„â–‡â–†â–ƒâ–„â–ƒâ–‡â–ƒâ–â–„â–‚â–„
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–„â–â–â–‚â–â–‚â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚
wandb:         train_loss â–ˆâ–â–â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–‚â–â–‚
wandb: valid_error_energy â–â–‚â–‚â–„â–†â–â–ƒâ–‚â–‚â–„â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–…â–ˆ
wandb:  valid_error_force â–‚â–â–„â–„â–†â–‚â–‚â–†â–…â–…â–†â–…â–ƒâ–‚â–…â–ˆâ–ƒâ–ƒâ–ˆâ–†
wandb:         valid_loss â–ƒâ–â–„â–ƒâ–„â–â–„â–„â–„â–…â–‡â–ƒâ–‚â–‚â–…â–„â–ƒâ–„â–…â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1417
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.37558
wandb:   test_error_force 15.06591
wandb:          test_loss 7.46883
wandb: train_error_energy 1.69652
wandb:  train_error_force 2.93881
wandb:         train_loss 1.35189
wandb: valid_error_energy 3.01089
wandb:  valid_error_force 2.80723
wandb:         valid_loss 1.57809
wandb: 
wandb: ğŸš€ View run al_81_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/q7jc3ymf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_123148-q7jc3ymf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7237907648086548, Uncertainty Bias: 0.016826584935188293
0.000118255615 0.16856766
1.4413648 6.3774376
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 57 steps.
Found uncertainty sample 2 after 1492 steps.
Found uncertainty sample 3 after 1403 steps.
Found uncertainty sample 4 after 544 steps.
Found uncertainty sample 5 after 134 steps.
Found uncertainty sample 6 after 1365 steps.
Found uncertainty sample 7 after 448 steps.
Found uncertainty sample 8 after 284 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 976 steps.
Found uncertainty sample 14 after 2363 steps.
Found uncertainty sample 15 after 2900 steps.
Found uncertainty sample 16 after 2673 steps.
Found uncertainty sample 17 after 2927 steps.
Found uncertainty sample 18 after 3039 steps.
Found uncertainty sample 19 after 3555 steps.
Found uncertainty sample 20 after 1121 steps.
Found uncertainty sample 21 after 473 steps.
Found uncertainty sample 22 after 3172 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1270 steps.
Found uncertainty sample 26 after 32 steps.
Found uncertainty sample 27 after 974 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2494 steps.
Found uncertainty sample 30 after 3 steps.
Found uncertainty sample 31 after 1604 steps.
Found uncertainty sample 32 after 268 steps.
Found uncertainty sample 33 after 2156 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 954 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 693 steps.
Found uncertainty sample 38 after 897 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 199 steps.
Found uncertainty sample 41 after 827 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 189 steps.
Found uncertainty sample 44 after 426 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3392 steps.
Found uncertainty sample 47 after 2705 steps.
Found uncertainty sample 48 after 1586 steps.
Found uncertainty sample 49 after 3892 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2047 steps.
Found uncertainty sample 52 after 1911 steps.
Found uncertainty sample 53 after 68 steps.
Did not find any uncertainty samples for sample 54.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 3496 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3467 steps.
Found uncertainty sample 60 after 2372 steps.
Found uncertainty sample 61 after 1913 steps.
Found uncertainty sample 62 after 1741 steps.
Found uncertainty sample 63 after 1897 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 332 steps.
Found uncertainty sample 66 after 332 steps.
Found uncertainty sample 67 after 1403 steps.
Found uncertainty sample 68 after 904 steps.
Found uncertainty sample 69 after 3084 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 319 steps.
Found uncertainty sample 73 after 1210 steps.
Found uncertainty sample 74 after 2461 steps.
Found uncertainty sample 75 after 28 steps.
Found uncertainty sample 76 after 1137 steps.
Found uncertainty sample 77 after 2711 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1024 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 732 steps.
Found uncertainty sample 82 after 1501 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 70 steps.
Found uncertainty sample 85 after 664 steps.
Found uncertainty sample 86 after 665 steps.
Found uncertainty sample 87 after 193 steps.
Found uncertainty sample 88 after 1949 steps.
Found uncertainty sample 89 after 507 steps.
Found uncertainty sample 90 after 1446 steps.
Found uncertainty sample 91 after 1263 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3971 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3052 steps.
Found uncertainty sample 96 after 149 steps.
Found uncertainty sample 97 after 3436 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2222 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_141844-fk167wh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/fk167wh7
Training model 9. Added 74 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.969084959522179, Training Loss Force: 3.2273184524277814, time: 1.6819562911987305
Validation Loss Energy: 1.3797325109978864, Validation Loss Force: 2.706053373962074, time: 0.12460732460021973
Test Loss Energy: 10.390416371992726, Test Loss Force: 15.082755423097662, time: 17.893465995788574


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7551657669224083, Training Loss Force: 2.9947624695235424, time: 1.6827874183654785
Validation Loss Energy: 1.0862323097504691, Validation Loss Force: 2.615434602320426, time: 0.1233217716217041
Test Loss Energy: 10.175625391018253, Test Loss Force: 14.898037805882991, time: 18.06529426574707


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.609859660312707, Training Loss Force: 2.9808733299417725, time: 1.662135362625122
Validation Loss Energy: 1.312418793174619, Validation Loss Force: 2.7704703331986806, time: 0.12536406517028809
Test Loss Energy: 10.324151503081493, Test Loss Force: 15.018640376992277, time: 18.065552949905396


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.66391125591857, Training Loss Force: 2.994141701108186, time: 1.7029969692230225
Validation Loss Energy: 1.013143862463067, Validation Loss Force: 2.564041116090844, time: 0.1286487579345703
Test Loss Energy: 10.391068417200426, Test Loss Force: 15.178920309587305, time: 17.941311836242676


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8505759166643851, Training Loss Force: 2.9918115821994453, time: 1.7092089653015137
Validation Loss Energy: 2.9532411762208355, Validation Loss Force: 2.7926460647762017, time: 0.1355419158935547
Test Loss Energy: 10.469994127841947, Test Loss Force: 15.055798681264339, time: 18.103379011154175


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.067291401295336, Training Loss Force: 2.9910940048196655, time: 1.6917901039123535
Validation Loss Energy: 1.1980243008073852, Validation Loss Force: 2.7667324975805636, time: 0.1237328052520752
Test Loss Energy: 10.343304775550605, Test Loss Force: 14.915975584609031, time: 18.53403329849243


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7538215665869081, Training Loss Force: 2.986458800699356, time: 1.6738171577453613
Validation Loss Energy: 1.1275255791880532, Validation Loss Force: 2.7197062213100636, time: 0.12717747688293457
Test Loss Energy: 10.367552312377693, Test Loss Force: 15.253704038362145, time: 18.085236310958862


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.604270983356304, Training Loss Force: 2.9870106459075862, time: 1.691831111907959
Validation Loss Energy: 1.2511623997953114, Validation Loss Force: 2.843717794089918, time: 0.13735175132751465
Test Loss Energy: 10.238203735559818, Test Loss Force: 15.163868150453052, time: 18.055424213409424


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6482931425327259, Training Loss Force: 2.9776335080814467, time: 1.6882250308990479
Validation Loss Energy: 1.221379733520032, Validation Loss Force: 2.7298280926765033, time: 0.12338089942932129
Test Loss Energy: 10.175107926576029, Test Loss Force: 15.23484096790956, time: 17.984295129776


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.57069655289082, Training Loss Force: 2.9774070677729627, time: 1.891136646270752
Validation Loss Energy: 1.2980493408477474, Validation Loss Force: 2.8275779550510616, time: 0.138535737991333
Test Loss Energy: 10.192831434630103, Test Loss Force: 14.84713356398736, time: 17.95385479927063


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9743037094618585, Training Loss Force: 2.994776379238701, time: 1.6949498653411865
Validation Loss Energy: 1.5434793928685546, Validation Loss Force: 2.580330922799483, time: 0.129225492477417
Test Loss Energy: 10.172044749907801, Test Loss Force: 15.262855488445453, time: 18.063764810562134


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5543456163951619, Training Loss Force: 2.9995792721764603, time: 1.6854138374328613
Validation Loss Energy: 1.1763901005927604, Validation Loss Force: 2.714225776955916, time: 0.1282637119293213
Test Loss Energy: 10.045492753002705, Test Loss Force: 14.744707967230738, time: 18.021012544631958


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7994608249033204, Training Loss Force: 2.9782957261214364, time: 1.699040412902832
Validation Loss Energy: 1.6139343043334256, Validation Loss Force: 2.6690898503997698, time: 0.12613773345947266
Test Loss Energy: 10.140337199798926, Test Loss Force: 14.926264666514378, time: 18.317935943603516


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5461962572891026, Training Loss Force: 2.9647894542919846, time: 1.691047191619873
Validation Loss Energy: 2.3972879780810046, Validation Loss Force: 2.626483445341363, time: 0.13491320610046387
Test Loss Energy: 10.130682787913052, Test Loss Force: 15.03886704065192, time: 18.41733694076538


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8491735155886635, Training Loss Force: 2.987245609232954, time: 1.679504156112671
Validation Loss Energy: 2.8777409715802467, Validation Loss Force: 2.6503630412235237, time: 0.1329636573791504
Test Loss Energy: 10.28058990567741, Test Loss Force: 14.986114635518625, time: 18.440091371536255


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7424471635084693, Training Loss Force: 2.9653097894472453, time: 1.6960415840148926
Validation Loss Energy: 1.1980937179136282, Validation Loss Force: 2.7346846180837607, time: 0.13769769668579102
Test Loss Energy: 10.117703666869314, Test Loss Force: 14.924992355999073, time: 18.49910020828247


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7177210707330883, Training Loss Force: 2.961969444311637, time: 1.6927425861358643
Validation Loss Energy: 1.6337838113434393, Validation Loss Force: 2.703586645163486, time: 0.12897562980651855
Test Loss Energy: 10.346694009796897, Test Loss Force: 14.543583499777359, time: 18.539148330688477


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9688575680002878, Training Loss Force: 2.998636964776742, time: 1.6816508769989014
Validation Loss Energy: 1.2032477849671324, Validation Loss Force: 2.7551719608622847, time: 0.13215422630310059
Test Loss Energy: 10.24799094219477, Test Loss Force: 14.988405702843027, time: 18.48215913772583


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6322545705788525, Training Loss Force: 2.958260434872636, time: 1.7202932834625244
Validation Loss Energy: 1.7484961639164849, Validation Loss Force: 2.627259892653213, time: 0.14056634902954102
Test Loss Energy: 10.073985487589168, Test Loss Force: 14.807618156416545, time: 18.578209400177002


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7417704198599397, Training Loss Force: 2.9645763362311253, time: 1.7454581260681152
Validation Loss Energy: 1.400484774392778, Validation Loss Force: 2.766814217157119, time: 0.12505292892456055
Test Loss Energy: 9.958309481825802, Test Loss Force: 14.805246527161987, time: 18.99643611907959

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–„â–†â–‡â–ˆâ–†â–‡â–…â–„â–„â–„â–‚â–ƒâ–ƒâ–…â–ƒâ–†â–…â–ƒâ–
wandb:   test_error_force â–†â–„â–†â–‡â–†â–…â–ˆâ–‡â–ˆâ–„â–ˆâ–ƒâ–…â–†â–…â–…â–â–…â–„â–„
wandb:          test_loss â–†â–ƒâ–…â–‡â–†â–„â–ˆâ–‡â–‡â–‚â–ˆâ–â–ƒâ–„â–„â–„â–â–†â–â–
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–ƒâ–‚â–â–â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–
wandb: valid_error_energy â–‚â–â–‚â–â–ˆâ–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–†â–ˆâ–‚â–ƒâ–‚â–„â–‚
wandb:  valid_error_force â–…â–‚â–†â–â–‡â–†â–…â–ˆâ–…â–ˆâ–â–…â–„â–ƒâ–ƒâ–…â–„â–†â–ƒâ–†
wandb:         valid_loss â–„â–ƒâ–ƒâ–â–‡â–„â–ƒâ–…â–ƒâ–†â–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–ˆâ–†â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1483
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.95831
wandb:   test_error_force 14.80525
wandb:          test_loss 7.22494
wandb: train_error_energy 1.74177
wandb:  train_error_force 2.96458
wandb:         train_loss 1.36591
wandb: valid_error_energy 1.40048
wandb:  valid_error_force 2.76681
wandb:         valid_loss 1.35794
wandb: 
wandb: ğŸš€ View run al_81_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/fk167wh7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_141844-fk167wh7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7133786082267761, Uncertainty Bias: 0.024071067571640015
9.536743e-06 0.003665924
0.43596977 4.3626056
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 65 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3933 steps.
Found uncertainty sample 5 after 1378 steps.
Found uncertainty sample 6 after 3712 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2528 steps.
Found uncertainty sample 9 after 1964 steps.
Found uncertainty sample 10 after 2319 steps.
Found uncertainty sample 11 after 807 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1200 steps.
Found uncertainty sample 14 after 467 steps.
Found uncertainty sample 15 after 244 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1224 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 39 steps.
Found uncertainty sample 20 after 1326 steps.
Found uncertainty sample 21 after 1116 steps.
Found uncertainty sample 22 after 2753 steps.
Found uncertainty sample 23 after 2429 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1202 steps.
Found uncertainty sample 26 after 3590 steps.
Found uncertainty sample 27 after 1606 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1972 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2931 steps.
Found uncertainty sample 32 after 2705 steps.
Found uncertainty sample 33 after 9 steps.
Found uncertainty sample 34 after 837 steps.
Found uncertainty sample 35 after 936 steps.
Found uncertainty sample 36 after 3013 steps.
Found uncertainty sample 37 after 2795 steps.
Found uncertainty sample 38 after 618 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1652 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2928 steps.
Found uncertainty sample 44 after 2127 steps.
Found uncertainty sample 45 after 2160 steps.
Found uncertainty sample 46 after 3298 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1628 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3412 steps.
Found uncertainty sample 51 after 1019 steps.
Found uncertainty sample 52 after 2256 steps.
Found uncertainty sample 53 after 3175 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 56 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1000 steps.
Found uncertainty sample 58 after 1537 steps.
Found uncertainty sample 59 after 3105 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3808 steps.
Found uncertainty sample 62 after 68 steps.
Found uncertainty sample 63 after 414 steps.
Found uncertainty sample 64 after 298 steps.
Found uncertainty sample 65 after 1018 steps.
Found uncertainty sample 66 after 3731 steps.
Found uncertainty sample 67 after 14 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 947 steps.
Found uncertainty sample 70 after 3314 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 79 steps.
Found uncertainty sample 74 after 177 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1303 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 609 steps.
Found uncertainty sample 80 after 92 steps.
Found uncertainty sample 81 after 558 steps.
Found uncertainty sample 82 after 3557 steps.
Did not find any uncertainty samples for sample 83.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 3027 steps.
Found uncertainty sample 86 after 26 steps.
Found uncertainty sample 87 after 2340 steps.
Found uncertainty sample 88 after 3042 steps.
Found uncertainty sample 89 after 54 steps.
Found uncertainty sample 90 after 492 steps.
Found uncertainty sample 91 after 2360 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1501 steps.
Found uncertainty sample 95 after 1870 steps.
Found uncertainty sample 96 after 100 steps.
Found uncertainty sample 97 after 392 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_161119-0b8p00zj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/0b8p00zj
Training model 10. Added 71 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8601332610377765, Training Loss Force: 3.3611268426465397, time: 1.7545397281646729
Validation Loss Energy: 1.34597592414252, Validation Loss Force: 2.6813500135745536, time: 0.12700104713439941
Test Loss Energy: 9.938113478891488, Test Loss Force: 14.872451726710663, time: 17.66146230697632


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7097531128465409, Training Loss Force: 2.998363572218165, time: 1.7587988376617432
Validation Loss Energy: 1.515026618067329, Validation Loss Force: 2.85928047470253, time: 0.12715673446655273
Test Loss Energy: 9.9015896954156, Test Loss Force: 14.779749212538196, time: 17.829639434814453


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.711175521078594, Training Loss Force: 2.9851157350531428, time: 1.7419264316558838
Validation Loss Energy: 1.957093844501939, Validation Loss Force: 2.7395270040002524, time: 0.1241598129272461
Test Loss Energy: 10.343038971543947, Test Loss Force: 14.477299632874495, time: 17.726046800613403


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8507757745020486, Training Loss Force: 3.0171736119401715, time: 1.7209768295288086
Validation Loss Energy: 1.2462062299452508, Validation Loss Force: 2.7359186504904924, time: 0.1292707920074463
Test Loss Energy: 9.812615334250822, Test Loss Force: 14.416829766957667, time: 17.64423418045044


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5900228519945252, Training Loss Force: 3.0059102930890234, time: 1.718151330947876
Validation Loss Energy: 1.8678518361895624, Validation Loss Force: 2.6697173320529943, time: 0.12837934494018555
Test Loss Energy: 10.080909085069381, Test Loss Force: 15.11623123669244, time: 18.291335582733154


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6278044483661638, Training Loss Force: 2.997625387645269, time: 1.736865758895874
Validation Loss Energy: 1.3166574673692137, Validation Loss Force: 2.5574457673230357, time: 0.13302302360534668
Test Loss Energy: 10.009436061778166, Test Loss Force: 14.704890438432146, time: 17.737000703811646


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6803148873383353, Training Loss Force: 3.003415921506462, time: 1.9165270328521729
Validation Loss Energy: 1.6412175094456656, Validation Loss Force: 2.6758794779973996, time: 0.13365936279296875
Test Loss Energy: 10.114898609207692, Test Loss Force: 14.864199724743287, time: 17.797473669052124


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6112628096698824, Training Loss Force: 2.9913491669341243, time: 1.6886043548583984
Validation Loss Energy: 1.470215621462378, Validation Loss Force: 2.633124775287805, time: 0.1281278133392334
Test Loss Energy: 10.208526382464106, Test Loss Force: 14.701811229585411, time: 17.74742603302002


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8225090352279771, Training Loss Force: 2.987017315926562, time: 1.7223410606384277
Validation Loss Energy: 1.5883477267785824, Validation Loss Force: 2.6346284600302554, time: 0.13134121894836426
Test Loss Energy: 10.14501900162376, Test Loss Force: 14.329345563676178, time: 17.71094059944153


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9290157730224258, Training Loss Force: 3.005132364345712, time: 1.6972620487213135
Validation Loss Energy: 1.0956808852869093, Validation Loss Force: 2.7393918438286744, time: 0.12282514572143555
Test Loss Energy: 9.761760256769962, Test Loss Force: 14.40329045231183, time: 17.75973892211914


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.875363862708137, Training Loss Force: 2.99228917155006, time: 1.7239012718200684
Validation Loss Energy: 1.4350994724692632, Validation Loss Force: 2.6964282774601998, time: 0.1369187831878662
Test Loss Energy: 9.79400590144256, Test Loss Force: 14.48074442948463, time: 17.776490211486816


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8080112493565577, Training Loss Force: 3.0142939818367407, time: 1.7428770065307617
Validation Loss Energy: 1.2208930344343203, Validation Loss Force: 2.7165823958618427, time: 0.13001704216003418
Test Loss Energy: 9.799484299222435, Test Loss Force: 14.716873237457596, time: 17.708309650421143


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6790035751051617, Training Loss Force: 3.017307672398825, time: 1.7037193775177002
Validation Loss Energy: 1.6990534264070898, Validation Loss Force: 2.884531823858179, time: 0.12408995628356934
Test Loss Energy: 9.88608700315329, Test Loss Force: 14.764195406631726, time: 17.803767442703247


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6625232192748947, Training Loss Force: 2.9970809070522555, time: 1.704364538192749
Validation Loss Energy: 1.5900765856948522, Validation Loss Force: 2.7429565541858323, time: 0.1297297477722168
Test Loss Energy: 9.811977619143342, Test Loss Force: 14.626246554649331, time: 18.031323194503784


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7669544125174677, Training Loss Force: 3.000424343353849, time: 1.7532165050506592
Validation Loss Energy: 1.343810522365659, Validation Loss Force: 2.7800144894660104, time: 0.12618279457092285
Test Loss Energy: 9.742541526566791, Test Loss Force: 14.46899080480843, time: 18.021262645721436


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7918810191729877, Training Loss Force: 2.986250011682499, time: 1.7110545635223389
Validation Loss Energy: 1.5131493501652984, Validation Loss Force: 2.6541978492546923, time: 0.12972497940063477
Test Loss Energy: 10.04298629116835, Test Loss Force: 14.304991747215482, time: 18.28305673599243


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1072857057601073, Training Loss Force: 3.000679195007766, time: 1.7602708339691162
Validation Loss Energy: 2.510156518791195, Validation Loss Force: 2.709266712406958, time: 0.13194584846496582
Test Loss Energy: 10.047027062330466, Test Loss Force: 14.727760476305713, time: 18.72431445121765


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6955549328552357, Training Loss Force: 2.9793688806986975, time: 1.8736188411712646
Validation Loss Energy: 1.394839944541649, Validation Loss Force: 2.7088852801599836, time: 0.13454747200012207
Test Loss Energy: 10.02722090993581, Test Loss Force: 14.549447844974903, time: 18.695302963256836


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7770352661823066, Training Loss Force: 2.988717258527672, time: 1.7362861633300781
Validation Loss Energy: 2.084149694177632, Validation Loss Force: 2.888768549697747, time: 0.13114643096923828
Test Loss Energy: 9.870201245348332, Test Loss Force: 14.512184627395092, time: 18.782773733139038


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.911777770654268, Training Loss Force: 3.001578701104753, time: 1.716090202331543
Validation Loss Energy: 1.5023442185245794, Validation Loss Force: 2.914405895817862, time: 0.13753318786621094
Test Loss Energy: 10.131893138115437, Test Loss Force: 14.321077594815483, time: 18.281595945358276

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ˆâ–‚â–…â–„â–…â–†â–†â–â–‚â–‚â–ƒâ–‚â–â–…â–…â–„â–‚â–†
wandb:   test_error_force â–†â–…â–‚â–‚â–ˆâ–„â–†â–„â–â–‚â–ƒâ–…â–…â–„â–‚â–â–…â–ƒâ–ƒâ–
wandb:          test_loss â–†â–…â–ƒâ–‚â–ˆâ–„â–…â–…â–‚â–‚â–‚â–„â–…â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–
wandb: train_error_energy â–ˆâ–â–â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–ƒâ–â–‚â–‚
wandb:  train_error_force â–ˆâ–â–â–‚â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–‚â–â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–â–‚â–â–‚â–
wandb: valid_error_energy â–‚â–ƒâ–…â–‚â–…â–‚â–„â–ƒâ–ƒâ–â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–ˆâ–‚â–†â–ƒ
wandb:  valid_error_force â–ƒâ–‡â–…â–„â–ƒâ–â–ƒâ–‚â–ƒâ–…â–„â–„â–‡â–…â–…â–ƒâ–„â–„â–‡â–ˆ
wandb:         valid_loss â–‡â–†â–…â–…â–…â–â–ƒâ–…â–„â–ƒâ–ƒâ–„â–‡â–†â–‡â–ƒâ–‡â–„â–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1546
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.13189
wandb:   test_error_force 14.32108
wandb:          test_loss 7.02303
wandb: train_error_energy 1.91178
wandb:  train_error_force 3.00158
wandb:         train_loss 1.37594
wandb: valid_error_energy 1.50234
wandb:  valid_error_force 2.91441
wandb:         valid_loss 1.45911
wandb: 
wandb: ğŸš€ View run al_81_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/0b8p00zj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_161119-0b8p00zj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.724288284778595, Uncertainty Bias: 0.013415873050689697
1.7166138e-05 0.0033025742
0.33185565 3.0787199
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 250 steps.
Found uncertainty sample 3 after 2589 steps.
Found uncertainty sample 4 after 130 steps.
Found uncertainty sample 5 after 3086 steps.
Found uncertainty sample 6 after 3207 steps.
Found uncertainty sample 7 after 1250 steps.
Found uncertainty sample 8 after 3984 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 658 steps.
Found uncertainty sample 11 after 2953 steps.
Found uncertainty sample 12 after 1762 steps.
Found uncertainty sample 13 after 542 steps.
Found uncertainty sample 14 after 3886 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2105 steps.
Found uncertainty sample 17 after 189 steps.
Found uncertainty sample 18 after 94 steps.
Found uncertainty sample 19 after 1199 steps.
Found uncertainty sample 20 after 171 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 309 steps.
Found uncertainty sample 27 after 2987 steps.
Found uncertainty sample 28 after 2800 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 260 steps.
Found uncertainty sample 31 after 789 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1049 steps.
Found uncertainty sample 34 after 2640 steps.
Found uncertainty sample 35 after 415 steps.
Found uncertainty sample 36 after 4 steps.
Found uncertainty sample 37 after 1539 steps.
Found uncertainty sample 38 after 3348 steps.
Found uncertainty sample 39 after 381 steps.
Found uncertainty sample 40 after 1255 steps.
Found uncertainty sample 41 after 2579 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 855 steps.
Found uncertainty sample 45 after 113 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 180 steps.
Found uncertainty sample 48 after 2072 steps.
Found uncertainty sample 49 after 5 steps.
Found uncertainty sample 50 after 3671 steps.
Found uncertainty sample 51 after 101 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 85 steps.
Found uncertainty sample 55 after 895 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3543 steps.
Found uncertainty sample 58 after 850 steps.
Found uncertainty sample 59 after 1011 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 706 steps.
Found uncertainty sample 62 after 128 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1235 steps.
Found uncertainty sample 65 after 9 steps.
Found uncertainty sample 66 after 3189 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1709 steps.
Found uncertainty sample 70 after 677 steps.
Found uncertainty sample 71 after 366 steps.
Found uncertainty sample 72 after 670 steps.
Found uncertainty sample 73 after 443 steps.
Found uncertainty sample 74 after 425 steps.
Found uncertainty sample 75 after 1137 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3639 steps.
Found uncertainty sample 78 after 279 steps.
Found uncertainty sample 79 after 191 steps.
Found uncertainty sample 80 after 548 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1917 steps.
Found uncertainty sample 83 after 2143 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 230 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 678 steps.
Found uncertainty sample 88 after 2875 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3819 steps.
Found uncertainty sample 91 after 3420 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 149 steps.
Found uncertainty sample 94 after 878 steps.
Found uncertainty sample 95 after 1572 steps.
Found uncertainty sample 96 after 1197 steps.
Found uncertainty sample 97 after 2806 steps.
Found uncertainty sample 98 after 3825 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_175919-5rovgxz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/5rovgxz2
Training model 11. Added 72 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.9432317311596834, Training Loss Force: 3.3198866834312195, time: 1.8136167526245117
Validation Loss Energy: 1.2647033002301855, Validation Loss Force: 2.7537579004510704, time: 0.1304464340209961
Test Loss Energy: 9.470156711670118, Test Loss Force: 13.75742572870171, time: 18.093432426452637


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6198507206855994, Training Loss Force: 3.045879157521405, time: 1.7447099685668945
Validation Loss Energy: 1.324752214498413, Validation Loss Force: 2.7529287918862084, time: 0.1373584270477295
Test Loss Energy: 9.684588833919463, Test Loss Force: 13.920554068327592, time: 18.163927793502808


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6072630592238342, Training Loss Force: 3.0271989320403048, time: 1.819136381149292
Validation Loss Energy: 1.1914696448259954, Validation Loss Force: 2.625369320269713, time: 0.14390850067138672
Test Loss Energy: 9.734796562063407, Test Loss Force: 13.883461030597235, time: 18.123637914657593


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5853809289218883, Training Loss Force: 3.0140811651990735, time: 1.8549878597259521
Validation Loss Energy: 1.1898465537540415, Validation Loss Force: 2.7642029760828244, time: 0.12882733345031738
Test Loss Energy: 9.681186976314471, Test Loss Force: 13.949161583612646, time: 18.080986499786377


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7681863675253189, Training Loss Force: 3.038492711121762, time: 1.8634369373321533
Validation Loss Energy: 1.2178454175012932, Validation Loss Force: 2.7183834552486794, time: 0.1351032257080078
Test Loss Energy: 9.495678559537403, Test Loss Force: 13.771499505256514, time: 18.23193073272705


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6716786627982876, Training Loss Force: 3.0415922132403375, time: 1.8466720581054688
Validation Loss Energy: 1.9078241209189297, Validation Loss Force: 2.7312916969726864, time: 0.12793755531311035
Test Loss Energy: 9.590761572424439, Test Loss Force: 13.765998243668836, time: 18.191741704940796


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.400297216240306, Training Loss Force: 3.0727689979400847, time: 1.8614575862884521
Validation Loss Energy: 1.7305631145781852, Validation Loss Force: 2.7524637473749385, time: 0.12681889533996582
Test Loss Energy: 9.86192051789532, Test Loss Force: 13.96284738890875, time: 18.09006905555725


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.785584911585488, Training Loss Force: 3.055177628948635, time: 1.7944750785827637
Validation Loss Energy: 0.9742243017883598, Validation Loss Force: 2.6217529506707002, time: 0.12697672843933105
Test Loss Energy: 9.677880766182822, Test Loss Force: 14.187745096250321, time: 18.15698790550232


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.637059574646778, Training Loss Force: 3.028200576447798, time: 1.864626407623291
Validation Loss Energy: 1.930053070422328, Validation Loss Force: 2.6389376646768232, time: 0.1268479824066162
Test Loss Energy: 9.738608606546181, Test Loss Force: 14.21330589139942, time: 18.642537355422974


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.914244617648383, Training Loss Force: 3.0361031175349615, time: 1.9059765338897705
Validation Loss Energy: 1.1665047038592962, Validation Loss Force: 2.7014938891954836, time: 0.14142417907714844
Test Loss Energy: 9.496950044661315, Test Loss Force: 13.776219354360132, time: 18.103132247924805


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.571442846764027, Training Loss Force: 3.0221155264206243, time: 1.8702173233032227
Validation Loss Energy: 1.5848945736635343, Validation Loss Force: 2.776247706858923, time: 0.13237214088439941
Test Loss Energy: 9.550162402643602, Test Loss Force: 14.00501962410681, time: 18.169825315475464


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.625966084279052, Training Loss Force: 3.028211578923245, time: 1.900522232055664
Validation Loss Energy: 1.1518819097116453, Validation Loss Force: 2.763232695279444, time: 0.13274717330932617
Test Loss Energy: 9.534116649479548, Test Loss Force: 13.987812741113885, time: 18.184767246246338


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0441025107515762, Training Loss Force: 3.028733008938144, time: 1.8217039108276367
Validation Loss Energy: 1.3653608319795556, Validation Loss Force: 2.7578865204202905, time: 0.12900161743164062
Test Loss Energy: 9.549743537498165, Test Loss Force: 14.039779368981536, time: 17.998517513275146


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8843609359869313, Training Loss Force: 3.0379006687912344, time: 1.8290972709655762
Validation Loss Energy: 1.21530392753696, Validation Loss Force: 2.84607196363524, time: 0.13269710540771484
Test Loss Energy: 9.59530424217309, Test Loss Force: 13.739349051060897, time: 18.27108407020569


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2489159663135125, Training Loss Force: 3.0343137439122234, time: 1.8539469242095947
Validation Loss Energy: 1.2703855941651168, Validation Loss Force: 2.577779357056297, time: 0.12749338150024414
Test Loss Energy: 9.582720623501574, Test Loss Force: 14.105192280092691, time: 18.525124073028564


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8757874840309652, Training Loss Force: 3.0075362204303855, time: 1.840555191040039
Validation Loss Energy: 1.319729577908293, Validation Loss Force: 2.8144385827535814, time: 0.12992620468139648
Test Loss Energy: 9.694289850107836, Test Loss Force: 14.167104272642481, time: 18.528843879699707


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7724661143536982, Training Loss Force: 3.020818015843056, time: 1.7999701499938965
Validation Loss Energy: 1.259210609073012, Validation Loss Force: 2.798458286157782, time: 0.13413667678833008
Test Loss Energy: 9.672625760349241, Test Loss Force: 13.899040195138584, time: 18.608112573623657


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8707377931396154, Training Loss Force: 3.0228110182167147, time: 1.9087765216827393
Validation Loss Energy: 1.1935397442083997, Validation Loss Force: 2.6761821967012884, time: 0.12913274765014648
Test Loss Energy: 9.608400890556824, Test Loss Force: 14.162866018429872, time: 18.59007477760315


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5520480028621124, Training Loss Force: 3.005390873066358, time: 1.8209867477416992
Validation Loss Energy: 1.5171949702103738, Validation Loss Force: 2.8313734619779733, time: 0.12905144691467285
Test Loss Energy: 9.716296020296541, Test Loss Force: 13.969394593925854, time: 18.47203755378723


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6592394496168381, Training Loss Force: 3.004060075634505, time: 1.8454606533050537
Validation Loss Energy: 1.1873129685443884, Validation Loss Force: 2.6776447989863152, time: 0.1294410228729248
Test Loss Energy: 9.58737068739537, Test Loss Force: 13.579783907408821, time: 18.67029643058777

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–†â–…â–â–ƒâ–ˆâ–…â–†â–â–‚â–‚â–‚â–ƒâ–ƒâ–…â–…â–ƒâ–…â–ƒ
wandb:   test_error_force â–ƒâ–…â–„â–…â–ƒâ–ƒâ–…â–ˆâ–ˆâ–ƒâ–†â–†â–†â–ƒâ–‡â–‡â–…â–‡â–…â–
wandb:          test_loss â–ƒâ–…â–…â–†â–ƒâ–ƒâ–†â–‡â–ˆâ–ƒâ–…â–‡â–…â–‚â–‡â–ˆâ–„â–‡â–†â–
wandb: train_error_energy â–ˆâ–â–â–â–‚â–â–ƒâ–‚â–â–‚â–â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–‚â–ƒâ–‚â–â–‚â–â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–
wandb: valid_error_energy â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ˆâ–‡â–â–ˆâ–‚â–…â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–ƒ
wandb:  valid_error_force â–†â–†â–‚â–†â–…â–…â–†â–‚â–ƒâ–„â–†â–†â–†â–ˆâ–â–‡â–‡â–„â–ˆâ–„
wandb:         valid_loss â–„â–„â–â–ƒâ–ƒâ–ˆâ–„â–„â–ƒâ–„â–„â–†â–„â–„â–ƒâ–‡â–„â–‚â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1610
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.58737
wandb:   test_error_force 13.57978
wandb:          test_loss 6.69732
wandb: train_error_energy 1.65924
wandb:  train_error_force 3.00406
wandb:         train_loss 1.36766
wandb: valid_error_energy 1.18731
wandb:  valid_error_force 2.67764
wandb:         valid_loss 1.34756
wandb: 
wandb: ğŸš€ View run al_81_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/5rovgxz2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_175919-5rovgxz2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7234317064285278, Uncertainty Bias: 0.01777893304824829
3.4332275e-05 0.0048951507
0.3141671 4.0465784
(48745, 22, 3)
Found uncertainty sample 0 after 1846 steps.
Found uncertainty sample 1 after 1221 steps.
Found uncertainty sample 2 after 668 steps.
Found uncertainty sample 3 after 7 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1633 steps.
Found uncertainty sample 6 after 3955 steps.
Found uncertainty sample 7 after 1254 steps.
Found uncertainty sample 8 after 1936 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 293 steps.
Found uncertainty sample 13 after 2790 steps.
Found uncertainty sample 14 after 3118 steps.
Found uncertainty sample 15 after 1290 steps.
Found uncertainty sample 16 after 1092 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 321 steps.
Found uncertainty sample 19 after 1506 steps.
Found uncertainty sample 20 after 1990 steps.
Found uncertainty sample 21 after 101 steps.
Found uncertainty sample 22 after 1041 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 754 steps.
Found uncertainty sample 25 after 2023 steps.
Found uncertainty sample 26 after 3012 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3400 steps.
Found uncertainty sample 31 after 1000 steps.
Found uncertainty sample 32 after 258 steps.
Found uncertainty sample 33 after 1074 steps.
Found uncertainty sample 34 after 3380 steps.
Found uncertainty sample 35 after 816 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 515 steps.
Found uncertainty sample 39 after 1541 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 603 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 966 steps.
Found uncertainty sample 44 after 1023 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2137 steps.
Found uncertainty sample 47 after 1087 steps.
Found uncertainty sample 48 after 528 steps.
Found uncertainty sample 49 after 3973 steps.
Found uncertainty sample 50 after 2360 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2373 steps.
Found uncertainty sample 53 after 939 steps.
Found uncertainty sample 54 after 1635 steps.
Found uncertainty sample 55 after 3735 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2578 steps.
Found uncertainty sample 58 after 2459 steps.
Found uncertainty sample 59 after 552 steps.
Found uncertainty sample 60 after 386 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1664 steps.
Found uncertainty sample 66 after 859 steps.
Found uncertainty sample 67 after 2643 steps.
Found uncertainty sample 68 after 383 steps.
Found uncertainty sample 69 after 2844 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 126 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1183 steps.
Found uncertainty sample 74 after 1079 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 41 steps.
Found uncertainty sample 78 after 683 steps.
Found uncertainty sample 79 after 1435 steps.
Found uncertainty sample 80 after 519 steps.
Found uncertainty sample 81 after 640 steps.
Found uncertainty sample 82 after 1133 steps.
Found uncertainty sample 83 after 1499 steps.
Found uncertainty sample 84 after 2877 steps.
Found uncertainty sample 85 after 795 steps.
Found uncertainty sample 86 after 138 steps.
Found uncertainty sample 87 after 352 steps.
Found uncertainty sample 88 after 350 steps.
Found uncertainty sample 89 after 950 steps.
Found uncertainty sample 90 after 996 steps.
Found uncertainty sample 91 after 98 steps.
Found uncertainty sample 92 after 3149 steps.
Found uncertainty sample 93 after 3146 steps.
Found uncertainty sample 94 after 1601 steps.
Found uncertainty sample 95 after 509 steps.
Found uncertainty sample 96 after 886 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_194530-7l1691zz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7l1691zz
Training model 12. Added 73 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.387873719347281, Training Loss Force: 3.3318590553434464, time: 1.9338171482086182
Validation Loss Energy: 1.6564427906349104, Validation Loss Force: 2.818137451271161, time: 0.13790345191955566
Test Loss Energy: 9.573364588271245, Test Loss Force: 13.977100802339772, time: 17.93713879585266


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6661455062400121, Training Loss Force: 3.0748848369878905, time: 1.94002103805542
Validation Loss Energy: 1.7748502263500545, Validation Loss Force: 2.769804441117784, time: 0.13066864013671875
Test Loss Energy: 9.531312762288202, Test Loss Force: 13.818933629212957, time: 18.136341333389282


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.587672610733348, Training Loss Force: 3.054263615435704, time: 1.9226913452148438
Validation Loss Energy: 1.870588773996734, Validation Loss Force: 2.776801596359418, time: 0.1306607723236084
Test Loss Energy: 9.594078825080432, Test Loss Force: 13.91148183716472, time: 18.14926314353943


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.731901117721173, Training Loss Force: 3.0470476268392774, time: 1.8995275497436523
Validation Loss Energy: 1.3083983347430332, Validation Loss Force: 2.791286780974886, time: 0.12987065315246582
Test Loss Energy: 9.522566672641501, Test Loss Force: 13.803541842506622, time: 18.133901357650757


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8534331865853548, Training Loss Force: 3.0548119277042893, time: 1.865553855895996
Validation Loss Energy: 1.517638749818208, Validation Loss Force: 2.8553176319124534, time: 0.13436532020568848
Test Loss Energy: 9.500294208807178, Test Loss Force: 13.691982310751756, time: 18.175575733184814


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8742172402021322, Training Loss Force: 3.042320205422959, time: 1.9404575824737549
Validation Loss Energy: 1.1392947568960663, Validation Loss Force: 2.7089564229521077, time: 0.12722539901733398
Test Loss Energy: 9.320504723783099, Test Loss Force: 13.506321369107146, time: 18.23816227912903


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.094583495608384, Training Loss Force: 3.0689314286632263, time: 1.9642624855041504
Validation Loss Energy: 1.2971841042139585, Validation Loss Force: 2.678134782441929, time: 0.1387009620666504
Test Loss Energy: 9.354059140752193, Test Loss Force: 13.539041669787212, time: 18.007112503051758


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7180941140026749, Training Loss Force: 3.060004664616028, time: 1.8543636798858643
Validation Loss Energy: 1.5274951995627015, Validation Loss Force: 2.7238856098445554, time: 0.13324737548828125
Test Loss Energy: 9.376832407314426, Test Loss Force: 13.461868418951262, time: 18.141796112060547


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9005133718963452, Training Loss Force: 3.0422636264533702, time: 1.9072182178497314
Validation Loss Energy: 1.4261487294758308, Validation Loss Force: 2.7817439607224315, time: 0.13435935974121094
Test Loss Energy: 9.628448211123628, Test Loss Force: 13.733729128968774, time: 18.125232458114624


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8682942052093636, Training Loss Force: 3.0332853334047605, time: 1.9379112720489502
Validation Loss Energy: 1.3071683660482147, Validation Loss Force: 2.7035701676466877, time: 0.13753938674926758
Test Loss Energy: 9.418954634053408, Test Loss Force: 13.584700456140597, time: 18.48164415359497


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.784250858698594, Training Loss Force: 3.038913501932013, time: 1.9958174228668213
Validation Loss Energy: 2.0527702674569044, Validation Loss Force: 2.7482408270224177, time: 0.138566255569458
Test Loss Energy: 9.469141979226947, Test Loss Force: 13.804688180575681, time: 18.495847940444946


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9101449520616056, Training Loss Force: 3.0434160611213814, time: 2.0289306640625
Validation Loss Energy: 1.414301172228451, Validation Loss Force: 2.728434851830433, time: 0.13609719276428223
Test Loss Energy: 9.552581680763774, Test Loss Force: 13.48529619290568, time: 19.09693932533264


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7375249641562762, Training Loss Force: 3.027324173673036, time: 2.03252911567688
Validation Loss Energy: 2.9928345337311204, Validation Loss Force: 2.6185731239322783, time: 0.13987088203430176
Test Loss Energy: 10.056308877620973, Test Loss Force: 12.99097256822695, time: 19.224161624908447


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7359249182905996, Training Loss Force: 3.0282380960753192, time: 1.9612512588500977
Validation Loss Energy: 1.6666901917323669, Validation Loss Force: 2.7481077822077262, time: 0.14295125007629395
Test Loss Energy: 9.502014207881345, Test Loss Force: 13.407493089164975, time: 19.290788888931274


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8436543706486541, Training Loss Force: 3.0374946877445974, time: 2.042738437652588
Validation Loss Energy: 1.8410293335402472, Validation Loss Force: 2.7301657704363027, time: 0.13542795181274414
Test Loss Energy: 9.65307076009828, Test Loss Force: 13.46468738702257, time: 19.24024200439453


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7155417636658468, Training Loss Force: 3.032729824301327, time: 2.0808746814727783
Validation Loss Energy: 1.8933661576065521, Validation Loss Force: 2.7208224617385994, time: 0.138580322265625
Test Loss Energy: 9.747322986241214, Test Loss Force: 13.710439139417602, time: 19.194565057754517


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7874991047334066, Training Loss Force: 3.0392969003895582, time: 2.0877480506896973
Validation Loss Energy: 1.1601690429829263, Validation Loss Force: 2.8159421561614586, time: 0.1370539665222168
Test Loss Energy: 9.286200301171778, Test Loss Force: 13.563351698535232, time: 19.40018105506897


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6932734794477555, Training Loss Force: 3.0307875821727097, time: 2.01204514503479
Validation Loss Energy: 1.1314044200428288, Validation Loss Force: 2.6304848098936855, time: 0.1353163719177246
Test Loss Energy: 9.281543256425385, Test Loss Force: 13.640697614721262, time: 19.1551034450531


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8235932838363107, Training Loss Force: 3.0313194379310184, time: 2.0622684955596924
Validation Loss Energy: 1.169109097857354, Validation Loss Force: 2.7008213170402087, time: 0.13989758491516113
Test Loss Energy: 9.261843201798438, Test Loss Force: 13.32079162272435, time: 19.475329637527466


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7810610969250245, Training Loss Force: 3.034898117626106, time: 1.9891319274902344
Validation Loss Energy: 1.2474485567776683, Validation Loss Force: 2.691030888697483, time: 0.1444704532623291
Test Loss Energy: 9.570658558923398, Test Loss Force: 13.713562919399347, time: 19.308402061462402

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–„â–ˆâ–ƒâ–„â–…â–â–â–â–„
wandb:   test_error_force â–ˆâ–‡â–ˆâ–‡â–†â–…â–…â–„â–†â–…â–‡â–…â–â–„â–„â–†â–…â–†â–ƒâ–†
wandb:          test_loss â–ˆâ–‡â–‡â–‡â–…â–„â–„â–„â–†â–„â–‡â–„â–â–„â–„â–†â–„â–„â–ƒâ–†
wandb: train_error_energy â–ˆâ–â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–‚â–â–â–
wandb: valid_error_energy â–ƒâ–ƒâ–„â–‚â–‚â–â–‚â–‚â–‚â–‚â–„â–‚â–ˆâ–ƒâ–„â–„â–â–â–â–
wandb:  valid_error_force â–‡â–…â–†â–†â–ˆâ–„â–ƒâ–„â–†â–„â–…â–„â–â–…â–„â–„â–‡â–â–ƒâ–ƒ
wandb:         valid_loss â–‡â–„â–‡â–…â–…â–‚â–ƒâ–…â–†â–â–‡â–ƒâ–†â–…â–„â–†â–ˆâ–‚â–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1675
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.57066
wandb:   test_error_force 13.71356
wandb:          test_loss 6.7593
wandb: train_error_energy 1.78106
wandb:  train_error_force 3.0349
wandb:         train_loss 1.38816
wandb: valid_error_energy 1.24745
wandb:  valid_error_force 2.69103
wandb:         valid_loss 1.38646
wandb: 
wandb: ğŸš€ View run al_81_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7l1691zz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_194530-7l1691zz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7092325091362, Uncertainty Bias: 0.01908816397190094
9.7334385e-05 0.004422188
0.6374999 4.921032
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2692 steps.
Found uncertainty sample 3 after 713 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 12 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 366 steps.
Found uncertainty sample 8 after 543 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 351 steps.
Found uncertainty sample 12 after 2403 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3588 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2505 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3422 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1137 steps.
Found uncertainty sample 23 after 1289 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2059 steps.
Found uncertainty sample 26 after 1099 steps.
Found uncertainty sample 27 after 2100 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 176 steps.
Found uncertainty sample 30 after 2962 steps.
Found uncertainty sample 31 after 3420 steps.
Found uncertainty sample 32 after 3439 steps.
Found uncertainty sample 33 after 1153 steps.
Found uncertainty sample 34 after 3619 steps.
Found uncertainty sample 35 after 2991 steps.
Found uncertainty sample 36 after 1581 steps.
Found uncertainty sample 37 after 3092 steps.
Found uncertainty sample 38 after 166 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1829 steps.
Found uncertainty sample 41 after 67 steps.
Found uncertainty sample 42 after 986 steps.
Found uncertainty sample 43 after 75 steps.
Found uncertainty sample 44 after 3061 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 171 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1210 steps.
Found uncertainty sample 49 after 2114 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 503 steps.
Found uncertainty sample 52 after 871 steps.
Found uncertainty sample 53 after 22 steps.
Found uncertainty sample 54 after 813 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3230 steps.
Found uncertainty sample 57 after 1314 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 285 steps.
Found uncertainty sample 61 after 783 steps.
Found uncertainty sample 62 after 1729 steps.
Found uncertainty sample 63 after 851 steps.
Found uncertainty sample 64 after 2009 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1268 steps.
Found uncertainty sample 70 after 965 steps.
Found uncertainty sample 71 after 2398 steps.
Found uncertainty sample 72 after 215 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3428 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2034 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 168 steps.
Found uncertainty sample 82 after 1728 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 555 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 659 steps.
Found uncertainty sample 88 after 1116 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 516 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 339 steps.
Found uncertainty sample 93 after 2001 steps.
Found uncertainty sample 94 after 3318 steps.
Found uncertainty sample 95 after 1532 steps.
Found uncertainty sample 96 after 1294 steps.
Found uncertainty sample 97 after 3109 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3214 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_214815-jizcwg66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jizcwg66
Training model 13. Added 63 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.9474530424200154, Training Loss Force: 3.2966819677633055, time: 1.9771754741668701
Validation Loss Energy: 1.1549229579048677, Validation Loss Force: 2.733794164169196, time: 0.13916921615600586
Test Loss Energy: 9.268740148929565, Test Loss Force: 13.574228729576848, time: 18.071900844573975


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.92020014289887, Training Loss Force: 3.056095510145173, time: 1.9417438507080078
Validation Loss Energy: 1.3201571583357607, Validation Loss Force: 2.7525131799253337, time: 0.13641357421875
Test Loss Energy: 9.253927315992321, Test Loss Force: 13.319369202893707, time: 18.158828496932983


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6773110423879158, Training Loss Force: 3.0601917762874886, time: 1.9477818012237549
Validation Loss Energy: 1.2528422158321906, Validation Loss Force: 2.857122588009344, time: 0.14503145217895508
Test Loss Energy: 9.350361378002598, Test Loss Force: 13.613619129989655, time: 18.551884651184082


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7753898366855008, Training Loss Force: 3.0566894011456016, time: 1.9287686347961426
Validation Loss Energy: 2.2526766146039323, Validation Loss Force: 2.721231616294242, time: 0.13581252098083496
Test Loss Energy: 9.537133077285203, Test Loss Force: 13.809833348732544, time: 18.022897243499756


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9296827655598554, Training Loss Force: 3.063096130928424, time: 1.9284462928771973
Validation Loss Energy: 1.2943791409827061, Validation Loss Force: 2.7929687123686513, time: 0.13161206245422363
Test Loss Energy: 9.555643537738424, Test Loss Force: 13.589413371023896, time: 18.232157468795776


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7261748340451033, Training Loss Force: 3.0384249158685153, time: 1.9775214195251465
Validation Loss Energy: 1.121076691050979, Validation Loss Force: 2.690971992708385, time: 0.13132786750793457
Test Loss Energy: 9.268177283297712, Test Loss Force: 13.245861948896945, time: 18.165922164916992


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8887277467490549, Training Loss Force: 3.0655698191499545, time: 1.9927127361297607
Validation Loss Energy: 1.2005461958868768, Validation Loss Force: 2.817648358492131, time: 0.134002685546875
Test Loss Energy: 9.25135132076247, Test Loss Force: 13.530859910026013, time: 18.07324719429016


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6958524865851043, Training Loss Force: 3.0828811671236322, time: 1.9422516822814941
Validation Loss Energy: 1.2176892150954248, Validation Loss Force: 2.845482001733104, time: 0.13314294815063477
Test Loss Energy: 9.279003126083518, Test Loss Force: 13.270084803257237, time: 18.120712518692017


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.636713231445278, Training Loss Force: 3.075517004547149, time: 1.976794719696045
Validation Loss Energy: 1.2433011212656173, Validation Loss Force: 2.720756329002259, time: 0.14079904556274414
Test Loss Energy: 9.161945671612362, Test Loss Force: 13.33852053079666, time: 18.14562749862671


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7436149151491012, Training Loss Force: 3.0626605293510405, time: 1.9744784832000732
Validation Loss Energy: 1.1820357097858998, Validation Loss Force: 2.760146389582312, time: 0.13750362396240234
Test Loss Energy: 9.220797019626827, Test Loss Force: 13.420798435662988, time: 18.049667596817017


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7557445395492173, Training Loss Force: 3.062564376765298, time: 1.9923555850982666
Validation Loss Energy: 1.2398569305836928, Validation Loss Force: 2.7390902384705154, time: 0.14269709587097168
Test Loss Energy: 9.182319171001158, Test Loss Force: 13.085088483546748, time: 18.202948570251465


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9119190803982131, Training Loss Force: 3.073204249438704, time: 1.9709393978118896
Validation Loss Energy: 2.134741126143582, Validation Loss Force: 2.6728754485496875, time: 0.13245177268981934
Test Loss Energy: 9.500427577133326, Test Loss Force: 13.195863469128208, time: 18.220489263534546


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7189456727353996, Training Loss Force: 3.047524278371264, time: 1.9672505855560303
Validation Loss Energy: 1.4964104754566092, Validation Loss Force: 2.7749831687791993, time: 0.12909197807312012
Test Loss Energy: 9.138219898723886, Test Loss Force: 13.307300451246311, time: 18.289825916290283


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8173535072541869, Training Loss Force: 3.0574894513869197, time: 1.9384136199951172
Validation Loss Energy: 1.1294961454622277, Validation Loss Force: 2.785590347549188, time: 0.1420726776123047
Test Loss Energy: 9.169429845079389, Test Loss Force: 13.363087811190848, time: 18.577922821044922


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8667067226577267, Training Loss Force: 3.0569181349893584, time: 1.9782633781433105
Validation Loss Energy: 2.223897518169349, Validation Loss Force: 2.7878819470645038, time: 0.13913941383361816
Test Loss Energy: 9.386606048618583, Test Loss Force: 13.597885468035244, time: 19.1246657371521


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.878687676941902, Training Loss Force: 3.0701601719329656, time: 1.9560577869415283
Validation Loss Energy: 1.6549215706972182, Validation Loss Force: 2.7050649456233007, time: 0.13440632820129395
Test Loss Energy: 9.19648323231689, Test Loss Force: 12.856726762431679, time: 18.553213357925415


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6744150084881118, Training Loss Force: 3.0381871619000833, time: 1.9370899200439453
Validation Loss Energy: 1.4455953166662883, Validation Loss Force: 2.7516602457618577, time: 0.13927531242370605
Test Loss Energy: 9.246823307540009, Test Loss Force: 12.88198946538216, time: 18.647939205169678


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7920761594514865, Training Loss Force: 3.058002679477104, time: 1.969641923904419
Validation Loss Energy: 1.199720204690058, Validation Loss Force: 2.733613022818983, time: 0.14061617851257324
Test Loss Energy: 9.309131711791515, Test Loss Force: 13.362102503717539, time: 18.727511882781982


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5955119496682741, Training Loss Force: 3.033405443204532, time: 1.9956345558166504
Validation Loss Energy: 2.730833666539513, Validation Loss Force: 2.738792084484118, time: 0.13422179222106934
Test Loss Energy: 9.436721631373553, Test Loss Force: 13.315595215016168, time: 18.573004961013794


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9509105621949223, Training Loss Force: 3.063066447107007, time: 1.9710543155670166
Validation Loss Energy: 1.3330617260188597, Validation Loss Force: 2.7263965384686095, time: 0.14085674285888672
Test Loss Energy: 9.280062970596168, Test Loss Force: 13.295946833620762, time: 18.646451234817505

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–…â–ˆâ–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–‡â–â–‚â–…â–‚â–ƒâ–„â–†â–ƒ
wandb:   test_error_force â–†â–„â–‡â–ˆâ–†â–„â–†â–„â–…â–…â–ƒâ–ƒâ–„â–…â–†â–â–â–…â–„â–„
wandb:          test_loss â–‡â–…â–†â–ˆâ–‡â–„â–‡â–„â–„â–…â–‚â–ƒâ–„â–„â–†â–â–â–…â–…â–„
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–‚â–‚â–â–‚â–â–‚
wandb: valid_error_energy â–â–‚â–‚â–†â–‚â–â–â–â–‚â–â–‚â–…â–ƒâ–â–†â–ƒâ–‚â–â–ˆâ–‚
wandb:  valid_error_force â–ƒâ–„â–ˆâ–ƒâ–†â–‚â–‡â–ˆâ–ƒâ–„â–„â–â–…â–…â–…â–‚â–„â–ƒâ–„â–ƒ
wandb:         valid_loss â–†â–ƒâ–„â–…â–„â–…â–†â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–„â–…â–†â–„â–„â–ˆâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1731
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.28006
wandb:   test_error_force 13.29595
wandb:          test_loss 6.53583
wandb: train_error_energy 1.95091
wandb:  train_error_force 3.06307
wandb:         train_loss 1.41835
wandb: valid_error_energy 1.33306
wandb:  valid_error_force 2.7264
wandb:         valid_loss 1.34174
wandb: 
wandb: ğŸš€ View run al_81_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jizcwg66
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_214815-jizcwg66/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7096656560897827, Uncertainty Bias: 0.02367711067199707
9.012222e-05 0.019313812
0.41478527 3.6343458
(48745, 22, 3)
Found uncertainty sample 0 after 3148 steps.
Found uncertainty sample 1 after 496 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3076 steps.
Found uncertainty sample 4 after 423 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2520 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1432 steps.
Found uncertainty sample 11 after 891 steps.
Found uncertainty sample 12 after 873 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3575 steps.
Found uncertainty sample 15 after 3046 steps.
Found uncertainty sample 16 after 215 steps.
Found uncertainty sample 17 after 406 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 266 steps.
Found uncertainty sample 20 after 430 steps.
Found uncertainty sample 21 after 1212 steps.
Found uncertainty sample 22 after 948 steps.
Found uncertainty sample 23 after 907 steps.
Found uncertainty sample 24 after 1996 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2308 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2 steps.
Found uncertainty sample 29 after 2296 steps.
Found uncertainty sample 30 after 219 steps.
Found uncertainty sample 31 after 340 steps.
Found uncertainty sample 32 after 140 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3257 steps.
Found uncertainty sample 36 after 644 steps.
Found uncertainty sample 37 after 592 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1214 steps.
Found uncertainty sample 41 after 152 steps.
Found uncertainty sample 42 after 1835 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2811 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2357 steps.
Found uncertainty sample 48 after 730 steps.
Found uncertainty sample 49 after 1135 steps.
Found uncertainty sample 50 after 648 steps.
Found uncertainty sample 51 after 591 steps.
Found uncertainty sample 52 after 393 steps.
Found uncertainty sample 53 after 16 steps.
Found uncertainty sample 54 after 1622 steps.
Found uncertainty sample 55 after 1413 steps.
Found uncertainty sample 56 after 3856 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3947 steps.
Found uncertainty sample 59 after 3039 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3375 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1501 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3132 steps.
Found uncertainty sample 70 after 3426 steps.
Found uncertainty sample 71 after 1876 steps.
Found uncertainty sample 72 after 3178 steps.
Found uncertainty sample 73 after 1219 steps.
Found uncertainty sample 74 after 899 steps.
Found uncertainty sample 75 after 590 steps.
Found uncertainty sample 76 after 2068 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2201 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 493 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 129 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 781 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1167 steps.
Found uncertainty sample 89 after 855 steps.
Found uncertainty sample 90 after 854 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1713 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2689 steps.
Found uncertainty sample 98 after 1328 steps.
Found uncertainty sample 99 after 207 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_234643-s4z5tf2j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/s4z5tf2j
Training model 14. Added 64 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.134818758153313, Training Loss Force: 3.378392295235302, time: 1.977989912033081
Validation Loss Energy: 1.9925033600948137, Validation Loss Force: 2.723747220970361, time: 0.1404421329498291
Test Loss Energy: 9.254023798183509, Test Loss Force: 13.209282309273833, time: 18.08270525932312


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.686566786841606, Training Loss Force: 3.0919659348928836, time: 2.000375747680664
Validation Loss Energy: 1.5049975997347416, Validation Loss Force: 2.7542532279661867, time: 0.13992762565612793
Test Loss Energy: 9.141212530076103, Test Loss Force: 13.138099264164197, time: 18.270122289657593


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8733637564179813, Training Loss Force: 3.059730826430468, time: 2.048618793487549
Validation Loss Energy: 1.470152439092221, Validation Loss Force: 2.732434101025869, time: 0.13834500312805176
Test Loss Energy: 9.043561463436818, Test Loss Force: 13.124480194326674, time: 18.262611627578735


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9501882380891584, Training Loss Force: 3.0704405960332086, time: 2.058587074279785
Validation Loss Energy: 1.2651724641206554, Validation Loss Force: 2.778788918486824, time: 0.14060401916503906
Test Loss Energy: 9.122173996336532, Test Loss Force: 12.985519557061322, time: 18.619250059127808


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0039747078795616, Training Loss Force: 3.0843325144954647, time: 2.0300865173339844
Validation Loss Energy: 1.3092739811593943, Validation Loss Force: 2.7810006911133245, time: 0.13393354415893555
Test Loss Energy: 9.018764780195204, Test Loss Force: 13.030936429126049, time: 18.189168214797974


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5586940475704338, Training Loss Force: 3.06995060860136, time: 1.9661564826965332
Validation Loss Energy: 1.6218759664247995, Validation Loss Force: 2.773126887444172, time: 0.13016414642333984
Test Loss Energy: 9.114839155757354, Test Loss Force: 13.13128933287104, time: 18.211446046829224


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6608717296503488, Training Loss Force: 3.056879369086299, time: 1.9873967170715332
Validation Loss Energy: 1.1990017070234353, Validation Loss Force: 2.7141838038219084, time: 0.14136385917663574
Test Loss Energy: 9.01077986229062, Test Loss Force: 12.973889298086808, time: 18.0787456035614


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6072696140078346, Training Loss Force: 3.071064749577949, time: 1.9680709838867188
Validation Loss Energy: 1.3192848519565885, Validation Loss Force: 2.781471413687816, time: 0.13091206550598145
Test Loss Energy: 9.013023231785507, Test Loss Force: 13.15337249295711, time: 18.268292665481567


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7860888699664277, Training Loss Force: 3.0560124584576807, time: 2.0196919441223145
Validation Loss Energy: 1.2369333403649474, Validation Loss Force: 2.7763467946288607, time: 0.13739752769470215
Test Loss Energy: 9.02498611183176, Test Loss Force: 13.075423504785807, time: 18.18222975730896


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7254163558441493, Training Loss Force: 3.058092204185585, time: 1.9820842742919922
Validation Loss Energy: 1.368663627753816, Validation Loss Force: 2.78059521059859, time: 0.14234471321105957
Test Loss Energy: 9.049114393592808, Test Loss Force: 12.640822104638369, time: 18.103947401046753


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8502711697212215, Training Loss Force: 3.079743140372268, time: 2.013573169708252
Validation Loss Energy: 1.240198505053546, Validation Loss Force: 2.7055195246847124, time: 0.13919472694396973
Test Loss Energy: 9.084808374265736, Test Loss Force: 12.999874027310385, time: 18.19306707382202


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7080334126189816, Training Loss Force: 3.0682020275607362, time: 2.0013678073883057
Validation Loss Energy: 1.237697485206485, Validation Loss Force: 2.7633439185178346, time: 0.13631391525268555
Test Loss Energy: 8.88893853259284, Test Loss Force: 12.976800145743079, time: 18.180623054504395


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.779377640795279, Training Loss Force: 3.0500392949984123, time: 1.9456682205200195
Validation Loss Energy: 1.2366827262412057, Validation Loss Force: 2.763735704880095, time: 0.13219499588012695
Test Loss Energy: 8.910696521114206, Test Loss Force: 12.979396910991273, time: 18.078355073928833


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.78389170900857, Training Loss Force: 3.0567069794287685, time: 1.9691741466522217
Validation Loss Energy: 2.72155159185694, Validation Loss Force: 2.862405302161908, time: 0.13332056999206543
Test Loss Energy: 9.142492026626046, Test Loss Force: 12.907703312343589, time: 18.368958234786987


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.091094745833179, Training Loss Force: 3.0762382803005477, time: 2.050128221511841
Validation Loss Energy: 1.3250411277152543, Validation Loss Force: 2.8301877487759084, time: 0.14216995239257812
Test Loss Energy: 8.89780355787445, Test Loss Force: 12.67183841976986, time: 18.567098379135132


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9636262136875626, Training Loss Force: 3.0786827262796033, time: 1.9569551944732666
Validation Loss Energy: 1.3511469140511148, Validation Loss Force: 2.657991018155572, time: 0.13109493255615234
Test Loss Energy: 9.015929824246063, Test Loss Force: 12.740917122538164, time: 18.936514139175415


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8745260108290878, Training Loss Force: 3.0536471952174105, time: 2.0007152557373047
Validation Loss Energy: 2.2535668458493516, Validation Loss Force: 2.745806607919135, time: 0.13776683807373047
Test Loss Energy: 9.329352732945054, Test Loss Force: 12.760178917653644, time: 18.47798180580139


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7816664986967357, Training Loss Force: 3.048268284017571, time: 1.9609858989715576
Validation Loss Energy: 1.4958107161120529, Validation Loss Force: 2.7490848544200572, time: 0.13762593269348145
Test Loss Energy: 8.979664276357482, Test Loss Force: 12.486602703913936, time: 18.639573335647583


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5909006106435881, Training Loss Force: 3.0565624472718875, time: 2.060548782348633
Validation Loss Energy: 1.53449023944745, Validation Loss Force: 2.813219469179627, time: 0.13778018951416016
Test Loss Energy: 8.92968816842597, Test Loss Force: 12.80046812265689, time: 18.50835680961609


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7091169345998876, Training Loss Force: 3.052097354341998, time: 2.013932228088379
Validation Loss Energy: 1.198142649458446, Validation Loss Force: 2.754574428209188, time: 0.13920378684997559
Test Loss Energy: 8.989841781202001, Test Loss Force: 13.00953581176002, time: 18.72988510131836

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–…â–ƒâ–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–„â–â–â–…â–â–ƒâ–ˆâ–‚â–‚â–ƒ
wandb:   test_error_force â–ˆâ–‡â–‡â–†â–†â–‡â–†â–‡â–‡â–‚â–†â–†â–†â–…â–ƒâ–ƒâ–„â–â–„â–†
wandb:          test_loss â–ˆâ–‡â–‡â–†â–†â–‡â–†â–‡â–†â–ƒâ–…â–…â–…â–…â–ƒâ–„â–„â–â–ƒâ–…
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–ƒâ–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–â–â–
wandb: valid_error_energy â–…â–‚â–‚â–â–‚â–ƒâ–â–‚â–â–‚â–â–â–â–ˆâ–‚â–‚â–†â–‚â–ƒâ–
wandb:  valid_error_force â–ƒâ–„â–„â–…â–…â–…â–ƒâ–…â–…â–…â–ƒâ–…â–…â–ˆâ–‡â–â–„â–„â–†â–„
wandb:         valid_loss â–…â–‚â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–â–‚â–â–ˆâ–ˆâ–‚â–„â–„â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1788
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.98984
wandb:   test_error_force 13.00954
wandb:          test_loss 6.37825
wandb: train_error_energy 1.70912
wandb:  train_error_force 3.0521
wandb:         train_loss 1.38307
wandb: valid_error_energy 1.19814
wandb:  valid_error_force 2.75457
wandb:         valid_loss 1.34645
wandb: 
wandb: ğŸš€ View run al_81_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/s4z5tf2j
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_234643-s4z5tf2j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.745104193687439, Uncertainty Bias: 0.01504497230052948
3.8146973e-05 0.0023860931
0.37357113 3.4082303
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2113 steps.
Found uncertainty sample 2 after 3448 steps.
Found uncertainty sample 3 after 1478 steps.
Found uncertainty sample 4 after 703 steps.
Found uncertainty sample 5 after 3292 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3884 steps.
Found uncertainty sample 8 after 690 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1054 steps.
Found uncertainty sample 11 after 89 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 799 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 280 steps.
Found uncertainty sample 17 after 359 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2452 steps.
Found uncertainty sample 20 after 316 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3404 steps.
Found uncertainty sample 23 after 917 steps.
Found uncertainty sample 24 after 1146 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3209 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1139 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1045 steps.
Found uncertainty sample 34 after 2812 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1473 steps.
Found uncertainty sample 37 after 2412 steps.
Found uncertainty sample 38 after 1377 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2242 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 14 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 894 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 627 steps.
Found uncertainty sample 49 after 2340 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1663 steps.
Found uncertainty sample 54 after 14 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2773 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1906 steps.
Found uncertainty sample 60 after 3639 steps.
Found uncertainty sample 61 after 787 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1539 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2639 steps.
Found uncertainty sample 66 after 3442 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1160 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 15 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 479 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3156 steps.
Found uncertainty sample 79 after 539 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 828 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1642 steps.
Found uncertainty sample 84 after 3233 steps.
Found uncertainty sample 85 after 2754 steps.
Found uncertainty sample 86 after 531 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2516 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3897 steps.
Found uncertainty sample 92 after 1207 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2595 steps.
Found uncertainty sample 95 after 1451 steps.
Found uncertainty sample 96 after 3167 steps.
Found uncertainty sample 97 after 2689 steps.
Found uncertainty sample 98 after 1298 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_020054-6qjf17f1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/6qjf17f1
Training model 15. Added 56 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9764737646691475, Training Loss Force: 3.328878239842343, time: 2.079338550567627
Validation Loss Energy: 1.5092992336303475, Validation Loss Force: 2.75053231520316, time: 0.1355752944946289
Test Loss Energy: 9.180361251693279, Test Loss Force: 12.783981008934623, time: 18.14799189567566


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9328813534477123, Training Loss Force: 3.0761480336200178, time: 2.0806057453155518
Validation Loss Energy: 1.2630947383200033, Validation Loss Force: 2.7331468649619834, time: 0.14184308052062988
Test Loss Energy: 8.902661839570023, Test Loss Force: 13.134335423471189, time: 18.25417470932007


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7221994407075532, Training Loss Force: 3.082082189393732, time: 2.029595136642456
Validation Loss Energy: 1.1997376285507266, Validation Loss Force: 2.7054592926807386, time: 0.13837575912475586
Test Loss Energy: 8.826215147664975, Test Loss Force: 12.664516680530273, time: 18.277414560317993


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7052392501438662, Training Loss Force: 3.0617327210468934, time: 2.042734146118164
Validation Loss Energy: 1.2800457610574751, Validation Loss Force: 2.6719264326497436, time: 0.13243436813354492
Test Loss Energy: 9.003984380010001, Test Loss Force: 12.883883650018792, time: 18.18354344367981


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.660740570050818, Training Loss Force: 3.075831877984909, time: 2.055572271347046
Validation Loss Energy: 1.1637963790373764, Validation Loss Force: 2.734789940589785, time: 0.13396143913269043
Test Loss Energy: 8.85113583780215, Test Loss Force: 12.65358874568977, time: 18.26562762260437


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.028954669758582, Training Loss Force: 3.0624857689028047, time: 2.0643723011016846
Validation Loss Energy: 1.3422494446508457, Validation Loss Force: 2.7816603484581357, time: 0.13419747352600098
Test Loss Energy: 8.886026122755126, Test Loss Force: 12.740253591799439, time: 18.285269260406494


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5763917085419579, Training Loss Force: 3.0639111624057223, time: 2.0499961376190186
Validation Loss Energy: 1.3877813882830246, Validation Loss Force: 2.725067203667421, time: 0.1304621696472168
Test Loss Energy: 8.847305919165736, Test Loss Force: 12.453689037813874, time: 18.098082542419434


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6988801552594492, Training Loss Force: 3.0635457277851463, time: 2.0377163887023926
Validation Loss Energy: 1.7225967918788996, Validation Loss Force: 2.7901433749105466, time: 0.14357566833496094
Test Loss Energy: 8.989839561505384, Test Loss Force: 12.78473736589364, time: 18.267847537994385


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9449706401279552, Training Loss Force: 3.0691157695966673, time: 2.0928046703338623
Validation Loss Energy: 1.243836807563433, Validation Loss Force: 2.743078242874082, time: 0.1412649154663086
Test Loss Energy: 8.856569186466125, Test Loss Force: 12.686385901033583, time: 18.918577671051025


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.306311236993854, Training Loss Force: 3.085525134280176, time: 2.2437632083892822
Validation Loss Energy: 2.1225798280695902, Validation Loss Force: 2.80199482886798, time: 0.1311795711517334
Test Loss Energy: 8.875168416131116, Test Loss Force: 12.481882080714444, time: 19.183329820632935


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.853850692066987, Training Loss Force: 3.08431991065398, time: 2.1474034786224365
Validation Loss Energy: 1.2155676791403114, Validation Loss Force: 2.672397600562527, time: 0.14303016662597656
Test Loss Energy: 8.824437634665966, Test Loss Force: 12.478628098738492, time: 18.86654019355774


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9999002323674706, Training Loss Force: 3.062344830850802, time: 2.208756685256958
Validation Loss Energy: 1.1010561184696064, Validation Loss Force: 2.731487645821103, time: 0.14236760139465332
Test Loss Energy: 8.733176885726273, Test Loss Force: 12.553043712280244, time: 18.86748170852661


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9770756822497284, Training Loss Force: 3.075151712043933, time: 2.198403835296631
Validation Loss Energy: 1.3565455831614204, Validation Loss Force: 2.7415394877411483, time: 0.1487722396850586
Test Loss Energy: 8.78054798149054, Test Loss Force: 12.510836474891416, time: 18.775257349014282


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6978277018629748, Training Loss Force: 3.066197068501324, time: 2.35602068901062
Validation Loss Energy: 2.139012811039061, Validation Loss Force: 2.7504527109834913, time: 0.14359402656555176
Test Loss Energy: 9.040426048700745, Test Loss Force: 12.424909570652648, time: 18.764153480529785


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8607971996757313, Training Loss Force: 3.0578228658353006, time: 2.203138828277588
Validation Loss Energy: 1.513122295864068, Validation Loss Force: 2.7357381771477183, time: 0.1404414176940918
Test Loss Energy: 8.82175656991022, Test Loss Force: 12.766903026895244, time: 19.138899326324463


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.913380055872232, Training Loss Force: 3.053316073034708, time: 2.1591124534606934
Validation Loss Energy: 1.5360441360823072, Validation Loss Force: 2.7232484420834826, time: 0.14206242561340332
Test Loss Energy: 8.713523440065055, Test Loss Force: 12.594398255078948, time: 19.243699550628662


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7127553281518393, Training Loss Force: 3.0565809248347655, time: 2.247770071029663
Validation Loss Energy: 1.1780669105961694, Validation Loss Force: 2.752017852410218, time: 0.15437889099121094
Test Loss Energy: 8.759867287281702, Test Loss Force: 12.731785407236544, time: 19.042579889297485


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7593402655370833, Training Loss Force: 3.057261866278628, time: 2.2669575214385986
Validation Loss Energy: 1.2695718497713235, Validation Loss Force: 2.7173753206904916, time: 0.14758658409118652
Test Loss Energy: 8.719166722598782, Test Loss Force: 12.634604384672047, time: 19.210346221923828


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.708404286660138, Training Loss Force: 3.0427689458299017, time: 2.1016712188720703
Validation Loss Energy: 2.6400419923060516, Validation Loss Force: 2.782803420518756, time: 0.1401207447052002
Test Loss Energy: 9.119904962765316, Test Loss Force: 12.664126615482118, time: 19.154296398162842


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0130950703974637, Training Loss Force: 3.0556881098594286, time: 2.0690841674804688
Validation Loss Energy: 1.8152610022950404, Validation Loss Force: 2.7377835045876378, time: 0.14033937454223633
Test Loss Energy: 8.673280055941975, Test Loss Force: 12.445649324646478, time: 18.31271266937256

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–ƒâ–†â–ƒâ–„â–ƒâ–…â–„â–„â–ƒâ–‚â–‚â–†â–ƒâ–‚â–‚â–‚â–‡â–
wandb:   test_error_force â–…â–ˆâ–ƒâ–†â–ƒâ–„â–â–…â–„â–‚â–‚â–‚â–‚â–â–„â–ƒâ–„â–ƒâ–ƒâ–
wandb:          test_loss â–…â–ˆâ–ƒâ–†â–ƒâ–„â–‚â–…â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–â–‚â–ƒâ–…â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–â–â–‚â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–ƒâ–‚â–â–‚â–â–‚â–‚â–„â–‚â–†â–‚â–â–‚â–†â–ƒâ–ƒâ–â–‚â–ˆâ–„
wandb:  valid_error_force â–…â–„â–ƒâ–â–„â–‡â–„â–‡â–…â–ˆâ–â–„â–…â–…â–„â–„â–…â–ƒâ–‡â–…
wandb:         valid_loss â–ƒâ–…â–‚â–‚â–â–ƒâ–‚â–ƒâ–„â–ˆâ–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–‚â–â–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1838
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.67328
wandb:   test_error_force 12.44565
wandb:          test_loss 6.13281
wandb: train_error_energy 2.0131
wandb:  train_error_force 3.05569
wandb:         train_loss 1.40459
wandb: valid_error_energy 1.81526
wandb:  valid_error_force 2.73778
wandb:         valid_loss 1.36415
wandb: 
wandb: ğŸš€ View run al_81_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/6qjf17f1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_020054-6qjf17f1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7358468174934387, Uncertainty Bias: 0.017352402210235596
0.00012350082 0.0041594505
0.296911 3.2238884
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 449 steps.
Found uncertainty sample 3 after 1512 steps.
Found uncertainty sample 4 after 671 steps.
Found uncertainty sample 5 after 2618 steps.
Found uncertainty sample 6 after 3365 steps.
Found uncertainty sample 7 after 317 steps.
Found uncertainty sample 8 after 19 steps.
Found uncertainty sample 9 after 2443 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3134 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1020 steps.
Found uncertainty sample 16 after 1879 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 197 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 99 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 213 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3851 steps.
Found uncertainty sample 25 after 555 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1674 steps.
Found uncertainty sample 28 after 877 steps.
Found uncertainty sample 29 after 2273 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 268 steps.
Found uncertainty sample 32 after 3557 steps.
Found uncertainty sample 33 after 1230 steps.
Found uncertainty sample 34 after 1364 steps.
Found uncertainty sample 35 after 2200 steps.
Found uncertainty sample 36 after 1373 steps.
Found uncertainty sample 37 after 605 steps.
Found uncertainty sample 38 after 3930 steps.
Found uncertainty sample 39 after 2619 steps.
Found uncertainty sample 40 after 584 steps.
Found uncertainty sample 41 after 2991 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 314 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1128 steps.
Found uncertainty sample 51 after 122 steps.
Found uncertainty sample 52 after 3242 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3123 steps.
Found uncertainty sample 55 after 491 steps.
Found uncertainty sample 56 after 2543 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2531 steps.
Found uncertainty sample 59 after 85 steps.
Found uncertainty sample 60 after 751 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 235 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 738 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2414 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2868 steps.
Found uncertainty sample 74 after 3650 steps.
Found uncertainty sample 75 after 2917 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 10 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3247 steps.
Found uncertainty sample 84 after 685 steps.
Found uncertainty sample 85 after 777 steps.
Found uncertainty sample 86 after 37 steps.
Found uncertainty sample 87 after 2892 steps.
Found uncertainty sample 88 after 3593 steps.
Found uncertainty sample 89 after 1882 steps.
Found uncertainty sample 90 after 3756 steps.
Found uncertainty sample 91 after 3858 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 386 steps.
Found uncertainty sample 94 after 3343 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2436 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 301 steps.
Found uncertainty sample 99 after 285 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_040901-2wl15ulx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2wl15ulx
Training model 16. Added 61 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.221733832471633, Training Loss Force: 3.328831074678112, time: 2.1507728099823
Validation Loss Energy: 2.2890598623719494, Validation Loss Force: 2.7886721998634014, time: 0.1448216438293457
Test Loss Energy: 9.081318332684114, Test Loss Force: 12.488247890818304, time: 18.24899172782898


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.805513881245621, Training Loss Force: 3.0831964156902645, time: 2.147545337677002
Validation Loss Energy: 2.28265266903245, Validation Loss Force: 2.7948308944360454, time: 0.14114809036254883
Test Loss Energy: 8.834838846224681, Test Loss Force: 12.658511529157625, time: 18.31912088394165


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0576038783534707, Training Loss Force: 3.0816204339872835, time: 2.08731746673584
Validation Loss Energy: 1.463252757269216, Validation Loss Force: 2.777653862515457, time: 0.14610743522644043
Test Loss Energy: 8.713992749681408, Test Loss Force: 12.417496898463414, time: 18.35253381729126


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9089014035248095, Training Loss Force: 3.068665606166796, time: 2.1805176734924316
Validation Loss Energy: 1.261143599928811, Validation Loss Force: 2.7256027229633775, time: 0.14549827575683594
Test Loss Energy: 8.735508821582503, Test Loss Force: 12.446086553584516, time: 18.77405858039856


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9687460541075965, Training Loss Force: 3.088889152808139, time: 2.129206657409668
Validation Loss Energy: 1.5146354440452203, Validation Loss Force: 2.7550308999583395, time: 0.1378462314605713
Test Loss Energy: 8.790342479082764, Test Loss Force: 12.233507700807694, time: 18.36571979522705


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7834777428112583, Training Loss Force: 3.066248384141653, time: 2.0734589099884033
Validation Loss Energy: 2.083666056792677, Validation Loss Force: 2.743750258356492, time: 0.13374614715576172
Test Loss Energy: 8.95784581042976, Test Loss Force: 12.396205330688534, time: 18.33724331855774


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7235259438354509, Training Loss Force: 3.0638012205386866, time: 2.117478847503662
Validation Loss Energy: 1.3077894459634938, Validation Loss Force: 2.7286283513182443, time: 0.13756203651428223
Test Loss Energy: 8.595299327508013, Test Loss Force: 12.286143982232673, time: 18.211917877197266


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7219658291646938, Training Loss Force: 3.076604833742175, time: 2.131272315979004
Validation Loss Energy: 1.3200856258726312, Validation Loss Force: 2.7959011536859473, time: 0.14250993728637695
Test Loss Energy: 8.679263868382439, Test Loss Force: 12.283027654089569, time: 18.334623098373413


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7102702259814355, Training Loss Force: 3.088327855847389, time: 2.104156732559204
Validation Loss Energy: 1.1672572699052455, Validation Loss Force: 2.717364187233195, time: 0.1354203224182129
Test Loss Energy: 8.697962574031113, Test Loss Force: 12.692205908257524, time: 18.332361936569214


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5954915671756733, Training Loss Force: 3.0768822275418666, time: 2.1021344661712646
Validation Loss Energy: 1.4383684225333426, Validation Loss Force: 2.796241169471779, time: 0.1416301727294922
Test Loss Energy: 8.62415647239276, Test Loss Force: 12.419890528828558, time: 18.334253072738647


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6481779762343565, Training Loss Force: 3.067776016950747, time: 2.2644262313842773
Validation Loss Energy: 1.683724325728556, Validation Loss Force: 2.7996254064861628, time: 0.1416778564453125
Test Loss Energy: 8.660110745136631, Test Loss Force: 12.615016863067707, time: 19.102478981018066


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3213977591534425, Training Loss Force: 3.1208330012799643, time: 2.308032274246216
Validation Loss Energy: 1.579904836439725, Validation Loss Force: 2.8663250584722477, time: 0.14444541931152344
Test Loss Energy: 8.52654709734508, Test Loss Force: 12.127855308695443, time: 19.050196886062622


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.145832743907452, Training Loss Force: 3.0892033204172815, time: 2.1914148330688477
Validation Loss Energy: 1.9112013438552167, Validation Loss Force: 2.7633050627518703, time: 0.15241384506225586
Test Loss Energy: 8.771418338993847, Test Loss Force: 12.027823370283336, time: 19.160208225250244


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7480828083362892, Training Loss Force: 3.0647688070454016, time: 2.4504950046539307
Validation Loss Energy: 1.9760645320602623, Validation Loss Force: 2.8541037510634277, time: 0.147385835647583
Test Loss Energy: 8.670366333405521, Test Loss Force: 12.109761302498688, time: 19.79773736000061


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7920088806437993, Training Loss Force: 3.0803853550355655, time: 2.263767719268799
Validation Loss Energy: 1.1581899039466337, Validation Loss Force: 2.7258342988751423, time: 0.14537811279296875
Test Loss Energy: 8.57784230429191, Test Loss Force: 12.20790765526694, time: 19.55985951423645


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7978512996727194, Training Loss Force: 3.0777980731613725, time: 2.2651171684265137
Validation Loss Energy: 2.7073000985101237, Validation Loss Force: 2.706082098281899, time: 0.1402597427368164
Test Loss Energy: 8.780116518634156, Test Loss Force: 12.310309926556172, time: 19.337083339691162


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7653457228186737, Training Loss Force: 3.0652352321053757, time: 2.2763431072235107
Validation Loss Energy: 1.3778918721703608, Validation Loss Force: 2.812133289085791, time: 0.14429688453674316
Test Loss Energy: 8.450947441202755, Test Loss Force: 11.924572550013837, time: 19.425833225250244


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.063057069859733, Training Loss Force: 3.07476729372693, time: 2.3529131412506104
Validation Loss Energy: 1.2191233713970593, Validation Loss Force: 2.7988089900626183, time: 0.14371681213378906
Test Loss Energy: 8.348534423504166, Test Loss Force: 11.849274723647524, time: 19.489874124526978


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8666555109471175, Training Loss Force: 3.0752238730995027, time: 2.320142984390259
Validation Loss Energy: 1.1937253946088169, Validation Loss Force: 2.7227772741706993, time: 0.14469027519226074
Test Loss Energy: 8.430480719219274, Test Loss Force: 12.085577651897761, time: 19.462088584899902


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0039457485642633, Training Loss Force: 3.0606667218160704, time: 2.314246892929077
Validation Loss Energy: 1.74920987419647, Validation Loss Force: 2.7871092851281345, time: 0.14202189445495605
Test Loss Energy: 8.531896521891376, Test Loss Force: 11.770923000437078, time: 19.242412090301514

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–„â–…â–…â–‡â–ƒâ–„â–„â–„â–„â–ƒâ–…â–„â–ƒâ–…â–‚â–â–‚â–ƒ
wandb:   test_error_force â–†â–ˆâ–†â–†â–…â–†â–…â–…â–ˆâ–†â–‡â–„â–ƒâ–„â–„â–…â–‚â–‚â–ƒâ–
wandb:          test_loss â–†â–‡â–†â–…â–„â–…â–„â–…â–ˆâ–…â–†â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–â–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–â–â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–â–â–â–‚â–â–â–ƒâ–‚â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–ƒâ–ƒâ–â–‚â–â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–†â–†â–‚â–â–ƒâ–…â–‚â–‚â–â–‚â–ƒâ–ƒâ–„â–…â–â–ˆâ–‚â–â–â–„
wandb:  valid_error_force â–…â–…â–„â–‚â–ƒâ–ƒâ–‚â–…â–â–…â–…â–ˆâ–ƒâ–‡â–‚â–â–†â–…â–‚â–…
wandb:         valid_loss â–„â–…â–„â–â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ˆâ–ƒâ–„â–â–ƒâ–ƒâ–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1892
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.5319
wandb:   test_error_force 11.77092
wandb:          test_loss 5.89194
wandb: train_error_energy 2.00395
wandb:  train_error_force 3.06067
wandb:         train_loss 1.40314
wandb: valid_error_energy 1.74921
wandb:  valid_error_force 2.78711
wandb:         valid_loss 1.42685
wandb: 
wandb: ğŸš€ View run al_81_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2wl15ulx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_040901-2wl15ulx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7513902187347412, Uncertainty Bias: 0.011347725987434387
0.0002593994 0.013463974
0.55725414 4.901835
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2869 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3196 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1254 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 481 steps.
Found uncertainty sample 10 after 1644 steps.
Found uncertainty sample 11 after 3916 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 462 steps.
Found uncertainty sample 14 after 856 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 25 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1093 steps.
Found uncertainty sample 22 after 3490 steps.
Found uncertainty sample 23 after 1032 steps.
Found uncertainty sample 24 after 3972 steps.
Found uncertainty sample 25 after 556 steps.
Found uncertainty sample 26 after 785 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 520 steps.
Found uncertainty sample 29 after 2677 steps.
Found uncertainty sample 30 after 1710 steps.
Found uncertainty sample 31 after 3108 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 907 steps.
Found uncertainty sample 35 after 9 steps.
Found uncertainty sample 36 after 2469 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2696 steps.
Found uncertainty sample 40 after 2657 steps.
Found uncertainty sample 41 after 81 steps.
Found uncertainty sample 42 after 12 steps.
Found uncertainty sample 43 after 2394 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1501 steps.
Found uncertainty sample 46 after 3039 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3571 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3215 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3893 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 294 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 940 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2891 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1180 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 15 steps.
Found uncertainty sample 65 after 3788 steps.
Found uncertainty sample 66 after 1918 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3122 steps.
Found uncertainty sample 70 after 2366 steps.
Found uncertainty sample 71 after 2680 steps.
Found uncertainty sample 72 after 1209 steps.
Found uncertainty sample 73 after 569 steps.
Found uncertainty sample 74 after 684 steps.
Found uncertainty sample 75 after 2833 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1369 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 436 steps.
Found uncertainty sample 82 after 115 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1291 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 268 steps.
Found uncertainty sample 90 after 1702 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1007 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1307 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2976 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_062423-dshzp0z2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/dshzp0z2
Training model 17. Added 55 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9048730108071763, Training Loss Force: 3.3690326869084175, time: 2.1762592792510986
Validation Loss Energy: 2.2365058245537917, Validation Loss Force: 2.7508941525652935, time: 0.13806486129760742
Test Loss Energy: 8.741486058871224, Test Loss Force: 12.267654408378498, time: 17.86831045150757


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6205670606051714, Training Loss Force: 3.0763989241606304, time: 2.138819932937622
Validation Loss Energy: 1.3210408208413753, Validation Loss Force: 2.7455739186616404, time: 0.13912439346313477
Test Loss Energy: 8.43072913871125, Test Loss Force: 12.055526694949396, time: 18.88807773590088


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7910875178182368, Training Loss Force: 3.0604322797386954, time: 2.4202427864074707
Validation Loss Energy: 1.3030074033855485, Validation Loss Force: 2.7388754740792676, time: 0.15718936920166016
Test Loss Energy: 8.589736767785816, Test Loss Force: 12.416139871081635, time: 18.963539838790894


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0061064198993837, Training Loss Force: 3.0872448462336632, time: 2.198948621749878
Validation Loss Energy: 3.7244629998889716, Validation Loss Force: 2.868391316811884, time: 0.1429133415222168
Test Loss Energy: 9.508631179455353, Test Loss Force: 11.959017718178293, time: 18.17298674583435


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2683495401708185, Training Loss Force: 3.097749482211639, time: 2.159442186355591
Validation Loss Energy: 1.2908185500047478, Validation Loss Force: 2.74321340304566, time: 0.13776493072509766
Test Loss Energy: 8.41249869112097, Test Loss Force: 11.93676179481435, time: 18.385663270950317


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8564938124966126, Training Loss Force: 3.0746419769917273, time: 2.2248058319091797
Validation Loss Energy: 1.2453714433171674, Validation Loss Force: 2.7641921766292468, time: 0.13505792617797852
Test Loss Energy: 8.481835347351277, Test Loss Force: 11.95152072549698, time: 18.321192979812622


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6448115272602883, Training Loss Force: 3.08023276120831, time: 2.1770970821380615
Validation Loss Energy: 1.9620584201122586, Validation Loss Force: 2.7428080338654985, time: 0.13813018798828125
Test Loss Energy: 8.630391618842818, Test Loss Force: 12.176766132458628, time: 18.310827493667603


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7057658717683017, Training Loss Force: 3.071018664495737, time: 2.18230938911438
Validation Loss Energy: 1.210686493125142, Validation Loss Force: 2.778051438275511, time: 0.13454008102416992
Test Loss Energy: 8.308446070733773, Test Loss Force: 11.755925121278919, time: 18.290700435638428


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.938816136178568, Training Loss Force: 3.072866803805683, time: 2.140162706375122
Validation Loss Energy: 2.1168150352160926, Validation Loss Force: 2.7757652941542705, time: 0.14151763916015625
Test Loss Energy: 8.651943506668005, Test Loss Force: 12.136025181887993, time: 18.299954175949097


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.850284574765579, Training Loss Force: 3.0694632694070383, time: 2.162605047225952
Validation Loss Energy: 1.8657689333312675, Validation Loss Force: 2.785275604711419, time: 0.14519071578979492
Test Loss Energy: 8.656326285980196, Test Loss Force: 11.843993836897507, time: 18.180821895599365


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.017594373776718, Training Loss Force: 3.0641737346430125, time: 2.18296480178833
Validation Loss Energy: 1.5567981251630796, Validation Loss Force: 2.7844575182692806, time: 0.1375894546508789
Test Loss Energy: 8.526695588520237, Test Loss Force: 11.684602636320037, time: 18.39076566696167


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1851295495540954, Training Loss Force: 3.086773032215325, time: 2.2525267601013184
Validation Loss Energy: 3.1434968199142075, Validation Loss Force: 2.727545845265316, time: 0.1351304054260254
Test Loss Energy: 9.060411879940673, Test Loss Force: 11.86658101267571, time: 18.32243299484253


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0360180134353123, Training Loss Force: 3.078880319920339, time: 2.1295905113220215
Validation Loss Energy: 1.4015298163619034, Validation Loss Force: 2.801080994693092, time: 0.14404535293579102
Test Loss Energy: 8.48969093295371, Test Loss Force: 11.874977635338851, time: 18.228943347930908


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6981774715392066, Training Loss Force: 3.0628176101883486, time: 2.2001523971557617
Validation Loss Energy: 1.200120007141571, Validation Loss Force: 2.759369385597597, time: 0.16205859184265137
Test Loss Energy: 8.335344769365857, Test Loss Force: 11.884408286883403, time: 18.445094347000122


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7881315082494538, Training Loss Force: 3.0656762257328274, time: 2.2426559925079346
Validation Loss Energy: 1.250822551011339, Validation Loss Force: 2.717895030477087, time: 0.13709330558776855
Test Loss Energy: 8.431409450076604, Test Loss Force: 11.925460531251654, time: 19.143287897109985


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9539487313358201, Training Loss Force: 3.053450674834137, time: 2.1624934673309326
Validation Loss Energy: 1.957517750888499, Validation Loss Force: 2.7809127368006834, time: 0.14148402214050293
Test Loss Energy: 8.584492233231128, Test Loss Force: 11.646688581308625, time: 18.614209413528442


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7161629384720678, Training Loss Force: 3.069015061968483, time: 2.4143216609954834
Validation Loss Energy: 1.393254039217065, Validation Loss Force: 2.750882685104278, time: 0.13663744926452637
Test Loss Energy: 8.397121745138335, Test Loss Force: 11.988021085577685, time: 18.710164070129395


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6323489268041882, Training Loss Force: 3.060196520567238, time: 2.2192509174346924
Validation Loss Energy: 1.625656721520794, Validation Loss Force: 2.730479733932061, time: 0.14385056495666504
Test Loss Energy: 8.478072996559678, Test Loss Force: 11.618993743717862, time: 18.79342555999756


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.672499528453413, Training Loss Force: 3.047476775575887, time: 2.2104785442352295
Validation Loss Energy: 1.6365548175299378, Validation Loss Force: 2.7504818806416083, time: 0.13813328742980957
Test Loss Energy: 8.442363188890281, Test Loss Force: 11.839596851060644, time: 18.775973796844482


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.836647671075985, Training Loss Force: 3.063815014648923, time: 2.2516398429870605
Validation Loss Energy: 1.194346585858669, Validation Loss Force: 2.682794356989614, time: 0.14621996879577637
Test Loss Energy: 8.270338025429785, Test Loss Force: 11.673333544368598, time: 18.84250783920288

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–ƒâ–ˆâ–‚â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–…â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–
wandb:   test_error_force â–‡â–…â–ˆâ–„â–„â–„â–†â–‚â–†â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–â–„â–â–ƒâ–
wandb:          test_loss â–†â–„â–ˆâ–†â–ƒâ–„â–…â–‚â–…â–ƒâ–‚â–„â–ƒâ–ƒâ–„â–â–„â–â–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–ƒâ–…â–‚â–â–â–ƒâ–‚â–ƒâ–„â–ƒâ–â–‚â–ƒâ–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–ƒâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–„â–â–â–ˆâ–â–â–ƒâ–â–„â–ƒâ–‚â–†â–‚â–â–â–ƒâ–‚â–‚â–‚â–
wandb:  valid_error_force â–„â–ƒâ–ƒâ–ˆâ–ƒâ–„â–ƒâ–…â–…â–…â–…â–ƒâ–…â–„â–‚â–…â–„â–ƒâ–„â–
wandb:         valid_loss â–ƒâ–‚â–†â–ˆâ–â–‚â–ƒâ–‚â–ƒâ–ƒâ–…â–…â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1941
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.27034
wandb:   test_error_force 11.67333
wandb:          test_loss 5.81359
wandb: train_error_energy 1.83665
wandb:  train_error_force 3.06382
wandb:         train_loss 1.39374
wandb: valid_error_energy 1.19435
wandb:  valid_error_force 2.68279
wandb:         valid_loss 1.37464
wandb: 
wandb: ğŸš€ View run al_81_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/dshzp0z2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_062423-dshzp0z2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7434495687484741, Uncertainty Bias: 0.014875799417495728
1.1086464e-05 0.0016908646
0.5660999 4.4997826
(48745, 22, 3)
Found uncertainty sample 0 after 188 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 952 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1554 steps.
Found uncertainty sample 5 after 810 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1057 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2063 steps.
Found uncertainty sample 11 after 594 steps.
Found uncertainty sample 12 after 55 steps.
Found uncertainty sample 13 after 147 steps.
Found uncertainty sample 14 after 721 steps.
Found uncertainty sample 15 after 2036 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2128 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1826 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2762 steps.
Found uncertainty sample 24 after 3853 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 883 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1271 steps.
Found uncertainty sample 32 after 1474 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1517 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3303 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 853 steps.
Found uncertainty sample 45 after 1615 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 216 steps.
Found uncertainty sample 48 after 1523 steps.
Found uncertainty sample 49 after 540 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2642 steps.
Found uncertainty sample 53 after 2009 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1800 steps.
Found uncertainty sample 56 after 15 steps.
Found uncertainty sample 57 after 2943 steps.
Found uncertainty sample 58 after 1611 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3209 steps.
Found uncertainty sample 61 after 511 steps.
Found uncertainty sample 62 after 332 steps.
Found uncertainty sample 63 after 3347 steps.
Found uncertainty sample 64 after 1016 steps.
Found uncertainty sample 65 after 1405 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1502 steps.
Found uncertainty sample 70 after 1217 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 96 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1212 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1075 steps.
Found uncertainty sample 77 after 2137 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 227 steps.
Found uncertainty sample 81 after 649 steps.
Found uncertainty sample 82 after 93 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3441 steps.
Found uncertainty sample 85 after 1696 steps.
Found uncertainty sample 86 after 2353 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3290 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 436 steps.
Found uncertainty sample 91 after 1729 steps.
Found uncertainty sample 92 after 2447 steps.
Found uncertainty sample 93 after 2821 steps.
Found uncertainty sample 94 after 1180 steps.
Found uncertainty sample 95 after 3295 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2616 steps.
Found uncertainty sample 99 after 1298 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_083207-eutxqz5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/eutxqz5u
Training model 18. Added 58 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.817911590534141, Training Loss Force: 3.3804032490094267, time: 2.2441112995147705
Validation Loss Energy: 2.450878540773456, Validation Loss Force: 2.783629300381002, time: 0.14576053619384766
Test Loss Energy: 8.58823557204141, Test Loss Force: 11.75727128333902, time: 17.772194385528564


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8388314388566274, Training Loss Force: 3.090912615728423, time: 2.2397913932800293
Validation Loss Energy: 1.4765791716492753, Validation Loss Force: 2.7755704586515835, time: 0.133331298828125
Test Loss Energy: 8.367955554131951, Test Loss Force: 11.658416651494365, time: 18.175421237945557


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7970339616463213, Training Loss Force: 3.0605071226453977, time: 2.497117757797241
Validation Loss Energy: 1.2317105242126383, Validation Loss Force: 2.7659834385736626, time: 0.14126992225646973
Test Loss Energy: 8.248991450215216, Test Loss Force: 11.52630922494297, time: 18.96553349494934


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7011857096829253, Training Loss Force: 3.0755333385017916, time: 2.215188503265381
Validation Loss Energy: 2.1141533595802446, Validation Loss Force: 2.7140477529737463, time: 0.13932180404663086
Test Loss Energy: 8.501863954383364, Test Loss Force: 11.939742297110055, time: 18.161085844039917


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.790745017993818, Training Loss Force: 3.0860542753909037, time: 2.209404706954956
Validation Loss Energy: 1.4578430660361867, Validation Loss Force: 2.787058739232009, time: 0.1541140079498291
Test Loss Energy: 8.36035493519387, Test Loss Force: 11.784023388729818, time: 18.262288570404053


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7964136115910205, Training Loss Force: 3.070239814292357, time: 2.239631414413452
Validation Loss Energy: 1.2296211082818247, Validation Loss Force: 2.712586932041887, time: 0.13788723945617676
Test Loss Energy: 8.226722453491051, Test Loss Force: 11.577228510412736, time: 18.23698377609253


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8918774296920111, Training Loss Force: 3.0754372868079853, time: 2.195066213607788
Validation Loss Energy: 1.8340910186204238, Validation Loss Force: 2.6780044096569884, time: 0.13488245010375977
Test Loss Energy: 8.484414770053846, Test Loss Force: 11.734119595809416, time: 18.635637521743774


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9004533259668206, Training Loss Force: 3.0828300296923, time: 2.2258706092834473
Validation Loss Energy: 1.8947624044860922, Validation Loss Force: 2.8015647434126207, time: 0.1495039463043213
Test Loss Energy: 8.492074535046637, Test Loss Force: 11.685355369950749, time: 18.28675603866577


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.954337386916582, Training Loss Force: 3.07084463317473, time: 2.267078399658203
Validation Loss Energy: 2.6188031411600217, Validation Loss Force: 2.853408243986123, time: 0.14259552955627441
Test Loss Energy: 8.73289026040576, Test Loss Force: 11.609021929205445, time: 18.290213346481323


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8679967416707057, Training Loss Force: 3.0924250623250433, time: 2.2282238006591797
Validation Loss Energy: 1.8277895931252401, Validation Loss Force: 2.7598593690532107, time: 0.14162540435791016
Test Loss Energy: 8.486055983887793, Test Loss Force: 11.827460272759273, time: 18.159684896469116


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8510551205193955, Training Loss Force: 3.078579095440564, time: 2.1991922855377197
Validation Loss Energy: 2.1829670324377686, Validation Loss Force: 2.7482777901006417, time: 0.1405184268951416
Test Loss Energy: 8.433811642128699, Test Loss Force: 11.273272265037967, time: 18.288628578186035


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.245821893392643, Training Loss Force: 3.0906672838116425, time: 2.2225799560546875
Validation Loss Energy: 1.5653111006156177, Validation Loss Force: 2.7602883411628407, time: 0.14286541938781738
Test Loss Energy: 8.360759649773373, Test Loss Force: 11.645178851856636, time: 18.29373526573181


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7723901405143199, Training Loss Force: 3.088859083107197, time: 2.223524808883667
Validation Loss Energy: 1.6445566002907124, Validation Loss Force: 2.7643096346037233, time: 0.14016056060791016
Test Loss Energy: 8.313816295609397, Test Loss Force: 11.583787849149582, time: 18.31216073036194


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8214602809703526, Training Loss Force: 3.073861008389532, time: 2.2825918197631836
Validation Loss Energy: 1.9914806407075674, Validation Loss Force: 2.7272313250966933, time: 0.1627810001373291
Test Loss Energy: 8.332665299434153, Test Loss Force: 11.569738992886206, time: 18.57309079170227


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8579978649647289, Training Loss Force: 3.0882632522825726, time: 2.2522518634796143
Validation Loss Energy: 1.2910717248236678, Validation Loss Force: 2.7251917870545674, time: 0.13656163215637207
Test Loss Energy: 8.095508137728483, Test Loss Force: 11.430180581062798, time: 18.78501796722412


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7682410579574754, Training Loss Force: 3.062908775502481, time: 2.2004621028900146
Validation Loss Energy: 1.2323990728791334, Validation Loss Force: 2.7189070617453286, time: 0.14755988121032715
Test Loss Energy: 8.251865768473486, Test Loss Force: 11.511346930879105, time: 18.67275357246399


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.676914474117386, Training Loss Force: 3.0621240399501986, time: 2.5055630207061768
Validation Loss Energy: 1.8422903089136362, Validation Loss Force: 2.7528894907819517, time: 0.14274024963378906
Test Loss Energy: 8.35322898158971, Test Loss Force: 11.740445539975505, time: 18.59593439102173


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8656413227040651, Training Loss Force: 3.080418879819422, time: 2.244290590286255
Validation Loss Energy: 2.6713871279783064, Validation Loss Force: 2.678902322987942, time: 0.14585280418395996
Test Loss Energy: 8.51511969579154, Test Loss Force: 11.552489548609621, time: 18.760960817337036


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.143809563918361, Training Loss Force: 3.0644127111895245, time: 2.289660692214966
Validation Loss Energy: 1.229438519582164, Validation Loss Force: 2.734219350903345, time: 0.14519095420837402
Test Loss Energy: 8.289097129209937, Test Loss Force: 11.611718394272282, time: 18.71950650215149


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.794786183772367, Training Loss Force: 3.0562129517006116, time: 2.2556357383728027
Validation Loss Energy: 1.296265092981428, Validation Loss Force: 2.709319707663689, time: 0.15259122848510742
Test Loss Energy: 8.265183836257993, Test Loss Force: 11.882132626864934, time: 19.134085655212402

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–„â–ƒâ–…â–„â–‚â–…â–…â–ˆâ–…â–…â–„â–ƒâ–„â–â–ƒâ–„â–†â–ƒâ–ƒ
wandb:   test_error_force â–†â–…â–„â–ˆâ–†â–„â–†â–…â–…â–‡â–â–…â–„â–„â–ƒâ–„â–†â–„â–…â–‡
wandb:          test_loss â–‡â–…â–ƒâ–ˆâ–‡â–ƒâ–‡â–‡â–‡â–‡â–â–…â–ƒâ–„â–‚â–„â–†â–„â–„â–ˆ
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–‚â–‚â–‚â–â–‚â–„â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–
wandb: valid_error_energy â–‡â–‚â–â–…â–‚â–â–„â–„â–ˆâ–„â–†â–ƒâ–ƒâ–…â–â–â–„â–ˆâ–â–
wandb:  valid_error_force â–…â–…â–…â–‚â–…â–‚â–â–†â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–â–ƒâ–‚
wandb:         valid_loss â–†â–‚â–‚â–ƒâ–ƒâ–â–‚â–…â–‡â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–â–‚â–ƒâ–…â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1993
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.26518
wandb:   test_error_force 11.88213
wandb:          test_loss 5.86777
wandb: train_error_energy 1.79479
wandb:  train_error_force 3.05621
wandb:         train_loss 1.39695
wandb: valid_error_energy 1.29627
wandb:  valid_error_force 2.70932
wandb:         valid_loss 1.38643
wandb: 
wandb: ğŸš€ View run al_81_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/eutxqz5u
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_083207-eutxqz5u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7500181198120117, Uncertainty Bias: 0.013587474822998047
1.2397766e-05 0.0011301041
0.48588094 4.56396
(48745, 22, 3)
Found uncertainty sample 0 after 1847 steps.
Found uncertainty sample 1 after 3422 steps.
Found uncertainty sample 2 after 1997 steps.
Found uncertainty sample 3 after 1895 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1532 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3939 steps.
Found uncertainty sample 9 after 2559 steps.
Found uncertainty sample 10 after 1250 steps.
Found uncertainty sample 11 after 3551 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1992 steps.
Found uncertainty sample 15 after 2343 steps.
Found uncertainty sample 16 after 223 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 641 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 221 steps.
Found uncertainty sample 23 after 254 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1856 steps.
Found uncertainty sample 26 after 3358 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 459 steps.
Found uncertainty sample 29 after 1979 steps.
Found uncertainty sample 30 after 1436 steps.
Found uncertainty sample 31 after 1479 steps.
Found uncertainty sample 32 after 534 steps.
Found uncertainty sample 33 after 1077 steps.
Found uncertainty sample 34 after 738 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 785 steps.
Found uncertainty sample 38 after 784 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2024 steps.
Found uncertainty sample 41 after 1998 steps.
Found uncertainty sample 42 after 11 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2459 steps.
Found uncertainty sample 45 after 1452 steps.
Found uncertainty sample 46 after 1190 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1778 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2736 steps.
Found uncertainty sample 52 after 461 steps.
Found uncertainty sample 53 after 3147 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2556 steps.
Found uncertainty sample 56 after 2601 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2193 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 120 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 946 steps.
Found uncertainty sample 64 after 683 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1092 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2152 steps.
Found uncertainty sample 69 after 2203 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 306 steps.
Found uncertainty sample 74 after 3163 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1719 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1986 steps.
Found uncertainty sample 81 after 1434 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3539 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 14 steps.
Found uncertainty sample 86 after 3593 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 282 steps.
Found uncertainty sample 89 after 2697 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 757 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 584 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3675 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1645 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_104155-w1oawkm5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/w1oawkm5
Training model 19. Added 59 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1400032906204327, Training Loss Force: 3.2618139111025966, time: 2.3290493488311768
Validation Loss Energy: 1.4055403660164951, Validation Loss Force: 2.8312380791372496, time: 0.14193987846374512
Test Loss Energy: 8.290737186563295, Test Loss Force: 11.80686222494359, time: 18.160982370376587


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.748690347068158, Training Loss Force: 3.070908275297029, time: 2.240903377532959
Validation Loss Energy: 1.7358886368740536, Validation Loss Force: 2.762405145398603, time: 0.1434926986694336
Test Loss Energy: 8.322223217011992, Test Loss Force: 11.921998690542493, time: 18.250712394714355


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7019686117353778, Training Loss Force: 3.0769644759576433, time: 2.2778103351593018
Validation Loss Energy: 1.6849701039327356, Validation Loss Force: 2.7379099806625247, time: 0.14147734642028809
Test Loss Energy: 8.386037130493975, Test Loss Force: 11.62554228241823, time: 18.311437368392944


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8929627263438011, Training Loss Force: 3.065896525140622, time: 2.29154896736145
Validation Loss Energy: 1.2545771981499736, Validation Loss Force: 2.7449046865435545, time: 0.1360788345336914
Test Loss Energy: 8.137923956650889, Test Loss Force: 11.550916735006721, time: 18.21867346763611


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.743971075444331, Training Loss Force: 3.0745842819558913, time: 2.2507922649383545
Validation Loss Energy: 1.5437801075501303, Validation Loss Force: 2.7816057945173833, time: 0.1396620273590088
Test Loss Energy: 8.142434147015218, Test Loss Force: 11.358125339742752, time: 18.32676935195923


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.135812093411784, Training Loss Force: 3.0820069335809563, time: 2.2331032752990723
Validation Loss Energy: 1.334440994376023, Validation Loss Force: 2.778590742946948, time: 0.14774823188781738
Test Loss Energy: 8.08741189924062, Test Loss Force: 11.22300189108656, time: 18.36093807220459


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7225553214900733, Training Loss Force: 3.083264927275313, time: 2.276244640350342
Validation Loss Energy: 1.324636927548109, Validation Loss Force: 2.7280024283490407, time: 0.14577364921569824
Test Loss Energy: 8.147050181001322, Test Loss Force: 11.45282138396515, time: 18.23853039741516


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6935511222053816, Training Loss Force: 3.0860411453115084, time: 2.2550015449523926
Validation Loss Energy: 1.2143920973843856, Validation Loss Force: 2.712350234739766, time: 0.14567351341247559
Test Loss Energy: 8.054836109670454, Test Loss Force: 11.289558155800735, time: 18.28431272506714


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7184469574547219, Training Loss Force: 3.0775430225868448, time: 2.19240665435791
Validation Loss Energy: 2.131040587607408, Validation Loss Force: 2.7785774941327652, time: 0.1389462947845459
Test Loss Energy: 8.30487497525142, Test Loss Force: 11.415058753299428, time: 18.30288553237915


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8856464896952572, Training Loss Force: 3.0610169395599387, time: 2.2530767917633057
Validation Loss Energy: 1.8617686821246748, Validation Loss Force: 2.709515545177532, time: 0.14628028869628906
Test Loss Energy: 8.267751013323345, Test Loss Force: 11.425806249188469, time: 18.18558406829834


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8293308202336145, Training Loss Force: 3.0666469027663714, time: 2.315530300140381
Validation Loss Energy: 1.7001648794489883, Validation Loss Force: 2.7308044968813965, time: 0.14102983474731445
Test Loss Energy: 8.251159270750248, Test Loss Force: 11.368524091448602, time: 18.366058349609375


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8196530450827013, Training Loss Force: 3.066048107161712, time: 2.3405494689941406
Validation Loss Energy: 1.3972430456317881, Validation Loss Force: 2.7494571572320483, time: 0.14461278915405273
Test Loss Energy: 8.093920161639133, Test Loss Force: 11.451915962253912, time: 18.874510765075684


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7379422256872077, Training Loss Force: 3.084236829388413, time: 2.3233320713043213
Validation Loss Energy: 1.2945094581003604, Validation Loss Force: 2.7434355155187227, time: 0.13739728927612305
Test Loss Energy: 8.154486104046295, Test Loss Force: 11.560171032587697, time: 18.22671341896057


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7635974062142292, Training Loss Force: 3.0570189533160645, time: 2.5325167179107666
Validation Loss Energy: 1.8429656087659487, Validation Loss Force: 2.7369005100894612, time: 0.1352994441986084
Test Loss Energy: 8.30376873161831, Test Loss Force: 11.504368717670367, time: 18.30930185317993


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8979953795662827, Training Loss Force: 3.0629286202826314, time: 2.284686326980591
Validation Loss Energy: 1.7203789515181724, Validation Loss Force: 2.748131719140913, time: 0.1429004669189453
Test Loss Energy: 8.171944439961132, Test Loss Force: 11.548981504635586, time: 18.74312663078308


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7426392190890247, Training Loss Force: 3.0717460088120907, time: 2.274348497390747
Validation Loss Energy: 1.6662937293180424, Validation Loss Force: 2.792174117521408, time: 0.1477973461151123
Test Loss Energy: 8.207237902959925, Test Loss Force: 11.651938770027488, time: 18.723247528076172


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.107011841668735, Training Loss Force: 3.072741134621269, time: 2.4273533821105957
Validation Loss Energy: 2.7053646582937194, Validation Loss Force: 2.821673771312213, time: 0.14814543724060059
Test Loss Energy: 8.535208155357406, Test Loss Force: 11.69314051282819, time: 18.588945865631104


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0647473763967494, Training Loss Force: 3.0701983886637843, time: 2.309767007827759
Validation Loss Energy: 1.3296954695380099, Validation Loss Force: 2.7152569577707073, time: 0.1462695598602295
Test Loss Energy: 8.056828506555933, Test Loss Force: 11.25963947598312, time: 18.769797563552856


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9519349970202085, Training Loss Force: 3.060718740343871, time: 2.356419801712036
Validation Loss Energy: 1.2445975567004954, Validation Loss Force: 2.7236084980924478, time: 0.14621639251708984
Test Loss Energy: 8.028047402601617, Test Loss Force: 11.322932315684263, time: 18.75995969772339


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7650343980682688, Training Loss Force: 3.053062449638236, time: 2.333662986755371
Validation Loss Energy: 1.9993695302113563, Validation Loss Force: 2.7687430886337188, time: 0.1441187858581543
Test Loss Energy: 8.257608627250303, Test Loss Force: 11.247428169450052, time: 18.67186141014099

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–…â–†â–ƒâ–ƒâ–‚â–ƒâ–â–…â–„â–„â–‚â–ƒâ–…â–ƒâ–ƒâ–ˆâ–â–â–„
wandb:   test_error_force â–‡â–ˆâ–…â–„â–‚â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–„â–„â–…â–†â–â–‚â–
wandb:          test_loss â–‡â–ˆâ–…â–„â–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–„â–…â–…â–‚â–â–
wandb: train_error_energy â–ˆâ–â–â–‚â–â–ƒâ–â–â–â–‚â–‚â–‚â–â–â–‚â–â–ƒâ–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–â–ƒâ–‚â–‚â–â–…â–„â–ƒâ–‚â–â–„â–ƒâ–ƒâ–ˆâ–‚â–â–…
wandb:  valid_error_force â–ˆâ–„â–ƒâ–ƒâ–…â–…â–‚â–â–…â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–†â–‡â–â–‚â–„
wandb:         valid_loss â–…â–†â–ƒâ–â–„â–„â–â–ƒâ–†â–„â–ƒâ–ƒâ–„â–‡â–„â–ƒâ–ˆâ–…â–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2046
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.25761
wandb:   test_error_force 11.24743
wandb:          test_loss 5.58698
wandb: train_error_energy 1.76503
wandb:  train_error_force 3.05306
wandb:         train_loss 1.40209
wandb: valid_error_energy 1.99937
wandb:  valid_error_force 2.76874
wandb:         valid_loss 1.41114
wandb: 
wandb: ğŸš€ View run al_81_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/w1oawkm5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_104155-w1oawkm5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7478981018066406, Uncertainty Bias: 0.018723130226135254
0.00031280518 0.033637047
0.7355933 4.9051137
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 604 steps.
Found uncertainty sample 3 after 1877 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1320 steps.
Found uncertainty sample 7 after 1065 steps.
Found uncertainty sample 8 after 2815 steps.
Found uncertainty sample 9 after 2141 steps.
Found uncertainty sample 10 after 1300 steps.
Found uncertainty sample 11 after 2397 steps.
Found uncertainty sample 12 after 208 steps.
Found uncertainty sample 13 after 962 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2243 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 304 steps.
Found uncertainty sample 22 after 1860 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3325 steps.
Found uncertainty sample 25 after 1562 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1031 steps.
Found uncertainty sample 29 after 316 steps.
Found uncertainty sample 30 after 5 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2356 steps.
Found uncertainty sample 33 after 3330 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 454 steps.
Found uncertainty sample 36 after 1259 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1022 steps.
Found uncertainty sample 39 after 269 steps.
Found uncertainty sample 40 after 1820 steps.
Found uncertainty sample 41 after 13 steps.
Found uncertainty sample 42 after 2664 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1674 steps.
Found uncertainty sample 47 after 455 steps.
Found uncertainty sample 48 after 366 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1870 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3023 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 528 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 222 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2230 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2121 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2670 steps.
Found uncertainty sample 69 after 1573 steps.
Found uncertainty sample 70 after 990 steps.
Found uncertainty sample 71 after 3813 steps.
Found uncertainty sample 72 after 2700 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 278 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1632 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1169 steps.
Found uncertainty sample 79 after 537 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2218 steps.
Found uncertainty sample 86 after 1723 steps.
Found uncertainty sample 87 after 3001 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2107 steps.
Found uncertainty sample 90 after 469 steps.
Found uncertainty sample 91 after 2857 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1916 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2765 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_125406-xbev3jqf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/xbev3jqf
Training model 20. Added 53 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1852768643474394, Training Loss Force: 3.2611821227202324, time: 2.352827787399292
Validation Loss Energy: 1.3546602435028499, Validation Loss Force: 2.7955300755542583, time: 0.1380324363708496
Test Loss Energy: 8.093147446075639, Test Loss Force: 11.444493212828563, time: 17.822746515274048


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7358571536497729, Training Loss Force: 3.0890264813048702, time: 2.2819173336029053
Validation Loss Energy: 1.299726651856735, Validation Loss Force: 2.731088066038735, time: 0.1455390453338623
Test Loss Energy: 8.011155068339589, Test Loss Force: 11.35771941971876, time: 17.88668394088745


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7384132663981327, Training Loss Force: 3.0818424459218527, time: 2.299044609069824
Validation Loss Energy: 1.2267828003459698, Validation Loss Force: 2.67695719666369, time: 0.13828611373901367
Test Loss Energy: 8.011587351924133, Test Loss Force: 11.368019903217023, time: 17.917280912399292


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8044582508525404, Training Loss Force: 3.101893127757663, time: 2.3406240940093994
Validation Loss Energy: 1.9578322153898355, Validation Loss Force: 2.726960670749818, time: 0.13544392585754395
Test Loss Energy: 8.144221247611382, Test Loss Force: 11.083195334901632, time: 17.753360271453857


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.023429074814289, Training Loss Force: 3.100528864264538, time: 2.326899766921997
Validation Loss Energy: 1.3676313335932946, Validation Loss Force: 2.7496689155898255, time: 0.13714075088500977
Test Loss Energy: 7.938452892709938, Test Loss Force: 11.133498939017102, time: 17.976247549057007


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8129484389857016, Training Loss Force: 3.091790810790766, time: 2.3232064247131348
Validation Loss Energy: 2.1927291817989616, Validation Loss Force: 2.7343450476362214, time: 0.13687729835510254
Test Loss Energy: 8.269907215425347, Test Loss Force: 11.283793277260422, time: 17.892658710479736


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.792962372530954, Training Loss Force: 3.0930269686757086, time: 2.2988593578338623
Validation Loss Energy: 1.320757919691474, Validation Loss Force: 2.7533513065906066, time: 0.1435561180114746
Test Loss Energy: 7.915945304247203, Test Loss Force: 11.14746375458209, time: 18.443990468978882


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7802857050318248, Training Loss Force: 3.0798323474398397, time: 2.350196599960327
Validation Loss Energy: 1.244823899887331, Validation Loss Force: 2.7225563863779394, time: 0.1533980369567871
Test Loss Energy: 7.930035029042403, Test Loss Force: 11.287325537378432, time: 18.480177879333496


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9148946110629548, Training Loss Force: 3.0759018962629447, time: 2.4312806129455566
Validation Loss Energy: 2.164695470330372, Validation Loss Force: 2.7484477979935575, time: 0.15661883354187012
Test Loss Energy: 8.267842566482338, Test Loss Force: 11.19108492472626, time: 18.427165031433105


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.066030422584063, Training Loss Force: 3.0903734204636875, time: 2.4199180603027344
Validation Loss Energy: 1.27328769681128, Validation Loss Force: 2.7417960025972565, time: 0.13895654678344727
Test Loss Energy: 7.913682160333186, Test Loss Force: 11.092162438248256, time: 18.29975700378418


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.642284999669787, Training Loss Force: 3.0706167023858013, time: 2.400329351425171
Validation Loss Energy: 1.463779369799335, Validation Loss Force: 2.6933419717630676, time: 0.14376330375671387
Test Loss Energy: 7.988869293320407, Test Loss Force: 11.168199353639604, time: 18.54515790939331


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9268161324217508, Training Loss Force: 3.074948953288973, time: 2.4107422828674316
Validation Loss Energy: 2.1687511661543004, Validation Loss Force: 2.7917921286015686, time: 0.14276909828186035
Test Loss Energy: 8.205108204315323, Test Loss Force: 11.271367392282327, time: 18.374165534973145


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9733166699698408, Training Loss Force: 3.0922088350007213, time: 2.452338933944702
Validation Loss Energy: 1.7001968881387155, Validation Loss Force: 2.7089873739633914, time: 0.14406514167785645
Test Loss Energy: 8.158603466399768, Test Loss Force: 11.138081810455951, time: 18.30297589302063


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8146393387166968, Training Loss Force: 3.0620572801736876, time: 2.3922464847564697
Validation Loss Energy: 3.4282381076374087, Validation Loss Force: 2.7526229558142763, time: 0.15110564231872559
Test Loss Energy: 8.763962123911417, Test Loss Force: 10.989149209454883, time: 18.577481031417847


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9820247137155367, Training Loss Force: 3.0781119077789274, time: 2.4523918628692627
Validation Loss Energy: 1.2626777903442534, Validation Loss Force: 2.7889547670095842, time: 0.13979649543762207
Test Loss Energy: 8.016805466959529, Test Loss Force: 11.372943302231004, time: 18.653730392456055


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8144011097207535, Training Loss Force: 3.0741415482182886, time: 2.3687779903411865
Validation Loss Energy: 1.2927843845595715, Validation Loss Force: 2.7474764038444475, time: 0.14189887046813965
Test Loss Energy: 7.886025171834005, Test Loss Force: 11.049773810609405, time: 18.709686517715454


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7422433089722007, Training Loss Force: 3.0728331004577423, time: 2.5925209522247314
Validation Loss Energy: 1.9059123392992805, Validation Loss Force: 2.738247992426043, time: 0.14514899253845215
Test Loss Energy: 8.154457103430202, Test Loss Force: 11.124132849866799, time: 18.72924256324768


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9562956793573676, Training Loss Force: 3.064748284035074, time: 2.4260733127593994
Validation Loss Energy: 1.9382795820186303, Validation Loss Force: 2.76109217677964, time: 0.15617060661315918
Test Loss Energy: 8.134242454577981, Test Loss Force: 11.209042941862627, time: 19.207266092300415


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.041043700526362, Training Loss Force: 3.0712665825308414, time: 2.5361862182617188
Validation Loss Energy: 2.158561826036645, Validation Loss Force: 2.7668748944993844, time: 0.1491563320159912
Test Loss Energy: 8.332354681804617, Test Loss Force: 11.364978466518608, time: 18.85446262359619


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.748127843845808, Training Loss Force: 3.04975492119575, time: 2.4043431282043457
Validation Loss Energy: 1.2795665770554383, Validation Loss Force: 2.753281722482504, time: 0.14950823783874512
Test Loss Energy: 7.802132139232212, Test Loss Force: 10.898722961520544, time: 19.398761987686157

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–‚â–„â–‚â–‚â–„â–„â–ˆâ–ƒâ–‚â–„â–ƒâ–…â–
wandb:   test_error_force â–ˆâ–‡â–‡â–ƒâ–„â–†â–„â–†â–…â–ƒâ–„â–†â–„â–‚â–‡â–ƒâ–„â–…â–‡â–
wandb:          test_loss â–ˆâ–†â–‡â–„â–„â–†â–„â–†â–ƒâ–‚â–‚â–†â–‚â–ƒâ–‡â–â–†â–†â–†â–
wandb: train_error_energy â–ˆâ–â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–ƒâ–
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–‚â–
wandb: valid_error_energy â–â–â–â–ƒâ–â–„â–â–â–„â–â–‚â–„â–ƒâ–ˆâ–â–â–ƒâ–ƒâ–„â–
wandb:  valid_error_force â–ˆâ–„â–â–„â–…â–„â–†â–„â–…â–…â–‚â–ˆâ–ƒâ–…â–ˆâ–…â–…â–†â–†â–†
wandb:         valid_loss â–ƒâ–â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‡â–‚â–‚â–†â–„â–ˆâ–„â–ƒâ–…â–…â–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2093
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.80213
wandb:   test_error_force 10.89872
wandb:          test_loss 5.50928
wandb: train_error_energy 1.74813
wandb:  train_error_force 3.04975
wandb:         train_loss 1.38509
wandb: valid_error_energy 1.27957
wandb:  valid_error_force 2.75328
wandb:         valid_loss 1.43989
wandb: 
wandb: ğŸš€ View run al_81_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/xbev3jqf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_125406-xbev3jqf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7487671971321106, Uncertainty Bias: 0.014304161071777344
0.00015258789 0.0035829544
0.6630839 6.6657114
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 20 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2959 steps.
Found uncertainty sample 5 after 1517 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2790 steps.
Found uncertainty sample 8 after 829 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1367 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 61 steps.
Found uncertainty sample 14 after 957 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1912 steps.
Found uncertainty sample 18 after 2426 steps.
Found uncertainty sample 19 after 376 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2869 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1654 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 368 steps.
Found uncertainty sample 30 after 718 steps.
Found uncertainty sample 31 after 1498 steps.
Found uncertainty sample 32 after 2079 steps.
Found uncertainty sample 33 after 1914 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2584 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 6 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2461 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2232 steps.
Found uncertainty sample 46 after 602 steps.
Found uncertainty sample 47 after 1738 steps.
Found uncertainty sample 48 after 3433 steps.
Found uncertainty sample 49 after 1294 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1701 steps.
Found uncertainty sample 54 after 1065 steps.
Found uncertainty sample 55 after 3582 steps.
Found uncertainty sample 56 after 1249 steps.
Found uncertainty sample 57 after 462 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3530 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 756 steps.
Found uncertainty sample 65 after 2620 steps.
Found uncertainty sample 66 after 1245 steps.
Found uncertainty sample 67 after 3608 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1708 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1880 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 19 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1403 steps.
Found uncertainty sample 81 after 36 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2732 steps.
Found uncertainty sample 86 after 3494 steps.
Found uncertainty sample 87 after 1874 steps.
Found uncertainty sample 88 after 1771 steps.
Found uncertainty sample 89 after 2156 steps.
Found uncertainty sample 90 after 1546 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 682 steps.
Found uncertainty sample 93 after 1280 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1673 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2687 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_150807-xhsjlltp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/xhsjlltp
Training model 21. Added 51 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.151435147784378, Training Loss Force: 3.2629088241577846, time: 2.390413999557495
Validation Loss Energy: 1.235174365446691, Validation Loss Force: 2.7572208510085394, time: 0.14940595626831055
Test Loss Energy: 7.873045400269936, Test Loss Force: 10.645953922727797, time: 17.68057131767273


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7423403416096523, Training Loss Force: 3.0730071546146163, time: 2.3232531547546387
Validation Loss Energy: 1.502559316919546, Validation Loss Force: 2.747011804671469, time: 0.13940930366516113
Test Loss Energy: 7.891730687479501, Test Loss Force: 10.791630634492586, time: 17.870494842529297


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8330967443857147, Training Loss Force: 3.0757702361059134, time: 2.3302719593048096
Validation Loss Energy: 1.3688861855651708, Validation Loss Force: 2.80036756274954, time: 0.1427147388458252
Test Loss Energy: 8.003438997198053, Test Loss Force: 10.892229528187666, time: 17.829842567443848


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8309002761087214, Training Loss Force: 3.0835727058862874, time: 2.330266237258911
Validation Loss Energy: 1.6300513197848248, Validation Loss Force: 2.748616247202452, time: 0.13892388343811035
Test Loss Energy: 7.961312237801275, Test Loss Force: 10.771133648158171, time: 17.781843185424805


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9482969924757036, Training Loss Force: 3.06535335138506, time: 2.325092077255249
Validation Loss Energy: 1.369036153234953, Validation Loss Force: 2.7412211821970445, time: 0.1405949592590332
Test Loss Energy: 7.850644406208711, Test Loss Force: 10.798010313037071, time: 17.862245082855225


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.009749357136513, Training Loss Force: 3.0926951384231995, time: 2.3690404891967773
Validation Loss Energy: 1.5776971831924238, Validation Loss Force: 2.7344239838484525, time: 0.14408493041992188
Test Loss Energy: 7.79220035387055, Test Loss Force: 10.563467576224744, time: 17.88452458381653


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.056319005457117, Training Loss Force: 3.0771349354202635, time: 2.2854487895965576
Validation Loss Energy: 1.1762006091495758, Validation Loss Force: 2.690115495838574, time: 0.1383211612701416
Test Loss Energy: 7.79601922998262, Test Loss Force: 10.784253407500803, time: 17.726503610610962


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7983397873123421, Training Loss Force: 3.0713740492470807, time: 2.3682613372802734
Validation Loss Energy: 1.7227645174130697, Validation Loss Force: 2.782515175309352, time: 0.14095163345336914
Test Loss Energy: 8.081214058616057, Test Loss Force: 10.823523165537182, time: 17.851140022277832


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8885090896509646, Training Loss Force: 3.081348314233711, time: 2.3751132488250732
Validation Loss Energy: 1.3191310989113254, Validation Loss Force: 2.7332210137875776, time: 0.1382288932800293
Test Loss Energy: 7.8851605440429475, Test Loss Force: 10.719771411969381, time: 17.873684644699097


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8592842145713644, Training Loss Force: 3.0813118563153394, time: 2.352579116821289
Validation Loss Energy: 1.5611693988340742, Validation Loss Force: 2.7155275007830095, time: 0.14563608169555664
Test Loss Energy: 7.868449406506967, Test Loss Force: 10.846154940429766, time: 17.71184539794922


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6692689629923976, Training Loss Force: 3.06039456932681, time: 2.3982410430908203
Validation Loss Energy: 1.3437246277426174, Validation Loss Force: 2.7365413447570797, time: 0.14098834991455078
Test Loss Energy: 7.923965832893835, Test Loss Force: 10.904153141520972, time: 17.88718032836914


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7450119110671036, Training Loss Force: 3.068404161293937, time: 2.4285788536071777
Validation Loss Energy: 1.8578552718849939, Validation Loss Force: 2.7149848560743837, time: 0.13706636428833008
Test Loss Energy: 7.955791665785674, Test Loss Force: 10.51418063979214, time: 17.88179636001587


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.823645979546291, Training Loss Force: 3.0627828388239493, time: 2.387824773788452
Validation Loss Energy: 1.4202684826701697, Validation Loss Force: 2.7610163579354516, time: 0.14516520500183105
Test Loss Energy: 7.945734971193796, Test Loss Force: 10.918853520710485, time: 18.52577805519104


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2258942372670547, Training Loss Force: 3.0715893636643523, time: 2.33732533454895
Validation Loss Energy: 2.607803285351189, Validation Loss Force: 2.76068235421656, time: 0.14966344833374023
Test Loss Energy: 8.289314785385564, Test Loss Force: 10.829295505242596, time: 18.17295503616333


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9625461336719523, Training Loss Force: 3.078762444148371, time: 2.384094476699829
Validation Loss Energy: 1.8978556685940347, Validation Loss Force: 2.7294839575114715, time: 0.13927364349365234
Test Loss Energy: 8.04994873875745, Test Loss Force: 10.822919809094982, time: 18.166625499725342


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.814888392066691, Training Loss Force: 3.0700857254497835, time: 2.3588626384735107
Validation Loss Energy: 1.2549118142090165, Validation Loss Force: 2.7577902160146768, time: 0.14159011840820312
Test Loss Energy: 7.827487847937264, Test Loss Force: 10.653644420725954, time: 18.271039962768555


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.734362715958646, Training Loss Force: 3.0641637364878105, time: 2.325831174850464
Validation Loss Energy: 2.2637075327586222, Validation Loss Force: 2.713769639210483, time: 0.14556431770324707
Test Loss Energy: 8.1728566163584, Test Loss Force: 10.884180619134286, time: 18.28083348274231


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.062321810025381, Training Loss Force: 3.057788848453282, time: 2.356456995010376
Validation Loss Energy: 2.0007173465516574, Validation Loss Force: 2.6986350400309167, time: 0.15164446830749512
Test Loss Energy: 8.139243974322161, Test Loss Force: 10.808688536671392, time: 18.186423778533936


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.01812067346949, Training Loss Force: 3.0658069483758363, time: 2.3531501293182373
Validation Loss Energy: 1.2643460832528308, Validation Loss Force: 2.7377502155503217, time: 0.15080857276916504
Test Loss Energy: 7.726265981930616, Test Loss Force: 10.771862506060566, time: 18.150747537612915


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8817202663209958, Training Loss Force: 3.057890295851483, time: 2.376735210418701
Validation Loss Energy: 1.267937625242073, Validation Loss Force: 2.7506129214339863, time: 0.14055800437927246
Test Loss Energy: 7.818760742292513, Test Loss Force: 10.695600109596695, time: 18.229634284973145

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–…â–ƒâ–ƒâ–ƒâ–„â–„â–ˆâ–…â–‚â–‡â–†â–â–‚
wandb:   test_error_force â–ƒâ–†â–ˆâ–…â–†â–‚â–†â–†â–…â–‡â–ˆâ–â–ˆâ–†â–†â–ƒâ–‡â–†â–…â–„
wandb:          test_loss â–ƒâ–‡â–‡â–…â–…â–â–…â–†â–„â–†â–ˆâ–â–†â–†â–‡â–ƒâ–‡â–…â–…â–ƒ
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–„â–‚â–‚â–â–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–‚â–â–â–‚â–‚â–
wandb: valid_error_energy â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–„â–‚â–ƒâ–‚â–„â–‚â–ˆâ–…â–â–†â–…â–â–
wandb:  valid_error_force â–…â–…â–ˆâ–…â–„â–„â–â–‡â–„â–ƒâ–„â–ƒâ–†â–…â–ƒâ–…â–ƒâ–‚â–„â–…
wandb:         valid_loss â–‚â–…â–„â–„â–ƒâ–†â–â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–ˆâ–…â–„â–…â–„â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2138
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.81876
wandb:   test_error_force 10.6956
wandb:          test_loss 5.35106
wandb: train_error_energy 1.88172
wandb:  train_error_force 3.05789
wandb:         train_loss 1.40538
wandb: valid_error_energy 1.26794
wandb:  valid_error_force 2.75061
wandb:         valid_loss 1.40398
wandb: 
wandb: ğŸš€ View run al_81_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/xhsjlltp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_150807-xhsjlltp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7383217215538025, Uncertainty Bias: 0.016976982355117798
7.6293945e-06 0.00037765503
0.4252545 4.4766603
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 835 steps.
Found uncertainty sample 3 after 994 steps.
Found uncertainty sample 4 after 652 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1592 steps.
Found uncertainty sample 7 after 6 steps.
Found uncertainty sample 8 after 33 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2325 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 689 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2895 steps.
Found uncertainty sample 19 after 3055 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2546 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1490 steps.
Found uncertainty sample 25 after 1005 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 821 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 218 steps.
Found uncertainty sample 31 after 917 steps.
Found uncertainty sample 32 after 1275 steps.
Found uncertainty sample 33 after 1515 steps.
Found uncertainty sample 34 after 2090 steps.
Found uncertainty sample 35 after 3930 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 505 steps.
Found uncertainty sample 40 after 1777 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 778 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 16 steps.
Found uncertainty sample 45 after 2305 steps.
Found uncertainty sample 46 after 260 steps.
Found uncertainty sample 47 after 1332 steps.
Found uncertainty sample 48 after 2866 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3699 steps.
Found uncertainty sample 51 after 3989 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3332 steps.
Found uncertainty sample 54 after 2910 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1350 steps.
Found uncertainty sample 57 after 657 steps.
Found uncertainty sample 58 after 1810 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2204 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2174 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 34 steps.
Found uncertainty sample 69 after 3998 steps.
Found uncertainty sample 70 after 1892 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1976 steps.
Found uncertainty sample 73 after 776 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1354 steps.
Found uncertainty sample 77 after 1962 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1708 steps.
Found uncertainty sample 81 after 1523 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3341 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 521 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 888 steps.
Found uncertainty sample 89 after 1528 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1232 steps.
Found uncertainty sample 94 after 194 steps.
Found uncertainty sample 95 after 1221 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3209 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_172024-22xsb90x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/22xsb90x
Training model 22. Added 54 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.950390709420131, Training Loss Force: 3.3164548418225697, time: 2.6678757667541504
Validation Loss Energy: 1.370394713361545, Validation Loss Force: 2.7165369713560734, time: 0.15576958656311035
Test Loss Energy: 7.8179384239707925, Test Loss Force: 10.691428824004083, time: 18.965602159500122


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.754802336459692, Training Loss Force: 3.084969472495747, time: 2.6997299194335938
Validation Loss Energy: 1.70063242898815, Validation Loss Force: 2.712147828486118, time: 0.15323901176452637
Test Loss Energy: 7.800379772691199, Test Loss Force: 10.56197007842029, time: 19.05319333076477


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9037399750777482, Training Loss Force: 3.094345237641786, time: 2.6446733474731445
Validation Loss Energy: 1.872657481696976, Validation Loss Force: 2.7260997204970883, time: 0.15179991722106934
Test Loss Energy: 7.889887891617488, Test Loss Force: 10.671105887998518, time: 19.122325897216797


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7709806415935083, Training Loss Force: 3.0977116659651287, time: 2.658334493637085
Validation Loss Energy: 2.40386406596769, Validation Loss Force: 2.8085563319256073, time: 0.14989662170410156
Test Loss Energy: 8.07670865971869, Test Loss Force: 10.81581331514205, time: 19.00178813934326


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9328257506612823, Training Loss Force: 3.0883544468999835, time: 2.818282127380371
Validation Loss Energy: 3.1366295921192213, Validation Loss Force: 2.8593175491153273, time: 0.15197110176086426
Test Loss Energy: 8.426561968417513, Test Loss Force: 10.610627138631994, time: 19.638593435287476


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1649081484085344, Training Loss Force: 3.114057920915805, time: 2.6786816120147705
Validation Loss Energy: 1.2561646064912928, Validation Loss Force: 2.7264524284242375, time: 0.15735816955566406
Test Loss Energy: 7.79853569210982, Test Loss Force: 10.476422401887373, time: 18.828975439071655


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7297041328497889, Training Loss Force: 3.0683086215398547, time: 2.540921211242676
Validation Loss Energy: 1.240052267091958, Validation Loss Force: 2.719859195013316, time: 0.15162253379821777
Test Loss Energy: 7.743521017417798, Test Loss Force: 10.488114695786457, time: 18.804300785064697


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7149906833159438, Training Loss Force: 3.0790261748238086, time: 2.364841938018799
Validation Loss Energy: 1.250352663446145, Validation Loss Force: 2.6842847929178815, time: 0.14786052703857422
Test Loss Energy: 7.740069097726605, Test Loss Force: 10.576524106856386, time: 17.804893493652344


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8058393689184853, Training Loss Force: 3.065036456488288, time: 2.371847629547119
Validation Loss Energy: 3.7152025241135536, Validation Loss Force: 2.7393544354121584, time: 0.14559149742126465
Test Loss Energy: 8.918955081912031, Test Loss Force: 10.899235240453025, time: 17.948457956314087


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1687810570668242, Training Loss Force: 3.109700944056169, time: 2.4751861095428467
Validation Loss Energy: 1.5550069188859499, Validation Loss Force: 2.7034843286909322, time: 0.14011120796203613
Test Loss Energy: 7.8892660221593855, Test Loss Force: 10.585103560707052, time: 17.89265727996826


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6260900122823736, Training Loss Force: 3.081674156307182, time: 2.413280487060547
Validation Loss Energy: 1.4843313422974647, Validation Loss Force: 2.7068282625899025, time: 0.14430832862854004
Test Loss Energy: 7.887380611386585, Test Loss Force: 10.794019727536703, time: 17.840331077575684


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.795671393744027, Training Loss Force: 3.06440064249108, time: 2.416571617126465
Validation Loss Energy: 1.5138289920659567, Validation Loss Force: 2.7618667314037495, time: 0.14264988899230957
Test Loss Energy: 7.873793890362998, Test Loss Force: 10.658563296408591, time: 17.92751145362854


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9509339938246355, Training Loss Force: 3.0705970084879994, time: 2.551837205886841
Validation Loss Energy: 1.4664810702141635, Validation Loss Force: 2.730579823713155, time: 0.1532883644104004
Test Loss Energy: 7.772745456807465, Test Loss Force: 10.791782483192037, time: 19.209131956100464


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1400763240592586, Training Loss Force: 3.100104404065487, time: 2.6600584983825684
Validation Loss Energy: 2.4864453721179283, Validation Loss Force: 2.794716219825893, time: 0.14655566215515137
Test Loss Energy: 8.218529408717641, Test Loss Force: 10.639108051935002, time: 18.601721048355103


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.216205022045496, Training Loss Force: 3.0952711701736018, time: 2.4541327953338623
Validation Loss Energy: 2.0104272799981304, Validation Loss Force: 2.7607909054252, time: 0.1467442512512207
Test Loss Energy: 7.940831512143548, Test Loss Force: 10.440313515149734, time: 18.7829270362854


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1310708964279668, Training Loss Force: 3.076560988573797, time: 2.608365774154663
Validation Loss Energy: 1.2934275643875837, Validation Loss Force: 2.6951398024472883, time: 0.15843987464904785
Test Loss Energy: 7.752570503685186, Test Loss Force: 10.414522575699921, time: 19.556761503219604


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9528125291658986, Training Loss Force: 3.0586677929787567, time: 2.661688804626465
Validation Loss Energy: 2.070376271487123, Validation Loss Force: 2.7368871499407055, time: 0.15492010116577148
Test Loss Energy: 7.943487516711017, Test Loss Force: 10.843409586078623, time: 19.635040044784546


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.813690271550042, Training Loss Force: 3.0520258079332327, time: 2.756875991821289
Validation Loss Energy: 1.98119338183299, Validation Loss Force: 2.724305452519202, time: 0.16240453720092773
Test Loss Energy: 7.856221051211644, Test Loss Force: 10.445298757895925, time: 19.98358154296875


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8207379016918435, Training Loss Force: 3.0611195609924096, time: 2.6693649291992188
Validation Loss Energy: 1.3779095743674619, Validation Loss Force: 2.7536398858037288, time: 0.15511035919189453
Test Loss Energy: 7.7178074339287654, Test Loss Force: 10.331003958352488, time: 19.510316610336304


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0329682583573883, Training Loss Force: 3.071136561645295, time: 2.714402914047241
Validation Loss Energy: 1.257527954004522, Validation Loss Force: 2.745402018080984, time: 0.16016149520874023
Test Loss Energy: 7.636530218193926, Test Loss Force: 10.279070290181666, time: 19.537236213684082

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–ƒâ–…â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–„â–ƒâ–‚â–ƒâ–‚â–â–
wandb:   test_error_force â–†â–„â–…â–‡â–…â–ƒâ–ƒâ–„â–ˆâ–„â–‡â–…â–‡â–…â–ƒâ–ƒâ–‡â–ƒâ–‚â–
wandb:          test_loss â–†â–„â–„â–ˆâ–†â–ƒâ–ƒâ–„â–ˆâ–„â–…â–„â–‡â–‡â–ƒâ–‚â–†â–ƒâ–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–„â–‚â–â–‚â–„â–â–‚â–ƒâ–„â–„â–„â–ƒâ–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–ƒâ–‚â–â–â–‚â–‚â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–ƒâ–â–â–â–ƒâ–â–â–‚â–ƒâ–ƒâ–ƒâ–â–â–â–‚
wandb: valid_error_energy â–â–‚â–ƒâ–„â–†â–â–â–â–ˆâ–‚â–‚â–‚â–‚â–…â–ƒâ–â–ƒâ–ƒâ–â–
wandb:  valid_error_force â–‚â–‚â–ƒâ–†â–ˆâ–ƒâ–‚â–â–ƒâ–‚â–‚â–„â–ƒâ–…â–„â–â–ƒâ–ƒâ–„â–ƒ
wandb:         valid_loss â–ƒâ–ƒâ–‚â–…â–†â–â–â–â–†â–â–‚â–‚â–„â–ˆâ–…â–‚â–ƒâ–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2186
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.63653
wandb:   test_error_force 10.27907
wandb:          test_loss 5.19617
wandb: train_error_energy 2.03297
wandb:  train_error_force 3.07114
wandb:         train_loss 1.41378
wandb: valid_error_energy 1.25753
wandb:  valid_error_force 2.7454
wandb:         valid_loss 1.38887
wandb: 
wandb: ğŸš€ View run al_81_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/22xsb90x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_172024-22xsb90x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7273904085159302, Uncertainty Bias: 0.020256072282791138
0.0 0.0054121017
0.48900077 4.7731237
(48745, 22, 3)
Found uncertainty sample 0 after 1171 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 610 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 568 steps.
Found uncertainty sample 10 after 1007 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 673 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1779 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3665 steps.
Found uncertainty sample 20 after 742 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3396 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 810 steps.
Found uncertainty sample 26 after 2383 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 10 steps.
Found uncertainty sample 31 after 2622 steps.
Found uncertainty sample 32 after 1372 steps.
Found uncertainty sample 33 after 146 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1135 steps.
Found uncertainty sample 36 after 640 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3878 steps.
Found uncertainty sample 39 after 798 steps.
Found uncertainty sample 40 after 1460 steps.
Found uncertainty sample 41 after 584 steps.
Found uncertainty sample 42 after 898 steps.
Found uncertainty sample 43 after 13 steps.
Found uncertainty sample 44 after 2597 steps.
Found uncertainty sample 45 after 1746 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1652 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1794 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1846 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1047 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2622 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2100 steps.
Found uncertainty sample 61 after 965 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 461 steps.
Found uncertainty sample 67 after 1867 steps.
Found uncertainty sample 68 after 347 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1449 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3844 steps.
Found uncertainty sample 73 after 1953 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1279 steps.
Found uncertainty sample 76 after 445 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1154 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2831 steps.
Found uncertainty sample 82 after 1150 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 953 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2784 steps.
Found uncertainty sample 87 after 621 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 665 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1418 steps.
Found uncertainty sample 93 after 3200 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 545 steps.
Found uncertainty sample 96 after 16 steps.
Found uncertainty sample 97 after 715 steps.
Found uncertainty sample 98 after 1865 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_193419-2ka3mulc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2ka3mulc
Training model 23. Added 53 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.318021380705642, Training Loss Force: 3.329437622250632, time: 2.5177619457244873
Validation Loss Energy: 1.4350564416568128, Validation Loss Force: 2.726091927076981, time: 0.14681601524353027
Test Loss Energy: 7.880082538030046, Test Loss Force: 10.302491265149385, time: 18.921494483947754


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8267588496962714, Training Loss Force: 3.0802546535485527, time: 2.782357692718506
Validation Loss Energy: 1.3011100952603845, Validation Loss Force: 2.750929779628642, time: 0.15677523612976074
Test Loss Energy: 7.68058056621267, Test Loss Force: 10.228815323536187, time: 18.986320734024048


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8326621300345842, Training Loss Force: 3.0731175093958605, time: 2.689361333847046
Validation Loss Energy: 1.2508541143627743, Validation Loss Force: 2.7448428958555597, time: 0.1617419719696045
Test Loss Energy: 7.726948002369101, Test Loss Force: 10.1708884791627, time: 19.106072187423706


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8022473251399427, Training Loss Force: 3.068479457411623, time: 2.6674070358276367
Validation Loss Energy: 1.3167187013843438, Validation Loss Force: 2.7101340087303467, time: 0.15826034545898438
Test Loss Energy: 7.679002884199544, Test Loss Force: 10.21335547235123, time: 19.085642099380493


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8183562290724549, Training Loss Force: 3.0701699679294823, time: 2.9258322715759277
Validation Loss Energy: 1.4273265935905024, Validation Loss Force: 2.782115706861558, time: 0.16054844856262207
Test Loss Energy: 7.7135975181538505, Test Loss Force: 10.352631306536196, time: 19.02945375442505


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.188730751707884, Training Loss Force: 3.099756484954115, time: 2.65785813331604
Validation Loss Energy: 1.3456896829554301, Validation Loss Force: 2.783657468027962, time: 0.15348052978515625
Test Loss Energy: 7.745616341075822, Test Loss Force: 10.154524619224645, time: 19.070255756378174


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.3221338315125712, Training Loss Force: 3.1008879814001338, time: 2.6528449058532715
Validation Loss Energy: 1.4409791626020594, Validation Loss Force: 2.6772942064160516, time: 0.1485130786895752
Test Loss Energy: 7.764502951504289, Test Loss Force: 10.370640689131044, time: 19.090513229370117


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.767235657281579, Training Loss Force: 3.0710013636245725, time: 2.6253230571746826
Validation Loss Energy: 1.4408450601089244, Validation Loss Force: 2.72860641840737, time: 0.16355586051940918
Test Loss Energy: 7.754404940710674, Test Loss Force: 10.243223845263163, time: 19.05158805847168


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6925410926731186, Training Loss Force: 3.071068736946155, time: 2.6763315200805664
Validation Loss Energy: 1.6563343507608437, Validation Loss Force: 2.7377118051226494, time: 0.16091275215148926
Test Loss Energy: 7.698506696194696, Test Loss Force: 10.059052539220282, time: 19.086897134780884


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.867372556757892, Training Loss Force: 3.072074565288188, time: 2.796111822128296
Validation Loss Energy: 1.2661999708945393, Validation Loss Force: 2.696854577540078, time: 0.15893769264221191
Test Loss Energy: 7.568309754594066, Test Loss Force: 10.14776257462174, time: 19.10481333732605


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9957916513599574, Training Loss Force: 3.075492597116948, time: 2.718533754348755
Validation Loss Energy: 1.241944676495912, Validation Loss Force: 2.699430525554744, time: 0.15304327011108398
Test Loss Energy: 7.634076017157863, Test Loss Force: 10.234162917765419, time: 18.945629119873047


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0502527510071182, Training Loss Force: 3.073836997940183, time: 2.9468026161193848
Validation Loss Energy: 1.6821050200320826, Validation Loss Force: 2.7255069752306285, time: 0.16390228271484375
Test Loss Energy: 7.745230221118712, Test Loss Force: 10.48700881122192, time: 19.03774881362915


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7329919228212216, Training Loss Force: 3.0850567967883995, time: 2.6647262573242188
Validation Loss Energy: 1.32281438058869, Validation Loss Force: 2.7442836622955618, time: 0.1490464210510254
Test Loss Energy: 7.637845700875784, Test Loss Force: 10.227497798360382, time: 18.821336030960083


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.070385948052007, Training Loss Force: 3.0803609049030127, time: 2.6216609477996826
Validation Loss Energy: 2.2591598494567657, Validation Loss Force: 2.7353491741497824, time: 0.1407608985900879
Test Loss Energy: 7.882582879377405, Test Loss Force: 10.332068172309949, time: 18.53872513771057


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.111211854038215, Training Loss Force: 3.0741857010036937, time: 2.5140373706817627
Validation Loss Energy: 1.6825947251512643, Validation Loss Force: 2.7672572174229426, time: 0.13987350463867188
Test Loss Energy: 7.885336958628487, Test Loss Force: 10.388976166609778, time: 18.015450477600098


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.25727861486295, Training Loss Force: 3.077061371231741, time: 2.477266550064087
Validation Loss Energy: 1.625143413472144, Validation Loss Force: 2.717174584455438, time: 0.15480875968933105
Test Loss Energy: 7.659225289414304, Test Loss Force: 10.465298424933884, time: 18.216259717941284


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2318493228403202, Training Loss Force: 3.0603418003475107, time: 2.5593738555908203
Validation Loss Energy: 2.6937729478950105, Validation Loss Force: 2.6745289896273476, time: 0.14533686637878418
Test Loss Energy: 8.3461339731678, Test Loss Force: 10.421600041057394, time: 18.2728009223938


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8077718691184415, Training Loss Force: 3.0661321079041426, time: 2.5195980072021484
Validation Loss Energy: 1.4259705941590886, Validation Loss Force: 2.743345000510903, time: 0.14545416831970215
Test Loss Energy: 7.892625938690065, Test Loss Force: 10.25929690629148, time: 18.051869869232178


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.753926420235634, Training Loss Force: 3.060365972673794, time: 2.4907546043395996
Validation Loss Energy: 1.4636618004902853, Validation Loss Force: 2.6819499955882558, time: 0.14727115631103516
Test Loss Energy: 7.745688854274127, Test Loss Force: 10.402398532155914, time: 19.280060291290283


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.731036329456617, Training Loss Force: 3.05591500094399, time: 2.766307830810547
Validation Loss Energy: 1.5503571417806858, Validation Loss Force: 2.719338483215564, time: 0.15825581550598145
Test Loss Energy: 7.822246806140489, Test Loss Force: 10.374916020670964, time: 18.87602162361145

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–ƒâ–‚â–„â–„â–‚â–ˆâ–„â–ƒâ–ƒ
wandb:   test_error_force â–…â–„â–ƒâ–„â–†â–ƒâ–†â–„â–â–‚â–„â–ˆâ–„â–…â–†â–ˆâ–‡â–„â–‡â–†
wandb:          test_loss â–„â–ƒâ–ƒâ–ƒâ–†â–ƒâ–„â–„â–â–‚â–ƒâ–…â–ƒâ–ˆâ–„â–ˆâ–…â–„â–„â–„
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–ƒâ–„â–â–â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–‚â–ƒâ–â–â–â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–â–â–
wandb: valid_error_energy â–‚â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–â–â–ƒâ–â–†â–ƒâ–ƒâ–ˆâ–‚â–‚â–‚
wandb:  valid_error_force â–„â–†â–†â–ƒâ–ˆâ–ˆâ–â–„â–…â–‚â–ƒâ–„â–…â–…â–‡â–„â–â–…â–â–„
wandb:         valid_loss â–â–‚â–„â–‚â–…â–…â–â–„â–„â–‚â–â–ƒâ–‚â–‡â–„â–ˆâ–„â–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2233
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.82225
wandb:   test_error_force 10.37492
wandb:          test_loss 5.19406
wandb: train_error_energy 1.73104
wandb:  train_error_force 3.05592
wandb:         train_loss 1.39118
wandb: valid_error_energy 1.55036
wandb:  valid_error_force 2.71934
wandb:         valid_loss 1.34889
wandb: 
wandb: ğŸš€ View run al_81_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2ka3mulc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_193419-2ka3mulc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7199918031692505, Uncertainty Bias: 0.022993415594100952
3.0517578e-05 0.0043621063
0.45816568 3.9090798
(48745, 22, 3)
Found uncertainty sample 0 after 2412 steps.
Found uncertainty sample 1 after 2397 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3641 steps.
Found uncertainty sample 4 after 514 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1128 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 980 steps.
Found uncertainty sample 10 after 2414 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 948 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3776 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1350 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1805 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 419 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3507 steps.
Found uncertainty sample 24 after 3968 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1305 steps.
Found uncertainty sample 27 after 3455 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2664 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2011 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1837 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3007 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1169 steps.
Found uncertainty sample 42 after 1638 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 89 steps.
Found uncertainty sample 47 after 3763 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2493 steps.
Found uncertainty sample 52 after 3278 steps.
Found uncertainty sample 53 after 2862 steps.
Found uncertainty sample 54 after 734 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3729 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1316 steps.
Found uncertainty sample 61 after 2063 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3376 steps.
Found uncertainty sample 64 after 2018 steps.
Found uncertainty sample 65 after 1417 steps.
Found uncertainty sample 66 after 2612 steps.
Found uncertainty sample 67 after 265 steps.
Found uncertainty sample 68 after 2258 steps.
Found uncertainty sample 69 after 976 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 491 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 448 steps.
Found uncertainty sample 81 after 15 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3415 steps.
Found uncertainty sample 84 after 3575 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2281 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 108 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3430 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 477 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_220241-8zyji7f3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/8zyji7f3
Training model 24. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.081594928782931, Training Loss Force: 3.289291570937821, time: 2.4470808506011963
Validation Loss Energy: 1.592109220993454, Validation Loss Force: 2.732068478288255, time: 0.14063549041748047
Test Loss Energy: 7.65737731503739, Test Loss Force: 10.260438469214877, time: 17.657007455825806


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8428461119771045, Training Loss Force: 3.081368407770041, time: 2.535386562347412
Validation Loss Energy: 3.7784083858654585, Validation Loss Force: 2.77928123996847, time: 0.15094828605651855
Test Loss Energy: 8.887083899126074, Test Loss Force: 10.362907308086479, time: 17.85108470916748


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.10439548732223, Training Loss Force: 3.0921141176750675, time: 2.6142125129699707
Validation Loss Energy: 2.1132133617807107, Validation Loss Force: 2.7611018628874877, time: 0.14203500747680664
Test Loss Energy: 8.128935446755275, Test Loss Force: 10.193316303107299, time: 17.853677988052368


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9400523778870695, Training Loss Force: 3.094721248648044, time: 2.584085464477539
Validation Loss Energy: 1.5691842077398857, Validation Loss Force: 2.8186475862844818, time: 0.14128804206848145
Test Loss Energy: 7.840601346896053, Test Loss Force: 10.28949099170259, time: 17.762983083724976


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.961955390789175, Training Loss Force: 3.0928328689371063, time: 2.490424633026123
Validation Loss Energy: 2.3667175083674326, Validation Loss Force: 2.7265478421532676, time: 0.14592671394348145
Test Loss Energy: 8.226631327017436, Test Loss Force: 10.410533650308787, time: 17.799094915390015


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7893269796910904, Training Loss Force: 3.0683892984977157, time: 2.5114688873291016
Validation Loss Energy: 2.606202962199406, Validation Loss Force: 2.7228789226358154, time: 0.14159154891967773
Test Loss Energy: 8.24357750291211, Test Loss Force: 10.246571320301037, time: 17.887487173080444


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.3370250331472917, Training Loss Force: 3.091886320953529, time: 2.5786354541778564
Validation Loss Energy: 2.543043192960708, Validation Loss Force: 2.7244383859993206, time: 0.1487259864807129
Test Loss Energy: 7.9327906494904035, Test Loss Force: 10.13048014266896, time: 17.78089189529419


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0720728743035033, Training Loss Force: 3.068650019326581, time: 2.4474422931671143
Validation Loss Energy: 1.2917911688341603, Validation Loss Force: 2.7610410742106497, time: 0.1426994800567627
Test Loss Energy: 7.810018781934371, Test Loss Force: 10.053852573468994, time: 17.812448263168335


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7836998605417866, Training Loss Force: 3.0781907953525707, time: 2.5216386318206787
Validation Loss Energy: 2.5909623725063784, Validation Loss Force: 2.7611311438801773, time: 0.14181256294250488
Test Loss Energy: 7.9243898975387035, Test Loss Force: 10.060603449640391, time: 18.47995662689209


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8413294900026445, Training Loss Force: 3.0875120907310967, time: 2.498687982559204
Validation Loss Energy: 2.389907609239228, Validation Loss Force: 2.7536188435694386, time: 0.14240598678588867
Test Loss Energy: 8.017338159173395, Test Loss Force: 10.017009596686938, time: 17.687453508377075


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7462473470303006, Training Loss Force: 3.085802152506977, time: 2.5139780044555664
Validation Loss Energy: 1.901592056862703, Validation Loss Force: 2.71854611505978, time: 0.14855575561523438
Test Loss Energy: 7.666072127826947, Test Loss Force: 10.18596429019032, time: 17.781370162963867


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9028860862337542, Training Loss Force: 3.083962293021462, time: 2.4629721641540527
Validation Loss Energy: 1.336124707122956, Validation Loss Force: 2.7158258774385526, time: 0.14954257011413574
Test Loss Energy: 7.5584172382769665, Test Loss Force: 10.040175539705109, time: 17.820408582687378


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9755698122463567, Training Loss Force: 3.0656593685833875, time: 2.5443615913391113
Validation Loss Energy: 2.006445176326931, Validation Loss Force: 2.7557996651846555, time: 0.14118432998657227
Test Loss Energy: 7.74233545926807, Test Loss Force: 9.960130696267768, time: 17.808624029159546


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8754313129982632, Training Loss Force: 3.0820091939047347, time: 2.5760021209716797
Validation Loss Energy: 1.1924218894285556, Validation Loss Force: 2.8133118768751872, time: 0.14300847053527832
Test Loss Energy: 7.499038005836896, Test Loss Force: 10.103408508219562, time: 18.024595499038696


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7870226733444783, Training Loss Force: 3.062071667636912, time: 2.4785351753234863
Validation Loss Energy: 1.2233879865471549, Validation Loss Force: 2.716711543966481, time: 0.14656853675842285
Test Loss Energy: 7.573008607512769, Test Loss Force: 10.156759079622082, time: 18.19774603843689


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.952920618026798, Training Loss Force: 3.086786266631048, time: 2.4685280323028564
Validation Loss Energy: 2.1135439141278405, Validation Loss Force: 2.729794803639187, time: 0.15224409103393555
Test Loss Energy: 7.741949717032443, Test Loss Force: 9.997190825596807, time: 18.116851091384888


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1002752313628035, Training Loss Force: 3.0599409001901234, time: 2.510833978652954
Validation Loss Energy: 1.305772787176112, Validation Loss Force: 2.730910487394858, time: 0.14230680465698242
Test Loss Energy: 7.439076133345841, Test Loss Force: 10.059225442395002, time: 18.21073865890503


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8517397534782711, Training Loss Force: 3.056717900378408, time: 2.4811649322509766
Validation Loss Energy: 1.5853311721914123, Validation Loss Force: 2.706923898988079, time: 0.150954008102417
Test Loss Energy: 7.593990462324381, Test Loss Force: 10.159213602420891, time: 18.256641149520874


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.903488393902981, Training Loss Force: 3.063238704464363, time: 2.5466830730438232
Validation Loss Energy: 1.473115274747936, Validation Loss Force: 2.7679813374855, time: 0.14705467224121094
Test Loss Energy: 7.741490155894617, Test Loss Force: 9.987513876329109, time: 18.16130828857422


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.897156278723497, Training Loss Force: 3.0630503232742807, time: 2.7119650840759277
Validation Loss Energy: 3.0592834602588908, Validation Loss Force: 2.7486886146748786, time: 0.15369582176208496
Test Loss Energy: 8.109389092129371, Test Loss Force: 10.014187173163545, time: 18.20400309562683

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–„â–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–„
wandb:   test_error_force â–†â–‡â–…â–†â–ˆâ–…â–„â–‚â–ƒâ–‚â–…â–‚â–â–ƒâ–„â–‚â–ƒâ–„â–â–‚
wandb:          test_loss â–…â–ˆâ–…â–‡â–ˆâ–…â–…â–ƒâ–„â–â–†â–‚â–â–‚â–„â–‚â–â–†â–â–„
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–‚â–â–„â–ƒâ–â–â–â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–
wandb: valid_error_energy â–‚â–ˆâ–ƒâ–‚â–„â–…â–…â–â–…â–„â–ƒâ–â–ƒâ–â–â–ƒâ–â–‚â–‚â–†
wandb:  valid_error_force â–ƒâ–†â–„â–ˆâ–‚â–‚â–‚â–„â–„â–„â–‚â–‚â–„â–ˆâ–‚â–‚â–ƒâ–â–…â–„
wandb:         valid_loss â–‚â–ˆâ–„â–ƒâ–…â–…â–…â–ƒâ–…â–…â–†â–„â–„â–„â–‚â–ƒâ–â–„â–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2275
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.10939
wandb:   test_error_force 10.01419
wandb:          test_loss 5.12354
wandb: train_error_energy 1.89716
wandb:  train_error_force 3.06305
wandb:         train_loss 1.40328
wandb: valid_error_energy 3.05928
wandb:  valid_error_force 2.74869
wandb:         valid_loss 1.4639
wandb: 
wandb: ğŸš€ View run al_81_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/8zyji7f3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_220241-8zyji7f3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7576911449432373, Uncertainty Bias: 0.014272108674049377
9.918213e-05 0.042967796
0.31175017 5.802471
(48745, 22, 3)
Found uncertainty sample 0 after 3272 steps.
Found uncertainty sample 1 after 1056 steps.
Found uncertainty sample 2 after 2257 steps.
Found uncertainty sample 3 after 3707 steps.
Found uncertainty sample 4 after 2836 steps.
Found uncertainty sample 5 after 2049 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1011 steps.
Found uncertainty sample 9 after 1281 steps.
Found uncertainty sample 10 after 1023 steps.
Found uncertainty sample 11 after 690 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 728 steps.
Found uncertainty sample 14 after 11 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 554 steps.
Found uncertainty sample 18 after 3383 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 976 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3273 steps.
Found uncertainty sample 23 after 652 steps.
Found uncertainty sample 24 after 1072 steps.
Found uncertainty sample 25 after 1428 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1788 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 237 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 554 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2733 steps.
Found uncertainty sample 37 after 3912 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 465 steps.
Found uncertainty sample 40 after 1317 steps.
Found uncertainty sample 41 after 2123 steps.
Found uncertainty sample 42 after 3626 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2011 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 998 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2008 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3051 steps.
Found uncertainty sample 57 after 596 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1207 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 918 steps.
Found uncertainty sample 68 after 18 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1456 steps.
Found uncertainty sample 73 after 2187 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1021 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 54 steps.
Found uncertainty sample 81 after 1313 steps.
Found uncertainty sample 82 after 95 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1560 steps.
Found uncertainty sample 85 after 3564 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1442 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3792 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 91 steps.
Found uncertainty sample 94 after 2266 steps.
Found uncertainty sample 95 after 468 steps.
Found uncertainty sample 96 after 2147 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1725 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_001520-uzemqi02
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/uzemqi02
Training model 25. Added 51 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.042770685478621, Training Loss Force: 3.3134798394663685, time: 2.5682315826416016
Validation Loss Energy: 1.491716554193165, Validation Loss Force: 2.7749605678608873, time: 0.14953041076660156
Test Loss Energy: 7.853174809056579, Test Loss Force: 10.048002427801281, time: 17.831270933151245


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7605641155767024, Training Loss Force: 3.069767885799097, time: 2.637205123901367
Validation Loss Energy: 1.3007433591770412, Validation Loss Force: 2.7122676244866266, time: 0.1484072208404541
Test Loss Energy: 7.641981121580411, Test Loss Force: 9.94432688070851, time: 18.0052433013916


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0279501948840326, Training Loss Force: 3.0751508025924594, time: 2.6102375984191895
Validation Loss Energy: 1.651740519278494, Validation Loss Force: 2.753962867399897, time: 0.14762592315673828
Test Loss Energy: 7.934234447890671, Test Loss Force: 10.019873177862307, time: 17.96724271774292


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.085053865121639, Training Loss Force: 3.0795196047884477, time: 2.5821216106414795
Validation Loss Energy: 1.5677086349771088, Validation Loss Force: 2.7615899536553616, time: 0.14197230339050293
Test Loss Energy: 7.582359086506714, Test Loss Force: 9.927895786346456, time: 17.866235971450806


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8788101893673435, Training Loss Force: 3.0787917756069665, time: 2.6172029972076416
Validation Loss Energy: 1.7142771489123132, Validation Loss Force: 2.7686307520495985, time: 0.14577913284301758
Test Loss Energy: 7.860242656505912, Test Loss Force: 10.043097933514373, time: 17.980603218078613


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.106059394080753, Training Loss Force: 3.0871911059128694, time: 2.6035959720611572
Validation Loss Energy: 3.5989465176863638, Validation Loss Force: 2.7280288146428333, time: 0.15047168731689453
Test Loss Energy: 8.176458745624336, Test Loss Force: 9.637459517210234, time: 18.015125274658203


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0795799620549356, Training Loss Force: 3.0666639389101094, time: 2.543196439743042
Validation Loss Energy: 1.759182946906143, Validation Loss Force: 2.74558215742004, time: 0.14109253883361816
Test Loss Energy: 7.860517241371248, Test Loss Force: 10.0158567114455, time: 18.413894414901733


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1229723022659925, Training Loss Force: 3.079138206094359, time: 2.530829429626465
Validation Loss Energy: 2.0577287753329974, Validation Loss Force: 2.753783396068279, time: 0.14800810813903809
Test Loss Energy: 7.9243791837719435, Test Loss Force: 9.835532083681139, time: 18.02482795715332


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9033001823837377, Training Loss Force: 3.078115090173016, time: 2.597452402114868
Validation Loss Energy: 1.5599665401077725, Validation Loss Force: 2.7292068457593643, time: 0.14470934867858887
Test Loss Energy: 7.725616042170442, Test Loss Force: 9.86450904321931, time: 17.94141387939453


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6413072946782366, Training Loss Force: 3.05752288242781, time: 2.560096263885498
Validation Loss Energy: 1.1976726505586788, Validation Loss Force: 2.7214384759308086, time: 0.14492297172546387
Test Loss Energy: 7.5341045817998635, Test Loss Force: 10.031557712149691, time: 17.856737852096558


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6800465299478895, Training Loss Force: 3.052154088348771, time: 2.543653964996338
Validation Loss Energy: 1.3862774808714282, Validation Loss Force: 2.732663895584466, time: 0.14790868759155273
Test Loss Energy: 7.567857325863751, Test Loss Force: 9.893045094532402, time: 17.99717688560486


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8190448892478235, Training Loss Force: 3.0562080638247777, time: 2.548621654510498
Validation Loss Energy: 1.2144119149383732, Validation Loss Force: 2.7398882846895205, time: 0.14169073104858398
Test Loss Energy: 7.337804881421079, Test Loss Force: 9.90783957766673, time: 18.028034448623657


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2590219821774205, Training Loss Force: 3.110345405856367, time: 2.59049129486084
Validation Loss Energy: 1.9770282441238378, Validation Loss Force: 2.729913152290248, time: 0.14867758750915527
Test Loss Energy: 8.059709425613704, Test Loss Force: 9.802235715770227, time: 17.919121503829956


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.041345862418737, Training Loss Force: 3.0641392581785967, time: 2.7953314781188965
Validation Loss Energy: 1.510006430837814, Validation Loss Force: 2.7197703500240906, time: 0.14054346084594727
Test Loss Energy: 7.51789823172028, Test Loss Force: 9.916323440002794, time: 17.950668811798096


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.779452765568628, Training Loss Force: 3.0569343892269587, time: 2.6479573249816895
Validation Loss Energy: 1.7511773787698879, Validation Loss Force: 2.704916759306686, time: 0.14741015434265137
Test Loss Energy: 7.513031581861727, Test Loss Force: 9.71981851561473, time: 18.193822145462036


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.016967705743451, Training Loss Force: 3.066942507162452, time: 2.5618884563446045
Validation Loss Energy: 1.2095573935534285, Validation Loss Force: 2.6988290961915933, time: 0.14612054824829102
Test Loss Energy: 7.567154791884471, Test Loss Force: 9.71703600466139, time: 18.23685574531555


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6688193518180314, Training Loss Force: 3.0558831651387712, time: 2.8667826652526855
Validation Loss Energy: 1.2430934822870396, Validation Loss Force: 2.7117080569229106, time: 0.14994525909423828
Test Loss Energy: 7.52922269017998, Test Loss Force: 9.844551242644014, time: 18.207404375076294


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.677443823507434, Training Loss Force: 3.0483565514723163, time: 2.575685977935791
Validation Loss Energy: 1.2585296868247646, Validation Loss Force: 2.714390552123902, time: 0.15210580825805664
Test Loss Energy: 7.393425542616, Test Loss Force: 9.962135861072023, time: 18.433058261871338


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8250218308926693, Training Loss Force: 3.0446849721261624, time: 2.6035923957824707
Validation Loss Energy: 1.2490302870557666, Validation Loss Force: 2.7002407072422026, time: 0.15293550491333008
Test Loss Energy: 7.42081377528508, Test Loss Force: 9.902511102673065, time: 18.908654928207397


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7657551396079059, Training Loss Force: 3.038350297247072, time: 2.5786006450653076
Validation Loss Energy: 1.2756413653510235, Validation Loss Force: 2.7068786971514553, time: 0.14644408226013184
Test Loss Energy: 7.503909085762227, Test Loss Force: 9.816397412829266, time: 18.374716997146606

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–†â–ƒâ–…â–ˆâ–…â–†â–„â–ƒâ–ƒâ–â–‡â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–‚
wandb:   test_error_force â–ˆâ–†â–ˆâ–†â–ˆâ–â–‡â–„â–…â–ˆâ–…â–†â–„â–†â–‚â–‚â–…â–‡â–†â–„
wandb:          test_loss â–ˆâ–†â–ˆâ–‡â–ˆâ–‚â–‡â–…â–…â–ˆâ–„â–„â–†â–‡â–‚â–â–„â–†â–…â–…
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–â–â–‚â–„â–ƒâ–‚â–ƒâ–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–ƒâ–‚â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–‚â–â–‚â–‚â–ƒâ–ˆâ–ƒâ–„â–‚â–â–‚â–â–ƒâ–‚â–ƒâ–â–â–â–â–
wandb:  valid_error_force â–ˆâ–‚â–†â–‡â–‡â–„â–…â–†â–„â–ƒâ–„â–…â–„â–ƒâ–‚â–â–‚â–‚â–â–‚
wandb:         valid_loss â–‚â–‚â–ƒâ–ƒâ–„â–ˆâ–„â–…â–ƒâ–â–‚â–„â–†â–„â–ƒâ–â–â–‚â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2320
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.50391
wandb:   test_error_force 9.8164
wandb:          test_loss 5.015
wandb: train_error_energy 1.76576
wandb:  train_error_force 3.03835
wandb:         train_loss 1.37578
wandb: valid_error_energy 1.27564
wandb:  valid_error_force 2.70688
wandb:         valid_loss 1.36717
wandb: 
wandb: ğŸš€ View run al_81_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/uzemqi02
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_001520-uzemqi02/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7413322925567627, Uncertainty Bias: 0.015812411904335022
2.193451e-05 0.00573349
0.3609292 5.3766165
(48745, 22, 3)
Found uncertainty sample 0 after 845 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 81 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2568 steps.
Found uncertainty sample 7 after 2081 steps.
Found uncertainty sample 8 after 3652 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1396 steps.
Found uncertainty sample 11 after 801 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 644 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2641 steps.
Found uncertainty sample 16 after 2837 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1067 steps.
Found uncertainty sample 19 after 1354 steps.
Found uncertainty sample 20 after 58 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1229 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3630 steps.
Found uncertainty sample 30 after 1433 steps.
Found uncertainty sample 31 after 2337 steps.
Found uncertainty sample 32 after 3424 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 98 steps.
Found uncertainty sample 38 after 3525 steps.
Found uncertainty sample 39 after 2920 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 315 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1714 steps.
Found uncertainty sample 45 after 1387 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1770 steps.
Found uncertainty sample 49 after 1758 steps.
Found uncertainty sample 50 after 1898 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 167 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1114 steps.
Found uncertainty sample 63 after 1118 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1760 steps.
Found uncertainty sample 66 after 2117 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2640 steps.
Found uncertainty sample 69 after 2069 steps.
Found uncertainty sample 70 after 1700 steps.
Found uncertainty sample 71 after 722 steps.
Found uncertainty sample 72 after 3267 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2608 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 110 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 679 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 435 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2775 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3004 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1068 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1570 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_023648-93ixzrsx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/93ixzrsx
Training model 26. Added 45 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5871067704088246, Training Loss Force: 3.243590079461892, time: 2.686960458755493
Validation Loss Energy: 1.254055540008351, Validation Loss Force: 2.7229221204501255, time: 0.15210819244384766
Test Loss Energy: 7.523627634752164, Test Loss Force: 9.671473826406357, time: 18.33146905899048


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.749661211014574, Training Loss Force: 3.0558276050236666, time: 2.699610710144043
Validation Loss Energy: 1.2389353586559841, Validation Loss Force: 2.6964521030588138, time: 0.14864659309387207
Test Loss Energy: 7.455832257044143, Test Loss Force: 9.62365765815424, time: 18.394283056259155


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.91475144982454, Training Loss Force: 3.0659762779317647, time: 2.644928216934204
Validation Loss Energy: 1.681425545133284, Validation Loss Force: 2.7207597803740207, time: 0.15261578559875488
Test Loss Energy: 7.56344728531958, Test Loss Force: 9.614255508260369, time: 19.164807319641113


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.794126018782979, Training Loss Force: 3.0656178889323513, time: 2.6186094284057617
Validation Loss Energy: 1.2515596972189331, Validation Loss Force: 2.7291106526883233, time: 0.14947152137756348
Test Loss Energy: 7.533335179459996, Test Loss Force: 9.725363578904767, time: 18.424646854400635


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.16535863320971, Training Loss Force: 3.086933783602873, time: 2.6620841026306152
Validation Loss Energy: 1.4681340546189585, Validation Loss Force: 2.7268506721917296, time: 0.15632081031799316
Test Loss Energy: 7.412854698659492, Test Loss Force: 9.576995279809827, time: 18.393203258514404


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8929285615810811, Training Loss Force: 3.0544583733278032, time: 2.6915624141693115
Validation Loss Energy: 2.0219138905599614, Validation Loss Force: 2.750073616762549, time: 0.1519908905029297
Test Loss Energy: 7.895658664478231, Test Loss Force: 9.828462107468138, time: 18.493478298187256


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.885888971317413, Training Loss Force: 3.0621270475598337, time: 2.687638521194458
Validation Loss Energy: 1.2168071112738321, Validation Loss Force: 2.753197887549062, time: 0.1464991569519043
Test Loss Energy: 7.60121864088524, Test Loss Force: 9.722514169279858, time: 18.453877449035645


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.857885792603199, Training Loss Force: 3.0727760971563853, time: 2.906750202178955
Validation Loss Energy: 1.8731058816895882, Validation Loss Force: 2.7177070977179234, time: 0.1579287052154541
Test Loss Energy: 7.677293218839039, Test Loss Force: 9.647043173934822, time: 18.383301258087158


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7876907029321578, Training Loss Force: 3.075961547795263, time: 2.7121291160583496
Validation Loss Energy: 1.3096236273857873, Validation Loss Force: 2.7319653824736907, time: 0.16298317909240723
Test Loss Energy: 7.583278460596687, Test Loss Force: 9.632886349949239, time: 18.604233741760254


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8616637869026875, Training Loss Force: 3.058636579308588, time: 2.7205288410186768
Validation Loss Energy: 2.9587520149134026, Validation Loss Force: 2.7224528452250825, time: 0.15099692344665527
Test Loss Energy: 7.87115956048014, Test Loss Force: 9.54859712948068, time: 18.560416221618652


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.92666888757071, Training Loss Force: 3.065562766282565, time: 2.7126591205596924
Validation Loss Energy: 1.2801686187587407, Validation Loss Force: 2.7447227658513316, time: 0.15012264251708984
Test Loss Energy: 7.509435568419555, Test Loss Force: 9.762421605117895, time: 18.420989274978638


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7780799159319516, Training Loss Force: 3.0651976791545184, time: 2.703812599182129
Validation Loss Energy: 1.3965393554633696, Validation Loss Force: 2.706255668881149, time: 0.15257787704467773
Test Loss Energy: 7.568188806776194, Test Loss Force: 9.6312668760851, time: 18.5348060131073


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8096014973435774, Training Loss Force: 3.049188968170273, time: 2.7185587882995605
Validation Loss Energy: 2.0785735020907357, Validation Loss Force: 2.680968915331298, time: 0.14798188209533691
Test Loss Energy: 7.84662312967203, Test Loss Force: 9.505083572653376, time: 18.589973211288452


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.01965070392857, Training Loss Force: 3.067781417580249, time: 2.7194690704345703
Validation Loss Energy: 1.3034783486291857, Validation Loss Force: 2.7270492930698973, time: 0.16030287742614746
Test Loss Energy: 7.3776464748087305, Test Loss Force: 9.436508810965558, time: 18.58954882621765


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8362775228124255, Training Loss Force: 3.059950381432327, time: 2.635584592819214
Validation Loss Energy: 1.7698145636148976, Validation Loss Force: 2.7078863863713516, time: 0.15467166900634766
Test Loss Energy: 7.441693542705222, Test Loss Force: 9.652381917356957, time: 18.833571672439575


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3887704875601763, Training Loss Force: 3.079843128383246, time: 2.6488959789276123
Validation Loss Energy: 1.7539651408096173, Validation Loss Force: 2.723781512018834, time: 0.15241241455078125
Test Loss Energy: 7.766928979647261, Test Loss Force: 9.716926111025934, time: 19.46723508834839


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.202762695641063, Training Loss Force: 3.094549456560087, time: 2.660198450088501
Validation Loss Energy: 1.6378402308420923, Validation Loss Force: 2.710738221457822, time: 0.15136194229125977
Test Loss Energy: 7.734530887050387, Test Loss Force: 9.668760881491112, time: 18.98904061317444


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.715195627544319, Training Loss Force: 3.0383708765834525, time: 2.581146717071533
Validation Loss Energy: 1.4062889796851046, Validation Loss Force: 2.7317773383799544, time: 0.14260339736938477
Test Loss Energy: 7.590270964268204, Test Loss Force: 9.61799621001511, time: 18.854364156723022


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8351101993736754, Training Loss Force: 3.041849714885388, time: 2.855168581008911
Validation Loss Energy: 2.128743755367163, Validation Loss Force: 2.7227842882487963, time: 0.16788005828857422
Test Loss Energy: 7.959395574073166, Test Loss Force: 9.745485478479964, time: 17.744977951049805


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9638942136290782, Training Loss Force: 3.0310581329631026, time: 2.5851314067840576
Validation Loss Energy: 1.2913855213175665, Validation Loss Force: 2.6930625219849285, time: 0.1351938247680664
Test Loss Energy: 7.484622531236689, Test Loss Force: 9.706155555473513, time: 17.56448221206665

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–ƒâ–ƒâ–â–‡â–„â–…â–ƒâ–‡â–ƒâ–ƒâ–‡â–â–‚â–†â–…â–„â–ˆâ–‚
wandb:   test_error_force â–…â–„â–„â–†â–„â–ˆâ–†â–…â–…â–ƒâ–‡â–„â–‚â–â–…â–†â–…â–„â–‡â–†
wandb:          test_loss â–‡â–„â–…â–…â–„â–‡â–…â–„â–…â–…â–ˆâ–ƒâ–ƒâ–â–ˆâ–…â–ƒâ–„â–‡â–…
wandb: train_error_energy â–ˆâ–â–‚â–â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–„â–ƒâ–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–â–
wandb:         train_loss â–ˆâ–â–â–â–ƒâ–â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–ƒâ–‚â–â–â–
wandb: valid_error_energy â–â–â–ƒâ–â–‚â–„â–â–„â–â–ˆâ–â–‚â–„â–â–ƒâ–ƒâ–ƒâ–‚â–…â–
wandb:  valid_error_force â–…â–ƒâ–…â–†â–…â–ˆâ–ˆâ–…â–†â–…â–‡â–ƒâ–â–…â–„â–…â–„â–†â–…â–‚
wandb:         valid_loss â–…â–‚â–…â–‚â–„â–„â–â–…â–ƒâ–†â–†â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–„â–„â–†â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2360
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.48462
wandb:   test_error_force 9.70616
wandb:          test_loss 4.90884
wandb: train_error_energy 1.96389
wandb:  train_error_force 3.03106
wandb:         train_loss 1.39768
wandb: valid_error_energy 1.29139
wandb:  valid_error_force 2.69306
wandb:         valid_loss 1.32596
wandb: 
wandb: ğŸš€ View run al_81_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/93ixzrsx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_023648-93ixzrsx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7442233562469482, Uncertainty Bias: 0.012991920113563538
2.4795532e-05 0.0013751984
0.21148609 4.334597
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2058 steps.
Found uncertainty sample 2 after 1024 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2908 steps.
Found uncertainty sample 6 after 1915 steps.
Found uncertainty sample 7 after 2730 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3208 steps.
Found uncertainty sample 10 after 297 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1437 steps.
Found uncertainty sample 13 after 576 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3061 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3677 steps.
Found uncertainty sample 23 after 1702 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2575 steps.
Found uncertainty sample 27 after 2788 steps.
Found uncertainty sample 28 after 372 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 976 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 693 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1324 steps.
Found uncertainty sample 37 after 12 steps.
Found uncertainty sample 38 after 3883 steps.
Found uncertainty sample 39 after 3238 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2792 steps.
Found uncertainty sample 44 after 2398 steps.
Found uncertainty sample 45 after 1653 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3216 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 64 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1457 steps.
Found uncertainty sample 53 after 1119 steps.
Found uncertainty sample 54 after 1160 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2571 steps.
Found uncertainty sample 59 after 1189 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2098 steps.
Found uncertainty sample 62 after 2782 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3688 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1100 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2731 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3975 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1842 steps.
Found uncertainty sample 81 after 1044 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 962 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1288 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 708 steps.
Found uncertainty sample 90 after 1450 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1060 steps.
Found uncertainty sample 93 after 1396 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1865 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_050049-wjoqgfsj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/wjoqgfsj
Training model 27. Added 46 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8647061512363514, Training Loss Force: 3.274983343185429, time: 2.7202765941619873
Validation Loss Energy: 1.8961600430477945, Validation Loss Force: 2.7830529212967683, time: 0.14983296394348145
Test Loss Energy: 7.8342143890523674, Test Loss Force: 9.66169604415557, time: 17.91472554206848


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7852614892325205, Training Loss Force: 3.079144935735498, time: 2.694934606552124
Validation Loss Energy: 1.282572554858177, Validation Loss Force: 2.7296723356089263, time: 0.15286588668823242
Test Loss Energy: 7.395150612950818, Test Loss Force: 9.76028356162645, time: 18.628154754638672


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9019803566949147, Training Loss Force: 3.0571400939379045, time: 2.5682129859924316
Validation Loss Energy: 1.5953526754403247, Validation Loss Force: 2.8297406291308853, time: 0.15474796295166016
Test Loss Energy: 7.58990550008035, Test Loss Force: 9.56587176917916, time: 17.998674869537354


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.752459125365778, Training Loss Force: 3.082121128610112, time: 2.6231610774993896
Validation Loss Energy: 1.4545323655072462, Validation Loss Force: 2.7317116509819064, time: 0.15604686737060547
Test Loss Energy: 7.348650001992212, Test Loss Force: 9.501525315038224, time: 17.905479907989502


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.946694763233177, Training Loss Force: 3.0829876426616325, time: 2.6339175701141357
Validation Loss Energy: 4.464258302312016, Validation Loss Force: 2.74288697007773, time: 0.15832161903381348
Test Loss Energy: 9.158293048911617, Test Loss Force: 9.699964980158466, time: 17.99177861213684


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.162585025349626, Training Loss Force: 3.108699790965493, time: 2.707993984222412
Validation Loss Energy: 1.397177302566453, Validation Loss Force: 2.7174404514156754, time: 0.1498880386352539
Test Loss Energy: 7.280587600843364, Test Loss Force: 9.370676134705922, time: 18.00975799560547


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.21218485887133, Training Loss Force: 3.068880251410518, time: 2.595628499984741
Validation Loss Energy: 2.8830567521009804, Validation Loss Force: 2.7179983489607977, time: 0.14456629753112793
Test Loss Energy: 7.842178471653411, Test Loss Force: 9.283080456954623, time: 17.825063943862915


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0634350457541872, Training Loss Force: 3.0978217410391973, time: 2.6709868907928467
Validation Loss Energy: 2.2702753818869077, Validation Loss Force: 2.8113796653613985, time: 0.15092968940734863
Test Loss Energy: 8.118071948401857, Test Loss Force: 9.995027204298758, time: 17.98027467727661


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0994931760601494, Training Loss Force: 3.1001324022053476, time: 2.6875815391540527
Validation Loss Energy: 1.475420624083013, Validation Loss Force: 2.7326140176957785, time: 0.1454756259918213
Test Loss Energy: 7.494649653967018, Test Loss Force: 9.510807610641232, time: 18.021459102630615


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2992003544457167, Training Loss Force: 3.101278620932582, time: 2.69050669670105
Validation Loss Energy: 3.829822468991039, Validation Loss Force: 2.7766947151693726, time: 0.15207147598266602
Test Loss Energy: 8.930103079153907, Test Loss Force: 9.904400866569377, time: 17.80914044380188


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.270021086397616, Training Loss Force: 3.1147399288672157, time: 2.9133565425872803
Validation Loss Energy: 1.2875296153848215, Validation Loss Force: 2.7346882921246687, time: 0.1512463092803955
Test Loss Energy: 7.4248123022630494, Test Loss Force: 9.524360523260462, time: 17.886617183685303


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.337933248059564, Training Loss Force: 3.0639536745829368, time: 2.651956558227539
Validation Loss Energy: 1.6231273670249138, Validation Loss Force: 2.727431838662601, time: 0.14861011505126953
Test Loss Energy: 7.569386892688447, Test Loss Force: 9.552858294133367, time: 18.041670560836792


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.345465896960905, Training Loss Force: 3.085377814292022, time: 2.694343090057373
Validation Loss Energy: 1.5015907061347598, Validation Loss Force: 2.768887823578572, time: 0.1473538875579834
Test Loss Energy: 7.50124444256454, Test Loss Force: 9.513714676419443, time: 17.96455407142639


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7608650694730896, Training Loss Force: 3.0625708801426534, time: 2.8706512451171875
Validation Loss Energy: 1.3865398407926177, Validation Loss Force: 2.6939064380479945, time: 0.150648832321167
Test Loss Energy: 7.564906994654419, Test Loss Force: 9.660809340642274, time: 18.165698528289795


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9576389143998483, Training Loss Force: 3.063681583141113, time: 2.687836170196533
Validation Loss Energy: 1.2650584018506539, Validation Loss Force: 2.7067393062661047, time: 0.14838409423828125
Test Loss Energy: 7.283733169758814, Test Loss Force: 9.247147807599855, time: 18.977854251861572


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.949000842102692, Training Loss Force: 3.074337816509921, time: 2.60394549369812
Validation Loss Energy: 1.635960235243024, Validation Loss Force: 2.7769981018806993, time: 0.15195155143737793
Test Loss Energy: 7.440598805587664, Test Loss Force: 9.251661448753042, time: 18.408894300460815


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7901499347013257, Training Loss Force: 3.0470354691757744, time: 2.6648786067962646
Validation Loss Energy: 2.6348383257002923, Validation Loss Force: 2.8075617801853205, time: 0.1527721881866455
Test Loss Energy: 7.758993331080085, Test Loss Force: 9.383922822456572, time: 18.34107756614685


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.84161381660945, Training Loss Force: 3.08556613672219, time: 2.668936252593994
Validation Loss Energy: 1.4313888581542362, Validation Loss Force: 2.7891156454675166, time: 0.15743422508239746
Test Loss Energy: 7.690312916962847, Test Loss Force: 9.271119225359534, time: 18.40785527229309


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7814862151668518, Training Loss Force: 3.061596755366648, time: 2.6987266540527344
Validation Loss Energy: 3.333850104028068, Validation Loss Force: 2.770940276431161, time: 0.15587735176086426
Test Loss Energy: 7.9533379916943945, Test Loss Force: 9.429198296116214, time: 18.48128342628479


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.088505600747701, Training Loss Force: 3.0880944599083424, time: 2.649688243865967
Validation Loss Energy: 1.3809179458635192, Validation Loss Force: 2.7914756044106324, time: 0.15326380729675293
Test Loss Energy: 7.401928612788963, Test Loss Force: 9.257373189808167, time: 18.264532566070557

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–‚â–â–ˆâ–â–ƒâ–„â–‚â–‡â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–„â–
wandb:   test_error_force â–…â–†â–„â–ƒâ–…â–‚â–â–ˆâ–ƒâ–‡â–„â–„â–ƒâ–…â–â–â–‚â–â–ƒâ–
wandb:          test_loss â–„â–…â–„â–ƒâ–‡â–…â–‚â–‡â–ƒâ–ˆâ–ƒâ–„â–ƒâ–†â–‚â–â–ƒâ–‚â–„â–
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–„â–„â–ƒâ–ƒâ–„â–„â–…â–…â–â–‚â–‚â–â–‚â–â–ƒ
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–„â–ƒâ–„â–â–‚â–‚â–â–‚â–â–ƒ
wandb: valid_error_energy â–‚â–â–‚â–â–ˆâ–â–…â–ƒâ–â–‡â–â–‚â–‚â–â–â–‚â–„â–â–†â–
wandb:  valid_error_force â–†â–ƒâ–ˆâ–ƒâ–„â–‚â–‚â–‡â–ƒâ–…â–ƒâ–ƒâ–…â–â–‚â–…â–‡â–†â–…â–†
wandb:         valid_loss â–‚â–„â–‚â–â–‡â–ˆâ–ƒâ–†â–„â–‡â–„â–†â–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2401
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.40193
wandb:   test_error_force 9.25737
wandb:          test_loss 4.72545
wandb: train_error_energy 2.08851
wandb:  train_error_force 3.08809
wandb:         train_loss 1.4376
wandb: valid_error_energy 1.38092
wandb:  valid_error_force 2.79148
wandb:         valid_loss 1.41636
wandb: 
wandb: ğŸš€ View run al_81_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/wjoqgfsj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_050049-wjoqgfsj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7221298217773438, Uncertainty Bias: 0.01839706301689148
7.6293945e-06 0.0026245117
0.42036152 5.7582746
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2194 steps.
Found uncertainty sample 3 after 1660 steps.
Found uncertainty sample 4 after 3555 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2393 steps.
Found uncertainty sample 7 after 2330 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 628 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3083 steps.
Found uncertainty sample 15 after 3645 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2857 steps.
Found uncertainty sample 18 after 1992 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 628 steps.
Found uncertainty sample 21 after 1850 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3712 steps.
Found uncertainty sample 25 after 818 steps.
Found uncertainty sample 26 after 2698 steps.
Found uncertainty sample 27 after 583 steps.
Found uncertainty sample 28 after 149 steps.
Found uncertainty sample 29 after 27 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1101 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1922 steps.
Found uncertainty sample 34 after 1059 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 12 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3439 steps.
Found uncertainty sample 40 after 966 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3545 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 565 steps.
Found uncertainty sample 45 after 2083 steps.
Found uncertainty sample 46 after 3064 steps.
Found uncertainty sample 47 after 458 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1467 steps.
Found uncertainty sample 51 after 2696 steps.
Found uncertainty sample 52 after 2504 steps.
Found uncertainty sample 53 after 2509 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 937 steps.
Found uncertainty sample 57 after 2974 steps.
Found uncertainty sample 58 after 3662 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1969 steps.
Found uncertainty sample 61 after 1326 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 670 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2174 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1587 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1046 steps.
Found uncertainty sample 72 after 3055 steps.
Found uncertainty sample 73 after 1408 steps.
Found uncertainty sample 74 after 1941 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1831 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 325 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 392 steps.
Found uncertainty sample 82 after 2854 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2585 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 10 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3583 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3157 steps.
Found uncertainty sample 99 after 903 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_071750-syj7go0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/syj7go0i
Training model 28. Added 54 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7594428288222606, Training Loss Force: 3.249373932606705, time: 2.7412636280059814
Validation Loss Energy: 2.282443026031559, Validation Loss Force: 2.701669686486194, time: 0.14990520477294922
Test Loss Energy: 7.560870940347614, Test Loss Force: 9.289707258613648, time: 17.89679741859436


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9682461036050753, Training Loss Force: 3.065618469755714, time: 2.7297732830047607
Validation Loss Energy: 2.879882269422061, Validation Loss Force: 2.728456228068442, time: 0.14962220191955566
Test Loss Energy: 8.318983390265197, Test Loss Force: 9.455227228079778, time: 18.03659987449646


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.078749303719156, Training Loss Force: 3.077901116730622, time: 2.6907846927642822
Validation Loss Energy: 2.0992916414390135, Validation Loss Force: 2.7074345906742643, time: 0.15405702590942383
Test Loss Energy: 7.453325466452201, Test Loss Force: 9.237304250515493, time: 18.040735721588135


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0294307512504806, Training Loss Force: 3.0704018714829915, time: 2.74800705909729
Validation Loss Energy: 1.3648061631370494, Validation Loss Force: 2.6909950389649886, time: 0.14792823791503906
Test Loss Energy: 7.6185177158994195, Test Loss Force: 9.425558105581816, time: 17.85965394973755


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7611653479008333, Training Loss Force: 3.0654001701302986, time: 2.691190004348755
Validation Loss Energy: 1.9265199790838918, Validation Loss Force: 2.728730333787079, time: 0.1494464874267578
Test Loss Energy: 7.874401464695091, Test Loss Force: 9.395426726600133, time: 17.965219974517822


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7375899672327304, Training Loss Force: 3.062658661822021, time: 2.6689910888671875
Validation Loss Energy: 1.455212564080769, Validation Loss Force: 2.7100087573357623, time: 0.15316200256347656
Test Loss Energy: 7.404318379669554, Test Loss Force: 9.284743629930103, time: 18.045048475265503


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9454719805077512, Training Loss Force: 3.0633269295224435, time: 2.677155017852783
Validation Loss Energy: 1.2849404742232595, Validation Loss Force: 2.7184580494125656, time: 0.15025019645690918
Test Loss Energy: 7.471617319431247, Test Loss Force: 9.32566921635757, time: 17.918442487716675


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0072601945617468, Training Loss Force: 3.0558389767814984, time: 2.6919121742248535
Validation Loss Energy: 1.6577789725123366, Validation Loss Force: 2.7435071036491387, time: 0.14877796173095703
Test Loss Energy: 7.5681544294580005, Test Loss Force: 9.39862744052051, time: 17.992319107055664


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9669515174808319, Training Loss Force: 3.0765475485860194, time: 2.667621612548828
Validation Loss Energy: 2.599051051901351, Validation Loss Force: 2.7668514029044893, time: 0.14827442169189453
Test Loss Energy: 7.563933289292841, Test Loss Force: 9.193776750635912, time: 18.084295988082886


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.371002404483602, Training Loss Force: 3.0986497053616544, time: 2.7130138874053955
Validation Loss Energy: 1.4194282406480114, Validation Loss Force: 2.7593360965602804, time: 0.15069842338562012
Test Loss Energy: 7.5221355672769326, Test Loss Force: 9.328100782084013, time: 17.879741191864014


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7354458513249067, Training Loss Force: 3.060880790390336, time: 2.947563409805298
Validation Loss Energy: 1.6182324311899832, Validation Loss Force: 2.692720613511356, time: 0.15157866477966309
Test Loss Energy: 7.339920275613219, Test Loss Force: 9.19355067267018, time: 17.88328766822815


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8108844734876113, Training Loss Force: 3.052302412382747, time: 2.6778295040130615
Validation Loss Energy: 1.5532721035700265, Validation Loss Force: 2.7228724652305836, time: 0.1534559726715088
Test Loss Energy: 7.69920019283775, Test Loss Force: 9.492289301974973, time: 18.035284757614136


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9159552173402987, Training Loss Force: 3.0723177717588888, time: 2.7510180473327637
Validation Loss Energy: 1.7210053198256672, Validation Loss Force: 2.7350040369735944, time: 0.15227818489074707
Test Loss Energy: 7.72632591140766, Test Loss Force: 9.412951893569732, time: 18.00087881088257


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8653114668004764, Training Loss Force: 3.059100270063355, time: 2.9147980213165283
Validation Loss Energy: 1.427369958406672, Validation Loss Force: 2.7091281008636177, time: 0.1479969024658203
Test Loss Energy: 7.587700774757447, Test Loss Force: 9.260166813234276, time: 18.889286279678345


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8859261170484256, Training Loss Force: 3.046534546984216, time: 2.6711008548736572
Validation Loss Energy: 1.22611774327437, Validation Loss Force: 2.700176244524456, time: 0.16127943992614746
Test Loss Energy: 7.346325291808059, Test Loss Force: 9.189182109209113, time: 18.484646558761597


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8916001266789957, Training Loss Force: 3.0506292099086822, time: 2.6692161560058594
Validation Loss Energy: 1.216427905718317, Validation Loss Force: 2.68927581048928, time: 0.1535801887512207
Test Loss Energy: 7.382044917904403, Test Loss Force: 9.097238633351868, time: 18.361774921417236


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.058720367308727, Training Loss Force: 3.064499190037927, time: 2.7495176792144775
Validation Loss Energy: 1.9247538787529654, Validation Loss Force: 2.7513281347307066, time: 0.16201329231262207
Test Loss Energy: 7.8290283080630045, Test Loss Force: 9.13868513034719, time: 18.35305094718933


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.160492851909526, Training Loss Force: 3.0617811689868337, time: 2.710815668106079
Validation Loss Energy: 1.3509192348494037, Validation Loss Force: 2.7016828239658035, time: 0.1544356346130371
Test Loss Energy: 7.155140476582291, Test Loss Force: 9.173243400448094, time: 18.390846014022827


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.981512278751644, Training Loss Force: 3.045164423244023, time: 2.672715663909912
Validation Loss Energy: 1.7049647355586077, Validation Loss Force: 2.679856794281962, time: 0.15678071975708008
Test Loss Energy: 7.7195601805228735, Test Loss Force: 9.354681280677532, time: 18.48572063446045


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.230199903744487, Training Loss Force: 3.0505612958191746, time: 2.7529659271240234
Validation Loss Energy: 1.2327240028303286, Validation Loss Force: 2.680929836896188, time: 0.15328216552734375
Test Loss Energy: 7.536505223328586, Test Loss Force: 9.053520178941259, time: 18.30673098564148

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–„â–„â–‚â–‚â–…â–â–„â–ƒ
wandb:   test_error_force â–…â–‡â–„â–‡â–†â–…â–…â–‡â–ƒâ–…â–ƒâ–ˆâ–‡â–„â–ƒâ–‚â–‚â–ƒâ–†â–
wandb:          test_loss â–†â–‡â–†â–†â–‡â–„â–…â–…â–ƒâ–†â–ƒâ–‡â–…â–„â–‚â–„â–‚â–ƒâ–ˆâ–
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–â–â–‚â–ƒâ–ƒâ–…â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–„
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–â–â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–â–‚â–â–‚â–ƒâ–â–â–‚â–â–â–â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–…â–ˆâ–…â–‚â–„â–‚â–â–ƒâ–‡â–‚â–ƒâ–‚â–ƒâ–‚â–â–â–„â–‚â–ƒâ–
wandb:  valid_error_force â–ƒâ–…â–ƒâ–‚â–…â–ƒâ–„â–†â–ˆâ–‡â–‚â–„â–…â–ƒâ–ƒâ–‚â–‡â–ƒâ–â–
wandb:         valid_loss â–…â–‡â–‡â–‚â–…â–ƒâ–‚â–…â–‡â–„â–ƒâ–ƒâ–ƒâ–„â–â–…â–†â–‡â–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2449
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.53651
wandb:   test_error_force 9.05352
wandb:          test_loss 4.6656
wandb: train_error_energy 2.2302
wandb:  train_error_force 3.05056
wandb:         train_loss 1.41953
wandb: valid_error_energy 1.23272
wandb:  valid_error_force 2.68093
wandb:         valid_loss 1.33905
wandb: 
wandb: ğŸš€ View run al_81_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/syj7go0i
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_071750-syj7go0i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7227784395217896, Uncertainty Bias: 0.020251959562301636
0.00016403198 0.0109939575
0.5109463 3.9531968
(48745, 22, 3)
Found uncertainty sample 0 after 1117 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1581 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2271 steps.
Found uncertainty sample 9 after 278 steps.
Found uncertainty sample 10 after 871 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1203 steps.
Found uncertainty sample 13 after 1253 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 92 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1124 steps.
Found uncertainty sample 18 after 2495 steps.
Found uncertainty sample 19 after 2995 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 174 steps.
Found uncertainty sample 24 after 1782 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1351 steps.
Found uncertainty sample 27 after 1209 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 712 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3254 steps.
Found uncertainty sample 35 after 1427 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1107 steps.
Found uncertainty sample 38 after 1823 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3739 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3462 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 883 steps.
Found uncertainty sample 50 after 1234 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3337 steps.
Found uncertainty sample 53 after 3712 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1376 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 996 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3079 steps.
Found uncertainty sample 63 after 1348 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2279 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1444 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3254 steps.
Found uncertainty sample 71 after 2218 steps.
Found uncertainty sample 72 after 1356 steps.
Found uncertainty sample 73 after 443 steps.
Found uncertainty sample 74 after 1413 steps.
Found uncertainty sample 75 after 2259 steps.
Found uncertainty sample 76 after 3147 steps.
Found uncertainty sample 77 after 2342 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2569 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1310 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 526 steps.
Found uncertainty sample 86 after 12 steps.
Found uncertainty sample 87 after 29 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3016 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2645 steps.
Found uncertainty sample 93 after 529 steps.
Found uncertainty sample 94 after 1937 steps.
Found uncertainty sample 95 after 1904 steps.
Found uncertainty sample 96 after 1034 steps.
Found uncertainty sample 97 after 1377 steps.
Found uncertainty sample 98 after 1047 steps.
Found uncertainty sample 99 after 3089 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_093144-uffgj5cw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_81_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/uffgj5cw
Training model 29. Added 54 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.919899738371822, Training Loss Force: 3.19772167680831, time: 2.8000080585479736
Validation Loss Energy: 1.2413338393613453, Validation Loss Force: 2.7196171536516927, time: 0.15657496452331543
Test Loss Energy: 7.393669014422867, Test Loss Force: 9.134567583796203, time: 18.361382961273193


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.019071293424451, Training Loss Force: 3.0828122239900613, time: 2.833407163619995
Validation Loss Energy: 1.6724392864110764, Validation Loss Force: 2.7111396939279295, time: 0.15337896347045898
Test Loss Energy: 7.5857433893891955, Test Loss Force: 8.952452654129528, time: 18.440240383148193


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0311945784929164, Training Loss Force: 3.1024162777270448, time: 2.8121907711029053
Validation Loss Energy: 2.4009153698027412, Validation Loss Force: 2.714938206888312, time: 0.15826964378356934
Test Loss Energy: 7.901903517437761, Test Loss Force: 9.017114319179761, time: 18.442177057266235


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8039130526019933, Training Loss Force: 3.0741136735345695, time: 2.878533124923706
Validation Loss Energy: 3.7053913875402564, Validation Loss Force: 2.750145427562111, time: 0.16911625862121582
Test Loss Energy: 7.972224501863456, Test Loss Force: 8.714628930586814, time: 19.055033206939697


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1254302940226726, Training Loss Force: 3.0674982464925717, time: 3.199862003326416
Validation Loss Energy: 1.4786658598830509, Validation Loss Force: 2.7228702385391244, time: 0.16370391845703125
Test Loss Energy: 7.472459817872944, Test Loss Force: 9.188765930083113, time: 19.064707279205322


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8618463020522078, Training Loss Force: 3.0855343486618354, time: 2.949359893798828
Validation Loss Energy: 2.918123579878272, Validation Loss Force: 2.76448042183865, time: 0.16150927543640137
Test Loss Energy: 7.761418200410852, Test Loss Force: 8.956175495720315, time: 19.178489685058594


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.080393548954807, Training Loss Force: 3.084857124412569, time: 2.9903507232666016
Validation Loss Energy: 2.243738007078953, Validation Loss Force: 2.700728352671784, time: 0.1599743366241455
Test Loss Energy: 7.419866370530473, Test Loss Force: 8.752280406213858, time: 19.187254667282104


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.977907788659551, Training Loss Force: 3.086051330046745, time: 2.9911563396453857
Validation Loss Energy: 1.8584573692555826, Validation Loss Force: 2.729652852058658, time: 0.1629934310913086
Test Loss Energy: 7.7117256120898805, Test Loss Force: 9.225539047043702, time: 19.07995295524597


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8605018708466448, Training Loss Force: 3.0564555691520994, time: 2.9684503078460693
Validation Loss Energy: 1.256887947211839, Validation Loss Force: 2.7305207050549116, time: 0.16111063957214355
Test Loss Energy: 7.416152661872093, Test Loss Force: 9.042274034735732, time: 19.222734689712524


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8702822410267474, Training Loss Force: 3.055570679147586, time: 3.0168492794036865
Validation Loss Energy: 2.4712514316109733, Validation Loss Force: 2.7932660870130377, time: 0.1671595573425293
Test Loss Energy: 7.6117875701089295, Test Loss Force: 8.76238183981696, time: 19.167065143585205


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7914490569635872, Training Loss Force: 3.077317124341936, time: 3.035907745361328
Validation Loss Energy: 1.775391757712951, Validation Loss Force: 2.7371839679122276, time: 0.16406631469726562
Test Loss Energy: 7.476628279880889, Test Loss Force: 8.911798309032783, time: 19.777766466140747


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.034290289847516, Training Loss Force: 3.063238140392681, time: 3.0379884243011475
Validation Loss Energy: 1.5758431842161427, Validation Loss Force: 2.8523870832828977, time: 0.16613054275512695
Test Loss Energy: 7.156099898475935, Test Loss Force: 8.995834768543924, time: 18.800134658813477


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.034765632102137, Training Loss Force: 3.089997901077587, time: 3.0805420875549316
Validation Loss Energy: 1.9473967701986434, Validation Loss Force: 2.728626013292212, time: 0.17194843292236328
Test Loss Energy: 7.807305212146547, Test Loss Force: 8.924461953363217, time: 18.621750593185425


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.024539348636435, Training Loss Force: 3.043523022668025, time: 2.8100662231445312
Validation Loss Energy: 2.2519443671175488, Validation Loss Force: 2.770507184942332, time: 0.154998779296875
Test Loss Energy: 7.473267955317746, Test Loss Force: 8.857663042233556, time: 18.081944942474365


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.21659478405274, Training Loss Force: 3.075886094568785, time: 2.7708771228790283
Validation Loss Energy: 2.4346603221952323, Validation Loss Force: 2.9017658590801254, time: 0.15225577354431152
Test Loss Energy: 7.684470230128618, Test Loss Force: 9.175939431834706, time: 18.161346435546875


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.904085817413747, Training Loss Force: 3.0738684950747266, time: 2.7755725383758545
Validation Loss Energy: 1.5469673380376543, Validation Loss Force: 2.7601251246788756, time: 0.1632840633392334
Test Loss Energy: 7.503035637475053, Test Loss Force: 9.029792545424737, time: 18.47419548034668


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7789226829597582, Training Loss Force: 3.0755389026355404, time: 2.838433265686035
Validation Loss Energy: 1.2758544040563897, Validation Loss Force: 2.7498312413972066, time: 0.15736126899719238
Test Loss Energy: 7.446683819406244, Test Loss Force: 8.970793643543978, time: 18.419410228729248


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9507511984380892, Training Loss Force: 3.0595471343508307, time: 2.801847219467163
Validation Loss Energy: 1.2319198888770968, Validation Loss Force: 2.7171258199124795, time: 0.1589217185974121
Test Loss Energy: 7.203843110523068, Test Loss Force: 9.058948059970186, time: 19.013480186462402


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1092834246987873, Training Loss Force: 3.1075725566743757, time: 3.1301591396331787
Validation Loss Energy: 1.2849424225782866, Validation Loss Force: 2.7661697013142312, time: 0.16573214530944824
Test Loss Energy: 7.5980122821271445, Test Loss Force: 8.992912463335996, time: 19.22086238861084


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8605183864144998, Training Loss Force: 3.0592574389733818, time: 2.8692686557769775
Validation Loss Energy: 1.222452998803404, Validation Loss Force: 2.7080313439853505, time: 0.1587541103363037
Test Loss Energy: 7.295044011592207, Test Loss Force: 8.980543978033657, time: 18.908928632736206

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–…â–‡â–ˆâ–„â–†â–ƒâ–†â–ƒâ–…â–„â–â–‡â–„â–†â–„â–ƒâ–â–…â–‚
wandb:   test_error_force â–‡â–„â–…â–â–‡â–„â–‚â–ˆâ–…â–‚â–„â–…â–„â–ƒâ–‡â–…â–…â–†â–…â–…
wandb:          test_loss â–†â–„â–†â–‚â–‡â–„â–ƒâ–ˆâ–†â–â–‚â–†â–…â–‚â–ˆâ–„â–‚â–ˆâ–†â–ƒ
wandb: train_error_energy â–ˆâ–‚â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–„â–‚â–â–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–‚â–‚â–„â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–‚â–â–ƒâ–‚â–â–â–â–‚â–‚â–â–ƒâ–â–â–‚â–ƒâ–
wandb: valid_error_energy â–â–‚â–„â–ˆâ–‚â–†â–„â–ƒâ–â–…â–ƒâ–‚â–ƒâ–„â–„â–‚â–â–â–â–
wandb:  valid_error_force â–‚â–â–â–ƒâ–‚â–ƒâ–â–‚â–‚â–„â–‚â–†â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–‚â–ƒâ–
wandb:         valid_loss â–ƒâ–†â–„â–ˆâ–ƒâ–‡â–†â–…â–â–„â–…â–†â–ƒâ–„â–ˆâ–‚â–‚â–‡â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2497
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.29504
wandb:   test_error_force 8.98054
wandb:          test_loss 4.61801
wandb: train_error_energy 1.86052
wandb:  train_error_force 3.05926
wandb:         train_loss 1.39889
wandb: valid_error_energy 1.22245
wandb:  valid_error_force 2.70803
wandb:         valid_loss 1.41626
wandb: 
wandb: ğŸš€ View run al_81_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/uffgj5cw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_093144-uffgj5cw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7265284657478333, Uncertainty Bias: 0.017530128359794617
0.00015640259 0.004055977
0.5256034 5.4300036
(48745, 22, 3)
