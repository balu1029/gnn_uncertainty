wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_145640-0aclz7x8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/0aclz7x8
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
69
Uncertainty Slope: 5.4503092765808105, Uncertainty Bias: -0.39419424533843994
0.00023651123 0.002193451
1.6673867 2.277966
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 10.996634842512329, Test Loss Force: 13.386480610933857, time: 7.973238945007324

wandb: - 0.039 MB of 0.047 MB uploadedwandb: \ 0.039 MB of 0.047 MB uploadedwandb: | 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.99663
wandb:   test_error_force 13.38648
wandb:          test_loss 16.63181
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_70 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/0aclz7x8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_145640-0aclz7x8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 1634 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3536 steps.
Found uncertainty sample 4 after 981 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 416 steps.
Found uncertainty sample 7 after 1062 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1761 steps.
Found uncertainty sample 10 after 3457 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1340 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 623 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 817 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 664 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2648 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3614 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3174 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 644 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 481 steps.
Found uncertainty sample 53 after 1064 steps.
Found uncertainty sample 54 after 2162 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1374 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1372 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 578 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1606 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1304 steps.
Found uncertainty sample 67 after 2532 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2427 steps.
Found uncertainty sample 70 after 3497 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1795 steps.
Found uncertainty sample 73 after 3824 steps.
Found uncertainty sample 74 after 1786 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 458 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3777 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2744 steps.
Found uncertainty sample 90 after 906 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1616 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2777 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_152908-zeq6231e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/zeq6231e
Training model 0. Added 35 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.869560242429804, Training Loss Force: 2.2685743180749887, time: 0.46868157386779785
Validation Loss Energy: 1.7036696918058918, Validation Loss Force: 2.28589740382691, time: 0.0385439395904541
Test Loss Energy: 11.382132142077914, Test Loss Force: 12.928987722063196, time: 8.523444414138794


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.445936502535661, Training Loss Force: 1.755252917840398, time: 0.40638113021850586
Validation Loss Energy: 1.098933803172482, Validation Loss Force: 2.232347255584444, time: 0.04492831230163574
Test Loss Energy: 11.738618030175488, Test Loss Force: 13.145431141261863, time: 8.359656810760498


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.238551215840368, Training Loss Force: 1.7054031411322466, time: 0.4020209312438965
Validation Loss Energy: 1.5727127343608303, Validation Loss Force: 2.2028406990501153, time: 0.03785204887390137
Test Loss Energy: 12.436581672773684, Test Loss Force: 12.784128572127374, time: 8.18773889541626


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4722194617865219, Training Loss Force: 1.693780591056827, time: 0.5512561798095703
Validation Loss Energy: 1.3407261093562672, Validation Loss Force: 2.2086773027031743, time: 0.057741641998291016
Test Loss Energy: 11.578030571671212, Test Loss Force: 12.72520339122102, time: 8.29103422164917


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.57410181728881, Training Loss Force: 1.7370143450233906, time: 0.3839690685272217
Validation Loss Energy: 1.6183306282833374, Validation Loss Force: 2.205533659700966, time: 0.03759026527404785
Test Loss Energy: 12.905641237502534, Test Loss Force: 12.798753710130091, time: 8.32100796699524


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4101382141076695, Training Loss Force: 1.6997217806948888, time: 0.41037464141845703
Validation Loss Energy: 1.8985788979800082, Validation Loss Force: 2.2320413081779393, time: 0.041846275329589844
Test Loss Energy: 11.470859403444294, Test Loss Force: 12.667265588261298, time: 8.327843427658081


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5179839105459403, Training Loss Force: 1.6724027301322535, time: 0.3828263282775879
Validation Loss Energy: 1.1109647284615334, Validation Loss Force: 2.17492132818796, time: 0.045183420181274414
Test Loss Energy: 12.471863242208986, Test Loss Force: 12.545468913636634, time: 8.599607229232788


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3812478837294484, Training Loss Force: 1.6476842496533044, time: 0.3940145969390869
Validation Loss Energy: 1.1975619839931526, Validation Loss Force: 2.226803239189134, time: 0.03693199157714844
Test Loss Energy: 11.732407197797194, Test Loss Force: 12.572783185175057, time: 8.357091188430786


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9437338070808445, Training Loss Force: 1.7123575010768741, time: 0.4044620990753174
Validation Loss Energy: 2.1626645050503646, Validation Loss Force: 2.2577297568670445, time: 0.0367586612701416
Test Loss Energy: 11.382862860608357, Test Loss Force: 12.567594462466927, time: 8.330793380737305


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6073798132128458, Training Loss Force: 1.693703538968138, time: 0.36937499046325684
Validation Loss Energy: 1.0604868577600064, Validation Loss Force: 2.189095110002847, time: 0.038559675216674805
Test Loss Energy: 12.014325320543724, Test Loss Force: 12.579539666546735, time: 8.611913204193115


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.556503097108923, Training Loss Force: 1.6926489222257375, time: 0.3786427974700928
Validation Loss Energy: 1.98788458966812, Validation Loss Force: 2.194151703637721, time: 0.03800773620605469
Test Loss Energy: 11.666119264559352, Test Loss Force: 12.681734787913445, time: 8.601956367492676


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5194312535713221, Training Loss Force: 1.6915533429246845, time: 0.3818199634552002
Validation Loss Energy: 1.0193684392692623, Validation Loss Force: 2.220830584687913, time: 0.034229278564453125
Test Loss Energy: 11.964087687117415, Test Loss Force: 12.79876102673512, time: 7.044119358062744


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.620571872455931, Training Loss Force: 1.691730673206822, time: 0.41314697265625
Validation Loss Energy: 1.3622389548863616, Validation Loss Force: 2.205999706223393, time: 0.038777828216552734
Test Loss Energy: 12.922701004972618, Test Loss Force: 12.608790441517586, time: 8.358559608459473


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3289209277601972, Training Loss Force: 1.6599031077015192, time: 0.40961265563964844
Validation Loss Energy: 2.33471471937268, Validation Loss Force: 2.211216398974189, time: 0.039138078689575195
Test Loss Energy: 11.666481382880983, Test Loss Force: 12.571162727369769, time: 7.012133359909058


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.095700467710282, Training Loss Force: 1.7121428523022986, time: 0.3915684223175049
Validation Loss Energy: 2.592686277034151, Validation Loss Force: 2.237500042290359, time: 0.03655600547790527
Test Loss Energy: 13.57598238316884, Test Loss Force: 12.663989968906556, time: 6.570802450180054


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2355668690605266, Training Loss Force: 1.673142402778234, time: 0.39357781410217285
Validation Loss Energy: 1.4617569216141595, Validation Loss Force: 2.1599759977824324, time: 0.03309941291809082
Test Loss Energy: 11.669756456638027, Test Loss Force: 12.35947737709294, time: 6.566057443618774


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6302640822948082, Training Loss Force: 1.6942307766847053, time: 0.4229898452758789
Validation Loss Energy: 0.9869805439866277, Validation Loss Force: 2.159184408968659, time: 0.03073287010192871
Test Loss Energy: 12.150443370487002, Test Loss Force: 12.55764224750258, time: 6.6472837924957275


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.1745677077889038, Training Loss Force: 1.6524540197356299, time: 0.383622407913208
Validation Loss Energy: 1.4856998668683368, Validation Loss Force: 2.237187192140331, time: 0.03165459632873535
Test Loss Energy: 11.85753905985346, Test Loss Force: 12.419417318421829, time: 6.846495151519775


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.487234738137514, Training Loss Force: 1.6770157454179444, time: 0.4008524417877197
Validation Loss Energy: 0.9890336648466549, Validation Loss Force: 2.2472001782944115, time: 0.032747507095336914
Test Loss Energy: 12.378517771460555, Test Loss Force: 12.366588832720668, time: 6.5576841831207275


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.2102725276313178, Training Loss Force: 1.6629763615610205, time: 0.4197885990142822
Validation Loss Energy: 1.4923920767146235, Validation Loss Force: 2.204392702997232, time: 0.03197193145751953
Test Loss Energy: 11.927608544724963, Test Loss Force: 12.497355651116726, time: 6.554413557052612

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–„â–‚â–†â–â–„â–‚â–â–ƒâ–‚â–ƒâ–†â–‚â–ˆâ–‚â–ƒâ–ƒâ–„â–ƒ
wandb:   test_error_force â–†â–ˆâ–…â–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–„â–â–ƒâ–‚â–â–‚
wandb:          test_loss â–ˆâ–ˆâ–†â–…â–†â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–â–â–â–‚
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–â–‚â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–‚â–â–‚â–â–â–
wandb: valid_error_energy â–„â–â–„â–ƒâ–„â–…â–‚â–‚â–†â–â–…â–â–ƒâ–‡â–ˆâ–ƒâ–â–ƒâ–â–ƒ
wandb:  valid_error_force â–ˆâ–…â–ƒâ–„â–„â–…â–‚â–…â–†â–ƒâ–ƒâ–„â–„â–„â–…â–â–â–…â–†â–ƒ
wandb:         valid_loss â–ˆâ–…â–…â–„â–„â–…â–‚â–„â–†â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–â–„â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 831
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.92761
wandb:   test_error_force 12.49736
wandb:          test_loss 13.41813
wandb: train_error_energy 1.21027
wandb:  train_error_force 1.66298
wandb:         train_loss -2.90743
wandb: valid_error_energy 1.49239
wandb:  valid_error_force 2.20439
wandb:         valid_loss -2.07518
wandb: 
wandb: ğŸš€ View run al_70_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/zeq6231e
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_152908-zeq6231e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 28.338274002075195, Uncertainty Bias: -3.0183053016662598
0.0002708435 0.006532669
-0.21436805 28.900639
(48745, 22, 3)
Found uncertainty sample 0 after 569 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 77 steps.
Found uncertainty sample 3 after 182 steps.
Found uncertainty sample 4 after 1110 steps.
Found uncertainty sample 5 after 3947 steps.
Found uncertainty sample 6 after 529 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1681 steps.
Found uncertainty sample 9 after 1857 steps.
Found uncertainty sample 10 after 2905 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3730 steps.
Found uncertainty sample 13 after 999 steps.
Found uncertainty sample 14 after 232 steps.
Found uncertainty sample 15 after 38 steps.
Found uncertainty sample 16 after 1562 steps.
Found uncertainty sample 17 after 2600 steps.
Found uncertainty sample 18 after 3324 steps.
Found uncertainty sample 19 after 121 steps.
Found uncertainty sample 20 after 1918 steps.
Found uncertainty sample 21 after 3 steps.
Found uncertainty sample 22 after 1392 steps.
Found uncertainty sample 23 after 628 steps.
Found uncertainty sample 24 after 962 steps.
Found uncertainty sample 25 after 2126 steps.
Found uncertainty sample 26 after 283 steps.
Found uncertainty sample 27 after 1621 steps.
Found uncertainty sample 28 after 1046 steps.
Found uncertainty sample 29 after 2666 steps.
Found uncertainty sample 30 after 45 steps.
Found uncertainty sample 31 after 796 steps.
Found uncertainty sample 32 after 748 steps.
Found uncertainty sample 33 after 337 steps.
Found uncertainty sample 34 after 265 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 751 steps.
Found uncertainty sample 37 after 316 steps.
Found uncertainty sample 38 after 933 steps.
Found uncertainty sample 39 after 2009 steps.
Found uncertainty sample 40 after 111 steps.
Found uncertainty sample 41 after 1110 steps.
Found uncertainty sample 42 after 1526 steps.
Found uncertainty sample 43 after 2569 steps.
Found uncertainty sample 44 after 2928 steps.
Found uncertainty sample 45 after 516 steps.
Found uncertainty sample 46 after 427 steps.
Found uncertainty sample 47 after 2139 steps.
Found uncertainty sample 48 after 1761 steps.
Found uncertainty sample 49 after 998 steps.
Found uncertainty sample 50 after 2822 steps.
Found uncertainty sample 51 after 2702 steps.
Found uncertainty sample 52 after 3517 steps.
Found uncertainty sample 53 after 385 steps.
Found uncertainty sample 54 after 242 steps.
Found uncertainty sample 55 after 104 steps.
Found uncertainty sample 56 after 142 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 64 steps.
Found uncertainty sample 59 after 998 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 511 steps.
Found uncertainty sample 62 after 927 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 890 steps.
Found uncertainty sample 66 after 1218 steps.
Found uncertainty sample 67 after 2852 steps.
Found uncertainty sample 68 after 803 steps.
Found uncertainty sample 69 after 282 steps.
Found uncertainty sample 70 after 2073 steps.
Found uncertainty sample 71 after 684 steps.
Found uncertainty sample 72 after 3903 steps.
Found uncertainty sample 73 after 1417 steps.
Found uncertainty sample 74 after 56 steps.
Found uncertainty sample 75 after 2784 steps.
Found uncertainty sample 76 after 26 steps.
Found uncertainty sample 77 after 363 steps.
Found uncertainty sample 78 after 1791 steps.
Found uncertainty sample 79 after 11 steps.
Found uncertainty sample 80 after 699 steps.
Found uncertainty sample 81 after 3358 steps.
Found uncertainty sample 82 after 3261 steps.
Found uncertainty sample 83 after 2375 steps.
Found uncertainty sample 84 after 970 steps.
Did not find any uncertainty samples for sample 85.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 958 steps.
Found uncertainty sample 88 after 1429 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1407 steps.
Found uncertainty sample 91 after 433 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2123 steps.
Found uncertainty sample 94 after 213 steps.
Found uncertainty sample 95 after 133 steps.
Found uncertainty sample 96 after 1360 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1396 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_154905-3r98b6rk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3r98b6rk
Training model 1. Added 88 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.872279721544562, Training Loss Force: 2.36655551656377, time: 0.48824024200439453
Validation Loss Energy: 1.792101629765383, Validation Loss Force: 2.2045320938825825, time: 0.04953765869140625
Test Loss Energy: 12.975821278187896, Test Loss Force: 12.552171632650545, time: 8.789637327194214


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3548967373314413, Training Loss Force: 1.7949745032470203, time: 0.4392223358154297
Validation Loss Energy: 1.221461508763874, Validation Loss Force: 2.2399752325164926, time: 0.043756723403930664
Test Loss Energy: 12.614781132219628, Test Loss Force: 12.473911980217423, time: 8.975911617279053


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.399733486774856, Training Loss Force: 1.761226084126274, time: 0.4546058177947998
Validation Loss Energy: 1.9935811344283907, Validation Loss Force: 2.178346424990621, time: 0.04458045959472656
Test Loss Energy: 13.399872520936709, Test Loss Force: 12.317830972168473, time: 8.93192720413208


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.917606596517936, Training Loss Force: 1.779602941865832, time: 0.4708571434020996
Validation Loss Energy: 1.4492401322486939, Validation Loss Force: 2.2684296773363126, time: 0.041908979415893555
Test Loss Energy: 12.234839761265755, Test Loss Force: 12.237769182559896, time: 8.689839839935303


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3466390386177782, Training Loss Force: 1.7707430018144599, time: 0.4222109317779541
Validation Loss Energy: 1.314470411017911, Validation Loss Force: 2.1711105684245515, time: 0.041243553161621094
Test Loss Energy: 12.505935771809025, Test Loss Force: 12.310568050226006, time: 8.776750802993774


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.552297313716441, Training Loss Force: 1.8254251116949884, time: 0.4466571807861328
Validation Loss Energy: 1.471009381300324, Validation Loss Force: 2.240028227773223, time: 0.050452470779418945
Test Loss Energy: 12.187517396236041, Test Loss Force: 12.40573324784661, time: 9.29186201095581


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4091437056313485, Training Loss Force: 1.7695851452903748, time: 0.4506211280822754
Validation Loss Energy: 1.8407950299314446, Validation Loss Force: 2.1960270231847248, time: 0.04481220245361328
Test Loss Energy: 13.392600650259352, Test Loss Force: 12.541484213130236, time: 9.315044164657593


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2564224208906065, Training Loss Force: 1.7648101167905264, time: 0.47145938873291016
Validation Loss Energy: 3.5583763106328936, Validation Loss Force: 2.188639083591987, time: 0.045369863510131836
Test Loss Energy: 11.501516407517526, Test Loss Force: 12.175775247764406, time: 9.263128280639648


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9229519901155163, Training Loss Force: 1.754574714872649, time: 0.42077088356018066
Validation Loss Energy: 5.220806785936375, Validation Loss Force: 2.235974758640754, time: 0.04165005683898926
Test Loss Energy: 15.816904974973465, Test Loss Force: 12.46379930823439, time: 9.039777994155884


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.683816556175666, Training Loss Force: 1.8166418850035113, time: 0.5009479522705078
Validation Loss Energy: 1.232747271756078, Validation Loss Force: 2.166943315358513, time: 0.04506325721740723
Test Loss Energy: 12.268022351072137, Test Loss Force: 12.281676642272151, time: 9.25668478012085


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.389104357817938, Training Loss Force: 1.7933049107952375, time: 0.44110703468322754
Validation Loss Energy: 1.0268558006356572, Validation Loss Force: 2.20380062573821, time: 0.045249223709106445
Test Loss Energy: 12.727574279022296, Test Loss Force: 12.382267822987808, time: 8.886564016342163


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4398460645835272, Training Loss Force: 1.825658591811863, time: 0.509324312210083
Validation Loss Energy: 2.571792785733455, Validation Loss Force: 2.231933981649602, time: 0.04454851150512695
Test Loss Energy: 11.637331837267613, Test Loss Force: 12.18517232406601, time: 8.948134660720825


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5701158727225022, Training Loss Force: 1.7921983411180562, time: 0.4218156337738037
Validation Loss Energy: 1.6212493754481587, Validation Loss Force: 2.205145102041322, time: 0.0467829704284668
Test Loss Energy: 12.979642681769642, Test Loss Force: 12.338282855759859, time: 9.161402940750122


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.2701516379969637, Training Loss Force: 1.794114409118765, time: 0.43889641761779785
Validation Loss Energy: 1.6709921039644051, Validation Loss Force: 2.2848493001570276, time: 0.04404497146606445
Test Loss Energy: 13.16398835057766, Test Loss Force: 12.345246883428457, time: 8.81354832649231


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.681121784107445, Training Loss Force: 1.7887489426655034, time: 0.4569976329803467
Validation Loss Energy: 1.1959448493208522, Validation Loss Force: 2.224784743381299, time: 0.04365229606628418
Test Loss Energy: 12.007078654614716, Test Loss Force: 12.233492391429555, time: 9.005366802215576


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.127559585492626, Training Loss Force: 1.7574254519698822, time: 0.4682128429412842
Validation Loss Energy: 1.2954591420077424, Validation Loss Force: 2.2278909779669913, time: 0.04175233840942383
Test Loss Energy: 12.724224038690107, Test Loss Force: 12.363330420677931, time: 9.007251739501953


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3626395424385707, Training Loss Force: 1.7830804311828805, time: 0.48481059074401855
Validation Loss Energy: 1.4802707477523256, Validation Loss Force: 2.247386329700407, time: 0.04671072959899902
Test Loss Energy: 11.927474183131213, Test Loss Force: 12.245522783361885, time: 8.170551538467407


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3435110534795636, Training Loss Force: 1.7350676231004705, time: 0.4257357120513916
Validation Loss Energy: 2.3554572409924375, Validation Loss Force: 2.1765029471314845, time: 0.03727555274963379
Test Loss Energy: 11.650619482151427, Test Loss Force: 12.14648690582728, time: 8.694390535354614


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.2839465962490961, Training Loss Force: 1.7341811503566695, time: 0.42844653129577637
Validation Loss Energy: 1.360233485223563, Validation Loss Force: 2.1674723772492372, time: 0.04849100112915039
Test Loss Energy: 13.203763318092589, Test Loss Force: 12.234162385402545, time: 8.682520151138306


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.2808369266079151, Training Loss Force: 1.7535910777596362, time: 0.4540588855743408
Validation Loss Energy: 1.7278267334438784, Validation Loss Force: 2.225394634171995, time: 0.04075956344604492
Test Loss Energy: 13.170453785888501, Test Loss Force: 12.290680244705795, time: 7.156972646713257

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–„â–â–ˆâ–‚â–ƒâ–â–ƒâ–„â–‚â–ƒâ–‚â–â–„â–„
wandb:   test_error_force â–ˆâ–‡â–„â–ƒâ–„â–…â–ˆâ–‚â–†â–ƒâ–…â–‚â–„â–„â–ƒâ–…â–ƒâ–â–ƒâ–ƒ
wandb:          test_loss â–ˆâ–…â–…â–„â–„â–…â–‡â–ƒâ–ˆâ–„â–„â–â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–…â–‡
wandb: train_error_energy â–ˆâ–â–â–‚â–â–‚â–â–â–‚â–„â–â–â–‚â–â–‚â–ƒâ–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–‚â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–‚â–â–ƒâ–‚â–â–‚â–‚â–…â–ˆâ–â–â–„â–‚â–‚â–â–â–‚â–ƒâ–‚â–‚
wandb:  valid_error_force â–ƒâ–…â–‚â–‡â–â–…â–ƒâ–‚â–…â–â–ƒâ–…â–ƒâ–ˆâ–„â–…â–†â–‚â–â–„
wandb:         valid_loss â–ƒâ–ƒâ–‚â–„â–â–ƒâ–ƒâ–…â–ˆâ–â–‚â–„â–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 910
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.17045
wandb:   test_error_force 12.29068
wandb:          test_loss 12.65295
wandb: train_error_energy 1.28084
wandb:  train_error_force 1.75359
wandb:         train_loss -2.7704
wandb: valid_error_energy 1.72783
wandb:  valid_error_force 2.22539
wandb:         valid_loss -2.05559
wandb: 
wandb: ğŸš€ View run al_70_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3r98b6rk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_154905-3r98b6rk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 29.693382263183594, Uncertainty Bias: -3.2844090461730957
0.0001411438 0.06375694
-0.52266324 23.695389
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 888 steps.
Found uncertainty sample 2 after 3524 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 807 steps.
Found uncertainty sample 5 after 63 steps.
Found uncertainty sample 6 after 2641 steps.
Found uncertainty sample 7 after 3172 steps.
Found uncertainty sample 8 after 615 steps.
Found uncertainty sample 9 after 280 steps.
Found uncertainty sample 10 after 650 steps.
Found uncertainty sample 11 after 1386 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 835 steps.
Found uncertainty sample 15 after 1566 steps.
Found uncertainty sample 16 after 2513 steps.
Found uncertainty sample 17 after 552 steps.
Found uncertainty sample 18 after 719 steps.
Found uncertainty sample 19 after 651 steps.
Found uncertainty sample 20 after 1512 steps.
Found uncertainty sample 21 after 1360 steps.
Found uncertainty sample 22 after 684 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 752 steps.
Found uncertainty sample 25 after 436 steps.
Found uncertainty sample 26 after 1784 steps.
Found uncertainty sample 27 after 348 steps.
Found uncertainty sample 28 after 3113 steps.
Found uncertainty sample 29 after 1372 steps.
Found uncertainty sample 30 after 59 steps.
Found uncertainty sample 31 after 1181 steps.
Found uncertainty sample 32 after 1439 steps.
Found uncertainty sample 33 after 287 steps.
Found uncertainty sample 34 after 547 steps.
Found uncertainty sample 35 after 3984 steps.
Found uncertainty sample 36 after 3669 steps.
Found uncertainty sample 37 after 3357 steps.
Found uncertainty sample 38 after 1486 steps.
Found uncertainty sample 39 after 74 steps.
Found uncertainty sample 40 after 50 steps.
Found uncertainty sample 41 after 1492 steps.
Found uncertainty sample 42 after 2954 steps.
Found uncertainty sample 43 after 1964 steps.
Found uncertainty sample 44 after 3960 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3701 steps.
Found uncertainty sample 47 after 2134 steps.
Found uncertainty sample 48 after 292 steps.
Found uncertainty sample 49 after 3244 steps.
Found uncertainty sample 50 after 3657 steps.
Found uncertainty sample 51 after 3190 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2354 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2604 steps.
Found uncertainty sample 57 after 923 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 483 steps.
Found uncertainty sample 60 after 1465 steps.
Found uncertainty sample 61 after 221 steps.
Found uncertainty sample 62 after 2680 steps.
Found uncertainty sample 63 after 91 steps.
Found uncertainty sample 64 after 595 steps.
Found uncertainty sample 65 after 1911 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 942 steps.
Found uncertainty sample 68 after 853 steps.
Found uncertainty sample 69 after 656 steps.
Found uncertainty sample 70 after 2036 steps.
Found uncertainty sample 71 after 3734 steps.
Found uncertainty sample 72 after 889 steps.
Found uncertainty sample 73 after 2092 steps.
Found uncertainty sample 74 after 279 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 39 steps.
Found uncertainty sample 78 after 586 steps.
Found uncertainty sample 79 after 172 steps.
Found uncertainty sample 80 after 1764 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2997 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1656 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 672 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 329 steps.
Found uncertainty sample 89 after 478 steps.
Found uncertainty sample 90 after 2410 steps.
Found uncertainty sample 91 after 2282 steps.
Found uncertainty sample 92 after 187 steps.
Found uncertainty sample 93 after 2096 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 937 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 617 steps.
Found uncertainty sample 98 after 1670 steps.
Found uncertainty sample 99 after 674 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_161253-r0q26hif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/r0q26hif
Training model 2. Added 81 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4974755073096, Training Loss Force: 2.198023575307373, time: 0.49887967109680176
Validation Loss Energy: 1.6984063498690236, Validation Loss Force: 2.2032312607320725, time: 0.043729543685913086
Test Loss Energy: 13.919767181213636, Test Loss Force: 11.565394566294241, time: 8.018309593200684


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5051580346501015, Training Loss Force: 1.9308032355920828, time: 0.49611496925354004
Validation Loss Energy: 2.5359337011349523, Validation Loss Force: 2.300086104474574, time: 0.046425819396972656
Test Loss Energy: 14.232496604927647, Test Loss Force: 11.697383985193134, time: 8.061641216278076


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.873220527568238, Training Loss Force: 1.9728230582913595, time: 0.46361732482910156
Validation Loss Energy: 1.0786447472684069, Validation Loss Force: 2.179298558258608, time: 0.03966784477233887
Test Loss Energy: 12.997756539328789, Test Loss Force: 11.513244720191128, time: 7.97961163520813


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.941275182361737, Training Loss Force: 1.9466182003470314, time: 0.47092700004577637
Validation Loss Energy: 1.2149712598329439, Validation Loss Force: 2.187659116680759, time: 0.04026460647583008
Test Loss Energy: 12.44332000486126, Test Loss Force: 11.346357193773976, time: 8.47801685333252


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8940879701702986, Training Loss Force: 1.94097724386161, time: 0.44542860984802246
Validation Loss Energy: 2.1942405486269463, Validation Loss Force: 2.232240597063545, time: 0.04636573791503906
Test Loss Energy: 12.063621667370809, Test Loss Force: 11.371860869041013, time: 7.9293248653411865


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.897150507731822, Training Loss Force: 1.9291683807654918, time: 0.44946908950805664
Validation Loss Energy: 1.8180662995300116, Validation Loss Force: 2.194815480361732, time: 0.04161405563354492
Test Loss Energy: 12.370145425563356, Test Loss Force: 11.335739867236548, time: 8.0204176902771


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.6136036549879056, Training Loss Force: 1.9163841190670747, time: 0.4814724922180176
Validation Loss Energy: 2.5792668982856672, Validation Loss Force: 2.204700877095196, time: 0.04332423210144043
Test Loss Energy: 11.994836398236172, Test Loss Force: 11.222996812831061, time: 8.085594654083252


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.654408936043163, Training Loss Force: 1.9723394496379067, time: 0.4641249179840088
Validation Loss Energy: 2.5775543498843367, Validation Loss Force: 2.2133702776227486, time: 0.04412508010864258
Test Loss Energy: 14.295954271092285, Test Loss Force: 11.358014382891275, time: 7.881593465805054


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7647807199430052, Training Loss Force: 1.9674703649725305, time: 0.47506284713745117
Validation Loss Energy: 1.534018292192656, Validation Loss Force: 2.2263120310532174, time: 0.040593624114990234
Test Loss Energy: 12.512301064294556, Test Loss Force: 11.269174108189782, time: 7.963600397109985


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8884534369714499, Training Loss Force: 1.9271839533369837, time: 0.45746564865112305
Validation Loss Energy: 2.180408786620204, Validation Loss Force: 2.2475261659240497, time: 0.03951263427734375
Test Loss Energy: 12.105434414307933, Test Loss Force: 11.195609911513628, time: 7.985830545425415


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5355556197290494, Training Loss Force: 1.9406043520538134, time: 0.4837617874145508
Validation Loss Energy: 1.1391993988343228, Validation Loss Force: 2.2204032825968776, time: 0.045577049255371094
Test Loss Energy: 12.464352800777585, Test Loss Force: 11.41567905124963, time: 8.21490478515625


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3298739981171954, Training Loss Force: 1.9149478204727706, time: 0.4565615653991699
Validation Loss Energy: 1.0060337861308037, Validation Loss Force: 2.2502870406644084, time: 0.039807796478271484
Test Loss Energy: 12.569461432503862, Test Loss Force: 11.24551324743767, time: 7.9941086769104


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3380981330795083, Training Loss Force: 1.9243935031060326, time: 0.4495868682861328
Validation Loss Energy: 0.9872190226419164, Validation Loss Force: 2.2140543172390386, time: 0.041710615158081055
Test Loss Energy: 12.70998532841756, Test Loss Force: 11.08637067619744, time: 7.94069242477417


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6543045975911066, Training Loss Force: 1.8882889616885228, time: 0.4636538028717041
Validation Loss Energy: 0.9848225459588686, Validation Loss Force: 2.2349366750824387, time: 0.04087114334106445
Test Loss Energy: 13.039619080216491, Test Loss Force: 11.175866232386992, time: 8.518023490905762


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2584832962222168, Training Loss Force: 1.9045464849624405, time: 0.4702937602996826
Validation Loss Energy: 2.0358159046822437, Validation Loss Force: 2.267898611423275, time: 0.039780616760253906
Test Loss Energy: 13.889529228814972, Test Loss Force: 11.254870322567884, time: 7.970406770706177


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0630790426355667, Training Loss Force: 1.960582820413698, time: 0.45226335525512695
Validation Loss Energy: 2.026925616361931, Validation Loss Force: 2.2805359761312607, time: 0.04298591613769531
Test Loss Energy: 13.9554811531458, Test Loss Force: 11.246840341557714, time: 7.983842134475708


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.32232832793222, Training Loss Force: 2.066870493033441, time: 0.47516632080078125
Validation Loss Energy: 2.8695562104488057, Validation Loss Force: 2.2332973848301183, time: 0.042684316635131836
Test Loss Energy: 14.8001875820943, Test Loss Force: 11.276124481926246, time: 8.02055287361145


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.806784379376294, Training Loss Force: 1.9218611731039041, time: 0.4949817657470703
Validation Loss Energy: 2.2188779989472724, Validation Loss Force: 2.1952821948915964, time: 0.04640030860900879
Test Loss Energy: 12.130620146013953, Test Loss Force: 10.877712278632282, time: 9.70094633102417


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.593429936343833, Training Loss Force: 1.891241967578877, time: 0.5150487422943115
Validation Loss Energy: 1.5604108207211849, Validation Loss Force: 2.1855733747908532, time: 0.04683661460876465
Test Loss Energy: 12.545229093137436, Test Loss Force: 10.996203503231493, time: 9.538109540939331


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8235055375221303, Training Loss Force: 1.8815171512140048, time: 0.47745299339294434
Validation Loss Energy: 2.158435127292612, Validation Loss Force: 2.190350518647588, time: 0.04893755912780762
Test Loss Energy: 14.247096584814296, Test Loss Force: 11.18789968806024, time: 9.65755295753479

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‡â–„â–‚â–â–‚â–â–‡â–‚â–â–‚â–‚â–ƒâ–„â–†â–†â–ˆâ–â–‚â–‡
wandb:   test_error_force â–‡â–ˆâ–†â–…â–…â–…â–„â–…â–„â–„â–†â–„â–ƒâ–„â–„â–„â–„â–â–‚â–„
wandb:          test_loss â–ˆâ–ˆâ–†â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–„â–„â–„â–â–‚â–„
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–‚â–â–â–‚â–â–„â–„â–ƒâ–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–…â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–ƒâ–„â–‚â–â–
wandb: valid_error_energy â–„â–‡â–â–‚â–…â–„â–‡â–‡â–ƒâ–…â–‚â–â–â–â–…â–…â–ˆâ–†â–ƒâ–…
wandb:  valid_error_force â–‚â–ˆâ–â–â–„â–‚â–‚â–ƒâ–„â–…â–ƒâ–…â–ƒâ–„â–†â–‡â–„â–‚â–â–‚
wandb:         valid_loss â–ƒâ–ˆâ–â–â–…â–ƒâ–„â–…â–ƒâ–…â–‚â–ƒâ–‚â–ƒâ–†â–†â–†â–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 982
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 14.2471
wandb:   test_error_force 11.1879
wandb:          test_loss 10.07795
wandb: train_error_energy 1.82351
wandb:  train_error_force 1.88152
wandb:         train_loss -2.55728
wandb: valid_error_energy 2.15844
wandb:  valid_error_force 2.19035
wandb:         valid_loss -2.12545
wandb: 
wandb: ğŸš€ View run al_70_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/r0q26hif
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_161253-r0q26hif/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 21.126419067382812, Uncertainty Bias: -2.5266172885894775
0.00016880035 0.09411454
-0.38490054 16.095505
(48745, 22, 3)
Found uncertainty sample 0 after 2115 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1525 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1830 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1942 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1294 steps.
Found uncertainty sample 14 after 2558 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1198 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1386 steps.
Found uncertainty sample 19 after 323 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3946 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3460 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2648 steps.
Found uncertainty sample 31 after 93 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1066 steps.
Found uncertainty sample 36 after 2273 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2915 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2037 steps.
Found uncertainty sample 41 after 395 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2523 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1677 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1507 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 96 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1757 steps.
Found uncertainty sample 53 after 3635 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3562 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3315 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2356 steps.
Found uncertainty sample 64 after 576 steps.
Found uncertainty sample 65 after 3686 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1120 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3333 steps.
Found uncertainty sample 75 after 2230 steps.
Found uncertainty sample 76 after 435 steps.
Found uncertainty sample 77 after 1882 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 459 steps.
Found uncertainty sample 80 after 472 steps.
Found uncertainty sample 81 after 1638 steps.
Found uncertainty sample 82 after 104 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3925 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2748 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3831 steps.
Found uncertainty sample 89 after 1687 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3786 steps.
Found uncertainty sample 94 after 3619 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1539 steps.
Found uncertainty sample 97 after 561 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2686 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_164646-fgtwusr9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/fgtwusr9
Training model 3. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7644733766987164, Training Loss Force: 2.4326916903592632, time: 0.46097350120544434
Validation Loss Energy: 2.39944508543218, Validation Loss Force: 2.3185382512593185, time: 0.04308366775512695
Test Loss Energy: 14.474467934190239, Test Loss Force: 11.25507641393761, time: 7.986757040023804


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6810883266285979, Training Loss Force: 2.0180941405297865, time: 0.47200727462768555
Validation Loss Energy: 1.7811416317336712, Validation Loss Force: 2.2348295712232473, time: 0.04191231727600098
Test Loss Energy: 12.338728501824777, Test Loss Force: 10.880693219271436, time: 8.3399178981781


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4187021096047299, Training Loss Force: 1.9668515717930624, time: 0.48613691329956055
Validation Loss Energy: 1.4894819023119203, Validation Loss Force: 2.2599462055456097, time: 0.04126572608947754
Test Loss Energy: 12.5511637364999, Test Loss Force: 11.019559412176317, time: 8.009852170944214


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5394242224046422, Training Loss Force: 2.001481400933854, time: 0.46809887886047363
Validation Loss Energy: 1.1191854506600414, Validation Loss Force: 2.328407170475984, time: 0.047080278396606445
Test Loss Energy: 12.929299160420893, Test Loss Force: 10.94120102521279, time: 8.188425302505493


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6377042965473114, Training Loss Force: 1.9752556620332418, time: 0.49298858642578125
Validation Loss Energy: 2.1396329446104696, Validation Loss Force: 2.372119350513068, time: 0.04305291175842285
Test Loss Energy: 14.145516426664743, Test Loss Force: 10.984294387874622, time: 8.046443462371826


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5643221938861012, Training Loss Force: 1.9726202648358189, time: 0.4468567371368408
Validation Loss Energy: 1.8511314430199854, Validation Loss Force: 2.2420102058411264, time: 0.04202699661254883
Test Loss Energy: 13.726051328940972, Test Loss Force: 10.972572142060889, time: 7.986931324005127


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6595408003790255, Training Loss Force: 1.9634649584813872, time: 0.47519397735595703
Validation Loss Energy: 1.1619033016259848, Validation Loss Force: 2.278947231775066, time: 0.04255533218383789
Test Loss Energy: 12.733095625133776, Test Loss Force: 10.866814524204603, time: 8.28122329711914


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5843994931720018, Training Loss Force: 1.9750133145015427, time: 0.49318766593933105
Validation Loss Energy: 1.4807353469253037, Validation Loss Force: 2.312875329540083, time: 0.04197955131530762
Test Loss Energy: 13.511699167065345, Test Loss Force: 10.89245789579844, time: 8.036295413970947


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.367081961841018, Training Loss Force: 1.9508414723237624, time: 0.4961271286010742
Validation Loss Energy: 1.1454172120652104, Validation Loss Force: 2.2386018092244098, time: 0.04079294204711914
Test Loss Energy: 12.872757168911772, Test Loss Force: 10.813428414340072, time: 8.712006092071533


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.536528196190719, Training Loss Force: 1.943668738981358, time: 0.4859645366668701
Validation Loss Energy: 1.7173279945479563, Validation Loss Force: 2.377901177556229, time: 0.04591536521911621
Test Loss Energy: 12.299314761954893, Test Loss Force: 10.764577303213825, time: 9.230663299560547


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4623961490648318, Training Loss Force: 1.9419294041776136, time: 0.6975440979003906
Validation Loss Energy: 1.077367851051084, Validation Loss Force: 2.256229634830929, time: 0.04785752296447754
Test Loss Energy: 12.979054699990773, Test Loss Force: 10.742039725530615, time: 9.234789609909058


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4609140232186744, Training Loss Force: 1.9691306287728927, time: 0.5048282146453857
Validation Loss Energy: 1.125335238466848, Validation Loss Force: 2.3295761834921045, time: 0.046156883239746094
Test Loss Energy: 13.09076028405245, Test Loss Force: 10.750889749207147, time: 9.057335615158081


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.57439296268355, Training Loss Force: 1.9645012050192485, time: 0.4683549404144287
Validation Loss Energy: 3.2165475526150176, Validation Loss Force: 2.28635343023777, time: 0.0506441593170166
Test Loss Energy: 15.200800796449913, Test Loss Force: 10.939342234478096, time: 9.51762580871582


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.2683208057897635, Training Loss Force: 1.9326096740549412, time: 0.47394800186157227
Validation Loss Energy: 1.1024621071242808, Validation Loss Force: 2.232084728661395, time: 0.047280311584472656
Test Loss Energy: 13.323400540345203, Test Loss Force: 10.644899692741884, time: 9.313040256500244


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2889703299886444, Training Loss Force: 1.9460040895046435, time: 0.48848891258239746
Validation Loss Energy: 1.543167099391391, Validation Loss Force: 2.2178588422663608, time: 0.04809284210205078
Test Loss Energy: 13.619005559583227, Test Loss Force: 10.76460331936388, time: 9.24793815612793


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2278056467242133, Training Loss Force: 1.9212791510852, time: 0.4907846450805664
Validation Loss Energy: 2.9674135106862742, Validation Loss Force: 2.207506953672178, time: 0.04765510559082031
Test Loss Energy: 14.87742131499983, Test Loss Force: 10.770581675827364, time: 9.139919757843018


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2153527880090786, Training Loss Force: 1.9637833857976803, time: 0.5249028205871582
Validation Loss Energy: 2.7646489823821176, Validation Loss Force: 2.28100625336746, time: 0.050073862075805664
Test Loss Energy: 12.457676955947717, Test Loss Force: 10.545688118758884, time: 9.259261131286621


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.474527338095248, Training Loss Force: 1.925610928816436, time: 0.558631420135498
Validation Loss Energy: 1.6617033492074544, Validation Loss Force: 2.239273156699382, time: 0.04832100868225098
Test Loss Energy: 12.527986051473151, Test Loss Force: 10.539443832381577, time: 9.10043716430664


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5712760834689203, Training Loss Force: 1.9424618269807592, time: 0.478344202041626
Validation Loss Energy: 1.501690183575703, Validation Loss Force: 2.215947227648571, time: 0.04843950271606445
Test Loss Energy: 12.848199000465467, Test Loss Force: 10.422600406094515, time: 9.058669805526733


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.330083312220943, Training Loss Force: 1.9198426567575335, time: 0.48148369789123535
Validation Loss Energy: 1.420630153030443, Validation Loss Force: 2.231303159959189, time: 0.0468900203704834
Test Loss Energy: 13.400017514690724, Test Loss Force: 10.516061081895307, time: 9.227749824523926

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–â–‚â–ƒâ–…â–„â–‚â–„â–‚â–â–ƒâ–ƒâ–ˆâ–ƒâ–„â–‡â–â–‚â–‚â–„
wandb:   test_error_force â–ˆâ–…â–†â–…â–†â–†â–…â–…â–„â–„â–„â–„â–…â–ƒâ–„â–„â–‚â–‚â–â–‚
wandb:          test_loss â–ˆâ–ƒâ–†â–…â–†â–‡â–…â–‡â–…â–…â–†â–„â–‡â–ƒâ–†â–†â–‚â–‚â–â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–„â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–‚â–â–â–
wandb: valid_error_energy â–…â–ƒâ–‚â–â–„â–„â–â–‚â–â–ƒâ–â–â–ˆâ–â–ƒâ–‡â–‡â–ƒâ–‚â–‚
wandb:  valid_error_force â–†â–‚â–ƒâ–†â–ˆâ–‚â–„â–…â–‚â–ˆâ–ƒâ–†â–„â–‚â–â–â–„â–‚â–â–‚
wandb:         valid_loss â–†â–‚â–ƒâ–„â–ˆâ–ƒâ–ƒâ–…â–â–ˆâ–‚â–…â–‡â–â–â–„â–†â–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1024
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.40002
wandb:   test_error_force 10.51606
wandb:          test_loss 9.17079
wandb: train_error_energy 1.33008
wandb:  train_error_force 1.91984
wandb:         train_loss -2.53983
wandb: valid_error_energy 1.42063
wandb:  valid_error_force 2.2313
wandb:         valid_loss -2.12737
wandb: 
wandb: ğŸš€ View run al_70_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/fgtwusr9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_164646-fgtwusr9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 20.390724182128906, Uncertainty Bias: -2.4693057537078857
2.2888184e-05 0.0050592422
-0.2750623 12.319496
(48745, 22, 3)
Found uncertainty sample 0 after 3516 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1869 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1518 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2374 steps.
Found uncertainty sample 9 after 3853 steps.
Found uncertainty sample 10 after 966 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3553 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 783 steps.
Found uncertainty sample 19 after 998 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1964 steps.
Found uncertainty sample 23 after 2782 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2631 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3277 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1690 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 703 steps.
Found uncertainty sample 38 after 2875 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1010 steps.
Found uncertainty sample 41 after 3081 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2612 steps.
Found uncertainty sample 46 after 244 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 550 steps.
Found uncertainty sample 52 after 2931 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3952 steps.
Found uncertainty sample 55 after 1916 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1785 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3577 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2425 steps.
Found uncertainty sample 65 after 1343 steps.
Found uncertainty sample 66 after 3516 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1471 steps.
Found uncertainty sample 72 after 2049 steps.
Found uncertainty sample 73 after 53 steps.
Found uncertainty sample 74 after 3641 steps.
Found uncertainty sample 75 after 3163 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2013 steps.
Found uncertainty sample 78 after 2584 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2958 steps.
Found uncertainty sample 81 after 3576 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1241 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1294 steps.
Found uncertainty sample 87 after 1696 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1338 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3396 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3933 steps.
Found uncertainty sample 96 after 3959 steps.
Found uncertainty sample 97 after 3207 steps.
Found uncertainty sample 98 after 2710 steps.
Found uncertainty sample 99 after 1634 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_172156-14w2aqim
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/14w2aqim
Training model 4. Added 48 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8337931281230473, Training Loss Force: 2.431792808581253, time: 0.5545470714569092
Validation Loss Energy: 2.252898727076995, Validation Loss Force: 2.3862056233536055, time: 0.05196094512939453
Test Loss Energy: 12.211344048739884, Test Loss Force: 10.417585817653345, time: 8.80200457572937


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.827054442753594, Training Loss Force: 2.133499585202268, time: 0.5640172958374023
Validation Loss Energy: 3.4335359632918956, Validation Loss Force: 2.2857571222649753, time: 0.049954891204833984
Test Loss Energy: 12.364425575154415, Test Loss Force: 10.29419200602756, time: 9.118798017501831


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8957594252342616, Training Loss Force: 2.080579489131844, time: 0.5259532928466797
Validation Loss Energy: 1.4929195799213264, Validation Loss Force: 2.34907264857125, time: 0.04054594039916992
Test Loss Energy: 13.726293429758753, Test Loss Force: 10.468523942564985, time: 8.367863416671753


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8717870213432604, Training Loss Force: 2.0805901968981253, time: 0.519841194152832
Validation Loss Energy: 1.5852172769232702, Validation Loss Force: 2.2327496187311358, time: 0.04884982109069824
Test Loss Energy: 13.103725877071218, Test Loss Force: 10.367376578623468, time: 9.916290283203125


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9056961242840382, Training Loss Force: 2.0942214649862376, time: 0.5703153610229492
Validation Loss Energy: 3.9516300625645004, Validation Loss Force: 2.342698521599921, time: 0.04131650924682617
Test Loss Energy: 12.080606683293052, Test Loss Force: 10.21415345794827, time: 7.225651979446411


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.5478204776229316, Training Loss Force: 2.080238654709446, time: 0.5062894821166992
Validation Loss Energy: 4.072308278229817, Validation Loss Force: 2.3765326529853565, time: 0.03961896896362305
Test Loss Energy: 16.61968147938695, Test Loss Force: 10.699220761204991, time: 7.133812427520752


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.95319336380818, Training Loss Force: 2.123534839663743, time: 0.5077238082885742
Validation Loss Energy: 1.1916417680757976, Validation Loss Force: 2.292572356814387, time: 0.03950905799865723
Test Loss Energy: 13.065619883587633, Test Loss Force: 10.342221913343625, time: 7.365386962890625


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4938939801039066, Training Loss Force: 2.0602051443957854, time: 0.48502469062805176
Validation Loss Energy: 1.2955120259299002, Validation Loss Force: 2.291070453425104, time: 0.04149889945983887
Test Loss Energy: 13.618395371511733, Test Loss Force: 10.376703132925197, time: 7.019453525543213


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5574291646108194, Training Loss Force: 2.0955330582957705, time: 0.5203244686126709
Validation Loss Energy: 1.4996349473587895, Validation Loss Force: 2.2780189241056927, time: 0.03770565986633301
Test Loss Energy: 14.296616267628936, Test Loss Force: 10.389128355724889, time: 7.123070001602173


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7794980976693935, Training Loss Force: 2.066172307482922, time: 0.4961700439453125
Validation Loss Energy: 3.056011337159482, Validation Loss Force: 2.3015156403914308, time: 0.042021751403808594
Test Loss Energy: 12.135336889407595, Test Loss Force: 10.22495105089772, time: 7.473124027252197


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.436708301254966, Training Loss Force: 2.0492098729517223, time: 0.5441770553588867
Validation Loss Energy: 1.6575188392826066, Validation Loss Force: 2.384348340007422, time: 0.04362773895263672
Test Loss Energy: 14.31345072190271, Test Loss Force: 10.372252491984813, time: 7.279940605163574


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.462072731079397, Training Loss Force: 2.1908436030985134, time: 0.4961979389190674
Validation Loss Energy: 3.6327364492463325, Validation Loss Force: 2.296618923203333, time: 0.03939247131347656
Test Loss Energy: 11.939638955310203, Test Loss Force: 10.145619541476135, time: 6.999251127243042


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.351307426522526, Training Loss Force: 2.047976665730648, time: 0.5165359973907471
Validation Loss Energy: 1.1333888474713372, Validation Loss Force: 2.2355503512486155, time: 0.0409398078918457
Test Loss Energy: 13.60895589713946, Test Loss Force: 10.271195557364297, time: 7.077846050262451


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.613559850144539, Training Loss Force: 2.0401372709936343, time: 0.4778275489807129
Validation Loss Energy: 3.9392995359396035, Validation Loss Force: 2.293947561459637, time: 0.03916788101196289
Test Loss Energy: 11.891916378047798, Test Loss Force: 10.109978325230145, time: 7.119752645492554


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7245385454205002, Training Loss Force: 2.0568709653701345, time: 0.49302220344543457
Validation Loss Energy: 2.8398370048801156, Validation Loss Force: 2.429962559889021, time: 0.043348073959350586
Test Loss Energy: 12.097573922989447, Test Loss Force: 10.149284885463377, time: 7.250984191894531


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5582427436400261, Training Loss Force: 2.085103988646153, time: 0.5196704864501953
Validation Loss Energy: 2.4304326144560746, Validation Loss Force: 2.2996329727626112, time: 0.03834700584411621
Test Loss Energy: 15.001256631743905, Test Loss Force: 10.55188913504184, time: 7.079407453536987


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4130611031956823, Training Loss Force: 2.03792092710055, time: 0.4791412353515625
Validation Loss Energy: 1.097614265813714, Validation Loss Force: 2.3027841865157814, time: 0.039774179458618164
Test Loss Energy: 13.95577825674005, Test Loss Force: 10.318286519021692, time: 7.119905471801758


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6297606055675384, Training Loss Force: 2.0485611591405237, time: 0.49619507789611816
Validation Loss Energy: 1.1424348928592265, Validation Loss Force: 2.249180597678293, time: 0.03857588768005371
Test Loss Energy: 13.810470905290268, Test Loss Force: 10.395061898565496, time: 7.088322639465332


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5479534807431354, Training Loss Force: 2.044733581307506, time: 0.489027738571167
Validation Loss Energy: 1.3460128315534576, Validation Loss Force: 2.264617804227175, time: 0.04329323768615723
Test Loss Energy: 13.33188094256595, Test Loss Force: 10.306492958459293, time: 8.756876230239868


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4013737531242514, Training Loss Force: 2.0149628049097097, time: 0.5234255790710449
Validation Loss Energy: 4.003397076286376, Validation Loss Force: 2.59267870628319, time: 0.05440211296081543
Test Loss Energy: 11.85263958320008, Test Loss Force: 10.145274434610931, time: 9.971891164779663

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–„â–ƒâ–â–ˆâ–ƒâ–„â–…â–â–…â–â–„â–â–â–†â–„â–„â–ƒâ–
wandb:   test_error_force â–…â–ƒâ–…â–„â–‚â–ˆâ–„â–„â–„â–‚â–„â–â–ƒâ–â–â–†â–ƒâ–„â–ƒâ–
wandb:          test_loss â–„â–‚â–„â–ƒâ–â–ˆâ–‚â–ƒâ–„â–‚â–„â–â–ƒâ–â–ƒâ–‡â–„â–…â–„â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–„â–ƒâ–â–â–‚â–â–„â–„â–‚â–‚â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–„â–‚â–â–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–„â–‚â–â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–„â–†â–‚â–‚â–ˆâ–ˆâ–â–â–‚â–†â–‚â–‡â–â–ˆâ–…â–„â–â–â–‚â–ˆ
wandb:  valid_error_force â–„â–‚â–ƒâ–â–ƒâ–„â–‚â–‚â–‚â–‚â–„â–‚â–â–‚â–…â–‚â–‚â–â–‚â–ˆ
wandb:         valid_loss â–„â–ƒâ–ƒâ–â–„â–…â–‚â–‚â–‚â–ƒâ–ƒâ–„â–â–„â–…â–ƒâ–‚â–â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1067
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.85264
wandb:   test_error_force 10.14527
wandb:          test_loss 8.09998
wandb: train_error_energy 1.40137
wandb:  train_error_force 2.01496
wandb:         train_loss -2.41435
wandb: valid_error_energy 4.0034
wandb:  valid_error_force 2.59268
wandb:         valid_loss -1.52507
wandb: 
wandb: ğŸš€ View run al_70_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/14w2aqim
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_172156-14w2aqim/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 16.693117141723633, Uncertainty Bias: -2.0867862701416016
0.00083065033 0.40860605
0.32079676 10.106892
(48745, 22, 3)
Found uncertainty sample 0 after 1217 steps.
Found uncertainty sample 1 after 904 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1828 steps.
Found uncertainty sample 4 after 3023 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3990 steps.
Found uncertainty sample 7 after 1377 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2811 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3367 steps.
Found uncertainty sample 21 after 1259 steps.
Found uncertainty sample 22 after 2148 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2389 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2532 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1627 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2815 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1805 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3068 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3232 steps.
Found uncertainty sample 49 after 2815 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 251 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3163 steps.
Found uncertainty sample 55 after 3016 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2575 steps.
Found uncertainty sample 58 after 1702 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 669 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3094 steps.
Found uncertainty sample 64 after 711 steps.
Found uncertainty sample 65 after 1013 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2405 steps.
Found uncertainty sample 68 after 1130 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 440 steps.
Found uncertainty sample 72 after 1785 steps.
Found uncertainty sample 73 after 1277 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3342 steps.
Found uncertainty sample 76 after 2529 steps.
Found uncertainty sample 77 after 1304 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1423 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 435 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2154 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2735 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 941 steps.
Found uncertainty sample 93 after 642 steps.
Found uncertainty sample 94 after 3053 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_175623-f04fp9jr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/f04fp9jr
Training model 5. Added 42 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.714210674622402, Training Loss Force: 2.669817005124687, time: 0.5036823749542236
Validation Loss Energy: 1.2609365176230982, Validation Loss Force: 2.537319371230061, time: 0.045903921127319336
Test Loss Energy: 12.956192855409132, Test Loss Force: 10.237750194649582, time: 8.100067138671875


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5618173024289683, Training Loss Force: 2.162259100879337, time: 0.5396084785461426
Validation Loss Energy: 1.4043327755708424, Validation Loss Force: 2.3946053715454396, time: 0.04397988319396973
Test Loss Energy: 14.377578829710247, Test Loss Force: 10.2113600397042, time: 8.071056842803955


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4710451483271354, Training Loss Force: 2.153285321172265, time: 0.5154423713684082
Validation Loss Energy: 1.2774758251097493, Validation Loss Force: 2.4343829877739793, time: 0.04399752616882324
Test Loss Energy: 13.495127327150152, Test Loss Force: 10.19393423680081, time: 8.38522744178772


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4385762794095844, Training Loss Force: 2.1566053213190366, time: 0.563652515411377
Validation Loss Energy: 1.1813851818760719, Validation Loss Force: 2.418902360741642, time: 0.052399635314941406
Test Loss Energy: 13.4922075820545, Test Loss Force: 10.113833896284815, time: 9.105867385864258


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4070587485130708, Training Loss Force: 2.105864675577412, time: 0.5176756381988525
Validation Loss Energy: 1.3186450121657651, Validation Loss Force: 2.4352992713094723, time: 0.049570322036743164
Test Loss Energy: 13.577612950852837, Test Loss Force: 10.010165418645977, time: 9.211003065109253


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5370586564735014, Training Loss Force: 2.166233942355392, time: 0.5153818130493164
Validation Loss Energy: 1.1765999105955107, Validation Loss Force: 2.5231772084338955, time: 0.0489499568939209
Test Loss Energy: 13.72191200511435, Test Loss Force: 10.294692053312504, time: 8.946558475494385


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7837123804237793, Training Loss Force: 2.1502145577815184, time: 0.5337786674499512
Validation Loss Energy: 1.3670245601706414, Validation Loss Force: 2.3945871126754734, time: 0.05099678039550781
Test Loss Energy: 13.307444535670836, Test Loss Force: 10.12272010194885, time: 9.168221473693848


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.202131300599092, Training Loss Force: 2.1777021318168788, time: 0.5247879028320312
Validation Loss Energy: 3.6091698148487734, Validation Loss Force: 2.4765375971352985, time: 0.05132699012756348
Test Loss Energy: 12.083142542117896, Test Loss Force: 9.998745252090966, time: 8.988527059555054


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.004303423603861, Training Loss Force: 2.2171942034946563, time: 0.5411458015441895
Validation Loss Energy: 2.378273257699074, Validation Loss Force: 2.3688303045585686, time: 0.05477452278137207
Test Loss Energy: 12.250880590060842, Test Loss Force: 9.927357239449599, time: 9.657797813415527


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9551454942465523, Training Loss Force: 2.1530723413151733, time: 0.5162625312805176
Validation Loss Energy: 3.0356355516230678, Validation Loss Force: 2.5739624738913753, time: 0.05023694038391113
Test Loss Energy: 12.375459421233503, Test Loss Force: 9.965285685183193, time: 9.299296379089355


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.653075054994734, Training Loss Force: 2.122282501140021, time: 0.5066671371459961
Validation Loss Energy: 1.4513690719529093, Validation Loss Force: 2.423366877117494, time: 0.05177569389343262
Test Loss Energy: 13.848400143772654, Test Loss Force: 10.07520767306469, time: 9.068316459655762


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8365626222828138, Training Loss Force: 2.1750598029488244, time: 0.5738906860351562
Validation Loss Energy: 3.1733096578587596, Validation Loss Force: 2.41228396571723, time: 0.05470442771911621
Test Loss Energy: 15.676187788251417, Test Loss Force: 10.226681672805697, time: 9.174082517623901


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6021362082653319, Training Loss Force: 2.113582308650574, time: 0.5291428565979004
Validation Loss Energy: 1.1668109296022333, Validation Loss Force: 2.4919556541376306, time: 0.05007052421569824
Test Loss Energy: 13.396885723282953, Test Loss Force: 10.078270905691658, time: 9.19832730293274


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.500378689344585, Training Loss Force: 2.1273486759101448, time: 0.5291001796722412
Validation Loss Energy: 2.622471838008328, Validation Loss Force: 2.4024896406644505, time: 0.05511975288391113
Test Loss Energy: 12.599214889483585, Test Loss Force: 10.007769619879724, time: 8.9844970703125


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.464086898156776, Training Loss Force: 2.074110309005808, time: 0.5978889465332031
Validation Loss Energy: 2.0187652375019693, Validation Loss Force: 2.436826336312245, time: 0.05014848709106445
Test Loss Energy: 12.831607276545284, Test Loss Force: 9.906472822790954, time: 8.895597219467163


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4572325804007722, Training Loss Force: 2.126824799029533, time: 0.5722389221191406
Validation Loss Energy: 1.230027479473143, Validation Loss Force: 2.4570669616770813, time: 0.04803204536437988
Test Loss Energy: 13.370514748195108, Test Loss Force: 10.057644202338766, time: 9.12452244758606


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.433537111225873, Training Loss Force: 2.15397738960176, time: 0.5189135074615479
Validation Loss Energy: 1.436973511668678, Validation Loss Force: 2.5483517367341992, time: 0.050334930419921875
Test Loss Energy: 13.052437982066188, Test Loss Force: 10.031010309782507, time: 8.909881830215454


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9908107453535255, Training Loss Force: 2.149061408351551, time: 0.5983529090881348
Validation Loss Energy: 1.9261878680527404, Validation Loss Force: 2.3890359708674938, time: 0.049788713455200195
Test Loss Energy: 14.427773076461502, Test Loss Force: 10.120717557878834, time: 8.959345817565918


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9149475486522327, Training Loss Force: 2.112950020524785, time: 0.5270459651947021
Validation Loss Energy: 2.268025087498162, Validation Loss Force: 2.4276534808457497, time: 0.05007028579711914
Test Loss Energy: 14.99748401485545, Test Loss Force: 10.176333716726939, time: 9.270014762878418


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6561561979486683, Training Loss Force: 2.1110583029856778, time: 0.5640079975128174
Validation Loss Energy: 1.1581384117066378, Validation Loss Force: 2.4572780520274207, time: 0.05064249038696289
Test Loss Energy: 13.241612843352346, Test Loss Force: 9.966814496564922, time: 9.414263010025024

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–…â–„â–„â–„â–„â–ƒâ–â–â–‚â–„â–ˆâ–„â–‚â–‚â–„â–ƒâ–†â–‡â–ƒ
wandb:   test_error_force â–‡â–†â–†â–…â–ƒâ–ˆâ–…â–ƒâ–â–‚â–„â–‡â–„â–ƒâ–â–„â–ƒâ–…â–†â–‚
wandb:          test_loss â–„â–…â–…â–…â–…â–ˆâ–…â–ƒâ–â–â–…â–ˆâ–„â–ƒâ–ƒâ–†â–…â–‡â–ˆâ–ƒ
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–â–‚â–â–â–â–â–‚â–ˆâ–„â–†â–‚â–‡â–â–…â–ƒâ–â–‚â–ƒâ–„â–
wandb:  valid_error_force â–‡â–‚â–ƒâ–ƒâ–ƒâ–†â–‚â–…â–â–ˆâ–ƒâ–‚â–…â–‚â–ƒâ–„â–‡â–‚â–ƒâ–„
wandb:         valid_loss â–„â–â–‚â–â–‚â–„â–â–†â–‚â–ˆâ–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1104
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.24161
wandb:   test_error_force 9.96681
wandb:          test_loss 7.54189
wandb: train_error_energy 1.65616
wandb:  train_error_force 2.11106
wandb:         train_loss -2.28067
wandb: valid_error_energy 1.15814
wandb:  valid_error_force 2.45728
wandb:         valid_loss -1.90867
wandb: 
wandb: ğŸš€ View run al_70_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/f04fp9jr
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_175623-f04fp9jr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.795438766479492, Uncertainty Bias: -2.5285587310791016
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:925: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
0.00030136108 2.861023e-05
-0.5693525 10.861344
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1931 steps.
Found uncertainty sample 2 after 258 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1035 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1536 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1627 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1559 steps.
Found uncertainty sample 18 after 1160 steps.
Found uncertainty sample 19 after 3099 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 117 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 613 steps.
Found uncertainty sample 24 after 1145 steps.
Found uncertainty sample 25 after 2835 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3220 steps.
Found uncertainty sample 28 after 2515 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1438 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3882 steps.
Found uncertainty sample 38 after 1721 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1444 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3906 steps.
Found uncertainty sample 46 after 2071 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3949 steps.
Found uncertainty sample 54 after 767 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2881 steps.
Found uncertainty sample 59 after 1561 steps.
Found uncertainty sample 60 after 1584 steps.
Found uncertainty sample 61 after 3606 steps.
Found uncertainty sample 62 after 3171 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3322 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 543 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3811 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3785 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3992 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1490 steps.
Found uncertainty sample 78 after 894 steps.
Found uncertainty sample 79 after 323 steps.
Found uncertainty sample 80 after 1495 steps.
Found uncertainty sample 81 after 1559 steps.
Found uncertainty sample 82 after 860 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2847 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2875 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2496 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_183152-g96ywdvk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/g96ywdvk
Training model 6. Added 41 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.561786179668931, Training Loss Force: 2.75507933977546, time: 0.5206906795501709
Validation Loss Energy: 1.2263284996209907, Validation Loss Force: 2.48335995709738, time: 0.046369314193725586
Test Loss Energy: 13.602409494197602, Test Loss Force: 9.917168402960588, time: 8.079265117645264


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4807146371484192, Training Loss Force: 2.253036652057135, time: 0.5444021224975586
Validation Loss Energy: 3.4765614316829385, Validation Loss Force: 2.5024609617733575, time: 0.045493125915527344
Test Loss Energy: 11.983946599275777, Test Loss Force: 9.672741795456218, time: 8.240861177444458


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.787704798624639, Training Loss Force: 2.26753976153885, time: 0.586493968963623
Validation Loss Energy: 1.3594525845287941, Validation Loss Force: 2.489608053332114, time: 0.04571533203125
Test Loss Energy: 13.34624270144067, Test Loss Force: 9.84902185619072, time: 8.155847311019897


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6307612957176751, Training Loss Force: 2.2547458511433955, time: 0.526482343673706
Validation Loss Energy: 1.4239459192824537, Validation Loss Force: 2.5192059042162733, time: 0.04704928398132324
Test Loss Energy: 13.889745896386223, Test Loss Force: 9.85434532754054, time: 8.397197008132935


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7881964892103714, Training Loss Force: 2.255075948874353, time: 0.5195050239562988
Validation Loss Energy: 3.4345947550807825, Validation Loss Force: 2.489852098716051, time: 0.045816659927368164
Test Loss Energy: 15.897933479764566, Test Loss Force: 10.046119211077341, time: 8.111852645874023


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.595364053215156, Training Loss Force: 2.2067723619745085, time: 0.5176708698272705
Validation Loss Energy: 2.179030241937765, Validation Loss Force: 2.4537202444137862, time: 0.04511141777038574
Test Loss Energy: 12.418092756434689, Test Loss Force: 9.691248301491939, time: 8.115057945251465


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8527921868259911, Training Loss Force: 2.238477974253004, time: 0.5308787822723389
Validation Loss Energy: 2.236415420880545, Validation Loss Force: 2.431658853442699, time: 0.04774212837219238
Test Loss Energy: 12.388355275674733, Test Loss Force: 9.6414012647218, time: 8.353614568710327


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0865609304231656, Training Loss Force: 2.2383137526652552, time: 0.5299422740936279
Validation Loss Energy: 2.07862137595711, Validation Loss Force: 2.4909280360291737, time: 0.0489652156829834
Test Loss Energy: 14.794855735586657, Test Loss Force: 9.816915446185329, time: 8.527628660202026


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0309602637663158, Training Loss Force: 2.277678577408769, time: 0.5059690475463867
Validation Loss Energy: 1.6179455219954553, Validation Loss Force: 2.461076119649511, time: 0.04640984535217285
Test Loss Energy: 12.87931266981182, Test Loss Force: 9.719435949037498, time: 8.08882999420166


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7132824239849131, Training Loss Force: 2.241886779096488, time: 0.534400224685669
Validation Loss Energy: 1.7075311087999985, Validation Loss Force: 2.4798221897068795, time: 0.04511713981628418
Test Loss Energy: 14.319586233819324, Test Loss Force: 9.842462512790648, time: 8.144792318344116


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1090766159339775, Training Loss Force: 2.2083962911483868, time: 0.7420010566711426
Validation Loss Energy: 1.9208861156881998, Validation Loss Force: 2.4453946450475463, time: 0.04573321342468262
Test Loss Energy: 14.533161851621111, Test Loss Force: 9.76948727717128, time: 8.182847499847412


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9969428478401383, Training Loss Force: 2.2196013705940896, time: 0.5656888484954834
Validation Loss Energy: 1.5662765940323606, Validation Loss Force: 2.427116625534918, time: 0.0454401969909668
Test Loss Energy: 14.506382167898817, Test Loss Force: 9.853371813371316, time: 8.146228790283203


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9829084228917044, Training Loss Force: 2.204481677876792, time: 0.551706075668335
Validation Loss Energy: 1.9289627709492925, Validation Loss Force: 2.440913205816604, time: 0.046161651611328125
Test Loss Energy: 12.91922886785562, Test Loss Force: 9.710012893891667, time: 8.087959051132202


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5771120148621798, Training Loss Force: 2.187455445542657, time: 0.5318293571472168
Validation Loss Energy: 1.9293056814340213, Validation Loss Force: 2.4383732188690055, time: 0.04610729217529297
Test Loss Energy: 12.839988827654926, Test Loss Force: 9.669283382219776, time: 8.38495659828186


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5796178623000294, Training Loss Force: 2.254864645132748, time: 0.5540304183959961
Validation Loss Energy: 1.1611723901544768, Validation Loss Force: 2.5020227488941718, time: 0.048276662826538086
Test Loss Energy: 13.351407296606158, Test Loss Force: 9.708692654717057, time: 8.18738842010498


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5219361839263117, Training Loss Force: 2.2125716314340997, time: 0.529029369354248
Validation Loss Energy: 1.4050312886816179, Validation Loss Force: 2.4601139662699567, time: 0.044812679290771484
Test Loss Energy: 14.273466142280778, Test Loss Force: 9.823786204626954, time: 8.16482424736023


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.573429483146869, Training Loss Force: 2.202090774107647, time: 0.5157203674316406
Validation Loss Energy: 1.116654704481999, Validation Loss Force: 2.3951604857262376, time: 0.05635523796081543
Test Loss Energy: 13.460407769975944, Test Loss Force: 9.68037539740727, time: 8.40265965461731


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6701214505943787, Training Loss Force: 2.251683788549527, time: 0.5223844051361084
Validation Loss Energy: 1.1125442320481722, Validation Loss Force: 2.460693351387661, time: 0.04523015022277832
Test Loss Energy: 13.853103177275429, Test Loss Force: 9.656423798367383, time: 8.104056596755981


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.863503389198652, Training Loss Force: 2.2100691797007257, time: 0.5223731994628906
Validation Loss Energy: 1.1178458730781398, Validation Loss Force: 2.4851718159377945, time: 0.04998326301574707
Test Loss Energy: 13.797087412414296, Test Loss Force: 9.65902665379159, time: 8.525640964508057


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.145656553234584, Training Loss Force: 2.24915591851462, time: 0.5223548412322998
Validation Loss Energy: 2.0181546787038354, Validation Loss Force: 2.5123169661795592, time: 0.0462033748626709
Test Loss Energy: 12.806457470349212, Test Loss Force: 9.684564501194783, time: 8.167733669281006

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–ƒâ–„â–ˆâ–‚â–‚â–†â–ƒâ–…â–†â–†â–ƒâ–ƒâ–ƒâ–…â–„â–„â–„â–‚
wandb:   test_error_force â–†â–‚â–…â–…â–ˆâ–‚â–â–„â–‚â–„â–ƒâ–…â–‚â–â–‚â–„â–‚â–â–â–‚
wandb:          test_loss â–ƒâ–â–„â–…â–ˆâ–„â–‚â–…â–ƒâ–…â–…â–†â–ƒâ–„â–„â–…â–„â–ƒâ–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–â–ƒâ–‚â–ƒâ–‚â–ƒâ–…â–…â–ƒâ–…â–„â–„â–‚â–‚â–â–‚â–‚â–ƒâ–…
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚
wandb: valid_error_energy â–â–ˆâ–‚â–‚â–ˆâ–„â–„â–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–‚â–â–â–â–„
wandb:  valid_error_force â–†â–‡â–†â–ˆâ–†â–„â–ƒâ–†â–…â–†â–„â–ƒâ–„â–ƒâ–‡â–…â–â–…â–†â–ˆ
wandb:         valid_loss â–ƒâ–ˆâ–„â–…â–ˆâ–…â–„â–…â–„â–„â–„â–ƒâ–„â–„â–„â–ƒâ–â–ƒâ–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1140
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.80646
wandb:   test_error_force 9.68456
wandb:          test_loss 6.9271
wandb: train_error_energy 2.14566
wandb:  train_error_force 2.24916
wandb:         train_loss -2.08885
wandb: valid_error_energy 2.01815
wandb:  valid_error_force 2.51232
wandb:         valid_loss -1.79973
wandb: 
wandb: ğŸš€ View run al_70_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/g96ywdvk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_183152-g96ywdvk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 15.594381332397461, Uncertainty Bias: -2.1421549320220947
2.2888184e-05 0.013133049
-0.093898684 7.378935
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2803 steps.
Found uncertainty sample 12 after 412 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1382 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2489 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1396 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1660 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1771 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 322 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3166 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1114 steps.
Found uncertainty sample 48 after 1549 steps.
Found uncertainty sample 49 after 1779 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1978 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2746 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 494 steps.
Found uncertainty sample 61 after 3902 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 902 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1512 steps.
Found uncertainty sample 68 after 1833 steps.
Found uncertainty sample 69 after 813 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3616 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1926 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3657 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 692 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2130 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2221 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_190911-xme9zyxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xme9zyxw
Training model 7. Added 26 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.046941189341067, Training Loss Force: 2.581792748751542, time: 0.6755030155181885
Validation Loss Energy: 2.2686423263706734, Validation Loss Force: 2.4778671546056334, time: 0.05774211883544922
Test Loss Energy: 12.688522317058391, Test Loss Force: 9.500420106641771, time: 8.235013723373413


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5817779879715983, Training Loss Force: 2.263765492935498, time: 0.5323638916015625
Validation Loss Energy: 1.3875252630979211, Validation Loss Force: 2.485758994475606, time: 0.04623579978942871
Test Loss Energy: 13.154592607959318, Test Loss Force: 9.565394790884056, time: 8.350616693496704


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5986931639856183, Training Loss Force: 2.2799132307109504, time: 0.5427014827728271
Validation Loss Energy: 2.501155897909075, Validation Loss Force: 2.4365232836046373, time: 0.046593666076660156
Test Loss Energy: 12.480207217025896, Test Loss Force: 9.544221650452215, time: 8.216668128967285


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9954490201358672, Training Loss Force: 2.232333007768147, time: 0.5910358428955078
Validation Loss Energy: 1.8246923766399576, Validation Loss Force: 2.4575730886457747, time: 0.06984663009643555
Test Loss Energy: 14.05381993868842, Test Loss Force: 9.668463157687514, time: 8.35541558265686


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9452639939652245, Training Loss Force: 2.238147886134265, time: 0.545851469039917
Validation Loss Energy: 3.2578974356829535, Validation Loss Force: 2.4917173981514877, time: 0.05063199996948242
Test Loss Energy: 15.581749643863898, Test Loss Force: 9.721360066935866, time: 8.29958462715149


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7502088462202074, Training Loss Force: 2.2513878898404935, time: 0.5353002548217773
Validation Loss Energy: 2.5315771792948754, Validation Loss Force: 2.4926118601106797, time: 0.049191951751708984
Test Loss Energy: 12.225409771899608, Test Loss Force: 9.571391170724485, time: 8.261248350143433


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.271477259665351, Training Loss Force: 2.3113370107183138, time: 0.5483152866363525
Validation Loss Energy: 1.1554465644015168, Validation Loss Force: 2.4961175631441668, time: 0.04756617546081543
Test Loss Energy: 13.45266661999322, Test Loss Force: 9.499114673216654, time: 8.4408700466156


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3001383204673964, Training Loss Force: 2.227772867030289, time: 0.5622694492340088
Validation Loss Energy: 1.2807000743427839, Validation Loss Force: 2.435725460054778, time: 0.04927253723144531
Test Loss Energy: 13.942272545316525, Test Loss Force: 9.58006796480033, time: 8.23467230796814


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5622684907293316, Training Loss Force: 2.2123822615227993, time: 0.556342363357544
Validation Loss Energy: 1.423769119980587, Validation Loss Force: 2.4114151107098203, time: 0.052449941635131836
Test Loss Energy: 13.154548563769094, Test Loss Force: 9.513615265720956, time: 8.307688236236572


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1128201070057044, Training Loss Force: 2.2608507658514734, time: 0.5663855075836182
Validation Loss Energy: 1.2504005929798059, Validation Loss Force: 2.4562920730492523, time: 0.04601860046386719
Test Loss Energy: 13.951633192479536, Test Loss Force: 9.659325184333664, time: 8.816062450408936


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3181770895053315, Training Loss Force: 2.229039782253598, time: 0.5263826847076416
Validation Loss Energy: 2.415096945037736, Validation Loss Force: 2.463970818546572, time: 0.048128366470336914
Test Loss Energy: 12.481114270867002, Test Loss Force: 9.472008941242754, time: 8.738187789916992


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3984561381116751, Training Loss Force: 2.247754140011928, time: 0.6102738380432129
Validation Loss Energy: 1.1369701466798667, Validation Loss Force: 2.4480891643824187, time: 0.05221128463745117
Test Loss Energy: 13.359352434842695, Test Loss Force: 9.523460678770137, time: 9.662544965744019


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2834649014604824, Training Loss Force: 2.218460175340151, time: 0.5726182460784912
Validation Loss Energy: 1.81026953938535, Validation Loss Force: 2.447428950364743, time: 0.05730915069580078
Test Loss Energy: 13.04181854308639, Test Loss Force: 9.417355799637225, time: 9.75729513168335


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.533426490261024, Training Loss Force: 2.2422794128385535, time: 0.5675323009490967
Validation Loss Energy: 1.716745603396782, Validation Loss Force: 2.5495047175718133, time: 0.05170416831970215
Test Loss Energy: 13.082835095106102, Test Loss Force: 9.448405298300496, time: 9.615928888320923


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.945835108729583, Training Loss Force: 2.2082451560536938, time: 0.5613470077514648
Validation Loss Energy: 1.954804416010796, Validation Loss Force: 2.4651888187747972, time: 0.05172228813171387
Test Loss Energy: 12.880395713884697, Test Loss Force: 9.416345515913745, time: 9.379659175872803


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7581417820882954, Training Loss Force: 2.2242224466160234, time: 0.6320884227752686
Validation Loss Energy: 1.567203231683139, Validation Loss Force: 2.391063596110312, time: 0.05789685249328613
Test Loss Energy: 14.052335283414394, Test Loss Force: 9.523528845839774, time: 9.744873285293579


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5119541720200096, Training Loss Force: 2.203564680696717, time: 0.614628791809082
Validation Loss Energy: 2.6723390385771477, Validation Loss Force: 2.4594526389065514, time: 0.05476737022399902
Test Loss Energy: 12.640175911782045, Test Loss Force: 9.431431273607089, time: 9.729480028152466


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5828205023450133, Training Loss Force: 2.225009220961776, time: 0.6056931018829346
Validation Loss Energy: 1.503223705983708, Validation Loss Force: 2.579493798145368, time: 0.05693626403808594
Test Loss Energy: 13.69126366998232, Test Loss Force: 9.637950923533348, time: 9.809979438781738


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.917524425429363, Training Loss Force: 2.2390005374477466, time: 0.5879909992218018
Validation Loss Energy: 2.2044944627969207, Validation Loss Force: 2.4284924981876057, time: 0.05484509468078613
Test Loss Energy: 12.4202215294285, Test Loss Force: 9.397243501648866, time: 9.845568656921387


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3920569367890891, Training Loss Force: 2.2042381014019803, time: 0.5491154193878174
Validation Loss Energy: 1.4411590236046825, Validation Loss Force: 2.6065494353904697, time: 0.051934242248535156
Test Loss Energy: 14.174590861661706, Test Loss Force: 9.616920725035122, time: 9.659982681274414

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‚â–…â–ˆâ–â–„â–…â–ƒâ–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–„â–â–…
wandb:   test_error_force â–ƒâ–…â–„â–‡â–ˆâ–…â–ƒâ–…â–„â–‡â–ƒâ–„â–â–‚â–â–„â–‚â–†â–â–†
wandb:          test_loss â–â–ƒâ–„â–‡â–ˆâ–…â–ƒâ–†â–…â–ˆâ–„â–…â–ƒâ–„â–„â–‡â–…â–‡â–„â–ˆ
wandb: train_error_energy â–ˆâ–‚â–‚â–„â–„â–ƒâ–…â–â–‚â–„â–â–â–â–‚â–„â–ƒâ–‚â–‚â–„â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–
wandb: valid_error_energy â–…â–‚â–†â–ƒâ–ˆâ–†â–â–â–‚â–â–…â–â–ƒâ–ƒâ–„â–‚â–†â–‚â–…â–‚
wandb:  valid_error_force â–„â–„â–‚â–ƒâ–„â–„â–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–â–ƒâ–‡â–‚â–ˆ
wandb:         valid_loss â–…â–ƒâ–„â–„â–ˆâ–†â–ƒâ–‚â–â–ƒâ–…â–‚â–ƒâ–‡â–„â–â–…â–‡â–ƒâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1163
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 14.17459
wandb:   test_error_force 9.61692
wandb:          test_loss 6.96803
wandb: train_error_energy 1.39206
wandb:  train_error_force 2.20424
wandb:         train_loss -2.19076
wandb: valid_error_energy 1.44116
wandb:  valid_error_force 2.60655
wandb:         valid_loss -1.73166
wandb: 
wandb: ğŸš€ View run al_70_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xme9zyxw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_190911-xme9zyxw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 16.884929656982422, Uncertainty Bias: -2.3233747482299805
3.0517578e-05 0.0019454956
0.22212762 7.30876
(48745, 22, 3)
Found uncertainty sample 0 after 2043 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2011 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1885 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 770 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2854 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2958 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1555 steps.
Found uncertainty sample 30 after 1029 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 779 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2607 steps.
Found uncertainty sample 37 after 3847 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2693 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2730 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2692 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 348 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 682 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 713 steps.
Found uncertainty sample 59 after 2865 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3715 steps.
Found uncertainty sample 63 after 1320 steps.
Found uncertainty sample 64 after 1186 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1537 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 565 steps.
Found uncertainty sample 73 after 3054 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1990 steps.
Found uncertainty sample 78 after 2120 steps.
Found uncertainty sample 79 after 733 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 459 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 967 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 361 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2703 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2260 steps.
Found uncertainty sample 97 after 1943 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_194530-l0843689
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/l0843689
Training model 8. Added 33 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.670173997332174, Training Loss Force: 2.7770322054183127, time: 0.5970020294189453
Validation Loss Energy: 2.718566934624924, Validation Loss Force: 2.5625961046683456, time: 0.053312063217163086
Test Loss Energy: 11.898227148069363, Test Loss Force: 9.438184047712358, time: 9.982920408248901


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.80102982750779, Training Loss Force: 2.3584349661823585, time: 0.5892930030822754
Validation Loss Energy: 1.5002902626552552, Validation Loss Force: 2.5602549612680607, time: 0.05302929878234863
Test Loss Energy: 12.810689056145511, Test Loss Force: 9.43096292228413, time: 9.920859336853027


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5169410424181577, Training Loss Force: 2.3093013989223685, time: 0.5849423408508301
Validation Loss Energy: 1.2707410854565906, Validation Loss Force: 2.484671255697749, time: 0.0572514533996582
Test Loss Energy: 13.655494760558883, Test Loss Force: 9.510904745684366, time: 9.956011295318604


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0223036831544077, Training Loss Force: 2.340024558143046, time: 0.5969812870025635
Validation Loss Energy: 2.299405182226327, Validation Loss Force: 2.68819508578952, time: 0.0619049072265625
Test Loss Energy: 14.987262521779448, Test Loss Force: 9.536925843424575, time: 10.041767597198486


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1907063966802096, Training Loss Force: 2.3718215832678187, time: 0.5668604373931885
Validation Loss Energy: 1.2377242611712829, Validation Loss Force: 2.5165683881827587, time: 0.05765652656555176
Test Loss Energy: 13.238937642606048, Test Loss Force: 9.45580740361466, time: 9.896902799606323


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7602998524122593, Training Loss Force: 2.3398244049495722, time: 0.6296050548553467
Validation Loss Energy: 5.209467137010857, Validation Loss Force: 2.611741411866068, time: 0.052780866622924805
Test Loss Energy: 11.560421517889758, Test Loss Force: 9.300439142014715, time: 9.927237033843994


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8887141391605426, Training Loss Force: 2.3329210197870878, time: 0.5797164440155029
Validation Loss Energy: 1.1610177464326301, Validation Loss Force: 2.4760539597503435, time: 0.05698585510253906
Test Loss Energy: 13.383288761810265, Test Loss Force: 9.355764063609632, time: 10.12459921836853


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.570390333256947, Training Loss Force: 2.3127388128446293, time: 0.586669921875
Validation Loss Energy: 2.450875868743705, Validation Loss Force: 2.4762202936023514, time: 0.059166908264160156
Test Loss Energy: 12.44697151305047, Test Loss Force: 9.387411262219311, time: 9.967719554901123


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8527585802247095, Training Loss Force: 2.316485268102579, time: 0.6088213920593262
Validation Loss Energy: 2.991090366311068, Validation Loss Force: 2.539253252762444, time: 0.05194592475891113
Test Loss Energy: 15.297777826097368, Test Loss Force: 9.54835283228242, time: 9.979300022125244


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.047245259975, Training Loss Force: 2.3278015250483457, time: 0.606895923614502
Validation Loss Energy: 2.562138964911756, Validation Loss Force: 2.532021181571855, time: 0.05561232566833496
Test Loss Energy: 12.299234801581173, Test Loss Force: 9.262259422893496, time: 9.775583744049072


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0965870228864305, Training Loss Force: 2.291521279339464, time: 0.5698375701904297
Validation Loss Energy: 1.6532449276956684, Validation Loss Force: 2.4925806864302498, time: 0.055022478103637695
Test Loss Energy: 14.025285463546458, Test Loss Force: 9.459105854134604, time: 10.025426626205444


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.097702820906532, Training Loss Force: 2.2815640102794377, time: 0.6351897716522217
Validation Loss Energy: 1.782604234018698, Validation Loss Force: 2.480310948482191, time: 0.0596776008605957
Test Loss Energy: 14.286288886630492, Test Loss Force: 9.516108987615903, time: 10.615072250366211


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.556740027560064, Training Loss Force: 2.2964098075767345, time: 0.6504712104797363
Validation Loss Energy: 1.559174338953848, Validation Loss Force: 2.5404476500612003, time: 0.05735301971435547
Test Loss Energy: 12.569786991116507, Test Loss Force: 9.320867522936044, time: 9.867161750793457


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6018990018377421, Training Loss Force: 2.329321866028883, time: 0.5902283191680908
Validation Loss Energy: 3.3926116009618275, Validation Loss Force: 2.605179352135576, time: 0.0577549934387207
Test Loss Energy: 15.308997786276631, Test Loss Force: 9.430913067711584, time: 9.95744514465332


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8429933867419028, Training Loss Force: 2.3424355376191515, time: 0.7376742362976074
Validation Loss Energy: 1.4270315569721481, Validation Loss Force: 2.5591037617836143, time: 0.07879638671875
Test Loss Energy: 13.356899567489892, Test Loss Force: 9.37827339611971, time: 10.120246887207031


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8101823717393628, Training Loss Force: 2.312189130619048, time: 0.6235270500183105
Validation Loss Energy: 2.2964835403626087, Validation Loss Force: 2.437958386250142, time: 0.05820655822753906
Test Loss Energy: 12.53153048727996, Test Loss Force: 9.317723560502705, time: 9.966491937637329


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.465912499199323, Training Loss Force: 2.265160949941379, time: 0.5924181938171387
Validation Loss Energy: 1.7354046098180929, Validation Loss Force: 2.5641340804592687, time: 0.056146860122680664
Test Loss Energy: 12.938221618020851, Test Loss Force: 9.370260841593275, time: 10.425161600112915


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5250936659461556, Training Loss Force: 2.3043615688858194, time: 0.5658926963806152
Validation Loss Energy: 2.1758841495749515, Validation Loss Force: 2.472309332723276, time: 0.05180215835571289
Test Loss Energy: 15.081088566171918, Test Loss Force: 9.421782630134484, time: 10.08707332611084


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4502099618540683, Training Loss Force: 2.319238006629539, time: 0.6209795475006104
Validation Loss Energy: 2.095213344696773, Validation Loss Force: 2.465967492778107, time: 0.05614185333251953
Test Loss Energy: 12.764144955920834, Test Loss Force: 9.324408540596592, time: 10.049142599105835


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.49470507151202, Training Loss Force: 2.243972515777759, time: 0.6406362056732178
Validation Loss Energy: 1.1985952801648305, Validation Loss Force: 2.4654246254003347, time: 0.05531716346740723
Test Loss Energy: 13.644183354474878, Test Loss Force: 9.323705787445586, time: 10.092779874801636

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–…â–‡â–„â–â–„â–ƒâ–ˆâ–‚â–†â–†â–ƒâ–ˆâ–„â–ƒâ–„â–ˆâ–ƒâ–…
wandb:   test_error_force â–…â–…â–‡â–ˆâ–†â–‚â–ƒâ–„â–ˆâ–â–†â–‡â–‚â–…â–„â–‚â–„â–…â–ƒâ–ƒ
wandb:          test_loss â–â–‚â–…â–‡â–„â–‚â–‚â–ƒâ–ˆâ–â–…â–†â–ƒâ–†â–ƒâ–â–„â–†â–‚â–„
wandb: train_error_energy â–ˆâ–‚â–â–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–â–â–‚â–‚â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–
wandb: valid_error_energy â–„â–‚â–â–ƒâ–â–ˆâ–â–ƒâ–„â–ƒâ–‚â–‚â–‚â–…â–â–ƒâ–‚â–ƒâ–ƒâ–
wandb:  valid_error_force â–„â–„â–‚â–ˆâ–ƒâ–†â–‚â–‚â–„â–„â–ƒâ–‚â–„â–†â–„â–â–…â–‚â–‚â–‚
wandb:         valid_loss â–„â–ƒâ–â–†â–‚â–ˆâ–â–‚â–„â–„â–‚â–‚â–ƒâ–†â–ƒâ–‚â–ƒâ–‚â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1192
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.64418
wandb:   test_error_force 9.32371
wandb:          test_loss 6.41072
wandb: train_error_energy 1.49471
wandb:  train_error_force 2.24397
wandb:         train_loss -2.13942
wandb: valid_error_energy 1.1986
wandb:  valid_error_force 2.46542
wandb:         valid_loss -1.91337
wandb: 
wandb: ğŸš€ View run al_70_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/l0843689
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_194530-l0843689/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 16.394176483154297, Uncertainty Bias: -2.314511775970459
3.0517578e-05 0.0024147034
0.22010756 7.1474266
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2064 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 440 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3309 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2930 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2883 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3785 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3677 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1627 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 341 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1262 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 921 steps.
Found uncertainty sample 37 after 3465 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 654 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2504 steps.
Found uncertainty sample 47 after 1489 steps.
Found uncertainty sample 48 after 3174 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2698 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 563 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3808 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2478 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2720 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3495 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1375 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3009 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1386 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3854 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3398 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2466 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1105 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_202401-06dhaxyl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/06dhaxyl
Training model 9. Added 29 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8695993468863636, Training Loss Force: 2.8501127063695995, time: 0.5999832153320312
Validation Loss Energy: 1.9400383342677407, Validation Loss Force: 2.56878074019649, time: 0.05752396583557129
Test Loss Energy: 12.88191484440471, Test Loss Force: 9.305098154643403, time: 9.439640522003174


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7898275897105367, Training Loss Force: 2.4085552966456207, time: 0.657738447189331
Validation Loss Energy: 3.4066816189547127, Validation Loss Force: 2.5271790183245098, time: 0.05580925941467285
Test Loss Energy: 15.965549178627315, Test Loss Force: 9.449935476008083, time: 9.97683596611023


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9845691845397886, Training Loss Force: 2.3616342229823735, time: 0.6459729671478271
Validation Loss Energy: 1.948482838957906, Validation Loss Force: 2.4794207172367715, time: 0.053911447525024414
Test Loss Energy: 12.445297526048822, Test Loss Force: 9.241607608056816, time: 9.606144905090332


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6801015743747263, Training Loss Force: 2.4432458306946896, time: 0.5863816738128662
Validation Loss Energy: 3.6207601892326062, Validation Loss Force: 2.583677528728205, time: 0.053578853607177734
Test Loss Energy: 12.001265157257324, Test Loss Force: 9.205351372634926, time: 9.462248802185059


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9001651144704506, Training Loss Force: 2.3686568681317515, time: 0.617600679397583
Validation Loss Energy: 1.8665118689366555, Validation Loss Force: 2.7340595857911416, time: 0.053676605224609375
Test Loss Energy: 12.959082116982126, Test Loss Force: 9.389753401218815, time: 9.520428895950317


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8698975718562496, Training Loss Force: 2.425925257107493, time: 0.612647294998169
Validation Loss Energy: 1.6183447677741039, Validation Loss Force: 2.575814413178057, time: 0.05522775650024414
Test Loss Energy: 13.17163095722234, Test Loss Force: 9.189503004593574, time: 9.79002046585083


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7575141173078292, Training Loss Force: 2.387237766213296, time: 0.6011881828308105
Validation Loss Energy: 2.63651357701968, Validation Loss Force: 2.577663903104133, time: 0.04982900619506836
Test Loss Energy: 12.570590409374383, Test Loss Force: 9.248985492563776, time: 9.477509260177612


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9632152634031343, Training Loss Force: 2.338547177958886, time: 0.5773072242736816
Validation Loss Energy: 1.1657582612148596, Validation Loss Force: 2.5373242699512715, time: 0.057132720947265625
Test Loss Energy: 13.428247840100651, Test Loss Force: 9.216300371277153, time: 9.48081922531128


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4319971117557628, Training Loss Force: 2.3241276122278833, time: 0.6599400043487549
Validation Loss Energy: 2.862010621100751, Validation Loss Force: 2.5408168355051486, time: 0.055477142333984375
Test Loss Energy: 15.659204726221782, Test Loss Force: 9.252589095409823, time: 9.73403811454773


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.46284210683367, Training Loss Force: 2.310744354411495, time: 0.611910343170166
Validation Loss Energy: 1.1034159104108625, Validation Loss Force: 2.624790269155728, time: 0.05448770523071289
Test Loss Energy: 13.533741752402964, Test Loss Force: 9.154065412869594, time: 9.325445175170898


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8272314429362797, Training Loss Force: 2.3980971720309694, time: 0.6149439811706543
Validation Loss Energy: 1.800549919831029, Validation Loss Force: 2.489681979488562, time: 0.056319475173950195
Test Loss Energy: 14.635187968271872, Test Loss Force: 9.255366061784846, time: 9.675789833068848


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4661634469511606, Training Loss Force: 2.335632715747757, time: 0.5945203304290771
Validation Loss Energy: 2.7490060295423984, Validation Loss Force: 2.5318693212143324, time: 0.057456016540527344
Test Loss Energy: 15.86131759286876, Test Loss Force: 9.223832865114654, time: 10.034189224243164


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6113293579446017, Training Loss Force: 2.358886303018736, time: 0.5630569458007812
Validation Loss Energy: 1.3925291954797834, Validation Loss Force: 2.6554355557023315, time: 0.04967451095581055
Test Loss Energy: 13.132797952474721, Test Loss Force: 9.32014131374726, time: 9.583428621292114


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7368013748316076, Training Loss Force: 2.316440408157751, time: 0.5816042423248291
Validation Loss Energy: 2.6363706234279944, Validation Loss Force: 2.5790573666193493, time: 0.0564117431640625
Test Loss Energy: 15.24226379660979, Test Loss Force: 9.278034158561777, time: 9.927963495254517


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7007840295650023, Training Loss Force: 2.370832162984577, time: 0.6162240505218506
Validation Loss Energy: 2.4453857382817095, Validation Loss Force: 2.477744463906227, time: 0.05645036697387695
Test Loss Energy: 14.955245440573204, Test Loss Force: 9.308783210096191, time: 8.323217153549194


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4707277690622096, Training Loss Force: 2.3423388338514664, time: 0.6029059886932373
Validation Loss Energy: 2.7521006853325027, Validation Loss Force: 2.4720024946401873, time: 0.04661226272583008
Test Loss Energy: 12.331086258911897, Test Loss Force: 9.113528548480561, time: 9.495862483978271


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9309892571537874, Training Loss Force: 2.307854385806418, time: 0.6343700885772705
Validation Loss Energy: 2.1482048160521057, Validation Loss Force: 2.4892475519848567, time: 0.05763125419616699
Test Loss Energy: 15.00273622741535, Test Loss Force: 9.264754263963209, time: 9.139625310897827


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9284855267380852, Training Loss Force: 2.340899420559675, time: 0.5767877101898193
Validation Loss Energy: 5.120517938625375, Validation Loss Force: 2.621913383790341, time: 0.050374746322631836
Test Loss Energy: 17.679066193074327, Test Loss Force: 9.46423319477011, time: 7.566084384918213


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0970193170784834, Training Loss Force: 2.3629083672374316, time: 0.6235013008117676
Validation Loss Energy: 1.6832179760907162, Validation Loss Force: 2.574239028970618, time: 0.04464125633239746
Test Loss Energy: 14.468152981252988, Test Loss Force: 9.35067788995256, time: 7.388130187988281


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8824411585970087, Training Loss Force: 2.31935812476409, time: 0.5897109508514404
Validation Loss Energy: 3.8676539568841704, Validation Loss Force: 2.5343269205779375, time: 0.04419398307800293
Test Loss Energy: 12.139732592856708, Test Loss Force: 9.159553817937157, time: 7.417813777923584

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–‚â–â–‚â–‚â–‚â–ƒâ–†â–ƒâ–„â–†â–‚â–…â–…â–â–…â–ˆâ–„â–
wandb:   test_error_force â–…â–ˆâ–„â–ƒâ–‡â–ƒâ–„â–ƒâ–„â–‚â–„â–ƒâ–…â–„â–…â–â–„â–ˆâ–†â–‚
wandb:          test_loss â–â–†â–‚â–‚â–ƒâ–â–â–‚â–„â–‚â–„â–„â–„â–…â–…â–â–„â–ˆâ–„â–‚
wandb: train_error_energy â–ˆâ–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–„â–â–â–ƒâ–â–‚â–‚â–‚â–â–ƒâ–ƒâ–„â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–â–â–‚â–â–‚â–â–‚â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–â–‚â–â–‚â–â–‚â–â–â–‚â–‚â–
wandb: valid_error_energy â–‚â–…â–‚â–…â–‚â–‚â–„â–â–„â–â–‚â–„â–‚â–„â–ƒâ–„â–ƒâ–ˆâ–‚â–†
wandb:  valid_error_force â–„â–‚â–â–„â–ˆâ–„â–„â–ƒâ–ƒâ–…â–â–ƒâ–†â–„â–â–â–â–…â–„â–ƒ
wandb:         valid_loss â–ƒâ–„â–â–…â–†â–‚â–„â–â–ƒâ–ƒâ–â–ƒâ–„â–„â–‚â–‚â–‚â–ˆâ–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1218
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.13973
wandb:   test_error_force 9.15955
wandb:          test_loss 5.92834
wandb: train_error_energy 1.88244
wandb:  train_error_force 2.31936
wandb:         train_loss -2.03102
wandb: valid_error_energy 3.86765
wandb:  valid_error_force 2.53433
wandb:         valid_loss -1.66276
wandb: 
wandb: ğŸš€ View run al_70_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/06dhaxyl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_202401-06dhaxyl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 15.87771987915039, Uncertainty Bias: -2.269878387451172
5.1558018e-05 0.39512014
0.37953866 7.707463
(48745, 22, 3)
Found uncertainty sample 0 after 1291 steps.
Found uncertainty sample 1 after 651 steps.
Found uncertainty sample 2 after 894 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2815 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1604 steps.
Found uncertainty sample 7 after 3868 steps.
Found uncertainty sample 8 after 1941 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1407 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2559 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 888 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2145 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3489 steps.
Found uncertainty sample 29 after 2262 steps.
Found uncertainty sample 30 after 2412 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1058 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2071 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 175 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2144 steps.
Found uncertainty sample 62 after 2131 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2140 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 477 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1592 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3665 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1731 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_210206-p9gwtdvm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p9gwtdvm
Training model 10. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7692851970374353, Training Loss Force: 2.7928877464415125, time: 0.5676460266113281
Validation Loss Energy: 1.1565150422982513, Validation Loss Force: 2.5095999572609484, time: 0.045603275299072266
Test Loss Energy: 13.494158522841397, Test Loss Force: 9.101366718798557, time: 7.455538272857666


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3599165884900168, Training Loss Force: 2.3671981682662446, time: 0.6045708656311035
Validation Loss Energy: 2.2535095085442753, Validation Loss Force: 2.552287413888473, time: 0.05155682563781738
Test Loss Energy: 15.50545693641681, Test Loss Force: 9.388882468743248, time: 7.438242197036743


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7384253622896102, Training Loss Force: 2.3808899712958405, time: 0.5731258392333984
Validation Loss Energy: 3.783110490220016, Validation Loss Force: 2.5096004025992404, time: 0.05176091194152832
Test Loss Energy: 16.63978717890743, Test Loss Force: 9.349783370868824, time: 7.442978382110596


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0650656109293792, Training Loss Force: 2.3494742694874553, time: 0.5810084342956543
Validation Loss Energy: 2.1333276224052327, Validation Loss Force: 2.5254439803394404, time: 0.046205997467041016
Test Loss Energy: 12.853648281048544, Test Loss Force: 9.102130499616845, time: 7.7731688022613525


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8427828116708054, Training Loss Force: 2.3398341228351014, time: 0.5854616165161133
Validation Loss Energy: 1.1476619397253083, Validation Loss Force: 2.5084191427800935, time: 0.05561065673828125
Test Loss Energy: 13.601101869055238, Test Loss Force: 9.17749878736106, time: 10.904337406158447


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6081017558280815, Training Loss Force: 2.3541240209001253, time: 0.6093904972076416
Validation Loss Energy: 1.6035887061426153, Validation Loss Force: 2.533492579288146, time: 0.0549159049987793
Test Loss Energy: 14.414486504120172, Test Loss Force: 9.204013016818813, time: 10.190671682357788


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2251481865305416, Training Loss Force: 2.398133415716568, time: 0.6099538803100586
Validation Loss Energy: 1.144546130366341, Validation Loss Force: 2.532957282661336, time: 0.05089211463928223
Test Loss Energy: 13.493954058938309, Test Loss Force: 9.122863221462566, time: 8.557027578353882


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4899408105753804, Training Loss Force: 2.3829632180209797, time: 0.6022427082061768
Validation Loss Energy: 1.0752872305515346, Validation Loss Force: 2.480138602563243, time: 0.04925131797790527
Test Loss Energy: 13.535215211266113, Test Loss Force: 9.16064786722856, time: 8.245228290557861


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6283384916196952, Training Loss Force: 2.3385077626653232, time: 0.5817101001739502
Validation Loss Energy: 1.060259957900306, Validation Loss Force: 2.561494337734295, time: 0.04916548728942871
Test Loss Energy: 13.432654254984909, Test Loss Force: 9.163950127605933, time: 8.241353750228882


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5044558285743033, Training Loss Force: 2.358695321405113, time: 0.5529575347900391
Validation Loss Energy: 1.9866189382426664, Validation Loss Force: 2.475891633942962, time: 0.04894208908081055
Test Loss Energy: 12.806428702894529, Test Loss Force: 9.136717812302898, time: 8.483375549316406


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4869145970003228, Training Loss Force: 2.321622464437425, time: 0.5753593444824219
Validation Loss Energy: 2.0336132614907263, Validation Loss Force: 2.5139132812867158, time: 0.050835371017456055
Test Loss Energy: 15.157816590633486, Test Loss Force: 9.26514840000957, time: 8.269307374954224


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.996731119219159, Training Loss Force: 2.3497396625620746, time: 0.589289665222168
Validation Loss Energy: 3.4260072967989315, Validation Loss Force: 2.5998800491316403, time: 0.05061221122741699
Test Loss Energy: 12.220031134560333, Test Loss Force: 9.089720441635219, time: 8.319969415664673


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.98503071059308, Training Loss Force: 2.3221132500729116, time: 0.5706136226654053
Validation Loss Energy: 1.1903235667319052, Validation Loss Force: 2.4472866647804947, time: 0.050371646881103516
Test Loss Energy: 14.285540079437913, Test Loss Force: 9.14906126539633, time: 8.282426357269287


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4626110447737806, Training Loss Force: 2.3329578855039035, time: 0.5521841049194336
Validation Loss Energy: 1.9303315181893106, Validation Loss Force: 2.4891079384303603, time: 0.0488283634185791
Test Loss Energy: 13.006823878765294, Test Loss Force: 9.13584564873509, time: 8.43691897392273


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9429004763664075, Training Loss Force: 2.306612108931822, time: 0.5972552299499512
Validation Loss Energy: 3.629973125145369, Validation Loss Force: 2.510422051747714, time: 0.04961037635803223
Test Loss Energy: 12.202326265429326, Test Loss Force: 9.087382956537446, time: 8.303544998168945


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.4574072458077802, Training Loss Force: 2.359533233965437, time: 0.5749526023864746
Validation Loss Energy: 2.2436722083463314, Validation Loss Force: 2.504612613730458, time: 0.04898786544799805
Test Loss Energy: 15.14024146183709, Test Loss Force: 9.179395891178538, time: 8.28787875175476


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4819115909792022, Training Loss Force: 2.318912415356991, time: 0.5909349918365479
Validation Loss Energy: 1.5459309801652197, Validation Loss Force: 2.459244665924255, time: 0.05053400993347168
Test Loss Energy: 13.018892215385375, Test Loss Force: 9.093825649284422, time: 8.469470500946045


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3169083170083982, Training Loss Force: 2.3127459844588927, time: 0.5730648040771484
Validation Loss Energy: 2.1512001614031266, Validation Loss Force: 2.487778603629171, time: 0.048920631408691406
Test Loss Energy: 14.974292652580433, Test Loss Force: 9.217464005259561, time: 8.699517965316772


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.611887081351033, Training Loss Force: 2.325466655974781, time: 0.5744569301605225
Validation Loss Energy: 1.4099637442676372, Validation Loss Force: 2.572792792867817, time: 0.04927515983581543
Test Loss Energy: 14.099164488747192, Test Loss Force: 9.265461731637908, time: 8.302989482879639


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.356673198659458, Training Loss Force: 2.320686123550403, time: 0.548325777053833
Validation Loss Energy: 4.15718530327457, Validation Loss Force: 2.6485406055986775, time: 0.04862689971923828
Test Loss Energy: 16.759007350010364, Test Loss Force: 9.418989673550005, time: 8.526564121246338

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–ˆâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–†â–â–„â–‚â–â–†â–‚â–…â–„â–ˆ
wandb:   test_error_force â–â–‡â–‡â–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–â–‚â–‚â–â–ƒâ–â–„â–…â–ˆ
wandb:          test_loss â–â–†â–†â–ƒâ–…â–…â–„â–„â–…â–„â–†â–„â–…â–…â–„â–…â–„â–†â–†â–ˆ
wandb: train_error_energy â–ˆâ–â–‚â–ƒâ–ƒâ–‚â–„â–â–‚â–‚â–â–ƒâ–ƒâ–â–ƒâ–„â–â–â–‚â–„
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–‚
wandb: valid_error_energy â–â–„â–‡â–ƒâ–â–‚â–â–â–â–ƒâ–ƒâ–†â–â–ƒâ–‡â–„â–‚â–ƒâ–‚â–ˆ
wandb:  valid_error_force â–ƒâ–…â–ƒâ–„â–ƒâ–„â–„â–‚â–…â–‚â–ƒâ–†â–â–‚â–ƒâ–ƒâ–â–‚â–…â–ˆ
wandb:         valid_loss â–‚â–„â–…â–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–†â–â–ƒâ–…â–ƒâ–‚â–ƒâ–„â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1239
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 16.75901
wandb:   test_error_force 9.41899
wandb:          test_loss 6.50791
wandb: train_error_energy 2.35667
wandb:  train_error_force 2.32069
wandb:         train_loss -1.99745
wandb: valid_error_energy 4.15719
wandb:  valid_error_force 2.64854
wandb:         valid_loss -1.52244
wandb: 
wandb: ğŸš€ View run al_70_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p9gwtdvm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_210206-p9gwtdvm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 16.72580337524414, Uncertainty Bias: -2.4132792949676514
7.6293945e-06 0.5770874
0.5302483 7.1802783
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2016 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1871 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1097 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2022 steps.
Found uncertainty sample 22 after 116 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3464 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2041 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3181 steps.
Found uncertainty sample 38 after 3151 steps.
Found uncertainty sample 39 after 2097 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1641 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 432 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3888 steps.
Found uncertainty sample 56 after 1917 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1965 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3327 steps.
Found uncertainty sample 62 after 3431 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1591 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2680 steps.
Found uncertainty sample 79 after 829 steps.
Found uncertainty sample 80 after 3820 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1055 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2237 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2422 steps.
Found uncertainty sample 91 after 502 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 490 steps.
Found uncertainty sample 98 after 3853 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_213957-fff3z1we
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/fff3z1we
Training model 11. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.849240803042992, Training Loss Force: 2.548381652333955, time: 0.6603219509124756
Validation Loss Energy: 1.5922624730331387, Validation Loss Force: 2.029588516678081, time: 0.050023555755615234
Test Loss Energy: 14.856841253255268, Test Loss Force: 9.140147150311595, time: 7.577808856964111


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.439834167236691, Training Loss Force: 2.3791617131580542, time: 0.6318819522857666
Validation Loss Energy: 0.9807636214323239, Validation Loss Force: 2.3841793341256627, time: 0.051550865173339844
Test Loss Energy: 13.364333891047597, Test Loss Force: 9.168833800578986, time: 7.5203845500946045


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8028723311894126, Training Loss Force: 2.391185151197074, time: 0.6270105838775635
Validation Loss Energy: 2.5430893968084876, Validation Loss Force: 2.1823418888105763, time: 0.04958200454711914
Test Loss Energy: 12.605600751468646, Test Loss Force: 9.124689225039878, time: 7.468874454498291


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.128723553708899, Training Loss Force: 2.4054908700476525, time: 0.6470439434051514
Validation Loss Energy: 1.069517204973108, Validation Loss Force: 2.135704337201579, time: 0.05014944076538086
Test Loss Energy: 13.656879790625924, Test Loss Force: 9.060974950754565, time: 7.618466377258301


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6408999902019836, Training Loss Force: 2.3904261110457066, time: 0.6163983345031738
Validation Loss Energy: 0.7773210099115303, Validation Loss Force: 2.4202970489371607, time: 0.05032014846801758
Test Loss Energy: 13.32619195806438, Test Loss Force: 9.049957090221701, time: 7.4481658935546875


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.360555037562151, Training Loss Force: 2.3866925339750056, time: 0.6232297420501709
Validation Loss Energy: 0.8241089188613149, Validation Loss Force: 2.4561474494389723, time: 0.04984927177429199
Test Loss Energy: 13.393844855498374, Test Loss Force: 9.072557971227548, time: 7.5436365604400635


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8852625593788024, Training Loss Force: 2.38581810110549, time: 0.620499849319458
Validation Loss Energy: 1.2436716427244412, Validation Loss Force: 2.1341263366316756, time: 0.04986715316772461
Test Loss Energy: 14.464804079267289, Test Loss Force: 9.10140312928424, time: 7.553477764129639


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3454828859445604, Training Loss Force: 2.3561089880158392, time: 0.7554779052734375
Validation Loss Energy: 2.2497867030935086, Validation Loss Force: 2.360465738091791, time: 0.0517573356628418
Test Loss Energy: 14.825357584731647, Test Loss Force: 9.127671102987897, time: 7.6136155128479


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0633810993925694, Training Loss Force: 2.449962797210642, time: 0.6047322750091553
Validation Loss Energy: 0.7656615802588163, Validation Loss Force: 2.729313838283983, time: 0.05007052421569824
Test Loss Energy: 13.813720126110244, Test Loss Force: 9.018050229076886, time: 7.8876051902771


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.797130967305113, Training Loss Force: 2.373285446563377, time: 0.6269054412841797
Validation Loss Energy: 1.3254634754177927, Validation Loss Force: 2.5580911738425076, time: 0.0502467155456543
Test Loss Energy: 13.14219006710153, Test Loss Force: 9.02292168439209, time: 7.524643421173096


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8625889507244437, Training Loss Force: 2.348654370147353, time: 0.6037371158599854
Validation Loss Energy: 2.03445595287349, Validation Loss Force: 2.370022029827574, time: 0.06167030334472656
Test Loss Energy: 15.323084438004457, Test Loss Force: 9.14576218534058, time: 10.460684299468994


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.055961798242309, Training Loss Force: 2.341672929780692, time: 0.6502153873443604
Validation Loss Energy: 1.9879483843784285, Validation Loss Force: 2.0563814043309883, time: 0.063507080078125
Test Loss Energy: 12.551051986899624, Test Loss Force: 9.021590192847864, time: 10.354938745498657


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0389096934543613, Training Loss Force: 2.3365904007570464, time: 0.6307127475738525
Validation Loss Energy: 1.0793894642269624, Validation Loss Force: 2.1015003523647575, time: 0.06158018112182617
Test Loss Energy: 13.883065351022344, Test Loss Force: 9.056300931857571, time: 8.291985273361206


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1248256718587823, Training Loss Force: 2.3514018290716696, time: 0.5788378715515137
Validation Loss Energy: 1.7337968829172077, Validation Loss Force: 2.3540172396257226, time: 0.05368447303771973
Test Loss Energy: 13.348012914155952, Test Loss Force: 9.036525407545648, time: 8.317001104354858


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5977573672231749, Training Loss Force: 2.368585457565706, time: 0.6169211864471436
Validation Loss Energy: 2.3271928442886667, Validation Loss Force: 2.5361794165374834, time: 0.057967185974121094
Test Loss Energy: 15.016125829120243, Test Loss Force: 9.129318999227836, time: 8.16231083869934


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7556134018451541, Training Loss Force: 2.3669214482548235, time: 0.5767674446105957
Validation Loss Energy: 1.9886360980356264, Validation Loss Force: 2.2023578410071707, time: 0.05347490310668945
Test Loss Energy: 12.793847835527643, Test Loss Force: 9.0402786347313, time: 8.179510831832886


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.426241344532033, Training Loss Force: 2.375727459086767, time: 0.6148083209991455
Validation Loss Energy: 0.9737983635458431, Validation Loss Force: 2.0235603618922378, time: 0.05711936950683594
Test Loss Energy: 13.518135289323807, Test Loss Force: 9.137276350458992, time: 8.341721057891846


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6868579639277015, Training Loss Force: 2.392294221679111, time: 0.6122972965240479
Validation Loss Energy: 2.3774836729076143, Validation Loss Force: 2.2381485661778737, time: 0.05345940589904785
Test Loss Energy: 15.099161126182242, Test Loss Force: 9.11150292609425, time: 8.07602596282959


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7671854937004245, Training Loss Force: 2.372191011010956, time: 0.6295962333679199
Validation Loss Energy: 3.125260328197294, Validation Loss Force: 2.464748490538725, time: 0.05461311340332031
Test Loss Energy: 15.300124469775303, Test Loss Force: 9.1171578923462, time: 8.21283769607544


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.015334358259925, Training Loss Force: 2.3484596682461536, time: 0.5979065895080566
Validation Loss Energy: 1.0840407443489615, Validation Loss Force: 2.217935885790852, time: 0.0560455322265625
Test Loss Energy: 13.475689089469764, Test Loss Force: 8.962861716232897, time: 8.182421684265137

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–ƒâ–â–„â–ƒâ–ƒâ–†â–‡â–„â–‚â–ˆâ–â–„â–ƒâ–‡â–‚â–ƒâ–‡â–ˆâ–ƒ
wandb:   test_error_force â–‡â–ˆâ–†â–„â–„â–…â–†â–‡â–ƒâ–ƒâ–‡â–ƒâ–„â–„â–‡â–„â–‡â–†â–†â–
wandb:          test_loss â–…â–†â–ƒâ–„â–ƒâ–ƒâ–†â–‡â–‚â–â–ˆâ–„â–†â–…â–‡â–ƒâ–†â–†â–†â–‚
wandb: train_error_energy â–ˆâ–â–ƒâ–…â–‚â–â–„â–â–„â–ƒâ–ƒâ–„â–„â–…â–‚â–ƒâ–â–ƒâ–ƒâ–„
wandb:  train_error_force â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–â–â–â–â–‚â–‚â–‚â–ƒâ–‚â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–ƒâ–‚â–†â–‚â–â–â–‚â–…â–â–ƒâ–…â–…â–‚â–„â–†â–…â–‚â–†â–ˆâ–‚
wandb:  valid_error_force â–â–…â–ƒâ–‚â–…â–…â–‚â–„â–ˆâ–†â–„â–â–‚â–„â–†â–ƒâ–â–ƒâ–…â–ƒ
wandb:         valid_loss â–‚â–…â–„â–‚â–…â–…â–‚â–…â–ˆâ–‡â–…â–‚â–‚â–…â–‡â–„â–â–„â–‡â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1263
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.47569
wandb:   test_error_force 8.96286
wandb:          test_loss 5.69167
wandb: train_error_energy 2.01533
wandb:  train_error_force 2.34846
wandb:         train_loss -1.99056
wandb: valid_error_energy 1.08404
wandb:  valid_error_force 2.21794
wandb:         valid_loss -2.19415
wandb: 
wandb: ğŸš€ View run al_70_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/fff3z1we
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_213957-fff3z1we/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 16.82709312438965, Uncertainty Bias: -2.501108407974243
0.00020980835 0.0036268234
0.30861944 7.042277
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2197 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1361 steps.
Found uncertainty sample 9 after 1507 steps.
Found uncertainty sample 10 after 2607 steps.
Found uncertainty sample 11 after 1979 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1645 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3662 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1106 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1723 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1781 steps.
Found uncertainty sample 39 after 3871 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3467 steps.
Found uncertainty sample 56 after 1390 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3052 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1668 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 501 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2756 steps.
Found uncertainty sample 73 after 2139 steps.
Found uncertainty sample 74 after 798 steps.
Found uncertainty sample 75 after 3534 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1476 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2095 steps.
Found uncertainty sample 81 after 832 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2704 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1121 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3507 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_221755-1f8kis8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1f8kis8m
Training model 12. Added 26 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.321566480733828, Training Loss Force: 2.653899285231209, time: 0.6242616176605225
Validation Loss Energy: 1.1836189987480195, Validation Loss Force: 2.44614793476822, time: 0.0631406307220459
Test Loss Energy: 14.204540001685837, Test Loss Force: 9.04522628253185, time: 8.617890357971191


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0386819946672694, Training Loss Force: 2.476170334249342, time: 0.5989718437194824
Validation Loss Energy: 1.2356576131606407, Validation Loss Force: 2.4721160559046105, time: 0.05328631401062012
Test Loss Energy: 13.892612564618656, Test Loss Force: 8.960390839492835, time: 8.192102193832397


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8078052395812867, Training Loss Force: 2.421268111798029, time: 0.650731086730957
Validation Loss Energy: 3.4352046458714787, Validation Loss Force: 2.2469220645311476, time: 0.05332446098327637
Test Loss Energy: 11.9015397421604, Test Loss Force: 8.81037050321133, time: 8.408683776855469


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9159696922806873, Training Loss Force: 2.4444518856075073, time: 0.6210956573486328
Validation Loss Energy: 0.8853802589070427, Validation Loss Force: 2.553827839040001, time: 0.05369281768798828
Test Loss Energy: 13.539655341290162, Test Loss Force: 8.972638882937563, time: 8.184197664260864


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4512188911181518, Training Loss Force: 2.348183476362012, time: 0.6354677677154541
Validation Loss Energy: 1.1259543143598139, Validation Loss Force: 2.328702541098057, time: 0.055112361907958984
Test Loss Energy: 14.24632089411122, Test Loss Force: 8.90693449674858, time: 8.092510461807251


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8869651962876612, Training Loss Force: 2.439083392239691, time: 0.6061322689056396
Validation Loss Energy: 0.8409912760009112, Validation Loss Force: 2.2637182208776268, time: 0.05277276039123535
Test Loss Energy: 14.371588339527023, Test Loss Force: 9.052802764600834, time: 9.833645343780518


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4782773551752162, Training Loss Force: 2.39856541196285, time: 0.6073100566864014
Validation Loss Energy: 1.600788975636292, Validation Loss Force: 2.8771580237562073, time: 0.06056356430053711
Test Loss Energy: 14.344466766566965, Test Loss Force: 9.02217846374688, time: 9.916020393371582


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.807350573624599, Training Loss Force: 2.3892164795114743, time: 0.6073472499847412
Validation Loss Energy: 2.5364911533417827, Validation Loss Force: 2.5714689134607034, time: 0.06245231628417969
Test Loss Energy: 12.615394239471966, Test Loss Force: 8.98724558253603, time: 9.702404022216797


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7409822845556444, Training Loss Force: 2.390311984554665, time: 0.6712179183959961
Validation Loss Energy: 3.1380052421027633, Validation Loss Force: 2.4410158562928768, time: 0.06197309494018555
Test Loss Energy: 12.281060984233996, Test Loss Force: 8.847157106227833, time: 9.517409324645996


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.566479791847668, Training Loss Force: 2.384980188148288, time: 0.7340269088745117
Validation Loss Energy: 1.3276677329606184, Validation Loss Force: 2.47781594070207, time: 0.0862119197845459
Test Loss Energy: 13.244588948223868, Test Loss Force: 8.916916948084493, time: 10.010697364807129


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7888293002896922, Training Loss Force: 2.3981899972137715, time: 0.6037838459014893
Validation Loss Energy: 0.8160155912479208, Validation Loss Force: 2.5355901226427857, time: 0.05521750450134277
Test Loss Energy: 13.716478616812934, Test Loss Force: 8.96688984072017, time: 10.089990139007568


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9482805888442074, Training Loss Force: 2.3782585642509204, time: 0.7064809799194336
Validation Loss Energy: 2.1537687613359764, Validation Loss Force: 2.300316344371464, time: 0.06173253059387207
Test Loss Energy: 14.572964318192659, Test Loss Force: 8.921852835223554, time: 10.005989789962769


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5277121509315514, Training Loss Force: 2.4311799735741304, time: 0.6309864521026611
Validation Loss Energy: 0.865417441135395, Validation Loss Force: 2.389086294094473, time: 0.06215858459472656
Test Loss Energy: 13.620410846713511, Test Loss Force: 8.912134136073895, time: 10.221366167068481


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8367763487798103, Training Loss Force: 2.4026735816718516, time: 0.6591579914093018
Validation Loss Energy: 3.893028664746663, Validation Loss Force: 2.2598374316678242, time: 0.06383419036865234
Test Loss Energy: 16.668126278778043, Test Loss Force: 9.043503989149414, time: 9.590757608413696


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.838878110073429, Training Loss Force: 2.3673902760370797, time: 0.6368317604064941
Validation Loss Energy: 2.752692985260671, Validation Loss Force: 3.065172836499535, time: 0.06149172782897949
Test Loss Energy: 12.207303562034683, Test Loss Force: 8.799144173062366, time: 9.989047288894653


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.943221712295442, Training Loss Force: 2.3979847831565015, time: 0.6154377460479736
Validation Loss Energy: 1.695628830610007, Validation Loss Force: 2.3756312882826407, time: 0.06644630432128906
Test Loss Energy: 12.776663541212054, Test Loss Force: 8.807804762420261, time: 9.925811290740967


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.494665490677863, Training Loss Force: 2.3720316351624366, time: 0.684262752532959
Validation Loss Energy: 1.9180878325313253, Validation Loss Force: 2.563909518625601, time: 0.06393289566040039
Test Loss Energy: 14.237198267441332, Test Loss Force: 8.950441114692339, time: 9.937252759933472


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.5976354626763665, Training Loss Force: 2.470425285631943, time: 0.6320297718048096
Validation Loss Energy: 3.0899844140919766, Validation Loss Force: 2.3815930319957115, time: 0.06536531448364258
Test Loss Energy: 11.929334909105604, Test Loss Force: 8.881907571278465, time: 10.304683685302734


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.8621624828160126, Training Loss Force: 2.4429854246291103, time: 0.6035444736480713
Validation Loss Energy: 3.7413685981206743, Validation Loss Force: 2.332657813137172, time: 0.05812978744506836
Test Loss Energy: 11.819892580875416, Test Loss Force: 8.863748811495105, time: 9.838469505310059


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.7929172513566454, Training Loss Force: 2.4752962709562993, time: 0.6444926261901855
Validation Loss Energy: 1.871504278190216, Validation Loss Force: 2.5568615948186943, time: 0.06312155723571777
Test Loss Energy: 12.875511495313948, Test Loss Force: 8.835836718766341, time: 9.983492374420166

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–â–ƒâ–…â–…â–…â–‚â–‚â–ƒâ–„â–…â–„â–ˆâ–‚â–‚â–„â–â–â–ƒ
wandb:   test_error_force â–ˆâ–…â–â–†â–„â–ˆâ–‡â–†â–‚â–„â–†â–„â–„â–ˆâ–â–â–…â–ƒâ–ƒâ–‚
wandb:          test_loss â–ƒâ–ƒâ–â–„â–…â–‡â–‡â–…â–‚â–…â–†â–†â–ƒâ–ˆâ–‚â–‚â–†â–‚â–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–„â–„â–â–ƒâ–„â–ƒ
wandb:  train_error_force â–ˆâ–„â–ƒâ–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–„â–ƒâ–„
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–„
wandb: valid_error_energy â–‚â–‚â–‡â–â–‚â–â–ƒâ–…â–†â–‚â–â–„â–â–ˆâ–…â–ƒâ–„â–†â–ˆâ–ƒ
wandb:  valid_error_force â–ƒâ–ƒâ–â–„â–‚â–â–†â–„â–ƒâ–ƒâ–ƒâ–â–‚â–â–ˆâ–‚â–„â–‚â–‚â–„
wandb:         valid_loss â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–†â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–ˆâ–‚â–„â–ƒâ–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1286
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.87551
wandb:   test_error_force 8.83584
wandb:          test_loss 5.3388
wandb: train_error_energy 2.79292
wandb:  train_error_force 2.4753
wandb:         train_loss -1.80707
wandb: valid_error_energy 1.8715
wandb:  valid_error_force 2.55686
wandb:         valid_loss -1.7836
wandb: 
wandb: ğŸš€ View run al_70_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1f8kis8m
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_221755-1f8kis8m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.78241539001465, Uncertainty Bias: -2.717839002609253
0.0005187988 0.0047864914
0.16432627 7.4833364
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2026 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1309 steps.
Found uncertainty sample 12 after 1350 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2578 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 725 steps.
Found uncertainty sample 20 after 647 steps.
Found uncertainty sample 21 after 2992 steps.
Found uncertainty sample 22 after 2751 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2832 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1850 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3684 steps.
Found uncertainty sample 42 after 3136 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3280 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2554 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3052 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1429 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3674 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1601 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2080 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3408 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_225750-v63l1722
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v63l1722
Training model 13. Added 20 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.607456912077643, Training Loss Force: 2.787730035112911, time: 0.6328780651092529
Validation Loss Energy: 0.7935329937536677, Validation Loss Force: 2.405846823377604, time: 0.05443120002746582
Test Loss Energy: 13.280948161713809, Test Loss Force: 8.829594451566843, time: 8.284205913543701


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.500904374655553, Training Loss Force: 2.428455062616316, time: 0.6847555637359619
Validation Loss Energy: 1.7854325775102726, Validation Loss Force: 2.25274864807264, time: 0.053885698318481445
Test Loss Energy: 12.453349918533656, Test Loss Force: 8.829230500596532, time: 8.356096744537354


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.503210924231636, Training Loss Force: 2.3955463713561302, time: 0.6562163829803467
Validation Loss Energy: 2.4451351241579675, Validation Loss Force: 2.3409053669677644, time: 0.055190324783325195
Test Loss Energy: 12.332814623817432, Test Loss Force: 8.798923075424337, time: 8.339444637298584


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.026972714959511, Training Loss Force: 2.387417858623333, time: 0.7662758827209473
Validation Loss Energy: 1.9202689881502608, Validation Loss Force: 2.3125239576278087, time: 0.053946495056152344
Test Loss Energy: 12.843104148540741, Test Loss Force: 8.787150704570823, time: 8.446334838867188


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.642943826675099, Training Loss Force: 2.3936366086939196, time: 0.63942551612854
Validation Loss Energy: 3.9115319141003977, Validation Loss Force: 2.788699699502924, time: 0.05677652359008789
Test Loss Energy: 11.837475641822955, Test Loss Force: 8.725969113451958, time: 8.740113735198975


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.964113754086358, Training Loss Force: 2.4066800621835753, time: 0.6377804279327393
Validation Loss Energy: 1.314230151009455, Validation Loss Force: 2.355783451291222, time: 0.05422472953796387
Test Loss Energy: 13.851614110587539, Test Loss Force: 8.876997886818586, time: 8.316446304321289


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.4146430271950687, Training Loss Force: 2.411388146019344, time: 0.6265413761138916
Validation Loss Energy: 1.884497913531686, Validation Loss Force: 2.4199089366158084, time: 0.056427717208862305
Test Loss Energy: 12.273684144290149, Test Loss Force: 8.773029363088513, time: 8.472869157791138


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7043738381745113, Training Loss Force: 2.3931655494002317, time: 0.6044578552246094
Validation Loss Energy: 1.0916461760299845, Validation Loss Force: 3.002031660134522, time: 0.05885791778564453
Test Loss Energy: 12.850588942217117, Test Loss Force: 8.716239996650533, time: 8.339732646942139


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7486209265251396, Training Loss Force: 2.3787910639360197, time: 0.6426162719726562
Validation Loss Energy: 1.9220695465315196, Validation Loss Force: 2.188813266531389, time: 0.05482029914855957
Test Loss Energy: 12.329311420274252, Test Loss Force: 8.77507181972858, time: 8.303353548049927


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7970760449080225, Training Loss Force: 2.38884007089767, time: 0.5977921485900879
Validation Loss Energy: 1.3110551116576705, Validation Loss Force: 2.354955233402943, time: 0.055475711822509766
Test Loss Energy: 12.667175168266755, Test Loss Force: 8.706913703489581, time: 8.472231149673462


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.125824247868673, Training Loss Force: 2.3599157398703947, time: 0.6405990123748779
Validation Loss Energy: 0.8803457373512587, Validation Loss Force: 2.4648391168811177, time: 0.05385231971740723
Test Loss Energy: 12.47382845247414, Test Loss Force: 8.765817983807198, time: 8.338009357452393


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0247762399748828, Training Loss Force: 2.3538858811224896, time: 0.595609188079834
Validation Loss Energy: 2.3254349827161396, Validation Loss Force: 2.5591176786052348, time: 0.05553579330444336
Test Loss Energy: 14.504451446869341, Test Loss Force: 8.752724581030282, time: 8.323229312896729


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.055217488265927, Training Loss Force: 2.344666914134445, time: 0.5800182819366455
Validation Loss Energy: 2.0840828934338536, Validation Loss Force: 2.3916318477707197, time: 0.054193973541259766
Test Loss Energy: 14.438964646907563, Test Loss Force: 8.881904526190457, time: 8.333365201950073


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0495808686606853, Training Loss Force: 2.355290966880932, time: 0.6078076362609863
Validation Loss Energy: 1.5497794266815763, Validation Loss Force: 2.5016810630897455, time: 0.08084917068481445
Test Loss Energy: 14.236392074562685, Test Loss Force: 8.786626944770546, time: 8.482964754104614


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9528717075646453, Training Loss Force: 2.349198527241111, time: 0.5816013813018799
Validation Loss Energy: 2.031482317764197, Validation Loss Force: 2.139824829746973, time: 0.05461692810058594
Test Loss Energy: 13.951664538699404, Test Loss Force: 8.705533849605828, time: 8.326661348342896


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5099805469073386, Training Loss Force: 2.392496056596317, time: 0.6236259937286377
Validation Loss Energy: 2.4560180786651884, Validation Loss Force: 2.6669882990005034, time: 0.05549430847167969
Test Loss Energy: 15.017023281374511, Test Loss Force: 8.841038344626865, time: 8.308768272399902


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5254937080742783, Training Loss Force: 2.3609598056253986, time: 0.6154451370239258
Validation Loss Energy: 1.3604966244867631, Validation Loss Force: 2.1793125864148015, time: 0.05623054504394531
Test Loss Energy: 12.327610862198398, Test Loss Force: 8.653250765746957, time: 8.923346042633057


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8250707689099948, Training Loss Force: 2.3921464171586178, time: 0.6145668029785156
Validation Loss Energy: 3.2167086537420966, Validation Loss Force: 2.454640647328479, time: 0.0582432746887207
Test Loss Energy: 11.721566605220632, Test Loss Force: 8.660117602413678, time: 8.32641053199768


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5021773565122194, Training Loss Force: 2.3649105183779775, time: 0.6106655597686768
Validation Loss Energy: 0.8568034295578921, Validation Loss Force: 2.9329756119116555, time: 0.055393218994140625
Test Loss Energy: 13.212268985683652, Test Loss Force: 8.792082828484737, time: 8.310922622680664


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9437210456948533, Training Loss Force: 2.3741592116970027, time: 0.5905930995941162
Validation Loss Energy: 2.270380815727505, Validation Loss Force: 2.2652927144084822, time: 0.05671811103820801
Test Loss Energy: 12.276029836669528, Test Loss Force: 8.694099884558614, time: 8.545416831970215

wandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–‚â–ƒâ–â–†â–‚â–ƒâ–‚â–ƒâ–ƒâ–‡â–‡â–†â–†â–ˆâ–‚â–â–„â–‚
wandb:   test_error_force â–†â–†â–…â–…â–ƒâ–ˆâ–…â–ƒâ–…â–ƒâ–„â–„â–ˆâ–…â–ƒâ–‡â–â–â–…â–‚
wandb:          test_loss â–â–ƒâ–„â–…â–„â–‡â–„â–„â–„â–ƒâ–„â–†â–ˆâ–‡â–…â–‡â–ƒâ–‚â–†â–„
wandb: train_error_energy â–ˆâ–â–â–ƒâ–â–ƒâ–„â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–â–‚
wandb: valid_error_energy â–â–ƒâ–…â–„â–ˆâ–‚â–ƒâ–‚â–„â–‚â–â–„â–„â–ƒâ–„â–…â–‚â–†â–â–„
wandb:  valid_error_force â–ƒâ–‚â–ƒâ–‚â–†â–ƒâ–ƒâ–ˆâ–â–ƒâ–„â–„â–ƒâ–„â–â–…â–â–„â–‡â–‚
wandb:         valid_loss â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ˆâ–â–ƒâ–ƒâ–…â–ƒâ–„â–â–†â–â–„â–‡â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1304
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.27603
wandb:   test_error_force 8.6941
wandb:          test_loss 5.31686
wandb: train_error_energy 1.94372
wandb:  train_error_force 2.37416
wandb:         train_loss -1.96868
wandb: valid_error_energy 2.27038
wandb:  valid_error_force 2.26529
wandb:         valid_loss -2.06358
wandb: 
wandb: ğŸš€ View run al_70_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v63l1722
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_225750-v63l1722/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.65665626525879, Uncertainty Bias: -2.626037359237671
0.00011634827 0.022372723
0.49013576 6.3696594
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2837 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1783 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1108 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2602 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3878 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2534 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1466 steps.
Found uncertainty sample 57 after 3472 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3356 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3996 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3554 steps.
Found uncertainty sample 71 after 1637 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2747 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1810 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2868 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_233834-jeivxadn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jeivxadn
Training model 14. Added 15 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.6201796099190666, Training Loss Force: 2.7439677424923072, time: 0.6172769069671631
Validation Loss Energy: 4.006663187318845, Validation Loss Force: 3.0030818791612903, time: 0.06164360046386719
Test Loss Energy: 12.018414454045365, Test Loss Force: 8.7166585027274, time: 8.326350688934326


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2247747776116067, Training Loss Force: 2.412862168567802, time: 0.6593117713928223
Validation Loss Energy: 3.502402520071577, Validation Loss Force: 2.393058377654106, time: 0.05424690246582031
Test Loss Energy: 11.3433690857531, Test Loss Force: 8.642477710704226, time: 8.30690884590149


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1830984151863353, Training Loss Force: 2.395439744645109, time: 0.6342325210571289
Validation Loss Energy: 2.367974253027049, Validation Loss Force: 2.440737297191321, time: 0.056563377380371094
Test Loss Energy: 11.896542584866191, Test Loss Force: 8.662567060946675, time: 8.357073307037354


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.20987826344009, Training Loss Force: 2.3694801671117816, time: 0.803746223449707
Validation Loss Energy: 2.0300553425425187, Validation Loss Force: 3.4156467241080573, time: 0.05864429473876953
Test Loss Energy: 12.100893288087809, Test Loss Force: 8.642019954235709, time: 8.38499641418457


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1181626474430097, Training Loss Force: 2.3906405883528055, time: 0.5987124443054199
Validation Loss Energy: 1.4561944793470238, Validation Loss Force: 2.4868918237555135, time: 0.058592796325683594
Test Loss Energy: 13.029560674219871, Test Loss Force: 8.739590897288284, time: 8.356254577636719


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.3165719355800904, Training Loss Force: 2.4250083569497494, time: 0.6054940223693848
Validation Loss Energy: 1.1932920526171982, Validation Loss Force: 2.7666396445467116, time: 0.06049609184265137
Test Loss Energy: 14.137763506694075, Test Loss Force: 8.85082978547301, time: 8.458345651626587


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.939550866443311, Training Loss Force: 2.451154698229223, time: 0.6062955856323242
Validation Loss Energy: 0.8872268819678651, Validation Loss Force: 2.7056352013060216, time: 0.058576345443725586
Test Loss Energy: 13.035408763403954, Test Loss Force: 8.603118390707285, time: 8.513885736465454


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6475046536310431, Training Loss Force: 2.3713359421395843, time: 0.6225972175598145
Validation Loss Energy: 3.0856066273484632, Validation Loss Force: 2.658382693183259, time: 0.05797719955444336
Test Loss Energy: 11.885666164707464, Test Loss Force: 8.66966228854031, time: 8.412594556808472


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.582246414575009, Training Loss Force: 2.40453618218138, time: 0.6482348442077637
Validation Loss Energy: 3.4082470943851577, Validation Loss Force: 2.7583633663962948, time: 0.05736398696899414
Test Loss Energy: 15.798291802256193, Test Loss Force: 8.80858571790796, time: 8.408360958099365


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4915801362059948, Training Loss Force: 2.3392477648290146, time: 0.6158828735351562
Validation Loss Energy: 1.0399382531327093, Validation Loss Force: 2.617870936780595, time: 0.05894327163696289
Test Loss Energy: 13.082716504550076, Test Loss Force: 8.66473787294259, time: 9.184110164642334


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8417717707908803, Training Loss Force: 2.4106755310465604, time: 0.6325459480285645
Validation Loss Energy: 2.5843597869913277, Validation Loss Force: 2.397567427859144, time: 0.05592226982116699
Test Loss Energy: 11.940691949540646, Test Loss Force: 8.614520412641419, time: 8.4961576461792


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.182995934362745, Training Loss Force: 2.383229963015414, time: 0.6219048500061035
Validation Loss Energy: 1.7923724511141177, Validation Loss Force: 2.58223452132802, time: 0.05582737922668457
Test Loss Energy: 12.451783512206287, Test Loss Force: 8.6231730092262, time: 8.465403079986572


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6911548348905139, Training Loss Force: 2.4204362860747675, time: 0.6185221672058105
Validation Loss Energy: 1.4398262374317317, Validation Loss Force: 2.7055115085954586, time: 0.05571269989013672
Test Loss Energy: 13.477534221609101, Test Loss Force: 8.680999575540753, time: 8.663711309432983


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5843970393381324, Training Loss Force: 2.414349791972691, time: 0.6222474575042725
Validation Loss Energy: 1.6682916282298794, Validation Loss Force: 2.495802597637252, time: 0.06008434295654297
Test Loss Energy: 13.887462448776681, Test Loss Force: 8.708000109749984, time: 8.439945459365845


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6034987743158917, Training Loss Force: 2.370255630968237, time: 0.625908374786377
Validation Loss Energy: 0.9363151858642296, Validation Loss Force: 2.4207646541436088, time: 0.06711792945861816
Test Loss Energy: 12.806085918316962, Test Loss Force: 8.710757364659461, time: 8.45611047744751


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8077212898219441, Training Loss Force: 2.382440675116149, time: 0.6569046974182129
Validation Loss Energy: 1.0933726412529354, Validation Loss Force: 2.7824304496993273, time: 0.05528569221496582
Test Loss Energy: 13.478331857464022, Test Loss Force: 8.767329023626303, time: 8.44914197921753


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7023430104786919, Training Loss Force: 2.408374102278945, time: 0.6000797748565674
Validation Loss Energy: 2.363620180547577, Validation Loss Force: 2.6117625654349306, time: 0.05530142784118652
Test Loss Energy: 12.097492535667898, Test Loss Force: 8.636635156772, time: 8.620949029922485


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.812921049114357, Training Loss Force: 2.382607851929924, time: 0.6292111873626709
Validation Loss Energy: 2.7274644596924795, Validation Loss Force: 3.0884818426952556, time: 0.05533909797668457
Test Loss Energy: 14.534506847874168, Test Loss Force: 8.713271511493868, time: 8.427003860473633


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4689061307234084, Training Loss Force: 2.390586887977112, time: 0.6303720474243164
Validation Loss Energy: 1.5294991105414786, Validation Loss Force: 2.7181952998203704, time: 0.05604147911071777
Test Loss Energy: 12.939907006615412, Test Loss Force: 8.695558141297875, time: 8.451205730438232


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5526697146088897, Training Loss Force: 2.3825972857487847, time: 0.6440773010253906
Validation Loss Energy: 2.442142562171271, Validation Loss Force: 2.385691702964804, time: 0.05594921112060547
Test Loss Energy: 11.90145607452027, Test Loss Force: 8.623298930376931, time: 8.66495418548584

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–‚â–„â–…â–„â–‚â–ˆâ–„â–‚â–ƒâ–„â–…â–ƒâ–„â–‚â–†â–„â–‚
wandb:   test_error_force â–„â–‚â–ƒâ–‚â–…â–ˆâ–â–ƒâ–‡â–ƒâ–â–‚â–ƒâ–„â–„â–†â–‚â–„â–„â–‚
wandb:          test_loss â–â–â–ƒâ–„â–†â–†â–‚â–„â–ˆâ–„â–ƒâ–„â–…â–…â–…â–‡â–„â–‡â–…â–„
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–â–â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–ˆâ–‡â–„â–„â–‚â–‚â–â–†â–‡â–â–…â–ƒâ–‚â–ƒâ–â–â–„â–…â–‚â–„
wandb:  valid_error_force â–…â–â–â–ˆâ–‚â–„â–ƒâ–ƒâ–„â–ƒâ–â–‚â–ƒâ–‚â–â–„â–ƒâ–†â–ƒâ–
wandb:         valid_loss â–†â–‚â–‚â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–†â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1317
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.90146
wandb:   test_error_force 8.6233
wandb:          test_loss 5.24485
wandb: train_error_energy 1.55267
wandb:  train_error_force 2.3826
wandb:         train_loss -1.98598
wandb: valid_error_energy 2.44214
wandb:  valid_error_force 2.38569
wandb:         valid_loss -1.92322
wandb: 
wandb: ğŸš€ View run al_70_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jeivxadn
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_233834-jeivxadn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.167146682739258, Uncertainty Bias: -2.707638740539551
0.00012302399 0.055178165
0.48192728 6.01657
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3742 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2603 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3420 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2574 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2782 steps.
Found uncertainty sample 39 after 3356 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1916 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2909 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3328 steps.
Found uncertainty sample 95 after 2154 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2671 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_002005-twejv5vu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/twejv5vu
Training model 15. Added 11 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.102429783325443, Training Loss Force: 2.7895756322081864, time: 0.6296865940093994
Validation Loss Energy: 1.4686990219094638, Validation Loss Force: 2.5429388724658404, time: 0.06219363212585449
Test Loss Energy: 13.896513518210039, Test Loss Force: 8.608248706482375, time: 8.53815245628357


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5150510931176189, Training Loss Force: 2.3910523089052718, time: 0.6526803970336914
Validation Loss Energy: 1.7460407912443392, Validation Loss Force: 2.4181543037458972, time: 0.056238651275634766
Test Loss Energy: 14.026255461641624, Test Loss Force: 8.735067379417798, time: 8.494718313217163


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8784777960416814, Training Loss Force: 2.4356417046460312, time: 0.6241836547851562
Validation Loss Energy: 0.9730851821050798, Validation Loss Force: 2.5871372505830577, time: 0.05817008018493652
Test Loss Energy: 12.846451161919028, Test Loss Force: 8.755470527611404, time: 8.64274525642395


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.4839242961427948, Training Loss Force: 2.4936211398244756, time: 0.6323604583740234
Validation Loss Energy: 1.6585170093965145, Validation Loss Force: 2.736161805197846, time: 0.0587773323059082
Test Loss Energy: 12.18220064459804, Test Loss Force: 8.691402407571264, time: 8.982427835464478


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.713994272945232, Training Loss Force: 2.352981981844902, time: 0.6231615543365479
Validation Loss Energy: 2.2178834472069857, Validation Loss Force: 2.3594121790278337, time: 0.05569148063659668
Test Loss Energy: 12.186312250196314, Test Loss Force: 8.731987466423606, time: 8.589788913726807


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7170229696279133, Training Loss Force: 2.394108761031911, time: 0.6262218952178955
Validation Loss Energy: 2.777721108597527, Validation Loss Force: 2.2736410260276063, time: 0.056412458419799805
Test Loss Energy: 14.457824028746645, Test Loss Force: 8.627059334270761, time: 8.541326761245728


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3643879414407685, Training Loss Force: 2.3442115451923846, time: 0.5980427265167236
Validation Loss Energy: 0.9301210312300969, Validation Loss Force: 2.633972922064644, time: 0.05538344383239746
Test Loss Energy: 13.018894253216093, Test Loss Force: 8.604605671378781, time: 8.699007511138916


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3901869175271837, Training Loss Force: 2.3823187637587537, time: 0.6239993572235107
Validation Loss Energy: 1.5271728303066845, Validation Loss Force: 2.902459584804263, time: 0.05550122261047363
Test Loss Energy: 13.895928073227305, Test Loss Force: 8.651173703290514, time: 8.52330207824707


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6920952316389342, Training Loss Force: 2.37616243106955, time: 0.5981247425079346
Validation Loss Energy: 1.3450033609803942, Validation Loss Force: 2.6540407561722397, time: 0.06277632713317871
Test Loss Energy: 13.447439691456553, Test Loss Force: 8.625096768055995, time: 8.536956787109375


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7977030788954036, Training Loss Force: 2.3766368674472975, time: 0.6324045658111572
Validation Loss Energy: 1.1781254169142619, Validation Loss Force: 2.495969599496698, time: 0.056841373443603516
Test Loss Energy: 12.577312769905417, Test Loss Force: 8.636005177960081, time: 8.693156957626343


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5320017593193749, Training Loss Force: 2.330633050783373, time: 0.6089456081390381
Validation Loss Energy: 1.271647989054311, Validation Loss Force: 2.419685822131589, time: 0.05531620979309082
Test Loss Energy: 12.240222357685758, Test Loss Force: 8.583335521810966, time: 8.547086238861084


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4107624213825558, Training Loss Force: 2.3524205268950915, time: 0.6175932884216309
Validation Loss Energy: 1.4212114865031742, Validation Loss Force: 2.428838303371232, time: 0.0560307502746582
Test Loss Energy: 13.423157730678989, Test Loss Force: 8.568995554201566, time: 8.540008306503296


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1829014404693536, Training Loss Force: 2.350557220878675, time: 0.6206586360931396
Validation Loss Energy: 1.8611951977393377, Validation Loss Force: 2.702364525556061, time: 0.0587465763092041
Test Loss Energy: 12.200178023457836, Test Loss Force: 8.581451843427438, time: 8.769561767578125


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5510183829923385, Training Loss Force: 2.361108101466268, time: 0.6272091865539551
Validation Loss Energy: 1.283211893643422, Validation Loss Force: 2.694527796299706, time: 0.05845499038696289
Test Loss Energy: 13.355269960430904, Test Loss Force: 8.696855530654368, time: 8.522183418273926


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.735957987709717, Training Loss Force: 2.3492162569162574, time: 0.6178245544433594
Validation Loss Energy: 2.7424042233693586, Validation Loss Force: 3.722061847153859, time: 0.05606532096862793
Test Loss Energy: 12.437880358507616, Test Loss Force: 8.571519405213829, time: 8.51918077468872


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1050979779931653, Training Loss Force: 2.3695030304615874, time: 0.6121933460235596
Validation Loss Energy: 2.3021460167435523, Validation Loss Force: 2.72441656442302, time: 0.05611610412597656
Test Loss Energy: 14.2124534299707, Test Loss Force: 8.743042040551986, time: 8.974284887313843


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8293092769109078, Training Loss Force: 2.3600464308834237, time: 0.8296070098876953
Validation Loss Energy: 3.5616482110631567, Validation Loss Force: 2.5767958274387333, time: 0.05781102180480957
Test Loss Energy: 11.367581662358472, Test Loss Force: 8.629816071561914, time: 8.515738487243652


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1652593706645527, Training Loss Force: 2.3493714281519145, time: 0.6131753921508789
Validation Loss Energy: 2.1829425388317163, Validation Loss Force: 2.4466417035993153, time: 0.056740522384643555
Test Loss Energy: 11.972696384072046, Test Loss Force: 8.560385910611616, time: 8.548818826675415


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.911621134838812, Training Loss Force: 2.3986173181838395, time: 0.6223037242889404
Validation Loss Energy: 1.3038145790395368, Validation Loss Force: 2.65151836008717, time: 0.056230783462524414
Test Loss Energy: 12.98702270203511, Test Loss Force: 8.641758249206626, time: 8.50093388557434


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5692584798287568, Training Loss Force: 2.345234235420576, time: 0.6160805225372314
Validation Loss Energy: 0.9284498157889791, Validation Loss Force: 2.315021414768535, time: 0.05659031867980957
Test Loss Energy: 13.192664247440849, Test Loss Force: 8.636559556516632, time: 8.663217544555664

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–‡â–„â–ƒâ–ƒâ–ˆâ–…â–‡â–†â–„â–ƒâ–†â–ƒâ–†â–ƒâ–‡â–â–‚â–…â–…
wandb:   test_error_force â–ƒâ–‡â–ˆâ–†â–‡â–ƒâ–ƒâ–„â–ƒâ–„â–‚â–â–‚â–†â–â–ˆâ–ƒâ–â–„â–„
wandb:          test_loss â–â–…â–…â–ƒâ–…â–†â–„â–†â–…â–…â–…â–…â–„â–†â–…â–ˆâ–…â–„â–†â–‡
wandb: train_error_energy â–ˆâ–â–‚â–„â–‚â–‚â–â–â–‚â–‚â–â–â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–ƒâ–ƒâ–â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–„â–â–‚â–â–â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–ƒâ–â–ƒâ–„â–†â–â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–†â–…â–ˆâ–„â–‚â–
wandb:  valid_error_force â–‚â–‚â–ƒâ–ƒâ–â–â–ƒâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–‚â–ƒâ–
wandb:         valid_loss â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–„â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–‚â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1326
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.19266
wandb:   test_error_force 8.63656
wandb:          test_loss 5.42259
wandb: train_error_energy 1.56926
wandb:  train_error_force 2.34523
wandb:         train_loss -2.0245
wandb: valid_error_energy 0.92845
wandb:  valid_error_force 2.31502
wandb:         valid_loss -2.09926
wandb: 
wandb: ğŸš€ View run al_70_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/twejv5vu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_002005-twejv5vu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 19.263296127319336, Uncertainty Bias: -2.831190347671509
8.201599e-05 0.0034675598
0.5370566 6.197812
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1944 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3978 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1624 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3375 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2633 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2088 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 938 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_010142-8w161era
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8w161era
Training model 16. Added 7 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.827923150545359, Training Loss Force: 2.7338081181023406, time: 0.6390788555145264
Validation Loss Energy: 3.953288279694225, Validation Loss Force: 2.2819665140592735, time: 0.0626688003540039
Test Loss Energy: 11.556088143148594, Test Loss Force: 8.498202728026614, time: 10.136944770812988


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.657020418256856, Training Loss Force: 2.3438672748353717, time: 0.6771845817565918
Validation Loss Energy: 1.1548574931759648, Validation Loss Force: 2.629442495621597, time: 0.06523442268371582
Test Loss Energy: 12.866991292440625, Test Loss Force: 8.606627567845772, time: 10.08025598526001


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7115582128452609, Training Loss Force: 2.395404865113893, time: 0.6658854484558105
Validation Loss Energy: 1.495471368333659, Validation Loss Force: 2.8143062059463277, time: 0.06659054756164551
Test Loss Energy: 12.347159366572495, Test Loss Force: 8.581709141705883, time: 10.337576866149902


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6517454259521738, Training Loss Force: 2.3554319415361427, time: 0.6210927963256836
Validation Loss Energy: 0.7769207621217251, Validation Loss Force: 2.375777804580661, time: 0.05965280532836914
Test Loss Energy: 12.582906176882068, Test Loss Force: 8.604698082571762, time: 9.752830028533936


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6257003381651645, Training Loss Force: 2.3686011355942385, time: 0.6219003200531006
Validation Loss Energy: 1.756764036306643, Validation Loss Force: 2.374352054039286, time: 0.0629427433013916
Test Loss Energy: 13.961163357313593, Test Loss Force: 8.652817169463678, time: 9.600064277648926


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0704798828867927, Training Loss Force: 2.3718380372062433, time: 0.6233816146850586
Validation Loss Energy: 2.764656107794787, Validation Loss Force: 2.886551321677171, time: 0.06349658966064453
Test Loss Energy: 14.402846494335515, Test Loss Force: 8.692857134246786, time: 9.865174055099487


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.050913975518585, Training Loss Force: 2.341516752822726, time: 0.7218739986419678
Validation Loss Energy: 2.6646157592506423, Validation Loss Force: 2.896681543136583, time: 0.06306982040405273
Test Loss Energy: 14.407748325919128, Test Loss Force: 8.57560433248365, time: 9.99751877784729


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9558663198660793, Training Loss Force: 2.3399044797601114, time: 0.645435094833374
Validation Loss Energy: 1.811318533731816, Validation Loss Force: 2.833754351820806, time: 0.0626683235168457
Test Loss Energy: 12.57015861776041, Test Loss Force: 8.503687141370852, time: 10.213322639465332


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.099175432002248, Training Loss Force: 2.3480434876837104, time: 0.6407802104949951
Validation Loss Energy: 1.4468055791416923, Validation Loss Force: 2.451994447198273, time: 0.06117105484008789
Test Loss Energy: 12.753959295090219, Test Loss Force: 8.593679098200907, time: 9.959817171096802


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.161301571065549, Training Loss Force: 2.370690726479381, time: 0.7035610675811768
Validation Loss Energy: 1.7360221826943236, Validation Loss Force: 2.5946950867341387, time: 0.06381082534790039
Test Loss Energy: 12.049251897070068, Test Loss Force: 8.561300257741605, time: 9.826651096343994


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.503769882914202, Training Loss Force: 2.3441988397969507, time: 0.646958589553833
Validation Loss Energy: 1.2316993350880554, Validation Loss Force: 2.6812625046002037, time: 0.06370687484741211
Test Loss Energy: 12.743100791054188, Test Loss Force: 8.7117276052425, time: 10.284358501434326


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7402721878325407, Training Loss Force: 2.3902143147811583, time: 0.7189764976501465
Validation Loss Energy: 1.2214296670760063, Validation Loss Force: 2.6089023802554885, time: 0.06565284729003906
Test Loss Energy: 12.698129560391148, Test Loss Force: 8.622929826539476, time: 10.004566669464111


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0806646225008443, Training Loss Force: 2.365056794162286, time: 0.657526969909668
Validation Loss Energy: 2.7064739959787314, Validation Loss Force: 2.951614800778979, time: 0.06552982330322266
Test Loss Energy: 12.04145603809425, Test Loss Force: 8.635523452498681, time: 9.746766567230225


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.245548918250086, Training Loss Force: 2.3910802644863787, time: 0.6402788162231445
Validation Loss Energy: 1.1143984536935994, Validation Loss Force: 2.70798024141636, time: 0.06765341758728027
Test Loss Energy: 12.781666951895266, Test Loss Force: 8.640473431913325, time: 10.185165643692017


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.970141552659757, Training Loss Force: 2.374174374664128, time: 0.621901273727417
Validation Loss Energy: 1.2375583726575667, Validation Loss Force: 2.4180217042694974, time: 0.05786871910095215
Test Loss Energy: 13.600989284737123, Test Loss Force: 8.540566934339447, time: 9.839476108551025


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.066490618016811, Training Loss Force: 2.31187238264283, time: 0.6835348606109619
Validation Loss Energy: 2.684881880232687, Validation Loss Force: 2.64727818287584, time: 0.06293296813964844
Test Loss Energy: 14.52554143261615, Test Loss Force: 8.600722209556324, time: 9.753637790679932


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.010509297792292, Training Loss Force: 2.3294319813627076, time: 0.6532406806945801
Validation Loss Energy: 2.6411130865652512, Validation Loss Force: 3.750633304609864, time: 0.06153273582458496
Test Loss Energy: 12.905572147113716, Test Loss Force: 8.494023090592318, time: 9.962585210800171


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5373183735239944, Training Loss Force: 2.355994743104122, time: 0.6635532379150391
Validation Loss Energy: 1.1781877086078354, Validation Loss Force: 2.5672834015246986, time: 0.06325387954711914
Test Loss Energy: 12.59116192808491, Test Loss Force: 8.53858846651656, time: 9.476495027542114


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8542723172373967, Training Loss Force: 2.3617737390681417, time: 0.6289405822753906
Validation Loss Energy: 1.0467157174282429, Validation Loss Force: 2.448612214206203, time: 0.053267717361450195
Test Loss Energy: 12.939638917626944, Test Loss Force: 8.593748389108537, time: 8.860118389129639


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2624235601688576, Training Loss Force: 2.365881780697126, time: 0.6348109245300293
Validation Loss Energy: 1.3913701469079427, Validation Loss Force: 2.5404253831466077, time: 0.06919980049133301
Test Loss Energy: 13.066122220517615, Test Loss Force: 8.589712770813565, time: 10.72836685180664

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–ƒâ–ƒâ–‡â–ˆâ–ˆâ–ƒâ–„â–‚â–„â–„â–‚â–„â–†â–ˆâ–„â–ƒâ–„â–…
wandb:   test_error_force â–â–…â–„â–…â–†â–‡â–„â–â–„â–ƒâ–ˆâ–…â–†â–†â–‚â–„â–â–‚â–„â–„
wandb:          test_loss â–â–…â–„â–†â–‡â–‡â–‡â–…â–†â–…â–‡â–…â–…â–†â–†â–ˆâ–†â–…â–†â–†
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–„â–„â–ƒâ–„â–„â–â–‚â–„â–…â–ƒâ–„â–„â–â–ƒâ–…
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–â–‚â–â–â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚
wandb: valid_error_energy â–ˆâ–‚â–ƒâ–â–ƒâ–…â–…â–ƒâ–‚â–ƒâ–‚â–‚â–…â–‚â–‚â–…â–…â–‚â–‚â–‚
wandb:  valid_error_force â–â–ƒâ–„â–â–â–„â–„â–„â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ˆâ–‚â–‚â–‚
wandb:         valid_loss â–‚â–‚â–ƒâ–â–â–„â–„â–ƒâ–‚â–‚â–ƒâ–‚â–„â–ƒâ–â–ƒâ–ˆâ–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1332
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.06612
wandb:   test_error_force 8.58971
wandb:          test_loss 5.34874
wandb: train_error_energy 2.26242
wandb:  train_error_force 2.36588
wandb:         train_loss -1.95607
wandb: valid_error_energy 1.39137
wandb:  valid_error_force 2.54043
wandb:         valid_loss -1.82817
wandb: 
wandb: ğŸš€ View run al_70_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8w161era
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_010142-8w161era/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.859071731567383, Uncertainty Bias: -2.7851200103759766
0.00016021729 0.0063877106
0.6600662 6.0781016
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2942 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2643 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1418 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2933 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_014415-50j3mpah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/50j3mpah
Training model 17. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.027704025621769, Training Loss Force: 2.7172738206714726, time: 0.685354471206665
Validation Loss Energy: 1.42745084297393, Validation Loss Force: 2.393301643696032, time: 0.056029558181762695
Test Loss Energy: 13.369764551360523, Test Loss Force: 8.513075422824093, time: 8.441190719604492


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7926901138336038, Training Loss Force: 2.358876378744622, time: 0.633263349533081
Validation Loss Energy: 2.3127446227514232, Validation Loss Force: 2.4045402008292998, time: 0.05993294715881348
Test Loss Energy: 14.123524110926981, Test Loss Force: 8.650730920447705, time: 8.424623012542725


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0362758357556268, Training Loss Force: 2.3270068572337075, time: 0.6419692039489746
Validation Loss Energy: 2.4420511564868677, Validation Loss Force: 2.5742421463386607, time: 0.05492758750915527
Test Loss Energy: 14.043810193477924, Test Loss Force: 8.608633091718596, time: 8.596591234207153


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.150671261212615, Training Loss Force: 2.3164098231639736, time: 0.6234381198883057
Validation Loss Energy: 1.888046090704759, Validation Loss Force: 2.366793549880767, time: 0.05574393272399902
Test Loss Energy: 13.506787892444658, Test Loss Force: 8.52273674095091, time: 8.451346397399902


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.015633327043093, Training Loss Force: 2.3261132276329892, time: 0.6244165897369385
Validation Loss Energy: 2.8313304868328095, Validation Loss Force: 3.549006949645117, time: 0.05586433410644531
Test Loss Energy: 11.68244515649351, Test Loss Force: 8.587329292296186, time: 8.415260553359985


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5707923945585902, Training Loss Force: 2.334557321445564, time: 0.5945305824279785
Validation Loss Energy: 1.7202003151958518, Validation Loss Force: 2.6189114696995155, time: 0.054998159408569336
Test Loss Energy: 14.080753919304964, Test Loss Force: 8.605977373939663, time: 8.902247190475464


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6981941024343719, Training Loss Force: 2.33785479701773, time: 0.6316602230072021
Validation Loss Energy: 1.2985201190895252, Validation Loss Force: 2.621601646986042, time: 0.0556025505065918
Test Loss Energy: 12.5537668390752, Test Loss Force: 8.408770904176693, time: 8.615535736083984


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4773945701567237, Training Loss Force: 2.368582860819333, time: 0.6004536151885986
Validation Loss Energy: 1.960274506249658, Validation Loss Force: 2.4223855741913902, time: 0.056218624114990234
Test Loss Energy: 14.09004805484434, Test Loss Force: 8.526938449444215, time: 8.383184909820557


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8072654476432939, Training Loss Force: 2.39864953098695, time: 0.6640243530273438
Validation Loss Energy: 1.4809616901121394, Validation Loss Force: 2.4562798262462264, time: 0.05479931831359863
Test Loss Energy: 13.313768283456445, Test Loss Force: 8.437587513950426, time: 8.37123727798462


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4201124247341643, Training Loss Force: 2.3443274948484802, time: 0.6549243927001953
Validation Loss Energy: 1.041718854791764, Validation Loss Force: 2.799657582177749, time: 0.057882070541381836
Test Loss Energy: 12.423076068604413, Test Loss Force: 8.44921737188732, time: 8.651503086090088


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.951141174556565, Training Loss Force: 2.3476956572711862, time: 0.6621544361114502
Validation Loss Energy: 2.6772202802596037, Validation Loss Force: 2.6859695076759715, time: 0.05696845054626465
Test Loss Energy: 14.397036741550355, Test Loss Force: 8.551084523752408, time: 8.470878601074219


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.936967305264513, Training Loss Force: 2.305917300448375, time: 0.6062195301055908
Validation Loss Energy: 1.1783206420879542, Validation Loss Force: 2.300853422351442, time: 0.05600905418395996
Test Loss Energy: 12.251590883651827, Test Loss Force: 8.453000550987614, time: 8.425721883773804


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9245544785327875, Training Loss Force: 2.345620926900711, time: 0.606170654296875
Validation Loss Energy: 1.8391084781529012, Validation Loss Force: 2.5129850849519153, time: 0.056905269622802734
Test Loss Energy: 13.423963932884096, Test Loss Force: 8.65803726170782, time: 8.588705778121948


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5702482985242807, Training Loss Force: 2.3588547745358204, time: 0.6077885627746582
Validation Loss Energy: 4.59450015779493, Validation Loss Force: 2.488332381795094, time: 0.05543804168701172
Test Loss Energy: 16.311554009041537, Test Loss Force: 8.661707767888663, time: 8.563674449920654


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9003478201121944, Training Loss Force: 2.3226740072445002, time: 0.6078052520751953
Validation Loss Energy: 1.6694977156587973, Validation Loss Force: 2.3271763667718677, time: 0.05555462837219238
Test Loss Energy: 11.918367220244805, Test Loss Force: 8.451989861563286, time: 8.520915031433105


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.582094062489789, Training Loss Force: 2.3340287022423083, time: 0.6058158874511719
Validation Loss Energy: 1.0196285168317059, Validation Loss Force: 2.3678345281379793, time: 0.055565595626831055
Test Loss Energy: 12.607605081555057, Test Loss Force: 8.406448593223441, time: 8.470386266708374


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3776243762792877, Training Loss Force: 2.344733664577238, time: 0.628371000289917
Validation Loss Energy: 1.7424086678032515, Validation Loss Force: 2.606668674718114, time: 0.05873584747314453
Test Loss Energy: 12.57161888901425, Test Loss Force: 8.37812018147183, time: 8.700751781463623


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4950657592540009, Training Loss Force: 2.3290629046025098, time: 0.6553153991699219
Validation Loss Energy: 1.665916806121273, Validation Loss Force: 2.6863739861795493, time: 0.05579733848571777
Test Loss Energy: 11.956906297056566, Test Loss Force: 8.413210110881561, time: 8.446019172668457


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.971945950758371, Training Loss Force: 2.295274208326136, time: 0.6140878200531006
Validation Loss Energy: 2.8654936118813534, Validation Loss Force: 2.3641044859399702, time: 0.05561327934265137
Test Loss Energy: 14.728838418806957, Test Loss Force: 8.502120408617506, time: 9.003847122192383


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0483193869154173, Training Loss Force: 2.299245014189003, time: 0.6148147583007812
Validation Loss Energy: 3.0899397689282178, Validation Loss Force: 2.5264641390315083, time: 0.058103084564208984
Test Loss Energy: 14.747636824274267, Test Loss Force: 8.518333343175291, time: 8.695411682128906

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–…â–…â–„â–â–…â–‚â–…â–ƒâ–‚â–…â–‚â–„â–ˆâ–â–‚â–‚â–â–†â–†
wandb:   test_error_force â–„â–ˆâ–‡â–…â–†â–‡â–‚â–…â–‚â–ƒâ–…â–ƒâ–ˆâ–ˆâ–ƒâ–‚â–â–‚â–„â–„
wandb:          test_loss â–â–…â–†â–…â–…â–‡â–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–‡â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–†â–‡
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–„â–„â–ƒâ–…â–‚â–‚â–ƒâ–‚â–â–„â–â–ƒâ–ˆâ–‚â–â–‚â–‚â–…â–…
wandb:  valid_error_force â–‚â–‚â–ƒâ–â–ˆâ–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–â–‚â–‚â–â–â–ƒâ–ƒâ–â–‚
wandb:         valid_loss â–‚â–‚â–ƒâ–‚â–ˆâ–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–â–‚â–ƒâ–â–â–ƒâ–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1335
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 14.74764
wandb:   test_error_force 8.51833
wandb:          test_loss 5.49697
wandb: train_error_energy 2.04832
wandb:  train_error_force 2.29925
wandb:         train_loss -2.04183
wandb: valid_error_energy 3.08994
wandb:  valid_error_force 2.52646
wandb:         valid_loss -1.72538
wandb: 
wandb: ğŸš€ View run al_70_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/50j3mpah
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_014415-50j3mpah/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 19.483169555664062, Uncertainty Bias: -2.8276796340942383
5.9127808e-05 0.031746864
0.8105192 6.075857
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1709 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_022656-2ehnlusf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/2ehnlusf
Training model 18. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.49834334239142, Training Loss Force: 2.667036013817487, time: 0.6451504230499268
Validation Loss Energy: 1.6866491962948904, Validation Loss Force: 2.5761239232908966, time: 0.057042598724365234
Test Loss Energy: 11.656810598400947, Test Loss Force: 8.407307648456817, time: 8.493521213531494


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4561343798842088, Training Loss Force: 2.3070608973719824, time: 0.6334309577941895
Validation Loss Energy: 5.265724274060366, Validation Loss Force: 2.4806702251491455, time: 0.060584068298339844
Test Loss Energy: 10.67016381797696, Test Loss Force: 8.36305663939757, time: 9.047855377197266


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.96406576788327, Training Loss Force: 2.3291977413736613, time: 0.630284309387207
Validation Loss Energy: 2.5354573004972396, Validation Loss Force: 2.324128026164116, time: 0.056488752365112305
Test Loss Energy: 14.095915678291297, Test Loss Force: 8.491420174546143, time: 8.71683120727539


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7797633905704846, Training Loss Force: 2.302401582604968, time: 0.6278696060180664
Validation Loss Energy: 1.611745744965388, Validation Loss Force: 2.5024610731079306, time: 0.05816793441772461
Test Loss Energy: 13.289858401655922, Test Loss Force: 8.364060352632533, time: 8.59712553024292


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9250405785324634, Training Loss Force: 2.3180006908295243, time: 0.6259109973907471
Validation Loss Energy: 2.3759774274699854, Validation Loss Force: 2.4007679628281373, time: 0.05628180503845215
Test Loss Energy: 11.620349306845993, Test Loss Force: 8.400471262670155, time: 8.523827314376831


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6885860891623896, Training Loss Force: 2.3033123895398, time: 0.6116228103637695
Validation Loss Energy: 2.609014160166744, Validation Loss Force: 2.587641373529438, time: 0.05875396728515625
Test Loss Energy: 11.734956710554174, Test Loss Force: 8.392553740070944, time: 8.533785820007324


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7736583870956533, Training Loss Force: 2.336726855855741, time: 0.621243953704834
Validation Loss Energy: 1.0884159703972964, Validation Loss Force: 2.3750229561759664, time: 0.056148529052734375
Test Loss Energy: 12.232459663588811, Test Loss Force: 8.408879151692597, time: 8.693078517913818


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9158990624228456, Training Loss Force: 2.305318829403877, time: 0.6207218170166016
Validation Loss Energy: 2.089392105214783, Validation Loss Force: 2.3939556229776224, time: 0.05690646171569824
Test Loss Energy: 11.30298979184451, Test Loss Force: 8.42548456218751, time: 8.576198101043701


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2270739730607043, Training Loss Force: 2.282964024118213, time: 0.6186659336090088
Validation Loss Energy: 3.0969464989431277, Validation Loss Force: 2.4225187303406552, time: 0.057443857192993164
Test Loss Energy: 11.165709525540187, Test Loss Force: 8.340181178189619, time: 8.533746719360352


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8981074967947862, Training Loss Force: 2.33152126210154, time: 0.6245050430297852
Validation Loss Energy: 1.3998705972210226, Validation Loss Force: 2.6062975965864252, time: 0.05607724189758301
Test Loss Energy: 12.605063841364883, Test Loss Force: 8.333795416463964, time: 8.838488578796387


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9236795372353888, Training Loss Force: 2.3126081848830786, time: 0.612128734588623
Validation Loss Energy: 0.9826498239338349, Validation Loss Force: 2.5440668030245375, time: 0.05597066879272461
Test Loss Energy: 12.151092337964098, Test Loss Force: 8.347264962221283, time: 8.543338775634766


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.819335992135382, Training Loss Force: 2.3324335216874665, time: 0.6160173416137695
Validation Loss Energy: 2.3236450567865994, Validation Loss Force: 2.573711080425623, time: 0.05599665641784668
Test Loss Energy: 14.098985187623406, Test Loss Force: 8.417424400764515, time: 8.617602586746216


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4835838751098744, Training Loss Force: 2.292715029418817, time: 0.6260871887207031
Validation Loss Energy: 0.8842564477275452, Validation Loss Force: 2.4892394245610303, time: 0.05606508255004883
Test Loss Energy: 12.815473654172505, Test Loss Force: 8.49791484363449, time: 8.80119800567627


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7688218131089526, Training Loss Force: 2.296771220946678, time: 0.6107156276702881
Validation Loss Energy: 2.1196444920533972, Validation Loss Force: 2.915935744184959, time: 0.06175994873046875
Test Loss Energy: 11.72463176376084, Test Loss Force: 8.34340786162777, time: 8.616454362869263


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9819807266788747, Training Loss Force: 2.2737059499885834, time: 0.6151001453399658
Validation Loss Energy: 0.951840485893969, Validation Loss Force: 2.4084785500133243, time: 0.06675457954406738
Test Loss Energy: 12.694502394253076, Test Loss Force: 8.313669674388743, time: 9.073128938674927


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5807430863682743, Training Loss Force: 2.3143013557670677, time: 0.5962738990783691
Validation Loss Energy: 4.685923433060815, Validation Loss Force: 2.5712897761328044, time: 0.05652499198913574
Test Loss Energy: 11.086625815401236, Test Loss Force: 8.35980082010971, time: 8.761560678482056


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6908833084228168, Training Loss Force: 2.2951937081282363, time: 0.6564223766326904
Validation Loss Energy: 1.8252261702500332, Validation Loss Force: 2.4070692769887474, time: 0.056728363037109375
Test Loss Energy: 13.564816721618591, Test Loss Force: 8.387830957796798, time: 8.624217987060547


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6727665729440657, Training Loss Force: 2.2985283774002427, time: 0.6618623733520508
Validation Loss Energy: 1.040643140147787, Validation Loss Force: 2.5336170513407197, time: 0.05616259574890137
Test Loss Energy: 12.832731744074149, Test Loss Force: 8.355501482271084, time: 8.623737812042236


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0425907990047185, Training Loss Force: 2.3462743972242532, time: 0.6025550365447998
Validation Loss Energy: 1.4245629911531061, Validation Loss Force: 2.5245036485361876, time: 0.056976318359375
Test Loss Energy: 11.6332120197245, Test Loss Force: 8.31593678904156, time: 8.583131790161133


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0774577586915433, Training Loss Force: 2.3405462546518465, time: 0.6258704662322998
Validation Loss Energy: 0.889483856430989, Validation Loss Force: 2.2471372742606865, time: 0.05623674392700195
Test Loss Energy: 12.597214234020983, Test Loss Force: 8.333715887438853, time: 8.83524775505066

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–ˆâ–†â–ƒâ–ƒâ–„â–‚â–‚â–…â–„â–ˆâ–…â–ƒâ–…â–‚â–‡â–…â–ƒâ–…
wandb:   test_error_force â–…â–ƒâ–ˆâ–ƒâ–„â–„â–…â–…â–‚â–‚â–‚â–…â–ˆâ–‚â–â–ƒâ–„â–ƒâ–â–‚
wandb:          test_loss â–â–â–ˆâ–†â–…â–†â–„â–…â–„â–…â–„â–‡â–†â–ƒâ–„â–‚â–†â–…â–‚â–ƒ
wandb: train_error_energy â–ˆâ–â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚
wandb: valid_error_energy â–‚â–ˆâ–„â–‚â–ƒâ–„â–â–ƒâ–…â–‚â–â–ƒâ–â–ƒâ–â–‡â–ƒâ–â–‚â–
wandb:  valid_error_force â–„â–ƒâ–‚â–„â–ƒâ–…â–‚â–ƒâ–ƒâ–…â–„â–„â–„â–ˆâ–ƒâ–„â–ƒâ–„â–„â–
wandb:         valid_loss â–„â–†â–ƒâ–„â–ƒâ–…â–‚â–ƒâ–„â–…â–„â–…â–ƒâ–ˆâ–ƒâ–†â–ƒâ–„â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1336
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.59721
wandb:   test_error_force 8.33372
wandb:          test_loss 5.08812
wandb: train_error_energy 2.07746
wandb:  train_error_force 2.34055
wandb:         train_loss -1.99566
wandb: valid_error_energy 0.88948
wandb:  valid_error_force 2.24714
wandb:         valid_loss -2.177
wandb: 
wandb: ğŸš€ View run al_70_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/2ehnlusf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_022656-2ehnlusf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.805503845214844, Uncertainty Bias: -2.594073534011841
0.00037384033 0.005399704
0.8206979 5.738216
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2074 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2957 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1552 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2967 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3108 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_030908-nbl1tg87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/nbl1tg87
Training model 19. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.553736053630175, Training Loss Force: 2.743294300867034, time: 0.652977466583252
Validation Loss Energy: 1.0368441261818264, Validation Loss Force: 2.7155928541773395, time: 0.05835366249084473
Test Loss Energy: 12.768788799068231, Test Loss Force: 8.484496413852941, time: 8.702666997909546


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9330297685577889, Training Loss Force: 2.335428421700196, time: 0.6143069267272949
Validation Loss Energy: 1.3056584465696783, Validation Loss Force: 2.603464243039067, time: 0.06044602394104004
Test Loss Energy: 12.195832808780308, Test Loss Force: 8.385462051867503, time: 8.577358961105347


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.478630698039168, Training Loss Force: 2.364664011090516, time: 0.6313121318817139
Validation Loss Energy: 1.1411422984671158, Validation Loss Force: 2.658108698799195, time: 0.0586698055267334
Test Loss Energy: 11.978478945573645, Test Loss Force: 8.35048380677285, time: 8.860163450241089


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.466590741395591, Training Loss Force: 2.287972542424152, time: 0.6114027500152588
Validation Loss Energy: 2.158733587449085, Validation Loss Force: 3.4650332933253924, time: 0.05693769454956055
Test Loss Energy: 12.085968817467771, Test Loss Force: 8.284457529600193, time: 8.679366827011108


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5577430415649978, Training Loss Force: 2.2829740760396575, time: 0.6021571159362793
Validation Loss Energy: 1.6178200479317248, Validation Loss Force: 2.2760288186139634, time: 0.05776834487915039
Test Loss Energy: 12.882237390571952, Test Loss Force: 8.386276745811134, time: 8.69468069076538


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8521687220534697, Training Loss Force: 2.28326329145034, time: 0.6738293170928955
Validation Loss Energy: 2.2098421963400954, Validation Loss Force: 2.6163858449118296, time: 0.057186126708984375
Test Loss Energy: 13.745005374312246, Test Loss Force: 8.414797930752766, time: 8.69653606414795


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4562406527103378, Training Loss Force: 2.309314006934931, time: 0.6086273193359375
Validation Loss Energy: 0.9664425439774053, Validation Loss Force: 2.557383753965895, time: 0.05918073654174805
Test Loss Energy: 12.400180476240376, Test Loss Force: 8.328304521232548, time: 8.846658706665039


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6095118750769764, Training Loss Force: 2.2744369224290244, time: 0.6178803443908691
Validation Loss Energy: 0.8388340016478764, Validation Loss Force: 2.342982536095552, time: 0.06239676475524902
Test Loss Energy: 12.37870269177431, Test Loss Force: 8.300413137900161, time: 8.70073914527893


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.573218792408122, Training Loss Force: 2.2703741754154745, time: 0.6283493041992188
Validation Loss Energy: 1.0275188536849436, Validation Loss Force: 2.855644510218675, time: 0.05783867835998535
Test Loss Energy: 12.195094573126028, Test Loss Force: 8.396860273270663, time: 8.704071283340454


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5486498526125163, Training Loss Force: 2.288466555130978, time: 0.6054987907409668
Validation Loss Energy: 0.8716919236639211, Validation Loss Force: 2.363830046217614, time: 0.05624580383300781
Test Loss Energy: 12.284184060068288, Test Loss Force: 8.240733054961995, time: 8.873535394668579


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7532086449183246, Training Loss Force: 2.298369521520385, time: 0.6168661117553711
Validation Loss Energy: 1.1112280347265928, Validation Loss Force: 2.128557436959308, time: 0.0573887825012207
Test Loss Energy: 12.923858492820273, Test Loss Force: 8.398301947570491, time: 9.166911840438843


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4527648178268713, Training Loss Force: 2.269948781917118, time: 0.6106975078582764
Validation Loss Energy: 1.1074447189354204, Validation Loss Force: 2.611006158346214, time: 0.05937004089355469
Test Loss Energy: 12.836970791035546, Test Loss Force: 8.345052265109796, time: 8.705411434173584


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.03408306555499, Training Loss Force: 2.2808308059854077, time: 0.6064543724060059
Validation Loss Energy: 1.6247507921005868, Validation Loss Force: 2.461593825413793, time: 0.05697989463806152
Test Loss Energy: 12.015329210981356, Test Loss Force: 8.344684285110334, time: 8.84585690498352


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.657638099816836, Training Loss Force: 2.279134470018559, time: 0.6154489517211914
Validation Loss Energy: 1.212434445920675, Validation Loss Force: 2.109004636586243, time: 0.056830406188964844
Test Loss Energy: 12.376528955934322, Test Loss Force: 8.441520350032926, time: 8.664281606674194


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5923431230025469, Training Loss Force: 2.317631118365394, time: 0.6470634937286377
Validation Loss Energy: 1.7774886887274395, Validation Loss Force: 2.392152559568472, time: 0.057676076889038086
Test Loss Energy: 11.561652120492159, Test Loss Force: 8.277894994220425, time: 8.751667261123657


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7949225893890295, Training Loss Force: 2.282343858736926, time: 0.6368498802185059
Validation Loss Energy: 1.5983706773769435, Validation Loss Force: 2.3849637975267663, time: 0.06213712692260742
Test Loss Energy: 11.392799192617497, Test Loss Force: 8.259095642117792, time: 8.886885404586792


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.199082571380664, Training Loss Force: 2.2910511289242255, time: 0.6064937114715576
Validation Loss Energy: 1.1824727536520696, Validation Loss Force: 2.4433653497861334, time: 0.05852627754211426
Test Loss Energy: 11.865066578026484, Test Loss Force: 8.288732847150428, time: 8.665289402008057


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.590559016955267, Training Loss Force: 2.2654629184623123, time: 0.6132500171661377
Validation Loss Energy: 1.4841222559694385, Validation Loss Force: 2.682955569451266, time: 0.057390451431274414
Test Loss Energy: 12.165605045535232, Test Loss Force: 8.319355844632105, time: 8.72904086112976


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.3194168811771525, Training Loss Force: 2.2761074658864695, time: 0.6173095703125
Validation Loss Energy: 1.3366760915955598, Validation Loss Force: 2.293423620959269, time: 0.057210445404052734
Test Loss Energy: 12.513596397167415, Test Loss Force: 8.343232706113838, time: 8.69736909866333


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5690908934628032, Training Loss Force: 2.2883202137872862, time: 0.8336191177368164
Validation Loss Energy: 1.1305972443888406, Validation Loss Force: 2.3994685770270756, time: 0.05843782424926758
Test Loss Energy: 12.487828545360362, Test Loss Force: 8.187035352853233, time: 8.652245998382568

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–ƒâ–ƒâ–…â–ˆâ–„â–„â–ƒâ–„â–†â–…â–ƒâ–„â–‚â–â–‚â–ƒâ–„â–„
wandb:   test_error_force â–ˆâ–†â–…â–ƒâ–†â–†â–„â–„â–†â–‚â–†â–…â–…â–‡â–ƒâ–ƒâ–ƒâ–„â–…â–
wandb:          test_loss â–â–â–â–â–†â–ˆâ–„â–„â–‡â–ƒâ–‡â–…â–…â–ˆâ–‚â–‚â–„â–…â–†â–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–‚â–â–â–â–â–‚â–â–‚â–â–â–‚â–ƒâ–â–ƒâ–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–‚â–â–‚â–
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–ˆâ–…â–ˆâ–‚â–â–‚â–â–‚â–‚â–…â–ƒâ–†â–…â–ƒâ–„â–„â–‚
wandb:  valid_error_force â–„â–„â–„â–ˆâ–‚â–„â–ƒâ–‚â–…â–‚â–â–„â–ƒâ–â–‚â–‚â–ƒâ–„â–‚â–‚
wandb:         valid_loss â–„â–ƒâ–„â–ˆâ–‚â–„â–ƒâ–‚â–…â–‚â–â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–„â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1340
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.48783
wandb:   test_error_force 8.18704
wandb:          test_loss 4.99751
wandb: train_error_energy 1.56909
wandb:  train_error_force 2.28832
wandb:         train_loss -2.08609
wandb: valid_error_energy 1.1306
wandb:  valid_error_force 2.39947
wandb:         valid_loss -1.99331
wandb: 
wandb: ğŸš€ View run al_70_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/nbl1tg87
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_030908-nbl1tg87/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 19.283100128173828, Uncertainty Bias: -2.7864906787872314
0.00024795532 0.0034843981
0.7993038 6.086841
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2258 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3137 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1666 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1869 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1088 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_035105-yuankzkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/yuankzkz
Training model 20. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.227955971188216, Training Loss Force: 2.587140558810369, time: 0.707564115524292
Validation Loss Energy: 2.2751855705583344, Validation Loss Force: 2.652005448843887, time: 0.06293606758117676
Test Loss Energy: 13.951818910205308, Test Loss Force: 8.416170104299697, time: 8.842682123184204


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4887322760288617, Training Loss Force: 2.295846831193944, time: 0.6651639938354492
Validation Loss Energy: 1.4852406117548607, Validation Loss Force: 2.558496320353523, time: 0.06174206733703613
Test Loss Energy: 12.50086020233285, Test Loss Force: 8.261849772664386, time: 9.350851774215698


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9843633779937015, Training Loss Force: 2.2855250533001015, time: 0.6282942295074463
Validation Loss Energy: 0.8289723470120967, Validation Loss Force: 2.305564099468117, time: 0.06390380859375
Test Loss Energy: 11.975527280681051, Test Loss Force: 8.386108076847613, time: 9.876227378845215


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.976549017708631, Training Loss Force: 2.296367829280598, time: 0.6528291702270508
Validation Loss Energy: 2.1493081416701783, Validation Loss Force: 2.4981856028369713, time: 0.06279373168945312
Test Loss Energy: 11.16203264006319, Test Loss Force: 8.238217320298387, time: 9.198756456375122


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9918457982257154, Training Loss Force: 2.282690209990124, time: 0.6572024822235107
Validation Loss Energy: 2.391670258198392, Validation Loss Force: 2.633452544270611, time: 0.06375336647033691
Test Loss Energy: 11.00498580750829, Test Loss Force: 8.314399681776887, time: 9.383202314376831


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.083337214226489, Training Loss Force: 2.2867753617610713, time: 0.6589179039001465
Validation Loss Energy: 3.8500567482852155, Validation Loss Force: 2.594299403661825, time: 0.0612187385559082
Test Loss Energy: 10.992866520457037, Test Loss Force: 8.256638405320178, time: 9.569745302200317


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0926402065546634, Training Loss Force: 2.2810934601479684, time: 0.6767642498016357
Validation Loss Energy: 2.7807818073428776, Validation Loss Force: 2.4492133095656348, time: 0.06880998611450195
Test Loss Energy: 11.10459742584777, Test Loss Force: 8.297454247335494, time: 9.980377674102783


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.954106670313327, Training Loss Force: 2.2885198419782573, time: 0.6409053802490234
Validation Loss Energy: 1.8709427622714725, Validation Loss Force: 2.3685792450965346, time: 0.06569266319274902
Test Loss Energy: 13.443545770013273, Test Loss Force: 8.366694904018727, time: 9.514318466186523


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7497321102175423, Training Loss Force: 2.3063285783133733, time: 0.6915109157562256
Validation Loss Energy: 1.0808142127571814, Validation Loss Force: 2.399917144021547, time: 0.06995415687561035
Test Loss Energy: 12.438099856658377, Test Loss Force: 8.300169945886983, time: 9.611153364181519


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9559029065274136, Training Loss Force: 2.278880009550404, time: 0.7212729454040527
Validation Loss Energy: 1.8819462921212131, Validation Loss Force: 2.3259929915958346, time: 0.06471371650695801
Test Loss Energy: 13.42783137651773, Test Loss Force: 8.186045037072853, time: 9.595284700393677


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.828165743278201, Training Loss Force: 2.3442183233472194, time: 0.6710183620452881
Validation Loss Energy: 2.620840118506969, Validation Loss Force: 2.455086430958626, time: 0.06412458419799805
Test Loss Energy: 10.841229186485553, Test Loss Force: 8.27810956333899, time: 9.794591665267944


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9011448921536864, Training Loss Force: 2.306746902066346, time: 0.632573127746582
Validation Loss Energy: 1.135358411734355, Validation Loss Force: 2.453681388647822, time: 0.057723283767700195
Test Loss Energy: 12.616088845963327, Test Loss Force: 8.260172824512841, time: 9.712486028671265


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5594996956875724, Training Loss Force: 2.3012892600930708, time: 0.6855950355529785
Validation Loss Energy: 1.5245216757879818, Validation Loss Force: 2.2591137569435586, time: 0.06393194198608398
Test Loss Energy: 11.009319172922998, Test Loss Force: 8.167484167122929, time: 9.203370332717896


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6379586126284427, Training Loss Force: 2.3039499602259936, time: 0.6983516216278076
Validation Loss Energy: 2.5028592055408496, Validation Loss Force: 2.324316181592425, time: 0.0635824203491211
Test Loss Energy: 10.75219581216807, Test Loss Force: 8.144898940574109, time: 9.35592007637024


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2388117464666726, Training Loss Force: 2.309141552332233, time: 0.6850156784057617
Validation Loss Energy: 2.8342153882874497, Validation Loss Force: 2.3396015277837847, time: 0.07206106185913086
Test Loss Energy: 10.786641936294306, Test Loss Force: 8.175109955835152, time: 9.705705642700195


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8559966101107641, Training Loss Force: 2.2903288697395303, time: 0.6207756996154785
Validation Loss Energy: 1.5203003141194829, Validation Loss Force: 2.6383001629120315, time: 0.06562066078186035
Test Loss Energy: 13.425839376006646, Test Loss Force: 8.222507872156335, time: 9.324209451675415


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.223270900684477, Training Loss Force: 2.3415724625223793, time: 0.6604061126708984
Validation Loss Energy: 3.6091219409823987, Validation Loss Force: 2.5555313693409216, time: 0.06129956245422363
Test Loss Energy: 10.513728992152547, Test Loss Force: 8.171055549393817, time: 9.48128080368042


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.686391354372932, Training Loss Force: 2.395178246241448, time: 0.6893401145935059
Validation Loss Energy: 3.38379512746339, Validation Loss Force: 2.4860995669343025, time: 0.06395959854125977
Test Loss Energy: 14.627860166835637, Test Loss Force: 8.46104973050823, time: 9.572047710418701


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9513779381292655, Training Loss Force: 2.28636265775321, time: 0.6589775085449219
Validation Loss Energy: 1.6881070668605662, Validation Loss Force: 2.423452938742395, time: 0.06302523612976074
Test Loss Energy: 12.750225387658942, Test Loss Force: 8.257612012753965, time: 9.424399137496948


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5338918094907115, Training Loss Force: 2.2362005822662487, time: 0.6088831424713135
Validation Loss Energy: 2.9269600935998437, Validation Loss Force: 2.322276309546581, time: 0.05865669250488281
Test Loss Energy: 10.822701388149932, Test Loss Force: 8.279219381336507, time: 9.921082019805908

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–„â–ƒâ–‚â–‚â–‚â–‚â–†â–„â–†â–‚â–…â–‚â–â–â–†â–â–ˆâ–…â–‚
wandb:   test_error_force â–‡â–„â–†â–ƒâ–…â–ƒâ–„â–†â–„â–‚â–„â–„â–‚â–â–‚â–ƒâ–‚â–ˆâ–ƒâ–„
wandb:          test_loss â–†â–ƒâ–†â–ƒâ–„â–ƒâ–…â–ˆâ–†â–…â–ƒâ–„â–‚â–â–‚â–…â–â–ˆâ–…â–„
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–„â–‚â–â–â–‚â–‚â–‚â–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–
wandb: valid_error_energy â–„â–ƒâ–â–„â–…â–ˆâ–†â–ƒâ–‚â–ƒâ–…â–‚â–ƒâ–…â–†â–ƒâ–‡â–‡â–ƒâ–†
wandb:  valid_error_force â–ˆâ–†â–‚â–…â–ˆâ–‡â–„â–ƒâ–„â–‚â–„â–„â–â–‚â–‚â–ˆâ–†â–…â–„â–‚
wandb:         valid_loss â–‡â–…â–â–…â–‡â–ˆâ–…â–ƒâ–ƒâ–‚â–…â–ƒâ–â–ƒâ–ƒâ–‡â–‡â–†â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1344
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.8227
wandb:   test_error_force 8.27922
wandb:          test_loss 5.05999
wandb: train_error_energy 1.53389
wandb:  train_error_force 2.2362
wandb:         train_loss -2.14517
wandb: valid_error_energy 2.92696
wandb:  valid_error_force 2.32228
wandb:         valid_loss -1.95757
wandb: 
wandb: ğŸš€ View run al_70_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/yuankzkz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_035105-yuankzkz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.2226505279541, Uncertainty Bias: -2.59782338142395
3.8146973e-06 0.035987854
1.0689223 5.82469
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3034 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2000 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 713 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_043335-8975t4yn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8975t4yn
Training model 21. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.164049492671385, Training Loss Force: 2.6490453654823827, time: 0.668848991394043
Validation Loss Energy: 1.3748053994713691, Validation Loss Force: 2.4654282994412426, time: 0.06174945831298828
Test Loss Energy: 13.24487868858081, Test Loss Force: 8.206162592850992, time: 10.39283013343811


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.743391573429371, Training Loss Force: 2.2942794679458753, time: 0.7269132137298584
Validation Loss Energy: 1.2985388789650696, Validation Loss Force: 2.5085642117286655, time: 0.062264442443847656
Test Loss Energy: 11.35670494841637, Test Loss Force: 8.176801238750143, time: 8.86978030204773


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9874602845484381, Training Loss Force: 2.2895127040961873, time: 0.6564877033233643
Validation Loss Energy: 1.048392972769944, Validation Loss Force: 2.7479394443334044, time: 0.05697774887084961
Test Loss Energy: 11.851939059072151, Test Loss Force: 8.25658928520607, time: 9.116204023361206


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0141619840077354, Training Loss Force: 2.250054812280262, time: 0.6321845054626465
Validation Loss Energy: 3.536552618975084, Validation Loss Force: 3.505795997855517, time: 0.0565190315246582
Test Loss Energy: 10.953605687839403, Test Loss Force: 8.294562698449072, time: 8.424633741378784


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8740890268144983, Training Loss Force: 2.2816131458922144, time: 0.6104309558868408
Validation Loss Energy: 1.200365555542243, Validation Loss Force: 2.5955314320462435, time: 0.05719637870788574
Test Loss Energy: 12.061077703855371, Test Loss Force: 8.416662909591267, time: 8.434722900390625


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9027157851885652, Training Loss Force: 2.315288747202454, time: 0.6273503303527832
Validation Loss Energy: 0.8449933642279578, Validation Loss Force: 2.373259305205645, time: 0.05877232551574707
Test Loss Energy: 11.514555259851111, Test Loss Force: 8.283668634966503, time: 8.602475881576538


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5642658476286389, Training Loss Force: 2.320240730354736, time: 0.6389005184173584
Validation Loss Energy: 2.0182699656541394, Validation Loss Force: 2.3218252931915044, time: 0.0591428279876709
Test Loss Energy: 11.145121009362922, Test Loss Force: 8.300253779071715, time: 8.493027448654175


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8692364110631743, Training Loss Force: 2.3075870149995814, time: 0.6623039245605469
Validation Loss Energy: 4.2465945361155395, Validation Loss Force: 2.4367463980888573, time: 0.057127952575683594
Test Loss Energy: 15.580339702831884, Test Loss Force: 8.393422574093828, time: 8.441718339920044


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8596412674451916, Training Loss Force: 2.2679058404029893, time: 0.6229910850524902
Validation Loss Energy: 1.4467077717193435, Validation Loss Force: 2.694980260004231, time: 0.06383943557739258
Test Loss Energy: 11.678052903833256, Test Loss Force: 8.183625008172944, time: 8.453483819961548


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.574679763820431, Training Loss Force: 2.2487370510963096, time: 0.6677441596984863
Validation Loss Energy: 1.1910043219782929, Validation Loss Force: 2.492139578852167, time: 0.05676627159118652
Test Loss Energy: 11.852045170829543, Test Loss Force: 8.161796301796123, time: 8.61436939239502


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7897738296842092, Training Loss Force: 2.2698232185268123, time: 0.6542387008666992
Validation Loss Energy: 2.913217788922478, Validation Loss Force: 3.3155650704373434, time: 0.05704164505004883
Test Loss Energy: 13.092559394792808, Test Loss Force: 8.135151392363271, time: 8.48904275894165


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7351395403240986, Training Loss Force: 2.269848369783598, time: 0.6327362060546875
Validation Loss Energy: 2.4433723638642304, Validation Loss Force: 2.701841475732277, time: 0.056867122650146484
Test Loss Energy: 13.74642715994386, Test Loss Force: 8.249529635711887, time: 8.576443195343018


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7030365023139205, Training Loss Force: 2.3095527252739507, time: 0.6252493858337402
Validation Loss Energy: 1.436284294994745, Validation Loss Force: 2.3843158303121164, time: 0.05902433395385742
Test Loss Energy: 12.397700450246617, Test Loss Force: 8.138807710672356, time: 8.566905736923218


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3621928183571606, Training Loss Force: 2.2770078974377834, time: 0.661700963973999
Validation Loss Energy: 2.087988621588, Validation Loss Force: 2.8069850670973677, time: 0.056169748306274414
Test Loss Energy: 10.927266903015733, Test Loss Force: 8.110476827409805, time: 8.52877402305603


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2997087231067235, Training Loss Force: 2.337754171338827, time: 0.6216909885406494
Validation Loss Energy: 5.4574907279088585, Validation Loss Force: 3.1502513771213536, time: 0.05640745162963867
Test Loss Energy: 15.332822298358733, Test Loss Force: 8.215795644820155, time: 8.44341492652893


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7634594114207307, Training Loss Force: 2.27599299477323, time: 0.6299567222595215
Validation Loss Energy: 2.073140820268389, Validation Loss Force: 3.5150185085415533, time: 0.05665755271911621
Test Loss Energy: 11.765371772359376, Test Loss Force: 8.191759951454758, time: 8.630967378616333


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.380326133995049, Training Loss Force: 2.250657489626301, time: 0.6174335479736328
Validation Loss Energy: 2.8556468482447075, Validation Loss Force: 2.5242465770072133, time: 0.06096363067626953
Test Loss Energy: 14.119673347660571, Test Loss Force: 8.22819371830534, time: 8.936311960220337


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.076244011277558, Training Loss Force: 2.25631538316552, time: 0.6405398845672607
Validation Loss Energy: 1.5750702996106272, Validation Loss Force: 2.2092579125011813, time: 0.057103872299194336
Test Loss Energy: 12.829392028647979, Test Loss Force: 8.227272681774517, time: 8.46903920173645


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5194084982982807, Training Loss Force: 2.270929744366563, time: 0.6229736804962158
Validation Loss Energy: 1.441864105455263, Validation Loss Force: 2.512604432046952, time: 0.05636763572692871
Test Loss Energy: 12.408782131720441, Test Loss Force: 8.307692714562098, time: 8.4388108253479


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4518883441687414, Training Loss Force: 2.2480786676261464, time: 0.6178915500640869
Validation Loss Energy: 1.6379734426586436, Validation Loss Force: 2.4766926861954373, time: 0.056565046310424805
Test Loss Energy: 11.365493552714451, Test Loss Force: 8.05658516998268, time: 8.722152948379517

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–‚â–â–ƒâ–‚â–â–ˆâ–‚â–‚â–„â–…â–ƒâ–â–ˆâ–‚â–†â–„â–ƒâ–‚
wandb:   test_error_force â–„â–ƒâ–…â–†â–ˆâ–…â–†â–ˆâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–„â–„â–„â–„â–†â–
wandb:          test_loss â–‚â–â–ƒâ–„â–†â–„â–…â–ˆâ–ƒâ–ƒâ–„â–†â–ƒâ–‚â–„â–ƒâ–†â–…â–…â–‚
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–ƒâ–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–‚â–‚â–â–…â–‚â–â–ƒâ–†â–‚â–‚â–„â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–„â–‚â–‚â–‚
wandb:  valid_error_force â–‚â–ƒâ–„â–ˆâ–ƒâ–‚â–‚â–‚â–„â–ƒâ–‡â–„â–‚â–„â–†â–ˆâ–ƒâ–â–ƒâ–‚
wandb:         valid_loss â–‚â–‚â–ƒâ–ˆâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‡â–„â–‚â–„â–‡â–ˆâ–ƒâ–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1346
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.36549
wandb:   test_error_force 8.05659
wandb:          test_loss 4.87795
wandb: train_error_energy 1.45189
wandb:  train_error_force 2.24808
wandb:         train_loss -2.13869
wandb: valid_error_energy 1.63797
wandb:  valid_error_force 2.47669
wandb:         valid_loss -1.87118
wandb: 
wandb: ğŸš€ View run al_70_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8975t4yn
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_043335-8975t4yn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.221729278564453, Uncertainty Bias: -2.4275028705596924
8.392334e-05 0.01128006
1.1442237 6.1947517
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3724 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_051629-lb37tcrz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lb37tcrz
Training model 22. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.915830765700086, Training Loss Force: 2.5571380385633633, time: 0.6352272033691406
Validation Loss Energy: 1.04843038118646, Validation Loss Force: 2.4458874118674845, time: 0.06029629707336426
Test Loss Energy: 11.6018334417113, Test Loss Force: 8.191000059768779, time: 9.310036420822144


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.70453662176086, Training Loss Force: 2.328554266749454, time: 0.6326172351837158
Validation Loss Energy: 1.4792263181233511, Validation Loss Force: 2.7510319847666223, time: 0.0590815544128418
Test Loss Energy: 12.652330005168489, Test Loss Force: 8.242521894942268, time: 8.707851648330688


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9113281047394761, Training Loss Force: 2.307618457954327, time: 0.6218419075012207
Validation Loss Energy: 1.3290736102807201, Validation Loss Force: 2.671786485091528, time: 0.05765223503112793
Test Loss Energy: 11.576912982403924, Test Loss Force: 8.23810643339533, time: 8.849520921707153


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.803154532614469, Training Loss Force: 2.2576195926016847, time: 0.6238510608673096
Validation Loss Energy: 1.72225009601869, Validation Loss Force: 2.070180767976998, time: 0.05697345733642578
Test Loss Energy: 12.967192837125124, Test Loss Force: 8.174412397520348, time: 8.752287864685059


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5750570274938596, Training Loss Force: 2.2472034406563166, time: 0.6532495021820068
Validation Loss Energy: 2.6458431915649085, Validation Loss Force: 2.538142245058837, time: 0.059198856353759766
Test Loss Energy: 13.696206416730043, Test Loss Force: 8.205642750162394, time: 8.707572221755981


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1339595988681936, Training Loss Force: 2.2632273182644917, time: 0.6220262050628662
Validation Loss Energy: 1.2096798615836888, Validation Loss Force: 2.49163445389463, time: 0.05710196495056152
Test Loss Energy: 12.083154046301834, Test Loss Force: 8.120586384356411, time: 8.694591999053955


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7001554393128717, Training Loss Force: 2.2454357402145506, time: 0.8302550315856934
Validation Loss Energy: 0.9751131135179739, Validation Loss Force: 2.4695824150276713, time: 0.08053159713745117
Test Loss Energy: 12.42005636254934, Test Loss Force: 8.154972732892134, time: 8.727820873260498


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5637006990958051, Training Loss Force: 2.263887187921744, time: 0.6222143173217773
Validation Loss Energy: 3.011166995849928, Validation Loss Force: 2.823400904542602, time: 0.05752921104431152
Test Loss Energy: 10.583012881624306, Test Loss Force: 8.198370359535096, time: 8.711240291595459


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.806957801891375, Training Loss Force: 2.2675626295738307, time: 0.6330974102020264
Validation Loss Energy: 2.017298181834024, Validation Loss Force: 2.5950319851519277, time: 0.0569148063659668
Test Loss Energy: 11.073473380818697, Test Loss Force: 8.054149038955844, time: 8.72024154663086


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8021591523378255, Training Loss Force: 2.2309470006602776, time: 0.6910140514373779
Validation Loss Energy: 1.9131959027298646, Validation Loss Force: 2.322603967194814, time: 0.05694890022277832
Test Loss Energy: 12.97581648438932, Test Loss Force: 8.098133180792404, time: 8.884383201599121


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.185216513825214, Training Loss Force: 2.2710831582297555, time: 0.6280136108398438
Validation Loss Energy: 1.2450448433473777, Validation Loss Force: 2.6129449385998074, time: 0.06166362762451172
Test Loss Energy: 12.6108172390374, Test Loss Force: 8.183448138922653, time: 8.660425424575806


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7835118127440903, Training Loss Force: 2.310649290553186, time: 0.6351003646850586
Validation Loss Energy: 2.07895493433771, Validation Loss Force: 3.3107869245694515, time: 0.058136940002441406
Test Loss Energy: 11.52256996412574, Test Loss Force: 8.110662479850385, time: 8.709329843521118


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4965120656652626, Training Loss Force: 2.24277528666983, time: 0.6399493217468262
Validation Loss Energy: 1.3362393817331086, Validation Loss Force: 2.4770009716279744, time: 0.057392120361328125
Test Loss Energy: 12.258413144520308, Test Loss Force: 8.20967591093611, time: 8.922979354858398


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4854340905292631, Training Loss Force: 2.2365472073556445, time: 0.6679129600524902
Validation Loss Energy: 1.4834722847324753, Validation Loss Force: 2.412004738608237, time: 0.05734443664550781
Test Loss Energy: 11.318712910239991, Test Loss Force: 8.195507720331817, time: 9.244813919067383


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4642781448024493, Training Loss Force: 2.2299856887629614, time: 0.6116585731506348
Validation Loss Energy: 1.0677069048167152, Validation Loss Force: 2.6101670296697854, time: 0.06337761878967285
Test Loss Energy: 12.062670774521518, Test Loss Force: 8.124851944101666, time: 8.694918870925903


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5344519610677594, Training Loss Force: 2.2390970254049534, time: 0.6347291469573975
Validation Loss Energy: 0.7628878742089236, Validation Loss Force: 2.5387338769795673, time: 0.057494401931762695
Test Loss Energy: 11.674041902719884, Test Loss Force: 8.147434113904412, time: 8.894817590713501


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.237294619646536, Training Loss Force: 2.2763128538230033, time: 0.6787147521972656
Validation Loss Energy: 0.9863292924020755, Validation Loss Force: 2.2387784971917037, time: 0.05870485305786133
Test Loss Energy: 11.828191252430495, Test Loss Force: 8.182145505766062, time: 8.700397729873657


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3674387351387716, Training Loss Force: 2.2890612579378757, time: 0.6194255352020264
Validation Loss Energy: 0.8268341108710386, Validation Loss Force: 2.5769891042573994, time: 0.057796478271484375
Test Loss Energy: 12.338051764823826, Test Loss Force: 8.196264534287193, time: 8.772878170013428


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8878540748148624, Training Loss Force: 2.266973781017425, time: 0.6122066974639893
Validation Loss Energy: 2.093151094401763, Validation Loss Force: 2.4512960454220707, time: 0.0589601993560791
Test Loss Energy: 13.079864105795899, Test Loss Force: 8.17693867341127, time: 8.918257474899292


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0331010952687425, Training Loss Force: 2.20643351232483, time: 0.6608235836029053
Validation Loss Energy: 1.4459485812663027, Validation Loss Force: 2.3792927483837043, time: 0.057695627212524414
Test Loss Energy: 11.337450884933228, Test Loss Force: 8.088645831387945, time: 8.714874505996704

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–ƒâ–†â–ˆâ–„â–…â–â–‚â–†â–†â–ƒâ–…â–ƒâ–„â–ƒâ–„â–…â–‡â–ƒ
wandb:   test_error_force â–†â–ˆâ–ˆâ–…â–‡â–ƒâ–…â–†â–â–ƒâ–†â–ƒâ–‡â–†â–„â–„â–†â–†â–†â–‚
wandb:          test_loss â–â–…â–…â–…â–ˆâ–…â–…â–…â–„â–†â–†â–ƒâ–‡â–…â–…â–…â–†â–†â–†â–„
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–„â–‡â–‚â–‚â–ˆâ–…â–…â–ƒâ–…â–ƒâ–ƒâ–‚â–â–‚â–â–…â–ƒ
wandb:  valid_error_force â–ƒâ–…â–„â–â–„â–ƒâ–ƒâ–…â–„â–‚â–„â–ˆâ–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–ƒ
wandb:         valid_loss â–ƒâ–…â–„â–â–„â–ƒâ–ƒâ–†â–„â–‚â–„â–ˆâ–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1347
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.33745
wandb:   test_error_force 8.08865
wandb:          test_loss 4.95485
wandb: train_error_energy 2.0331
wandb:  train_error_force 2.20643
wandb:         train_loss -2.14578
wandb: valid_error_energy 1.44595
wandb:  valid_error_force 2.37929
wandb:         valid_loss -1.99178
wandb: 
wandb: ğŸš€ View run al_70_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lb37tcrz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_051629-lb37tcrz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 19.123783111572266, Uncertainty Bias: -2.7032828330993652
0.00021362305 0.040301323
1.0530006 6.198247
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3495 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_055918-s7q0eufu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/s7q0eufu
Training model 23. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.144530839647518, Training Loss Force: 2.6264806801012717, time: 0.6412844657897949
Validation Loss Energy: 2.3253682933069344, Validation Loss Force: 2.9293415401155416, time: 0.06317782402038574
Test Loss Energy: 11.012340091417396, Test Loss Force: 8.169732204509234, time: 8.724490404129028


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4573093332717502, Training Loss Force: 2.2687092513949056, time: 0.6609072685241699
Validation Loss Energy: 0.9246968108352961, Validation Loss Force: 2.560996338189428, time: 0.05732917785644531
Test Loss Energy: 11.418836163986457, Test Loss Force: 8.096630660691195, time: 8.653805017471313


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.714928567498725, Training Loss Force: 2.226291737090825, time: 0.6176931858062744
Validation Loss Energy: 1.243530470485923, Validation Loss Force: 2.4416111622545147, time: 0.05827808380126953
Test Loss Energy: 12.213489716609415, Test Loss Force: 8.058514869765188, time: 8.910669565200806


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4627492829114526, Training Loss Force: 2.193143967812655, time: 0.6420361995697021
Validation Loss Energy: 0.8142541391354159, Validation Loss Force: 2.3338438603429568, time: 0.05964183807373047
Test Loss Energy: 11.622398319984892, Test Loss Force: 8.144666760774292, time: 8.718716859817505


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6942983863468528, Training Loss Force: 2.233524926805495, time: 0.6256546974182129
Validation Loss Energy: 3.041835217318562, Validation Loss Force: 2.7306313716204373, time: 0.05787539482116699
Test Loss Energy: 10.597777478129183, Test Loss Force: 8.203947650395131, time: 8.709266901016235


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.173860748572965, Training Loss Force: 2.278890241419589, time: 0.6506698131561279
Validation Loss Energy: 0.8729887209361613, Validation Loss Force: 2.255221388938168, time: 0.05878782272338867
Test Loss Energy: 11.585617690563693, Test Loss Force: 8.122120763632594, time: 8.680489301681519


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.080757514865515, Training Loss Force: 2.2170752384717276, time: 0.6088330745697021
Validation Loss Energy: 6.543380015840025, Validation Loss Force: 2.4239421428559984, time: 0.05803108215332031
Test Loss Energy: 10.010165987559814, Test Loss Force: 8.12139800056944, time: 8.917537450790405


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.685388184559945, Training Loss Force: 2.2419921385701933, time: 0.6197178363800049
Validation Loss Energy: 0.8052926941061574, Validation Loss Force: 2.413509759365563, time: 0.05698537826538086
Test Loss Energy: 11.309666877093075, Test Loss Force: 8.147337216685914, time: 8.749249935150146


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4197434068160755, Training Loss Force: 2.2287917109107354, time: 0.6550693511962891
Validation Loss Energy: 4.77458917362353, Validation Loss Force: 2.4553030880376143, time: 0.05814957618713379
Test Loss Energy: 15.810264477413252, Test Loss Force: 8.210081157123629, time: 8.788683652877808


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5807551594190887, Training Loss Force: 2.2645996696376627, time: 0.6072769165039062
Validation Loss Energy: 1.9226224896881448, Validation Loss Force: 2.263272882585771, time: 0.05782675743103027
Test Loss Energy: 11.102537780548603, Test Loss Force: 8.072025146489105, time: 8.888272762298584


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6723918863639304, Training Loss Force: 2.234083396558539, time: 0.6185591220855713
Validation Loss Energy: 1.0403180988620186, Validation Loss Force: 2.324562119664103, time: 0.057122230529785156
Test Loss Energy: 11.425564134380998, Test Loss Force: 8.124066316059322, time: 8.68828535079956


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5845036844507985, Training Loss Force: 2.2426386687920985, time: 0.6215345859527588
Validation Loss Energy: 0.8923862374135849, Validation Loss Force: 2.4892916404757504, time: 0.05947470664978027
Test Loss Energy: 11.368773616125656, Test Loss Force: 8.199462534208765, time: 9.278258800506592


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8393654111609528, Training Loss Force: 2.2972833938265422, time: 0.6234538555145264
Validation Loss Energy: 2.4145989454928687, Validation Loss Force: 2.4013932177899022, time: 0.05765962600708008
Test Loss Energy: 10.898434857956698, Test Loss Force: 8.157392470340282, time: 8.837525129318237


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.10748922287599, Training Loss Force: 2.2344232699396844, time: 0.6482264995574951
Validation Loss Energy: 4.005736438333494, Validation Loss Force: 2.2251125123641042, time: 0.058022260665893555
Test Loss Energy: 10.319600127085819, Test Loss Force: 8.063177470747966, time: 8.72285270690918


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.7618374659461167, Training Loss Force: 2.210776073327293, time: 0.6179983615875244
Validation Loss Energy: 3.248911733633611, Validation Loss Force: 2.4758484361286524, time: 0.05816531181335449
Test Loss Energy: 13.89483935400572, Test Loss Force: 8.167068036960822, time: 8.746763706207275


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7938679825409802, Training Loss Force: 2.2949068978155776, time: 0.638575553894043
Validation Loss Energy: 1.5722239199182324, Validation Loss Force: 2.474036799957384, time: 0.05827069282531738
Test Loss Energy: 11.474952943696573, Test Loss Force: 8.171619494562993, time: 8.89264702796936


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4562149985677388, Training Loss Force: 2.1803680226314426, time: 0.6980817317962646
Validation Loss Energy: 0.8659578313189185, Validation Loss Force: 2.2912623942288937, time: 0.05852198600769043
Test Loss Energy: 11.594999923809974, Test Loss Force: 8.073245305791982, time: 8.677969217300415


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7956947990518137, Training Loss Force: 2.256137398020993, time: 0.6385385990142822
Validation Loss Energy: 1.7989007764690015, Validation Loss Force: 2.644721495742297, time: 0.058072805404663086
Test Loss Energy: 12.450711678533965, Test Loss Force: 8.216426521303498, time: 8.691380977630615


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3802783611065432, Training Loss Force: 2.2461419017515714, time: 0.6166532039642334
Validation Loss Energy: 0.9600686118415791, Validation Loss Force: 2.7101491502322697, time: 0.057976484298706055
Test Loss Energy: 12.1258822735334, Test Loss Force: 8.111556395046073, time: 8.908311128616333


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8255391537426315, Training Loss Force: 2.248192485219006, time: 0.6214578151702881
Validation Loss Energy: 0.9582204300967352, Validation Loss Force: 2.2153588244304565, time: 0.06184697151184082
Test Loss Energy: 11.263232605218658, Test Loss Force: 8.137152101452996, time: 8.715068817138672

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–‚â–â–†â–ƒâ–ƒâ–„â–„â–ƒ
wandb:   test_error_force â–†â–ƒâ–â–…â–‡â–„â–„â–…â–ˆâ–‚â–„â–‡â–…â–â–†â–†â–‚â–ˆâ–ƒâ–„
wandb:          test_loss â–â–‚â–ƒâ–…â–…â–„â–„â–„â–ˆâ–‚â–„â–…â–ƒâ–‚â–‡â–„â–ƒâ–†â–…â–…
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–ƒâ–ƒâ–„â–â–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–‚
wandb: valid_error_energy â–ƒâ–â–‚â–â–„â–â–ˆâ–â–†â–‚â–â–â–ƒâ–…â–„â–‚â–â–‚â–â–
wandb:  valid_error_force â–ˆâ–„â–ƒâ–‚â–†â–â–ƒâ–ƒâ–ƒâ–â–‚â–„â–ƒâ–â–„â–„â–‚â–…â–†â–
wandb:         valid_loss â–ˆâ–„â–ƒâ–‚â–‡â–â–†â–ƒâ–…â–‚â–‚â–ƒâ–„â–ƒâ–…â–„â–‚â–…â–†â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1348
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.26323
wandb:   test_error_force 8.13715
wandb:          test_loss 5.03509
wandb: train_error_energy 1.82554
wandb:  train_error_force 2.24819
wandb:         train_loss -2.11291
wandb: valid_error_energy 0.95822
wandb:  valid_error_force 2.21536
wandb:         valid_loss -2.20897
wandb: 
wandb: ğŸš€ View run al_70_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/s7q0eufu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_055918-s7q0eufu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.96442985534668, Uncertainty Bias: -2.6483285427093506
0.00018787384 0.010423183
1.1292995 6.14502
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2938 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3350 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2554 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2150 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3011 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_064137-87u4phni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/87u4phni
Training model 24. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.575139218074287, Training Loss Force: 2.637664157691035, time: 0.6679949760437012
Validation Loss Energy: 0.7031506828281733, Validation Loss Force: 2.199299034949561, time: 0.057878971099853516
Test Loss Energy: 11.661806818386287, Test Loss Force: 7.999693469002139, time: 8.782368421554565


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2885547698922044, Training Loss Force: 2.2626731335979193, time: 0.6320664882659912
Validation Loss Energy: 3.5765080365166475, Validation Loss Force: 2.675468319419444, time: 0.05725741386413574
Test Loss Energy: 10.38756201468271, Test Loss Force: 7.9899385342378535, time: 8.727607488632202


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5019326508567978, Training Loss Force: 2.2285945114902543, time: 0.6056387424468994
Validation Loss Energy: 1.9149419628376576, Validation Loss Force: 2.365362789283608, time: 0.05747556686401367
Test Loss Energy: 11.012693624735935, Test Loss Force: 8.0668260714144, time: 8.977680683135986


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9126334055133738, Training Loss Force: 2.239302372962669, time: 0.6116864681243896
Validation Loss Energy: 1.2001471171100877, Validation Loss Force: 2.5091434855117964, time: 0.05777740478515625
Test Loss Energy: 11.571614655180486, Test Loss Force: 8.138050045677836, time: 8.77898359298706


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3140319664074627, Training Loss Force: 2.247883927922977, time: 0.6281287670135498
Validation Loss Energy: 1.4277932524530805, Validation Loss Force: 2.5354937069025993, time: 0.05917167663574219
Test Loss Energy: 12.322940709117574, Test Loss Force: 8.139731785296343, time: 8.778293371200562


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3586903725072266, Training Loss Force: 2.226797532644976, time: 0.6355929374694824
Validation Loss Energy: 1.115848363837308, Validation Loss Force: 2.2816964163852633, time: 0.05853915214538574
Test Loss Energy: 12.148577981284427, Test Loss Force: 8.020183784588632, time: 8.758292436599731


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7921420571612492, Training Loss Force: 2.234879679548609, time: 0.6984870433807373
Validation Loss Energy: 4.01493490075177, Validation Loss Force: 2.321449539007751, time: 0.08322286605834961
Test Loss Energy: 14.622883718937807, Test Loss Force: 8.064159103597465, time: 8.885509014129639


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.671501687483213, Training Loss Force: 2.2296893471998445, time: 0.6212418079376221
Validation Loss Energy: 0.9823962594439097, Validation Loss Force: 2.3939360280927806, time: 0.05751919746398926
Test Loss Energy: 11.49954277079904, Test Loss Force: 8.051410052242787, time: 8.746092557907104


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.81072130012856, Training Loss Force: 2.2657112495491907, time: 0.6366467475891113
Validation Loss Energy: 2.2402320813763206, Validation Loss Force: 2.31862319953849, time: 0.057268619537353516
Test Loss Energy: 10.52528623896334, Test Loss Force: 8.027663672548954, time: 8.789235830307007


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2959473685942715, Training Loss Force: 2.2436587549872358, time: 0.6368117332458496
Validation Loss Energy: 1.4488480675500015, Validation Loss Force: 2.193466773344847, time: 0.0634622573852539
Test Loss Energy: 12.42659439033337, Test Loss Force: 8.02724816492781, time: 9.4739089012146


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9766702063776547, Training Loss Force: 2.2153369096438156, time: 0.6414165496826172
Validation Loss Energy: 1.5402372744365596, Validation Loss Force: 2.5258748451368103, time: 0.06347346305847168
Test Loss Energy: 11.063666173598055, Test Loss Force: 8.032673686363275, time: 8.801729917526245


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9005120182946131, Training Loss Force: 2.228579186156827, time: 0.6618368625640869
Validation Loss Energy: 1.370728049072999, Validation Loss Force: 2.5215645271445135, time: 0.0609135627746582
Test Loss Energy: 12.429192671130728, Test Loss Force: 8.058948785479599, time: 8.867773294448853


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7142702837118429, Training Loss Force: 2.224526612879294, time: 0.6219704151153564
Validation Loss Energy: 2.1222359990746344, Validation Loss Force: 3.3609455990502908, time: 0.0592191219329834
Test Loss Energy: 11.327775535152796, Test Loss Force: 8.093211285669518, time: 8.997774600982666


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2709736554988926, Training Loss Force: 2.262497685845985, time: 0.6411314010620117
Validation Loss Energy: 1.3868525239407867, Validation Loss Force: 2.519944943111607, time: 0.05840730667114258
Test Loss Energy: 11.353743299552228, Test Loss Force: 7.935226405127374, time: 8.81507658958435


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0388994619689296, Training Loss Force: 2.2820045568239378, time: 0.6253318786621094
Validation Loss Energy: 2.7014435659685043, Validation Loss Force: 2.414116866791935, time: 0.06371116638183594
Test Loss Energy: 10.182764350365824, Test Loss Force: 7.9023911045769895, time: 8.863665580749512


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8299369664688099, Training Loss Force: 2.2566087135168145, time: 0.6360328197479248
Validation Loss Energy: 2.471825584003748, Validation Loss Force: 2.5756556500770103, time: 0.06365108489990234
Test Loss Energy: 13.482748414869588, Test Loss Force: 7.9109531249490805, time: 9.028201818466187


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8017845982372018, Training Loss Force: 2.228392006847914, time: 0.6313767433166504
Validation Loss Energy: 3.276885769771092, Validation Loss Force: 3.4543313688338104, time: 0.05810189247131348
Test Loss Energy: 10.802593590176777, Test Loss Force: 7.946651164962148, time: 8.804814577102661


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.561958336331505, Training Loss Force: 2.2601996392821415, time: 0.6424374580383301
Validation Loss Energy: 2.725788095027362, Validation Loss Force: 2.359200532004629, time: 0.0658266544342041
Test Loss Energy: 13.51935380017552, Test Loss Force: 8.118953345161476, time: 8.825365781784058


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.661135258075966, Training Loss Force: 2.211037344499925, time: 0.616187572479248
Validation Loss Energy: 1.490093017782919, Validation Loss Force: 2.637137384631997, time: 0.05798006057739258
Test Loss Energy: 11.78149057499298, Test Loss Force: 8.083584116362717, time: 9.045205354690552


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6912251948267452, Training Loss Force: 2.2062278540659808, time: 0.6248793601989746
Validation Loss Energy: 0.9212328582666705, Validation Loss Force: 2.4169923048078736, time: 0.057679176330566406
Test Loss Energy: 11.279719812205487, Test Loss Force: 7.924816438357736, time: 8.86487102508545

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–‚â–ƒâ–„â–„â–ˆâ–ƒâ–‚â–…â–‚â–…â–ƒâ–ƒâ–â–†â–‚â–†â–„â–ƒ
wandb:   test_error_force â–„â–„â–†â–ˆâ–ˆâ–„â–†â–…â–…â–…â–…â–†â–‡â–‚â–â–â–‚â–‡â–†â–‚
wandb:          test_loss â–‚â–‚â–„â–†â–‡â–…â–ˆâ–…â–„â–…â–„â–†â–…â–ƒâ–â–„â–ƒâ–‡â–†â–„
wandb: train_error_energy â–ˆâ–â–‚â–ƒâ–â–â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–‚â–â–â–â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–â–‡â–„â–‚â–ƒâ–‚â–ˆâ–‚â–„â–ƒâ–ƒâ–‚â–„â–‚â–…â–…â–†â–…â–ƒâ–
wandb:  valid_error_force â–â–„â–‚â–ƒâ–ƒâ–â–‚â–‚â–‚â–â–ƒâ–ƒâ–‡â–ƒâ–‚â–ƒâ–ˆâ–‚â–ƒâ–‚
wandb:         valid_loss â–â–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1352
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.27972
wandb:   test_error_force 7.92482
wandb:          test_loss 4.86446
wandb: train_error_energy 1.69123
wandb:  train_error_force 2.20623
wandb:         train_loss -2.16925
wandb: valid_error_energy 0.92123
wandb:  valid_error_force 2.41699
wandb:         valid_loss -1.98195
wandb: 
wandb: ğŸš€ View run al_70_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/87u4phni
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_064137-87u4phni/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 19.69304847717285, Uncertainty Bias: -2.7481775283813477
2.002716e-05 0.0011539459
1.097595 5.8371773
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2857 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_072427-bmrh22ks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/bmrh22ks
Training model 25. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.4009814054449774, Training Loss Force: 2.6542628608777745, time: 0.6358034610748291
Validation Loss Energy: 0.8429171414440406, Validation Loss Force: 2.3906160311269975, time: 0.05797171592712402
Test Loss Energy: 11.244061710410229, Test Loss Force: 7.993544478024449, time: 8.877430200576782


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.990525474219761, Training Loss Force: 2.2831976880155738, time: 0.6504507064819336
Validation Loss Energy: 2.772495509080894, Validation Loss Force: 2.6602947531393406, time: 0.05892443656921387
Test Loss Energy: 10.593895620457221, Test Loss Force: 7.955182107249986, time: 8.853602170944214


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.099651327195794, Training Loss Force: 2.197266309029795, time: 0.6177453994750977
Validation Loss Energy: 1.1138167027162198, Validation Loss Force: 2.562301068049991, time: 0.05812716484069824
Test Loss Energy: 11.137115337761289, Test Loss Force: 7.925854004297722, time: 9.018651723861694


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8645197231741473, Training Loss Force: 2.212578460961477, time: 0.6221663951873779
Validation Loss Energy: 1.0363279791015658, Validation Loss Force: 2.34574563752737, time: 0.058767080307006836
Test Loss Energy: 11.28477902774041, Test Loss Force: 7.924837914855152, time: 8.882322311401367


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.812941310218872, Training Loss Force: 2.25559428467149, time: 0.6096715927124023
Validation Loss Energy: 3.3373264147342927, Validation Loss Force: 2.5124743932657303, time: 0.0591731071472168
Test Loss Energy: 10.1299998628083, Test Loss Force: 8.035077762359558, time: 8.88256287574768


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.073790480804219, Training Loss Force: 2.2091646218965653, time: 0.622302770614624
Validation Loss Energy: 0.9738067971397453, Validation Loss Force: 2.1294118741395196, time: 0.0592193603515625
Test Loss Energy: 10.845572148823871, Test Loss Force: 7.972619766411041, time: 8.909358739852905


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.976504048589622, Training Loss Force: 2.2087055713280024, time: 0.8482084274291992
Validation Loss Energy: 1.917819961548774, Validation Loss Force: 2.5165374371714746, time: 0.05831098556518555
Test Loss Energy: 12.297825741899285, Test Loss Force: 8.00424759863406, time: 8.92047643661499


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9119932576105925, Training Loss Force: 2.229682100095897, time: 0.6591167449951172
Validation Loss Energy: 2.538681995068566, Validation Loss Force: 2.452571271620799, time: 0.059911489486694336
Test Loss Energy: 10.295927850751104, Test Loss Force: 8.007159735672927, time: 8.874017238616943


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.050770066767501, Training Loss Force: 2.2576274611078997, time: 0.6397216320037842
Validation Loss Energy: 0.8517755602428425, Validation Loss Force: 2.420586184823148, time: 0.0589447021484375
Test Loss Energy: 11.70290493493022, Test Loss Force: 8.02260714536508, time: 9.457366466522217


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.660033361683109, Training Loss Force: 2.2425141112967135, time: 0.6515154838562012
Validation Loss Energy: 0.9209839976624529, Validation Loss Force: 2.43410955006278, time: 0.06506180763244629
Test Loss Energy: 11.497459030599837, Test Loss Force: 8.027607025984553, time: 9.123290061950684


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.123169461146359, Training Loss Force: 2.2706676524251015, time: 0.6451303958892822
Validation Loss Energy: 1.4661954413672247, Validation Loss Force: 2.2194125162320724, time: 0.06526875495910645
Test Loss Energy: 10.790112879624889, Test Loss Force: 7.941579347053049, time: 8.905510187149048


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1930583010371114, Training Loss Force: 2.2519574605811643, time: 0.653139591217041
Validation Loss Energy: 1.0585037663463734, Validation Loss Force: 2.3397556148327663, time: 0.05922269821166992
Test Loss Energy: 10.79898296917231, Test Loss Force: 8.052190429490192, time: 8.948286294937134


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3384164865860118, Training Loss Force: 2.2376747650729816, time: 0.6602909564971924
Validation Loss Energy: 1.6400738807121804, Validation Loss Force: 2.290531148753667, time: 0.05848813056945801
Test Loss Energy: 10.61419645276118, Test Loss Force: 7.974414736204769, time: 9.051288604736328


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.527712953044684, Training Loss Force: 2.339302736860063, time: 0.6595947742462158
Validation Loss Energy: 4.115589816138676, Validation Loss Force: 2.875132513870275, time: 0.05861377716064453
Test Loss Energy: 9.893632465428375, Test Loss Force: 8.072118387736706, time: 8.938903570175171


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.051221827510711, Training Loss Force: 2.30601696449494, time: 0.6344866752624512
Validation Loss Energy: 0.9584623044564993, Validation Loss Force: 2.569094815026821, time: 0.058104515075683594
Test Loss Energy: 11.522361830262069, Test Loss Force: 7.942174974194529, time: 8.938703060150146


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7229174263869194, Training Loss Force: 2.2175622780340984, time: 0.6279261112213135
Validation Loss Energy: 0.7332713608669712, Validation Loss Force: 2.3761102496155315, time: 0.06006336212158203
Test Loss Energy: 11.43253318900958, Test Loss Force: 7.961940663758207, time: 9.072707414627075


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3901807428353246, Training Loss Force: 2.2139110814271565, time: 0.6488504409790039
Validation Loss Energy: 1.855231004665662, Validation Loss Force: 2.4921091845137475, time: 0.0581510066986084
Test Loss Energy: 12.274495322159732, Test Loss Force: 8.044982484676435, time: 9.050668001174927


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6243248324973671, Training Loss Force: 2.2440521311036306, time: 0.6465427875518799
Validation Loss Energy: 4.282052593582225, Validation Loss Force: 3.159815239608098, time: 0.0595395565032959
Test Loss Energy: 13.978460193978242, Test Loss Force: 8.060953110902783, time: 8.90454387664795


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8224881436943055, Training Loss Force: 2.2043566538981767, time: 0.609703779220581
Validation Loss Energy: 1.5365626768558864, Validation Loss Force: 2.4161649775961784, time: 0.059092044830322266
Test Loss Energy: 10.939327153598137, Test Loss Force: 7.9417282509239016, time: 9.128714561462402


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.732755586191333, Training Loss Force: 2.264137962574405, time: 0.7036917209625244
Validation Loss Energy: 1.8373732174986859, Validation Loss Force: 2.437760544713985, time: 0.0682673454284668
Test Loss Energy: 12.61001116273946, Test Loss Force: 7.896118822509265, time: 9.012582063674927

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–…â–‚â–„â–„â–ƒâ–ƒâ–‚â–â–„â–„â–…â–ˆâ–ƒâ–†
wandb:   test_error_force â–…â–ƒâ–‚â–‚â–‡â–„â–…â–…â–†â–†â–ƒâ–‡â–„â–ˆâ–ƒâ–„â–‡â–ˆâ–ƒâ–
wandb:          test_loss â–â–â–â–‚â–ƒâ–ƒâ–†â–„â–…â–…â–ƒâ–„â–„â–„â–ƒâ–„â–‡â–ˆâ–„â–„
wandb: train_error_energy â–‡â–…â–…â–„â–„â–…â–…â–„â–…â–ƒâ–†â–†â–â–ˆâ–…â–ƒâ–â–ƒâ–„â–ƒ
wandb:  train_error_force â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–„â–ƒâ–â–â–‚â–â–‚
wandb: valid_error_energy â–â–…â–‚â–‚â–†â–â–ƒâ–…â–â–â–‚â–‚â–ƒâ–ˆâ–â–â–ƒâ–ˆâ–ƒâ–ƒ
wandb:  valid_error_force â–ƒâ–…â–„â–‚â–„â–â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–†â–„â–ƒâ–ƒâ–ˆâ–ƒâ–ƒ
wandb:         valid_loss â–‚â–…â–ƒâ–‚â–„â–â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–†â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1353
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.61001
wandb:   test_error_force 7.89612
wandb:          test_loss 4.8126
wandb: train_error_energy 1.73276
wandb:  train_error_force 2.26414
wandb:         train_loss -2.10097
wandb: valid_error_energy 1.83737
wandb:  valid_error_force 2.43776
wandb:         valid_loss -1.90017
wandb: 
wandb: ğŸš€ View run al_70_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/bmrh22ks
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_072427-bmrh22ks/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.400880813598633, Uncertainty Bias: -2.4424335956573486
4.673004e-05 0.013744354
1.0964799 6.0444164
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 26.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3564 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_084422-k4fbjk9x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_70_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/k4fbjk9x
Training model 27. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.444998150042339, Training Loss Force: 2.559516352175962, time: 0.6403627395629883
Validation Loss Energy: 2.9777278795293682, Validation Loss Force: 2.3482842884600927, time: 0.05933499336242676
Test Loss Energy: 13.681875551742065, Test Loss Force: 8.052350361895705, time: 8.757453680038452


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9140228441543186, Training Loss Force: 2.2230222704861102, time: 0.6372368335723877
Validation Loss Energy: 1.4461331739882768, Validation Loss Force: 2.281121039312186, time: 0.05754685401916504
Test Loss Energy: 11.828565639705483, Test Loss Force: 7.8814313697882845, time: 8.788028478622437


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7998315231422752, Training Loss Force: 2.210510265918106, time: 0.6102876663208008
Validation Loss Energy: 1.5071340545226322, Validation Loss Force: 2.332405862998555, time: 0.05816531181335449
Test Loss Energy: 10.660459588824365, Test Loss Force: 7.908097303385416, time: 8.955944776535034


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.321896411386455, Training Loss Force: 2.2020749398572694, time: 0.6107876300811768
Validation Loss Energy: 1.1262448975952495, Validation Loss Force: 2.5064372760467633, time: 0.05958247184753418
Test Loss Energy: 11.612382801697905, Test Loss Force: 7.984274117953986, time: 8.723004817962646


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.820238032910882, Training Loss Force: 2.252897950324161, time: 0.6371297836303711
Validation Loss Energy: 3.8663828500646416, Validation Loss Force: 2.498232029353897, time: 0.05854630470275879
Test Loss Energy: 13.861735460838226, Test Loss Force: 8.098386139937022, time: 8.862829208374023


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.644448085330538, Training Loss Force: 2.221439279279244, time: 0.6543891429901123
Validation Loss Energy: 0.9163332185460321, Validation Loss Force: 2.506375708027914, time: 0.0595548152923584
Test Loss Energy: 10.956332282023553, Test Loss Force: 7.8911142786616075, time: 8.83855652809143


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3048415977537227, Training Loss Force: 2.226574394858171, time: 0.7807571887969971
Validation Loss Energy: 1.2669340554013766, Validation Loss Force: 2.4161969306186193, time: 0.08481526374816895
Test Loss Energy: 10.806550754320725, Test Loss Force: 7.930994278396606, time: 8.857019186019897


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8367122539145244, Training Loss Force: 2.2282688811669202, time: 0.6420114040374756
Validation Loss Energy: 2.3325301123819826, Validation Loss Force: 2.593109348411414, time: 0.05872297286987305
Test Loss Energy: 13.098132474757794, Test Loss Force: 8.011941491462338, time: 8.74950098991394


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0229081756151084, Training Loss Force: 2.1806323024267216, time: 0.6132395267486572
Validation Loss Energy: 2.478124448803753, Validation Loss Force: 2.329194862579703, time: 0.06066703796386719
Test Loss Energy: 12.917914005383109, Test Loss Force: 8.02138126428122, time: 8.803849697113037


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0290812025721383, Training Loss Force: 2.199173079299073, time: 0.6607160568237305
Validation Loss Energy: 1.2734678361503358, Validation Loss Force: 2.4174151535159902, time: 0.05762529373168945
Test Loss Energy: 10.552170369670568, Test Loss Force: 7.88934435506647, time: 9.712340593338013


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7628557359472994, Training Loss Force: 2.252142283739813, time: 0.7146973609924316
Validation Loss Energy: 2.3727070857237442, Validation Loss Force: 2.4474537779745136, time: 0.07038021087646484
Test Loss Energy: 12.519402242167354, Test Loss Force: 8.044275718817577, time: 10.51986837387085


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.017441655850109, Training Loss Force: 2.262807729329104, time: 0.6698746681213379
Validation Loss Energy: 1.1989527754786176, Validation Loss Force: 2.47066570042261, time: 0.06515312194824219
Test Loss Energy: 10.735018456736025, Test Loss Force: 7.973166555563719, time: 9.898836851119995


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8981542705079, Training Loss Force: 2.2032394787770637, time: 0.7522690296173096
Validation Loss Energy: 0.8231377195477076, Validation Loss Force: 2.836779757506527, time: 0.09344768524169922
Test Loss Energy: 11.307151121444944, Test Loss Force: 7.960906016999066, time: 10.138779163360596


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9636145046009335, Training Loss Force: 2.255595750145171, time: 0.6955611705780029
Validation Loss Energy: 2.2951572115948897, Validation Loss Force: 2.3605106059246954, time: 0.06558489799499512
Test Loss Energy: 10.451130390547739, Test Loss Force: 7.902470610285964, time: 10.109149932861328


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1851409784958107, Training Loss Force: 2.2239290362102024, time: 0.6526997089385986
Validation Loss Energy: 2.810795826860776, Validation Loss Force: 3.2888079211823573, time: 0.06695270538330078
Test Loss Energy: 12.54795531426333, Test Loss Force: 8.019717095706522, time: 10.010321855545044


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2720905821721904, Training Loss Force: 2.173866715329323, time: 0.6731178760528564
Validation Loss Energy: 0.8682708627395299, Validation Loss Force: 2.292288230984183, time: 0.06934547424316406
Test Loss Energy: 11.13914394927687, Test Loss Force: 7.883644388662518, time: 10.197794914245605


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9104648332903589, Training Loss Force: 2.185732956071552, time: 0.6602864265441895
Validation Loss Energy: 2.6810793592276783, Validation Loss Force: 2.423440135266504, time: 0.06941556930541992
Test Loss Energy: 13.1656933573732, Test Loss Force: 7.941299122013225, time: 10.043780326843262


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0766983249484183, Training Loss Force: 2.1742943307106684, time: 0.6161699295043945
Validation Loss Energy: 3.0354983874291763, Validation Loss Force: 2.4656479625537004, time: 0.05936098098754883
Test Loss Energy: 13.438936560661624, Test Loss Force: 8.00340072375271, time: 10.265902042388916


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9310078317040722, Training Loss Force: 2.176399525080729, time: 0.6920318603515625
Validation Loss Energy: 2.0801527273409417, Validation Loss Force: 2.4152871044883586, time: 0.06429219245910645
Test Loss Energy: 10.37564009410124, Test Loss Force: 7.862526402562059, time: 9.882285833358765


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5397088015834015, Training Loss Force: 2.195776849220923, time: 0.7242493629455566
Validation Loss Energy: 2.29650124255971, Validation Loss Force: 2.2092141580140066, time: 0.0660715103149414
Test Loss Energy: 13.010214311461223, Test Loss Force: 7.925274225137237, time: 9.897758960723877

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–‚â–ƒâ–ˆâ–‚â–‚â–†â–†â–â–…â–‚â–ƒâ–â–…â–ƒâ–‡â–‡â–â–†
wandb:   test_error_force â–‡â–‚â–‚â–…â–ˆâ–‚â–ƒâ–…â–†â–‚â–†â–„â–„â–‚â–†â–‚â–ƒâ–…â–â–ƒ
wandb:          test_loss â–„â–â–â–„â–ˆâ–‚â–‚â–…â–†â–ƒâ–†â–‚â–„â–‚â–†â–„â–‡â–ˆâ–ƒâ–†
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–‡â–‚â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–
wandb: valid_error_energy â–†â–‚â–ƒâ–‚â–ˆâ–â–‚â–„â–…â–‚â–…â–‚â–â–„â–†â–â–…â–†â–„â–„
wandb:  valid_error_force â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–…â–‚â–ˆâ–‚â–‚â–ƒâ–‚â–
wandb:         valid_loss â–‚â–â–â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–„â–‚â–ˆâ–â–ƒâ–ƒâ–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1354
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.01021
wandb:   test_error_force 7.92527
wandb:          test_loss 5.00934
wandb: train_error_energy 1.53971
wandb:  train_error_force 2.19578
wandb:         train_loss -2.19119
wandb: valid_error_energy 2.2965
wandb:  valid_error_force 2.20921
wandb:         valid_loss -2.12536
wandb: 
wandb: ğŸš€ View run al_70_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/k4fbjk9x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_084422-k4fbjk9x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.36501121520996, Uncertainty Bias: -2.3807005882263184
4.386902e-05 0.001842022
1.1765089 6.1017294
(48745, 22, 3)
Traceback (most recent call last):
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 948, in <module>
    al.improve_model(
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 627, in improve_model
    get_al_animation(f"al/run{run_idx}/data/train/")
  File "/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py", line 331, in get_al_animation
    animate_active_learning(paths[0], paths[1:], fps=1)
  File "/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py", line 318, in animate_active_learning
    ani.save(save_path + "animation.gif", writer=PillowWriter(fps=fps))
  File "/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/matplotlib/animation.py", line 1105, in save
    anim._draw_next_frame(d, blit=False)
  File "/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/matplotlib/animation.py", line 1140, in _draw_next_frame
    self._draw_frame(framedata)
  File "/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/matplotlib/animation.py", line 1768, in _draw_frame
    self._drawn_artists = self._func(framedata, *self._args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py", line 268, in update
    molecules, energies = read_xyz(path)
                          ^^^^^^^^^^^^^^
  File "/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py", line 75, in read_xyz
    with open(file_path, "r") as f:
         ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'al/run70/data/train/train26.xyz'
