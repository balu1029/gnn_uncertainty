wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_100205-dett6vrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/dett6vrc
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
78
Uncertainty Slope: 0.22826069593429565, Uncertainty Bias: 0.06533555686473846
0.000749588 0.011588335
1.0912335 3.6087105
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 9.371962005888795, Test Loss Force: 10.673030868594099, time: 8.218145608901978

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.051 MB uploadedwandb: | 0.050 MB of 0.051 MB uploadedwandb: / 0.050 MB of 0.051 MB uploadedwandb: - 0.051 MB of 0.051 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.37196
wandb:   test_error_force 10.67303
wandb:          test_loss 4.19841
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_79 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/dett6vrc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_100205-dett6vrc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3820 steps.
Found uncertainty sample 2 after 3452 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2037 steps.
Found uncertainty sample 5 after 825 steps.
Found uncertainty sample 6 after 2834 steps.
Found uncertainty sample 7 after 2775 steps.
Found uncertainty sample 8 after 1054 steps.
Found uncertainty sample 9 after 2422 steps.
Found uncertainty sample 10 after 4 steps.
Found uncertainty sample 11 after 2201 steps.
Found uncertainty sample 12 after 3059 steps.
Found uncertainty sample 13 after 1481 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1097 steps.
Found uncertainty sample 17 after 2321 steps.
Found uncertainty sample 18 after 975 steps.
Found uncertainty sample 19 after 1288 steps.
Found uncertainty sample 20 after 1579 steps.
Found uncertainty sample 21 after 19 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1054 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 748 steps.
Found uncertainty sample 26 after 2168 steps.
Found uncertainty sample 27 after 3038 steps.
Found uncertainty sample 28 after 1724 steps.
Found uncertainty sample 29 after 1606 steps.
Found uncertainty sample 30 after 894 steps.
Found uncertainty sample 31 after 1118 steps.
Found uncertainty sample 32 after 3840 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2549 steps.
Found uncertainty sample 35 after 1980 steps.
Found uncertainty sample 36 after 2373 steps.
Found uncertainty sample 37 after 2048 steps.
Found uncertainty sample 38 after 1028 steps.
Found uncertainty sample 39 after 2089 steps.
Found uncertainty sample 40 after 1478 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3200 steps.
Found uncertainty sample 44 after 3266 steps.
Found uncertainty sample 45 after 1213 steps.
Found uncertainty sample 46 after 3197 steps.
Found uncertainty sample 47 after 19 steps.
Found uncertainty sample 48 after 348 steps.
Found uncertainty sample 49 after 585 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2992 steps.
Found uncertainty sample 52 after 812 steps.
Found uncertainty sample 53 after 489 steps.
Found uncertainty sample 54 after 1836 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1743 steps.
Found uncertainty sample 57 after 2178 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1938 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 518 steps.
Found uncertainty sample 64 after 2260 steps.
Found uncertainty sample 65 after 2846 steps.
Found uncertainty sample 66 after 1524 steps.
Found uncertainty sample 67 after 702 steps.
Found uncertainty sample 68 after 3138 steps.
Found uncertainty sample 69 after 3891 steps.
Found uncertainty sample 70 after 3177 steps.
Found uncertainty sample 71 after 2120 steps.
Found uncertainty sample 72 after 2968 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1088 steps.
Found uncertainty sample 75 after 296 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 282 steps.
Found uncertainty sample 78 after 819 steps.
Found uncertainty sample 79 after 895 steps.
Found uncertainty sample 80 after 1547 steps.
Found uncertainty sample 81 after 2634 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1064 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3667 steps.
Found uncertainty sample 86 after 617 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3945 steps.
Found uncertainty sample 90 after 3731 steps.
Found uncertainty sample 91 after 1899 steps.
Found uncertainty sample 92 after 1932 steps.
Found uncertainty sample 93 after 1273 steps.
Found uncertainty sample 94 after 168 steps.
Found uncertainty sample 95 after 182 steps.
Found uncertainty sample 96 after 1973 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1667 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_111818-9a1flzut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/9a1flzut
Training model 0. Added 77 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.38780303391843, Training Loss Force: 3.738241162251301, time: 0.44879984855651855
Validation Loss Energy: 2.31488224655233, Validation Loss Force: 3.7122251036287803, time: 0.037154436111450195
Test Loss Energy: 10.29195166063615, Test Loss Force: 10.573502731365624, time: 7.1934309005737305


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.3522834263209553, Training Loss Force: 3.435174561679369, time: 0.3977487087249756
Validation Loss Energy: 1.930848333277009, Validation Loss Force: 3.5826196365649277, time: 0.0339508056640625
Test Loss Energy: 9.73673210953406, Test Loss Force: 10.52097657207428, time: 7.5244128704071045


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.291898361167072, Training Loss Force: 3.3522218115838456, time: 0.39852166175842285
Validation Loss Energy: 1.9483799658124876, Validation Loss Force: 3.522483157655064, time: 0.03291821479797363
Test Loss Energy: 9.781301966820592, Test Loss Force: 10.535793280154145, time: 7.236361026763916


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.4195353534562285, Training Loss Force: 3.265759215218227, time: 0.40134286880493164
Validation Loss Energy: 1.8532611620662118, Validation Loss Force: 3.5083536870002163, time: 0.03248143196105957
Test Loss Energy: 9.667276021035043, Test Loss Force: 10.513482102199417, time: 7.422080993652344


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1878288581659464, Training Loss Force: 3.2366453595801494, time: 0.4047517776489258
Validation Loss Energy: 2.5003184392512403, Validation Loss Force: 3.480334560360685, time: 0.03726768493652344
Test Loss Energy: 9.260690698941714, Test Loss Force: 10.460832679797406, time: 7.236695766448975


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.469476464276557, Training Loss Force: 3.2646060435213444, time: 0.39847469329833984
Validation Loss Energy: 1.9543290173842403, Validation Loss Force: 3.4874377061157813, time: 0.040392160415649414
Test Loss Energy: 9.40341770436975, Test Loss Force: 10.377240481372409, time: 7.238943815231323


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.502936263993703, Training Loss Force: 5.976118199310655, time: 0.41492748260498047
Validation Loss Energy: 9.012183645529815, Validation Loss Force: 6.484649247248404, time: 0.03692007064819336
Test Loss Energy: 11.626763152863404, Test Loss Force: 11.774024322311876, time: 7.270801544189453


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 9.608442996925925, Training Loss Force: 6.4035114415514585, time: 0.40706372261047363
Validation Loss Energy: 8.098779667432106, Validation Loss Force: 9.534609105029007, time: 0.03404498100280762
Test Loss Energy: 9.903786738070066, Test Loss Force: 13.402954094040133, time: 7.520694971084595


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.589044469498308, Training Loss Force: 7.046310107700863, time: 0.44974350929260254
Validation Loss Energy: 8.824438819125925, Validation Loss Force: 7.09227326603907, time: 0.033360958099365234
Test Loss Energy: 10.062140169857125, Test Loss Force: 11.628230782691318, time: 7.271656513214111


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.040989400635263, Training Loss Force: 6.5512629648491, time: 0.4291362762451172
Validation Loss Energy: 20.19606837805918, Validation Loss Force: 6.42456910363246, time: 0.04492521286010742
Test Loss Energy: 23.179562069357406, Test Loss Force: 12.679808086586663, time: 7.235527515411377


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 10.041974193698922, Training Loss Force: 6.492085012992701, time: 0.4013481140136719
Validation Loss Energy: 3.869532393799217, Validation Loss Force: 6.80171719623911, time: 0.037189483642578125
Test Loss Energy: 9.543835497852509, Test Loss Force: 11.87010828780279, time: 7.247211456298828


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.071675220918896, Training Loss Force: 6.723190074943596, time: 0.3971984386444092
Validation Loss Energy: 7.773056568739187, Validation Loss Force: 6.81646279242074, time: 0.03818869590759277
Test Loss Energy: 9.660618017716219, Test Loss Force: 11.964882478403144, time: 7.430745363235474


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.360407096601694, Training Loss Force: 5.755323800352067, time: 0.407926082611084
Validation Loss Energy: 3.2538490879408406, Validation Loss Force: 6.477013476896248, time: 0.035347700119018555
Test Loss Energy: 11.034637158443632, Test Loss Force: 11.966235873130168, time: 7.650184631347656


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 15.509542123953052, Training Loss Force: 7.423715446790816, time: 0.40511322021484375
Validation Loss Energy: 15.029472622390385, Validation Loss Force: 8.782385524226003, time: 0.03506779670715332
Test Loss Energy: 12.503436556631275, Test Loss Force: 13.21851126687284, time: 7.2698071002960205


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.410620091412004, Training Loss Force: 6.620744820098735, time: 0.4338514804840088
Validation Loss Energy: 6.2338471907475155, Validation Loss Force: 7.1329473482491155, time: 0.03296995162963867
Test Loss Energy: 12.466509184745489, Test Loss Force: 11.696425062264908, time: 7.2745020389556885


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.426029978258473, Training Loss Force: 5.506781581203322, time: 0.41892409324645996
Validation Loss Energy: 5.438648910118741, Validation Loss Force: 7.86793411046585, time: 0.0361485481262207
Test Loss Energy: 8.564447712932855, Test Loss Force: 12.461786649622438, time: 7.495506048202515


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 12.328190276836002, Training Loss Force: 6.072930004288237, time: 0.38486480712890625
Validation Loss Energy: 28.168573263512222, Validation Loss Force: 5.864267622410951, time: 0.03884553909301758
Test Loss Energy: 25.3037801431162, Test Loss Force: 10.74200581453524, time: 7.302251815795898


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 22.817841019044355, Training Loss Force: 7.310334751140052, time: 0.3988792896270752
Validation Loss Energy: 3.484885472365157, Validation Loss Force: 10.601485565265984, time: 0.035948991775512695
Test Loss Energy: 10.159437110947891, Test Loss Force: 15.076255330674934, time: 7.276204824447632


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.716501103745506, Training Loss Force: 7.992549800543545, time: 0.41045212745666504
Validation Loss Energy: 5.327060048990197, Validation Loss Force: 8.007349044084405, time: 0.03564310073852539
Test Loss Energy: 9.285812395198272, Test Loss Force: 12.397805041791619, time: 7.283583164215088


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.811352544470723, Training Loss Force: 5.893826013141464, time: 0.407989501953125
Validation Loss Energy: 6.974031941506788, Validation Loss Force: 6.707342441443952, time: 0.036223649978637695
Test Loss Energy: 10.935490515249906, Test Loss Force: 11.790283987079322, time: 7.5046515464782715

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–â–â–â–‚â–‚â–‚â–‡â–â–â–‚â–ƒâ–ƒâ–â–ˆâ–‚â–â–‚
wandb:   test_error_force â–â–â–â–â–â–â–ƒâ–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–‚â–ˆâ–„â–ƒ
wandb:          test_loss â–‚â–â–â–â–â–â–„â–…â–ƒâ–ˆâ–ƒâ–ƒâ–„â–†â–„â–„â–†â–ˆâ–„â–ƒ
wandb: train_error_energy â–‚â–â–â–â–â–â–ƒâ–„â–…â–„â–„â–„â–„â–†â–ƒâ–„â–„â–ˆâ–ƒâ–ƒ
wandb:  train_error_force â–‚â–â–â–â–â–â–…â–†â–‡â–†â–†â–†â–…â–‡â–†â–„â–…â–‡â–ˆâ–…
wandb:         train_loss â–‚â–â–â–â–â–â–…â–…â–†â–…â–…â–…â–…â–‡â–…â–…â–…â–ˆâ–†â–„
wandb: valid_error_energy â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–†â–‚â–ƒâ–â–…â–‚â–‚â–ˆâ–â–‚â–‚
wandb:  valid_error_force â–â–â–â–â–â–â–„â–‡â–…â–„â–„â–„â–„â–†â–…â–…â–ƒâ–ˆâ–…â–„
wandb:         valid_loss â–â–â–â–â–â–â–…â–‡â–…â–‡â–„â–…â–„â–ˆâ–…â–…â–ˆâ–ˆâ–†â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 869
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.93549
wandb:   test_error_force 11.79028
wandb:          test_loss 4.67688
wandb: train_error_energy 7.81135
wandb:  train_error_force 5.89383
wandb:         train_loss 2.49483
wandb: valid_error_energy 6.97403
wandb:  valid_error_force 6.70734
wandb:         valid_loss 2.711
wandb: 
wandb: ğŸš€ View run al_79_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/9a1flzut
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_111818-9a1flzut/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.9488612413406372, Uncertainty Bias: -0.6454576849937439
3.4332275e-05 0.12145233
-4.2064533 7.91888
(48745, 22, 3)
Found uncertainty sample 0 after 84 steps.
Found uncertainty sample 1 after 990 steps.
Found uncertainty sample 2 after 522 steps.
Found uncertainty sample 3 after 170 steps.
Found uncertainty sample 4 after 448 steps.
Found uncertainty sample 5 after 103 steps.
Found uncertainty sample 6 after 944 steps.
Found uncertainty sample 7 after 122 steps.
Found uncertainty sample 8 after 158 steps.
Found uncertainty sample 9 after 231 steps.
Found uncertainty sample 10 after 103 steps.
Found uncertainty sample 11 after 120 steps.
Found uncertainty sample 12 after 434 steps.
Found uncertainty sample 13 after 34 steps.
Found uncertainty sample 14 after 288 steps.
Found uncertainty sample 15 after 18 steps.
Found uncertainty sample 16 after 38 steps.
Found uncertainty sample 17 after 1025 steps.
Found uncertainty sample 18 after 211 steps.
Found uncertainty sample 19 after 359 steps.
Found uncertainty sample 20 after 1804 steps.
Found uncertainty sample 21 after 585 steps.
Found uncertainty sample 22 after 19 steps.
Found uncertainty sample 23 after 277 steps.
Found uncertainty sample 24 after 823 steps.
Found uncertainty sample 25 after 171 steps.
Found uncertainty sample 26 after 691 steps.
Found uncertainty sample 27 after 569 steps.
Found uncertainty sample 28 after 22 steps.
Found uncertainty sample 29 after 673 steps.
Found uncertainty sample 30 after 280 steps.
Found uncertainty sample 31 after 75 steps.
Found uncertainty sample 32 after 585 steps.
Found uncertainty sample 33 after 317 steps.
Found uncertainty sample 34 after 331 steps.
Found uncertainty sample 35 after 226 steps.
Found uncertainty sample 36 after 272 steps.
Found uncertainty sample 37 after 67 steps.
Found uncertainty sample 38 after 486 steps.
Found uncertainty sample 39 after 204 steps.
Found uncertainty sample 40 after 240 steps.
Found uncertainty sample 41 after 170 steps.
Found uncertainty sample 42 after 276 steps.
Found uncertainty sample 43 after 1050 steps.
Found uncertainty sample 44 after 57 steps.
Found uncertainty sample 45 after 621 steps.
Found uncertainty sample 46 after 80 steps.
Found uncertainty sample 47 after 472 steps.
Found uncertainty sample 48 after 85 steps.
Found uncertainty sample 49 after 449 steps.
Found uncertainty sample 50 after 91 steps.
Found uncertainty sample 51 after 166 steps.
Found uncertainty sample 52 after 625 steps.
Found uncertainty sample 53 after 403 steps.
Found uncertainty sample 54 after 126 steps.
Found uncertainty sample 55 after 60 steps.
Found uncertainty sample 56 after 45 steps.
Found uncertainty sample 57 after 98 steps.
Found uncertainty sample 58 after 454 steps.
Found uncertainty sample 59 after 602 steps.
Found uncertainty sample 60 after 28 steps.
Found uncertainty sample 61 after 18 steps.
Found uncertainty sample 62 after 9 steps.
Found uncertainty sample 63 after 185 steps.
Found uncertainty sample 64 after 617 steps.
Found uncertainty sample 65 after 265 steps.
Found uncertainty sample 66 after 315 steps.
Found uncertainty sample 67 after 171 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 5 steps.
Found uncertainty sample 70 after 219 steps.
Found uncertainty sample 71 after 33 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 444 steps.
Found uncertainty sample 74 after 367 steps.
Found uncertainty sample 75 after 68 steps.
Found uncertainty sample 76 after 252 steps.
Found uncertainty sample 77 after 572 steps.
Found uncertainty sample 78 after 18 steps.
Found uncertainty sample 79 after 356 steps.
Found uncertainty sample 80 after 945 steps.
Found uncertainty sample 81 after 392 steps.
Found uncertainty sample 82 after 650 steps.
Found uncertainty sample 83 after 1144 steps.
Found uncertainty sample 84 after 529 steps.
Found uncertainty sample 85 after 1632 steps.
Found uncertainty sample 86 after 601 steps.
Found uncertainty sample 87 after 211 steps.
Found uncertainty sample 88 after 765 steps.
Found uncertainty sample 89 after 562 steps.
Found uncertainty sample 90 after 47 steps.
Found uncertainty sample 91 after 480 steps.
Found uncertainty sample 92 after 200 steps.
Found uncertainty sample 93 after 809 steps.
Found uncertainty sample 94 after 182 steps.
Found uncertainty sample 95 after 27 steps.
Found uncertainty sample 96 after 49 steps.
Found uncertainty sample 97 after 350 steps.
Found uncertainty sample 98 after 290 steps.
Found uncertainty sample 99 after 534 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_113559-kxg4q3dx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/kxg4q3dx
Training model 1. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.614342559803614, Training Loss Force: 3.63538284977877, time: 0.4743375778198242
Validation Loss Energy: 2.103330525742425, Validation Loss Force: 3.57319427428695, time: 0.04236745834350586
Test Loss Energy: 9.763156735062202, Test Loss Force: 10.280369474881013, time: 8.271539449691772


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0802419545788675, Training Loss Force: 3.2650679685439123, time: 0.4557795524597168
Validation Loss Energy: 1.8811427905081326, Validation Loss Force: 3.4203457110945714, time: 0.04011058807373047
Test Loss Energy: 9.255273398777542, Test Loss Force: 10.227833410892996, time: 8.495768308639526


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.191924462927884, Training Loss Force: 3.2056299656333, time: 0.4451436996459961
Validation Loss Energy: 1.9767295334645756, Validation Loss Force: 3.361932468705043, time: 0.03839516639709473
Test Loss Energy: 9.701839266800423, Test Loss Force: 10.295847736490852, time: 8.348348140716553


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8159598085868578, Training Loss Force: 3.190737548839151, time: 0.45188426971435547
Validation Loss Energy: 1.6573933652188761, Validation Loss Force: 3.3827112853955863, time: 0.03945589065551758
Test Loss Energy: 9.598432657403654, Test Loss Force: 10.277898504876388, time: 8.125115394592285


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8540161106720228, Training Loss Force: 3.1704426441588422, time: 0.44937896728515625
Validation Loss Energy: 1.8092805543737118, Validation Loss Force: 3.4192072037514425, time: 0.04152679443359375
Test Loss Energy: 9.11402372735528, Test Loss Force: 10.276470871556633, time: 8.254981517791748


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7451889370262208, Training Loss Force: 3.1233587782249, time: 0.4526855945587158
Validation Loss Energy: 1.6176523780648413, Validation Loss Force: 3.3789613143090165, time: 0.045537710189819336
Test Loss Energy: 9.164427749426528, Test Loss Force: 10.263096066274773, time: 8.521008729934692


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 17.219804306939377, Training Loss Force: 7.704196343185555, time: 0.4523651599884033
Validation Loss Energy: 16.02262510976384, Validation Loss Force: 7.816780772910151, time: 0.04363870620727539
Test Loss Energy: 13.462778256739597, Test Loss Force: 12.745134788598325, time: 8.714028120040894


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 14.677734033411435, Training Loss Force: 7.587670387530451, time: 0.44170188903808594
Validation Loss Energy: 24.768538318563454, Validation Loss Force: 6.19951873385812, time: 0.04085731506347656
Test Loss Energy: 26.05530504642964, Test Loss Force: 11.089030623524343, time: 8.374823331832886


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.666262418747571, Training Loss Force: 5.463306875689711, time: 0.4395473003387451
Validation Loss Energy: 21.430856078533967, Validation Loss Force: 4.862315250390431, time: 0.037204742431640625
Test Loss Energy: 16.440657850317702, Test Loss Force: 10.568401999110153, time: 8.30411696434021


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 15.9792377075207, Training Loss Force: 5.643093803710337, time: 0.4578080177307129
Validation Loss Energy: 35.60111259550305, Validation Loss Force: 4.749787616142656, time: 0.046373844146728516
Test Loss Energy: 29.513421617621873, Test Loss Force: 10.37133774848043, time: 8.199736833572388


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 15.514307202853233, Training Loss Force: 6.5278670424030905, time: 0.5029993057250977
Validation Loss Energy: 14.808373739279679, Validation Loss Force: 6.47874673352815, time: 0.04027962684631348
Test Loss Energy: 20.005991876939838, Test Loss Force: 11.887015306570378, time: 8.502360820770264


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.066013427792619, Training Loss Force: 7.3655107531423765, time: 0.4310271739959717
Validation Loss Energy: 16.389770904335414, Validation Loss Force: 5.294882130712173, time: 0.04135918617248535
Test Loss Energy: 20.82868465588162, Test Loss Force: 11.082665946584935, time: 8.573960304260254


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 12.816836841212394, Training Loss Force: 5.715459806520504, time: 0.46353840827941895
Validation Loss Energy: 6.60806362137888, Validation Loss Force: 5.2314695206582735, time: 0.044289588928222656
Test Loss Energy: 9.134931469481316, Test Loss Force: 10.656906236925263, time: 8.603854894638062


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 11.671748771256388, Training Loss Force: 5.560407427412439, time: 0.4799532890319824
Validation Loss Energy: 2.813224256566264, Validation Loss Force: 4.231479309151669, time: 0.04165005683898926
Test Loss Energy: 10.093661069594587, Test Loss Force: 10.200299874365225, time: 8.745922803878784


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 12.044924583612326, Training Loss Force: 5.117147158249711, time: 0.4439525604248047
Validation Loss Energy: 5.631458568915904, Validation Loss Force: 5.7496277486449054, time: 0.042413949966430664
Test Loss Energy: 8.614896040335108, Test Loss Force: 10.852695290501433, time: 8.608917474746704


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.224245367751553, Training Loss Force: 5.483986589765707, time: 0.4479250907897949
Validation Loss Energy: 18.407124864790493, Validation Loss Force: 5.966260779364883, time: 0.03891324996948242
Test Loss Energy: 22.317113721929953, Test Loss Force: 11.487616154346785, time: 8.611061096191406


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 11.192884407067616, Training Loss Force: 5.906068425344, time: 0.46296024322509766
Validation Loss Energy: 6.094877595420816, Validation Loss Force: 6.29350738035424, time: 0.040184974670410156
Test Loss Energy: 9.904052789227817, Test Loss Force: 11.880598014427337, time: 8.8319571018219


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 19.108942845874427, Training Loss Force: 5.890044648886307, time: 0.43618106842041016
Validation Loss Energy: 13.242096699909027, Validation Loss Force: 5.776133393099566, time: 0.0414578914642334
Test Loss Energy: 19.834757652938592, Test Loss Force: 12.366591327547745, time: 8.609097480773926


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.825571122291196, Training Loss Force: 7.013976188479532, time: 0.4528052806854248
Validation Loss Energy: 16.64713724725825, Validation Loss Force: 6.89301065539292, time: 0.042092323303222656
Test Loss Energy: 19.437236718458326, Test Loss Force: 12.469486651279642, time: 8.715149879455566


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 14.301073749525068, Training Loss Force: 7.130154349773305, time: 0.4854159355163574
Validation Loss Energy: 2.2180109252930293, Validation Loss Force: 7.64198638403342, time: 0.04399871826171875
Test Loss Energy: 9.329105740400903, Test Loss Force: 11.921247024791038, time: 9.215584993362427

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–ƒâ–‡â–„â–ˆâ–…â–…â–â–â–â–†â–â–…â–…â–
wandb:   test_error_force â–â–â–â–â–â–â–ˆâ–ƒâ–‚â–â–†â–ƒâ–‚â–â–ƒâ–…â–†â–‡â–‡â–†
wandb:          test_loss â–â–â–â–â–â–â–†â–ˆâ–„â–ˆâ–‡â–†â–‚â–â–‚â–‡â–„â–ˆâ–ˆâ–„
wandb: train_error_energy â–‚â–â–â–â–â–â–‡â–†â–…â–‡â–‡â–†â–…â–…â–…â–„â–…â–ˆâ–…â–†
wandb:  train_error_force â–‚â–â–â–â–â–â–ˆâ–ˆâ–…â–…â–†â–‡â–…â–…â–„â–…â–…â–…â–‡â–‡
wandb:         train_loss â–‚â–â–â–â–â–â–ˆâ–‡â–…â–†â–‡â–‡â–…â–…â–…â–…â–…â–‡â–†â–‡
wandb: valid_error_energy â–â–â–â–â–â–â–„â–†â–…â–ˆâ–„â–„â–‚â–â–‚â–„â–‚â–ƒâ–„â–
wandb:  valid_error_force â–â–â–â–â–â–â–ˆâ–…â–ƒâ–ƒâ–†â–„â–„â–‚â–…â–…â–†â–…â–‡â–ˆ
wandb:         valid_loss â–â–â–â–â–â–â–‡â–‡â–†â–ˆâ–†â–…â–ƒâ–‚â–„â–†â–„â–…â–‡â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 959
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.32911
wandb:   test_error_force 11.92125
wandb:          test_loss 4.6132
wandb: train_error_energy 14.30107
wandb:  train_error_force 7.13015
wandb:         train_loss 3.34281
wandb: valid_error_energy 2.21801
wandb:  valid_error_force 7.64199
wandb:         valid_loss 2.70546
wandb: 
wandb: ğŸš€ View run al_79_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/kxg4q3dx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_113559-kxg4q3dx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.013451099395752, Uncertainty Bias: -0.5991023778915405
0.00032043457 0.0061740875
-1.5389769 10.830285
(48745, 22, 3)
Found uncertainty sample 0 after 188 steps.
Found uncertainty sample 1 after 54 steps.
Found uncertainty sample 2 after 224 steps.
Found uncertainty sample 3 after 10 steps.
Found uncertainty sample 4 after 82 steps.
Found uncertainty sample 5 after 46 steps.
Found uncertainty sample 6 after 93 steps.
Found uncertainty sample 7 after 21 steps.
Found uncertainty sample 8 after 15 steps.
Found uncertainty sample 9 after 33 steps.
Found uncertainty sample 10 after 42 steps.
Found uncertainty sample 11 after 366 steps.
Found uncertainty sample 12 after 100 steps.
Found uncertainty sample 13 after 56 steps.
Found uncertainty sample 14 after 224 steps.
Found uncertainty sample 15 after 199 steps.
Found uncertainty sample 16 after 69 steps.
Found uncertainty sample 17 after 205 steps.
Found uncertainty sample 18 after 8 steps.
Found uncertainty sample 19 after 90 steps.
Found uncertainty sample 20 after 88 steps.
Found uncertainty sample 21 after 227 steps.
Found uncertainty sample 22 after 48 steps.
Found uncertainty sample 23 after 21 steps.
Found uncertainty sample 24 after 11 steps.
Found uncertainty sample 25 after 82 steps.
Found uncertainty sample 26 after 5 steps.
Found uncertainty sample 27 after 63 steps.
Found uncertainty sample 28 after 88 steps.
Found uncertainty sample 29 after 63 steps.
Found uncertainty sample 30 after 62 steps.
Found uncertainty sample 31 after 5 steps.
Found uncertainty sample 32 after 57 steps.
Found uncertainty sample 33 after 64 steps.
Found uncertainty sample 34 after 49 steps.
Found uncertainty sample 35 after 44 steps.
Found uncertainty sample 36 after 42 steps.
Found uncertainty sample 37 after 95 steps.
Found uncertainty sample 38 after 87 steps.
Found uncertainty sample 39 after 27 steps.
Found uncertainty sample 40 after 26 steps.
Found uncertainty sample 41 after 101 steps.
Found uncertainty sample 42 after 101 steps.
Found uncertainty sample 43 after 21 steps.
Found uncertainty sample 44 after 47 steps.
Found uncertainty sample 45 after 293 steps.
Found uncertainty sample 46 after 107 steps.
Found uncertainty sample 47 after 21 steps.
Found uncertainty sample 48 after 104 steps.
Found uncertainty sample 49 after 21 steps.
Found uncertainty sample 50 after 16 steps.
Found uncertainty sample 51 after 216 steps.
Found uncertainty sample 52 after 149 steps.
Found uncertainty sample 53 after 53 steps.
Found uncertainty sample 54 after 206 steps.
Found uncertainty sample 55 after 68 steps.
Found uncertainty sample 56 after 49 steps.
Found uncertainty sample 57 after 20 steps.
Found uncertainty sample 58 after 27 steps.
Found uncertainty sample 59 after 112 steps.
Found uncertainty sample 60 after 68 steps.
Found uncertainty sample 61 after 41 steps.
Found uncertainty sample 62 after 51 steps.
Found uncertainty sample 63 after 28 steps.
Found uncertainty sample 64 after 48 steps.
Found uncertainty sample 65 after 42 steps.
Found uncertainty sample 66 after 13 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 19 steps.
Found uncertainty sample 69 after 178 steps.
Found uncertainty sample 70 after 105 steps.
Found uncertainty sample 71 after 249 steps.
Found uncertainty sample 72 after 9 steps.
Found uncertainty sample 73 after 163 steps.
Found uncertainty sample 74 after 169 steps.
Found uncertainty sample 75 after 63 steps.
Found uncertainty sample 76 after 7 steps.
Found uncertainty sample 77 after 75 steps.
Found uncertainty sample 78 after 106 steps.
Found uncertainty sample 79 after 73 steps.
Found uncertainty sample 80 after 745 steps.
Found uncertainty sample 81 after 44 steps.
Found uncertainty sample 82 after 149 steps.
Found uncertainty sample 83 after 6 steps.
Found uncertainty sample 84 after 82 steps.
Found uncertainty sample 85 after 68 steps.
Found uncertainty sample 86 after 288 steps.
Found uncertainty sample 87 after 29 steps.
Found uncertainty sample 88 after 234 steps.
Found uncertainty sample 89 after 165 steps.
Found uncertainty sample 90 after 30 steps.
Found uncertainty sample 91 after 84 steps.
Found uncertainty sample 92 after 66 steps.
Found uncertainty sample 93 after 62 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 42 steps.
Found uncertainty sample 96 after 14 steps.
Found uncertainty sample 97 after 97 steps.
Found uncertainty sample 98 after 8 steps.
Found uncertainty sample 99 after 16 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_114559-kgv933jr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/kgv933jr
Training model 2. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.312219167282985, Training Loss Force: 3.583650567720374, time: 0.49527835845947266
Validation Loss Energy: 1.9405290970653655, Validation Loss Force: 3.532119164945089, time: 0.045908212661743164
Test Loss Energy: 9.295484093671035, Test Loss Force: 10.130780594461045, time: 9.017629146575928


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2247406987494793, Training Loss Force: 3.1809110966771437, time: 0.503046989440918
Validation Loss Energy: 1.7247898602971423, Validation Loss Force: 3.400223545715369, time: 0.045711517333984375
Test Loss Energy: 8.913976973904964, Test Loss Force: 10.135998327111727, time: 9.065039157867432


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1919906725862925, Training Loss Force: 3.14093355054576, time: 0.47399020195007324
Validation Loss Energy: 2.410717710944774, Validation Loss Force: 3.370498773418031, time: 0.04485750198364258
Test Loss Energy: 9.641594299052597, Test Loss Force: 10.197334317715862, time: 9.21636700630188


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8189402202604916, Training Loss Force: 3.1201612249981974, time: 0.4871349334716797
Validation Loss Energy: 2.2615939572254753, Validation Loss Force: 3.341414842922673, time: 0.04509472846984863
Test Loss Energy: 8.973131566985199, Test Loss Force: 10.110315266782795, time: 9.019551992416382


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.785304031624461, Training Loss Force: 3.118337746876896, time: 0.4681525230407715
Validation Loss Energy: 1.667557432388469, Validation Loss Force: 3.341713442247362, time: 0.04834747314453125
Test Loss Energy: 8.985712070620288, Test Loss Force: 10.147327238954347, time: 9.073115587234497


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7726170235051457, Training Loss Force: 3.106507524085149, time: 0.49175286293029785
Validation Loss Energy: 2.956814236670966, Validation Loss Force: 3.340510360851914, time: 0.05526852607727051
Test Loss Energy: 8.766372852002707, Test Loss Force: 10.157795477423408, time: 9.61748480796814


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 20.9895554328064, Training Loss Force: 5.657360968916496, time: 0.48565077781677246
Validation Loss Energy: 3.244658864280963, Validation Loss Force: 9.450910445104503, time: 0.04734206199645996
Test Loss Energy: 9.756077968664066, Test Loss Force: 13.84333328986996, time: 9.079523086547852


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 12.29797332692442, Training Loss Force: 7.451696665213172, time: 0.5308837890625
Validation Loss Energy: 8.74545361968242, Validation Loss Force: 6.808298405516152, time: 0.046575069427490234
Test Loss Energy: 9.97086496257844, Test Loss Force: 11.447692243323566, time: 9.07721757888794


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 20.376705527728234, Training Loss Force: 6.735278337055756, time: 0.4852030277252197
Validation Loss Energy: 8.290752535578873, Validation Loss Force: 9.771897816401829, time: 0.046361684799194336
Test Loss Energy: 11.88788384680989, Test Loss Force: 13.964373313752233, time: 9.142132043838501


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.519160312793863, Training Loss Force: 8.834392237909697, time: 0.5049681663513184
Validation Loss Energy: 9.944323896242471, Validation Loss Force: 6.245064816981066, time: 0.05561041831970215
Test Loss Energy: 10.303667499174352, Test Loss Force: 10.927012304746405, time: 9.208744287490845


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.374866358609061, Training Loss Force: 5.739694505035266, time: 0.4710721969604492
Validation Loss Energy: 10.865351175220164, Validation Loss Force: 4.481996794484061, time: 0.04793357849121094
Test Loss Energy: 14.84599125028422, Test Loss Force: 10.27129874061439, time: 9.151884078979492


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.355037542960742, Training Loss Force: 5.433251423516551, time: 0.49678945541381836
Validation Loss Energy: 3.0965852182538596, Validation Loss Force: 5.221746449732191, time: 0.04599308967590332
Test Loss Energy: 9.362782529804083, Test Loss Force: 10.34488046170207, time: 8.991766452789307


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.560337982692374, Training Loss Force: 5.323257251335644, time: 0.5042786598205566
Validation Loss Energy: 4.209269843198539, Validation Loss Force: 4.637563702609927, time: 0.04569292068481445
Test Loss Energy: 11.730063403351682, Test Loss Force: 10.672768907087468, time: 9.054763317108154


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.065323812641777, Training Loss Force: 5.382240162371053, time: 0.5024831295013428
Validation Loss Energy: 6.2122019684101675, Validation Loss Force: 5.756846237017593, time: 0.046379804611206055
Test Loss Energy: 11.45604592698156, Test Loss Force: 11.693442083795038, time: 8.597891092300415


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 9.852086029765282, Training Loss Force: 5.408910635974099, time: 0.4833183288574219
Validation Loss Energy: 18.648573035809246, Validation Loss Force: 5.370511260788254, time: 0.04889273643493652
Test Loss Energy: 13.021856802083276, Test Loss Force: 10.7730448722306, time: 8.884567975997925


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.744294511926395, Training Loss Force: 5.813617571105448, time: 0.4949054718017578
Validation Loss Energy: 18.888870452681843, Validation Loss Force: 7.08150454080371, time: 0.04494905471801758
Test Loss Energy: 24.378300973452973, Test Loss Force: 12.14444185643234, time: 8.774454593658447


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 12.212958368465088, Training Loss Force: 5.4030218332751945, time: 0.4999821186065674
Validation Loss Energy: 10.937585936835722, Validation Loss Force: 6.4841918848226685, time: 0.04323744773864746
Test Loss Energy: 10.370809721826364, Test Loss Force: 11.566243674861893, time: 8.704163789749146


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.66281598484269, Training Loss Force: 5.264273287682452, time: 0.492689847946167
Validation Loss Energy: 16.42209177620512, Validation Loss Force: 5.456127102059196, time: 0.04347705841064453
Test Loss Energy: 21.268197008887, Test Loss Force: 11.037868257958873, time: 8.869701385498047


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 12.562187852682719, Training Loss Force: 5.297992845670983, time: 0.5088906288146973
Validation Loss Energy: 20.217784854523227, Validation Loss Force: 5.537598625186131, time: 0.045078277587890625
Test Loss Energy: 14.453077146909228, Test Loss Force: 10.781724235745173, time: 9.139955759048462


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.5392395347073, Training Loss Force: 5.861203209139394, time: 0.47965478897094727
Validation Loss Energy: 8.45068331362663, Validation Loss Force: 5.1699513796979275, time: 0.04910635948181152
Test Loss Energy: 13.550582819134306, Test Loss Force: 10.773790741589423, time: 8.903696298599243

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–â–‚â–‚â–‚â–„â–â–‚â–‚â–ƒâ–ˆâ–‚â–‡â–„â–ƒ
wandb:   test_error_force â–â–â–â–â–â–â–ˆâ–ƒâ–ˆâ–‚â–â–â–‚â–„â–‚â–…â–„â–ƒâ–‚â–‚
wandb:          test_loss â–â–â–â–â–â–â–†â–ƒâ–‡â–‚â–ƒâ–â–ƒâ–„â–ƒâ–ˆâ–ƒâ–†â–ƒâ–ƒ
wandb: train_error_energy â–‚â–â–â–â–â–â–ˆâ–…â–ˆâ–…â–„â–„â–…â–„â–„â–…â–…â–…â–…â–ƒ
wandb:  train_error_force â–‚â–â–â–â–â–â–„â–†â–…â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:         train_loss â–‚â–â–â–â–â–â–‡â–‡â–ˆâ–ˆâ–…â–…â–…â–„â–„â–…â–…â–…â–…â–…
wandb: valid_error_energy â–â–â–â–â–â–â–‚â–„â–ƒâ–„â–„â–‚â–‚â–ƒâ–‡â–‡â–„â–‡â–ˆâ–„
wandb:  valid_error_force â–â–â–â–â–â–â–ˆâ–…â–ˆâ–„â–‚â–ƒâ–‚â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒ
wandb:         valid_loss â–â–â–â–â–â–â–‡â–…â–ˆâ–…â–„â–ƒâ–ƒâ–„â–†â–‡â–†â–†â–†â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1049
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 13.55058
wandb:   test_error_force 10.77379
wandb:          test_loss 4.51176
wandb: train_error_energy 8.53924
wandb:  train_error_force 5.8612
wandb:         train_loss 2.53263
wandb: valid_error_energy 8.45068
wandb:  valid_error_force 5.16995
wandb:         valid_loss 2.29541
wandb: 
wandb: ğŸš€ View run al_79_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/kgv933jr
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_114559-kgv933jr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.9330145716667175, Uncertainty Bias: -0.4912031292915344
0.00022125244 0.022820473
-6.086254 10.319729
(48745, 22, 3)
Found uncertainty sample 0 after 154 steps.
Found uncertainty sample 1 after 273 steps.
Found uncertainty sample 2 after 6 steps.
Found uncertainty sample 3 after 108 steps.
Found uncertainty sample 4 after 14 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 2 steps.
Found uncertainty sample 7 after 77 steps.
Found uncertainty sample 8 after 41 steps.
Found uncertainty sample 9 after 26 steps.
Found uncertainty sample 10 after 96 steps.
Found uncertainty sample 11 after 420 steps.
Found uncertainty sample 12 after 38 steps.
Found uncertainty sample 13 after 60 steps.
Found uncertainty sample 14 after 10 steps.
Found uncertainty sample 15 after 18 steps.
Found uncertainty sample 16 after 93 steps.
Found uncertainty sample 17 after 57 steps.
Found uncertainty sample 18 after 242 steps.
Found uncertainty sample 19 after 8 steps.
Found uncertainty sample 20 after 32 steps.
Found uncertainty sample 21 after 46 steps.
Found uncertainty sample 22 after 85 steps.
Found uncertainty sample 23 after 58 steps.
Found uncertainty sample 24 after 228 steps.
Found uncertainty sample 25 after 32 steps.
Found uncertainty sample 26 after 337 steps.
Found uncertainty sample 27 after 159 steps.
Found uncertainty sample 28 after 15 steps.
Found uncertainty sample 29 after 84 steps.
Found uncertainty sample 30 after 82 steps.
Found uncertainty sample 31 after 38 steps.
Found uncertainty sample 32 after 44 steps.
Found uncertainty sample 33 after 117 steps.
Found uncertainty sample 34 after 70 steps.
Found uncertainty sample 35 after 230 steps.
Found uncertainty sample 36 after 274 steps.
Found uncertainty sample 37 after 54 steps.
Found uncertainty sample 38 after 238 steps.
Found uncertainty sample 39 after 92 steps.
Found uncertainty sample 40 after 68 steps.
Found uncertainty sample 41 after 90 steps.
Found uncertainty sample 42 after 90 steps.
Found uncertainty sample 43 after 65 steps.
Found uncertainty sample 44 after 107 steps.
Found uncertainty sample 45 after 98 steps.
Found uncertainty sample 46 after 72 steps.
Found uncertainty sample 47 after 171 steps.
Found uncertainty sample 48 after 10 steps.
Found uncertainty sample 49 after 11 steps.
Found uncertainty sample 50 after 17 steps.
Found uncertainty sample 51 after 39 steps.
Found uncertainty sample 52 after 33 steps.
Found uncertainty sample 53 after 74 steps.
Found uncertainty sample 54 after 332 steps.
Found uncertainty sample 55 after 55 steps.
Found uncertainty sample 56 after 24 steps.
Found uncertainty sample 57 after 54 steps.
Found uncertainty sample 58 after 30 steps.
Found uncertainty sample 59 after 16 steps.
Found uncertainty sample 60 after 29 steps.
Found uncertainty sample 61 after 117 steps.
Found uncertainty sample 62 after 101 steps.
Found uncertainty sample 63 after 116 steps.
Found uncertainty sample 64 after 209 steps.
Found uncertainty sample 65 after 249 steps.
Found uncertainty sample 66 after 6 steps.
Found uncertainty sample 67 after 159 steps.
Found uncertainty sample 68 after 2 steps.
Found uncertainty sample 69 after 237 steps.
Found uncertainty sample 70 after 21 steps.
Found uncertainty sample 71 after 198 steps.
Found uncertainty sample 72 after 45 steps.
Found uncertainty sample 73 after 250 steps.
Found uncertainty sample 74 after 60 steps.
Found uncertainty sample 75 after 240 steps.
Found uncertainty sample 76 after 40 steps.
Found uncertainty sample 77 after 111 steps.
Found uncertainty sample 78 after 35 steps.
Found uncertainty sample 79 after 215 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 84 steps.
Found uncertainty sample 82 after 114 steps.
Found uncertainty sample 83 after 124 steps.
Found uncertainty sample 84 after 40 steps.
Found uncertainty sample 85 after 193 steps.
Found uncertainty sample 86 after 64 steps.
Found uncertainty sample 87 after 62 steps.
Found uncertainty sample 88 after 90 steps.
Found uncertainty sample 89 after 155 steps.
Found uncertainty sample 90 after 113 steps.
Found uncertainty sample 91 after 90 steps.
Found uncertainty sample 92 after 265 steps.
Found uncertainty sample 93 after 16 steps.
Found uncertainty sample 94 after 75 steps.
Found uncertainty sample 95 after 297 steps.
Found uncertainty sample 96 after 17 steps.
Found uncertainty sample 97 after 808 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 2 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_115650-iax4d5z2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/iax4d5z2
Training model 3. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.865530549889706, Training Loss Force: 3.513125690910832, time: 0.5325145721435547
Validation Loss Energy: 1.5186143746810905, Validation Loss Force: 3.476368822871711, time: 0.057865142822265625
Test Loss Energy: 8.859699483309264, Test Loss Force: 10.073449281632861, time: 8.970119714736938


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0771881056931187, Training Loss Force: 3.1572583545464257, time: 0.5312774181365967
Validation Loss Energy: 1.9192566228783003, Validation Loss Force: 3.430158963024755, time: 0.04955625534057617
Test Loss Energy: 9.22427015001143, Test Loss Force: 10.115176099264184, time: 9.340095043182373


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7049957824413295, Training Loss Force: 3.1360421414302313, time: 0.5238831043243408
Validation Loss Energy: 2.3736740264899354, Validation Loss Force: 3.3181131848087677, time: 0.04769110679626465
Test Loss Energy: 8.56079200317505, Test Loss Force: 10.021039936207597, time: 9.168688535690308


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1046545381325, Training Loss Force: 3.108275478305404, time: 0.5290486812591553
Validation Loss Energy: 1.91089495111042, Validation Loss Force: 3.3400937468798833, time: 0.04768490791320801
Test Loss Energy: 9.296448407291045, Test Loss Force: 10.080398498888734, time: 8.88341736793518


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6848300017431683, Training Loss Force: 3.0838184394753116, time: 0.5373246669769287
Validation Loss Energy: 1.7763440023155113, Validation Loss Force: 3.356693286370508, time: 0.046181440353393555
Test Loss Energy: 8.640799629388232, Test Loss Force: 10.082051865095336, time: 8.806727170944214


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8141389075235428, Training Loss Force: 3.1147545504822594, time: 0.5406012535095215
Validation Loss Energy: 1.58088881139558, Validation Loss Force: 3.2739659092605407, time: 0.04884696006774902
Test Loss Energy: 8.912188192215039, Test Loss Force: 10.071830050256587, time: 9.228892803192139


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 23.267051499955777, Training Loss Force: 6.831338495421386, time: 0.614781379699707
Validation Loss Energy: 14.208470995793206, Validation Loss Force: 9.559922133538077, time: 0.04948568344116211
Test Loss Energy: 15.434451019366628, Test Loss Force: 13.923263054162105, time: 8.921766519546509


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.500743654280816, Training Loss Force: 7.960962780791841, time: 0.5450654029846191
Validation Loss Energy: 18.140930135569906, Validation Loss Force: 5.96004163011912, time: 0.047542572021484375
Test Loss Energy: 22.80904569345229, Test Loss Force: 11.320756583982618, time: 8.95832085609436


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.453554474868246, Training Loss Force: 4.9870827849207116, time: 0.5295653343200684
Validation Loss Energy: 4.470338728679866, Validation Loss Force: 4.013433220031634, time: 0.04651141166687012
Test Loss Energy: 11.630675736545886, Test Loss Force: 10.043285353318437, time: 8.462708950042725


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 23.404598888891673, Training Loss Force: 6.001592818465483, time: 0.5467193126678467
Validation Loss Energy: 3.9173318886789517, Validation Loss Force: 10.994263250563597, time: 0.04869413375854492
Test Loss Energy: 9.358062424222915, Test Loss Force: 14.366313990622917, time: 8.743154287338257


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.855270475668478, Training Loss Force: 8.390594114798752, time: 0.5190415382385254
Validation Loss Energy: 11.206905159511965, Validation Loss Force: 6.239549302236434, time: 0.04853248596191406
Test Loss Energy: 10.589994536295443, Test Loss Force: 10.940045799030806, time: 8.91706657409668


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 12.879486638728476, Training Loss Force: 6.089461032370534, time: 0.520097017288208
Validation Loss Energy: 13.568347969816086, Validation Loss Force: 7.8373313537261176, time: 0.04691338539123535
Test Loss Energy: 16.70870757440524, Test Loss Force: 12.651049095660404, time: 8.9427490234375


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 9.536140771860795, Training Loss Force: 5.825026836752227, time: 0.5459558963775635
Validation Loss Energy: 20.248256681805152, Validation Loss Force: 8.726379780642246, time: 0.04772329330444336
Test Loss Energy: 15.684974247464531, Test Loss Force: 13.433469461883641, time: 9.4415762424469


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 14.818230516842638, Training Loss Force: 8.243413198859706, time: 0.6028366088867188
Validation Loss Energy: 12.2808758587382, Validation Loss Force: 6.443645614702386, time: 0.04937005043029785
Test Loss Energy: 17.028358734971416, Test Loss Force: 11.482120712467886, time: 8.957317352294922


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 12.540556630949068, Training Loss Force: 6.553037683889746, time: 0.5303671360015869
Validation Loss Energy: 23.086572188411143, Validation Loss Force: 7.950432138355511, time: 0.047492027282714844
Test Loss Energy: 19.393124044063242, Test Loss Force: 12.31486808754886, time: 9.031223058700562


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.507088977510585, Training Loss Force: 5.918035547263389, time: 0.5427017211914062
Validation Loss Energy: 12.629073399667904, Validation Loss Force: 4.4651589990072935, time: 0.05480813980102539
Test Loss Energy: 17.252860426985663, Test Loss Force: 10.564461664556728, time: 9.274259805679321


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.491138017245905, Training Loss Force: 5.312937542931413, time: 0.579679012298584
Validation Loss Energy: 23.181480903818237, Validation Loss Force: 6.348448765420462, time: 0.051210641860961914
Test Loss Energy: 26.799031931692607, Test Loss Force: 12.263107714263922, time: 8.976571559906006


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 17.423749309535417, Training Loss Force: 7.7432254966656835, time: 0.5414257049560547
Validation Loss Energy: 18.304768311790404, Validation Loss Force: 9.606309460694337, time: 0.04763436317443848
Test Loss Energy: 22.340222787553937, Test Loss Force: 14.483803521164972, time: 8.401360034942627


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 15.184584438078751, Training Loss Force: 7.471855206633759, time: 0.5436992645263672
Validation Loss Energy: 19.181500462906975, Validation Loss Force: 5.543630287011023, time: 0.04568839073181152
Test Loss Energy: 23.54379052039584, Test Loss Force: 11.071891198790372, time: 8.615869998931885


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.213506334789093, Training Loss Force: 5.304553455802843, time: 0.5205380916595459
Validation Loss Energy: 19.924844888846962, Validation Loss Force: 5.249003825223503, time: 0.047187089920043945
Test Loss Energy: 23.78087389117868, Test Loss Force: 11.067758627318165, time: 8.92311716079712

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–„â–†â–‚â–â–‚â–„â–„â–„â–…â–„â–ˆâ–†â–‡â–‡
wandb:   test_error_force â–â–â–â–â–â–â–‡â–ƒâ–â–ˆâ–‚â–…â–†â–ƒâ–…â–‚â–…â–ˆâ–ƒâ–ƒ
wandb:          test_loss â–â–â–â–â–â–â–†â–…â–‚â–…â–‚â–…â–†â–„â–…â–ƒâ–‡â–ˆâ–…â–…
wandb: train_error_energy â–‚â–â–â–â–â–â–ˆâ–„â–ƒâ–ˆâ–„â–…â–„â–…â–„â–ƒâ–ƒâ–†â–…â–„
wandb:  train_error_force â–‚â–â–â–â–â–â–†â–‡â–„â–…â–ˆâ–…â–…â–ˆâ–†â–…â–„â–‡â–‡â–„
wandb:         train_loss â–‚â–â–â–â–â–â–ˆâ–‡â–„â–‡â–‡â–†â–…â–ˆâ–†â–„â–„â–ˆâ–‡â–…
wandb: valid_error_energy â–â–â–â–â–â–â–…â–†â–‚â–‚â–„â–…â–‡â–„â–ˆâ–…â–ˆâ–†â–‡â–‡
wandb:  valid_error_force â–â–â–â–â–â–â–‡â–ƒâ–‚â–ˆâ–„â–…â–†â–„â–…â–‚â–„â–‡â–ƒâ–ƒ
wandb:         valid_loss â–â–â–â–â–â–â–‡â–…â–‚â–‡â–…â–†â–ˆâ–…â–‡â–ƒâ–†â–ˆâ–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1139
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 23.78087
wandb:   test_error_force 11.06776
wandb:          test_loss 5.29474
wandb: train_error_energy 11.21351
wandb:  train_error_force 5.30455
wandb:         train_loss 2.52534
wandb: valid_error_energy 19.92484
wandb:  valid_error_force 5.249
wandb:         valid_loss 3.08972
wandb: 
wandb: ğŸš€ View run al_79_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/iax4d5z2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_115650-iax4d5z2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.587074339389801, Uncertainty Bias: -0.35192030668258667
0.0002670288 0.0049700737
-0.7154667 6.024604
(48745, 22, 3)
Found uncertainty sample 0 after 1179 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2943 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1203 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 691 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1307 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3385 steps.
Found uncertainty sample 19 after 3932 steps.
Found uncertainty sample 20 after 1538 steps.
Found uncertainty sample 21 after 2983 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2039 steps.
Found uncertainty sample 25 after 95 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3001 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1263 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3659 steps.
Found uncertainty sample 33 after 2721 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 949 steps.
Found uncertainty sample 36 after 3459 steps.
Found uncertainty sample 37 after 944 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1044 steps.
Found uncertainty sample 40 after 3401 steps.
Found uncertainty sample 41 after 2906 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 861 steps.
Found uncertainty sample 44 after 2558 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2367 steps.
Found uncertainty sample 47 after 1292 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1395 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1663 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1000 steps.
Found uncertainty sample 55 after 3816 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3417 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1691 steps.
Found uncertainty sample 63 after 530 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 351 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2331 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3826 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 825 steps.
Found uncertainty sample 79 after 1674 steps.
Found uncertainty sample 80 after 1945 steps.
Found uncertainty sample 81 after 1298 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2943 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 984 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 156 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2134 steps.
Found uncertainty sample 98 after 3128 steps.
Found uncertainty sample 99 after 2204 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_134222-0vc9po3q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/0vc9po3q
Training model 4. Added 45 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.0751879952604115, Training Loss Force: 3.5688631969103595, time: 0.560966968536377
Validation Loss Energy: 1.6477378743785824, Validation Loss Force: 3.4021055453367506, time: 0.05235791206359863
Test Loss Energy: 8.672750651303977, Test Loss Force: 9.950668409383198, time: 10.227399110794067


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9053634733952598, Training Loss Force: 3.2285309440594987, time: 0.5817408561706543
Validation Loss Energy: 1.6412674430016398, Validation Loss Force: 3.3276109145591715, time: 0.05223655700683594
Test Loss Energy: 8.464289403368493, Test Loss Force: 9.983804511467785, time: 9.595002889633179


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.142765615139156, Training Loss Force: 3.186220664892835, time: 0.5837504863739014
Validation Loss Energy: 2.099946177393468, Validation Loss Force: 3.3372622860202656, time: 0.0523378849029541
Test Loss Energy: 9.326614718515074, Test Loss Force: 9.977619317518064, time: 9.871592998504639


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0753882199582385, Training Loss Force: 3.160674549932659, time: 0.59316086769104
Validation Loss Energy: 2.0470593605367213, Validation Loss Force: 3.311374771114701, time: 0.0493471622467041
Test Loss Energy: 9.309409961954204, Test Loss Force: 9.951187366058441, time: 9.598294258117676


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0816213341703023, Training Loss Force: 3.138751280030981, time: 0.5590417385101318
Validation Loss Energy: 1.7716902171656204, Validation Loss Force: 3.27219925225675, time: 0.06639599800109863
Test Loss Energy: 9.083660739819237, Test Loss Force: 9.973088366461845, time: 9.601879596710205


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.811654694934189, Training Loss Force: 3.1438552841396836, time: 0.6275827884674072
Validation Loss Energy: 1.4639971958913391, Validation Loss Force: 3.324763421521047, time: 0.05799531936645508
Test Loss Energy: 8.800989622301218, Test Loss Force: 9.984361697287703, time: 9.71636962890625


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.937153164774012, Training Loss Force: 5.713909523344499, time: 0.5854980945587158
Validation Loss Energy: 2.955854755321163, Validation Loss Force: 7.4381488131150375, time: 0.05472612380981445
Test Loss Energy: 8.693394571295334, Test Loss Force: 12.20044294145114, time: 9.664097547531128


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 13.752926356711692, Training Loss Force: 7.6002526975930085, time: 0.562800407409668
Validation Loss Energy: 17.807216777244516, Validation Loss Force: 6.180777562521962, time: 0.058487892150878906
Test Loss Energy: 13.719767848130754, Test Loss Force: 10.755387176315931, time: 9.761267900466919


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 15.666644156802061, Training Loss Force: 6.557112659986404, time: 0.5850751399993896
Validation Loss Energy: 29.28495976300795, Validation Loss Force: 6.177718088456914, time: 0.05150127410888672
Test Loss Energy: 24.211432799432796, Test Loss Force: 10.757977618226706, time: 9.82277536392212


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 16.554891799270496, Training Loss Force: 6.755972757033738, time: 0.5859169960021973
Validation Loss Energy: 21.848529955699476, Validation Loss Force: 7.246587882888237, time: 0.05016160011291504
Test Loss Energy: 18.883528342408958, Test Loss Force: 12.299928885790976, time: 9.753573656082153


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 14.282473305089137, Training Loss Force: 7.567659242580173, time: 0.5515661239624023
Validation Loss Energy: 2.6055935167470015, Validation Loss Force: 5.983103028224569, time: 0.052916526794433594
Test Loss Energy: 10.703166337226897, Test Loss Force: 10.888752140275733, time: 9.929307222366333


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.564918221033704, Training Loss Force: 7.281730213560254, time: 0.5569818019866943
Validation Loss Energy: 3.399026476386861, Validation Loss Force: 11.06558952206377, time: 0.05080389976501465
Test Loss Energy: 8.871085207260885, Test Loss Force: 14.12810823211099, time: 9.76356816291809


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.350252165451863, Training Loss Force: 8.313536018517862, time: 0.5557610988616943
Validation Loss Energy: 6.534136128915979, Validation Loss Force: 8.946257546156682, time: 0.057523488998413086
Test Loss Energy: 9.059125229998692, Test Loss Force: 12.97219116488961, time: 9.465680837631226


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.748945983552344, Training Loss Force: 6.55382567823507, time: 0.5543575286865234
Validation Loss Energy: 11.78708743275849, Validation Loss Force: 7.971861816959601, time: 0.05255866050720215
Test Loss Energy: 17.56238796164579, Test Loss Force: 12.196310822312068, time: 9.747719526290894


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 6.6351633711872156, Training Loss Force: 5.833735289302183, time: 0.5981156826019287
Validation Loss Energy: 5.352583277173024, Validation Loss Force: 4.241413025089799, time: 0.05186319351196289
Test Loss Energy: 12.365094310055797, Test Loss Force: 10.41874968946039, time: 9.85566759109497


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 10.433536772177616, Training Loss Force: 5.4874589859082255, time: 0.5272233486175537
Validation Loss Energy: 4.771947204207097, Validation Loss Force: 4.523354470972105, time: 0.051734209060668945
Test Loss Energy: 8.389708818803165, Test Loss Force: 10.468036565271026, time: 9.656407833099365


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 11.17858394305843, Training Loss Force: 5.118763943672477, time: 0.5777103900909424
Validation Loss Energy: 12.975478008634596, Validation Loss Force: 5.299421018582764, time: 0.05305790901184082
Test Loss Energy: 16.810027230638582, Test Loss Force: 10.739983400449923, time: 9.62240219116211


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.391368588947422, Training Loss Force: 5.052421266435824, time: 0.5627820491790771
Validation Loss Energy: 21.19407327146069, Validation Loss Force: 5.934497916374868, time: 0.05716705322265625
Test Loss Energy: 23.500300955877567, Test Loss Force: 11.313174011737614, time: 9.865819454193115


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.27213393133707, Training Loss Force: 4.718427537565284, time: 0.5685548782348633
Validation Loss Energy: 3.2300199266202325, Validation Loss Force: 5.265094788384829, time: 0.055147647857666016
Test Loss Energy: 8.963896001591854, Test Loss Force: 10.897602080014154, time: 9.63861632347107


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 13.21180753956187, Training Loss Force: 6.081664492554651, time: 0.5774941444396973
Validation Loss Energy: 2.2004868635085124, Validation Loss Force: 6.0569116153635445, time: 0.052045345306396484
Test Loss Energy: 8.343901438683604, Test Loss Force: 10.910058910174493, time: 9.571233749389648

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–â–ƒâ–ˆâ–†â–‚â–â–â–…â–ƒâ–â–…â–ˆâ–â–
wandb:   test_error_force â–â–â–â–â–â–â–…â–‚â–‚â–…â–ƒâ–ˆâ–†â–…â–‚â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–â–â–â–â–â–â–…â–„â–‡â–ˆâ–ƒâ–ˆâ–†â–‡â–ƒâ–‚â–…â–ˆâ–ƒâ–‚
wandb: train_error_energy â–â–â–â–â–â–â–‚â–‡â–ˆâ–ˆâ–‡â–‡â–†â–…â–ƒâ–…â–…â–†â–…â–†
wandb:  train_error_force â–‚â–â–â–â–â–â–„â–‡â–†â–†â–‡â–‡â–ˆâ–†â–…â–„â–„â–„â–ƒâ–…
wandb:         train_loss â–â–â–â–â–â–â–„â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–†â–…â–…â–…â–…â–„â–†
wandb: valid_error_energy â–â–â–â–â–â–â–â–…â–ˆâ–†â–â–â–‚â–„â–‚â–‚â–„â–†â–â–
wandb:  valid_error_force â–â–â–â–â–â–â–…â–„â–„â–…â–ƒâ–ˆâ–†â–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–„
wandb:         valid_loss â–â–â–â–â–â–â–…â–†â–ˆâ–ˆâ–ƒâ–ˆâ–‡â–‡â–‚â–ƒâ–…â–†â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1179
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.3439
wandb:   test_error_force 10.91006
wandb:          test_loss 4.20892
wandb: train_error_energy 13.21181
wandb:  train_error_force 6.08166
wandb:         train_loss 2.91909
wandb: valid_error_energy 2.20049
wandb:  valid_error_force 6.05691
wandb:         valid_loss 2.17392
wandb: 
wandb: ğŸš€ View run al_79_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/0vc9po3q
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_134222-0vc9po3q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.9536910057067871, Uncertainty Bias: -0.5024042725563049
0.00039577484 0.020613194
6.927679 23.501894
(48745, 22, 3)
Found uncertainty sample 0 after 59 steps.
Found uncertainty sample 1 after 27 steps.
Found uncertainty sample 2 after 10 steps.
Found uncertainty sample 3 after 230 steps.
Found uncertainty sample 4 after 114 steps.
Found uncertainty sample 5 after 78 steps.
Found uncertainty sample 6 after 62 steps.
Found uncertainty sample 7 after 62 steps.
Found uncertainty sample 8 after 52 steps.
Found uncertainty sample 9 after 67 steps.
Found uncertainty sample 10 after 249 steps.
Found uncertainty sample 11 after 107 steps.
Found uncertainty sample 12 after 16 steps.
Found uncertainty sample 13 after 40 steps.
Found uncertainty sample 14 after 78 steps.
Found uncertainty sample 15 after 67 steps.
Found uncertainty sample 16 after 52 steps.
Found uncertainty sample 17 after 168 steps.
Found uncertainty sample 18 after 23 steps.
Found uncertainty sample 19 after 61 steps.
Found uncertainty sample 20 after 143 steps.
Found uncertainty sample 21 after 126 steps.
Found uncertainty sample 22 after 266 steps.
Found uncertainty sample 23 after 6 steps.
Found uncertainty sample 24 after 140 steps.
Found uncertainty sample 25 after 9 steps.
Found uncertainty sample 26 after 149 steps.
Found uncertainty sample 27 after 150 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 64 steps.
Found uncertainty sample 30 after 53 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 4 steps.
Found uncertainty sample 33 after 17 steps.
Found uncertainty sample 34 after 26 steps.
Found uncertainty sample 35 after 108 steps.
Found uncertainty sample 36 after 66 steps.
Found uncertainty sample 37 after 87 steps.
Found uncertainty sample 38 after 251 steps.
Found uncertainty sample 39 after 19 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 111 steps.
Found uncertainty sample 42 after 132 steps.
Found uncertainty sample 43 after 5 steps.
Found uncertainty sample 44 after 13 steps.
Found uncertainty sample 45 after 28 steps.
Found uncertainty sample 46 after 18 steps.
Found uncertainty sample 47 after 83 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 94 steps.
Found uncertainty sample 50 after 4 steps.
Found uncertainty sample 51 after 56 steps.
Found uncertainty sample 52 after 11 steps.
Found uncertainty sample 53 after 73 steps.
Found uncertainty sample 54 after 111 steps.
Found uncertainty sample 55 after 144 steps.
Found uncertainty sample 56 after 37 steps.
Found uncertainty sample 57 after 75 steps.
Found uncertainty sample 58 after 3 steps.
Found uncertainty sample 59 after 16 steps.
Found uncertainty sample 60 after 11 steps.
Found uncertainty sample 61 after 18 steps.
Found uncertainty sample 62 after 16 steps.
Found uncertainty sample 63 after 158 steps.
Found uncertainty sample 64 after 38 steps.
Found uncertainty sample 65 after 106 steps.
Found uncertainty sample 66 after 2 steps.
Found uncertainty sample 67 after 14 steps.
Found uncertainty sample 68 after 112 steps.
Found uncertainty sample 69 after 18 steps.
Found uncertainty sample 70 after 44 steps.
Found uncertainty sample 71 after 11 steps.
Found uncertainty sample 72 after 83 steps.
Found uncertainty sample 73 after 113 steps.
Found uncertainty sample 74 after 60 steps.
Found uncertainty sample 75 after 6 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 100 steps.
Found uncertainty sample 78 after 232 steps.
Found uncertainty sample 79 after 135 steps.
Found uncertainty sample 80 after 54 steps.
Found uncertainty sample 81 after 91 steps.
Found uncertainty sample 82 after 88 steps.
Found uncertainty sample 83 after 39 steps.
Found uncertainty sample 84 after 148 steps.
Found uncertainty sample 85 after 134 steps.
Found uncertainty sample 86 after 2 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 417 steps.
Found uncertainty sample 89 after 88 steps.
Found uncertainty sample 90 after 5 steps.
Found uncertainty sample 91 after 13 steps.
Found uncertainty sample 92 after 62 steps.
Found uncertainty sample 93 after 62 steps.
Found uncertainty sample 94 after 15 steps.
Found uncertainty sample 95 after 60 steps.
Found uncertainty sample 96 after 37 steps.
Found uncertainty sample 97 after 192 steps.
Found uncertainty sample 98 after 12 steps.
Found uncertainty sample 99 after 37 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_135216-g7gh1e4e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/g7gh1e4e
Training model 5. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.503805049603329, Training Loss Force: 3.606246592034119, time: 0.6644229888916016
Validation Loss Energy: 2.534670499070104, Validation Loss Force: 3.5468001870743997, time: 0.059207916259765625
Test Loss Energy: 8.588737302751731, Test Loss Force: 9.821456721628753, time: 9.533765316009521


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.3701185123685042, Training Loss Force: 3.217671402761616, time: 0.6608552932739258
Validation Loss Energy: 1.4253952727532977, Validation Loss Force: 3.2922512768549845, time: 0.053369760513305664
Test Loss Energy: 8.66810925168815, Test Loss Force: 9.832854500025237, time: 9.801029920578003


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.735353071652586, Training Loss Force: 3.1700255829929436, time: 0.6304359436035156
Validation Loss Energy: 1.5529629831281921, Validation Loss Force: 3.296604235988727, time: 0.06696915626525879
Test Loss Energy: 9.297717719350628, Test Loss Force: 9.918824296636867, time: 10.104910612106323


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9204920497505582, Training Loss Force: 3.142170769482921, time: 0.5938866138458252
Validation Loss Energy: 3.8800606363569745, Validation Loss Force: 3.3290166248774136, time: 0.05549979209899902
Test Loss Energy: 10.935404660555756, Test Loss Force: 9.971321534586997, time: 9.879120588302612


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.5286650509704165, Training Loss Force: 3.1642158555057973, time: 0.6512441635131836
Validation Loss Energy: 1.6706406207175581, Validation Loss Force: 3.27483699095941, time: 0.05860018730163574
Test Loss Energy: 9.227283793869857, Test Loss Force: 9.97603452408195, time: 9.872395038604736


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9249676856668851, Training Loss Force: 3.1201410921649417, time: 0.5925586223602295
Validation Loss Energy: 1.3345454818727496, Validation Loss Force: 3.221884709373761, time: 0.05508923530578613
Test Loss Energy: 8.840237659020705, Test Loss Force: 9.94203198487377, time: 10.06353235244751


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7.5063554369968415, Training Loss Force: 5.380164001664595, time: 0.610776424407959
Validation Loss Energy: 2.652329321116639, Validation Loss Force: 6.992089518564948, time: 0.055837392807006836
Test Loss Energy: 10.154484641369399, Test Loss Force: 11.574648616724122, time: 9.900291919708252


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.57082470022926, Training Loss Force: 6.216129050535409, time: 0.6042907238006592
Validation Loss Energy: 4.480116576215847, Validation Loss Force: 4.546292955709002, time: 0.054723501205444336
Test Loss Energy: 8.957393125221897, Test Loss Force: 10.26045273869313, time: 10.359888792037964


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 17.03770082747006, Training Loss Force: 6.113492212747886, time: 0.594778299331665
Validation Loss Energy: 11.128034857347759, Validation Loss Force: 8.931016288456217, time: 0.05256462097167969
Test Loss Energy: 15.197669242866782, Test Loss Force: 13.062009724242756, time: 10.046502113342285


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.106613710354255, Training Loss Force: 6.64586242144139, time: 0.6458747386932373
Validation Loss Energy: 22.85584776346027, Validation Loss Force: 7.680929436303024, time: 0.056969642639160156
Test Loss Energy: 16.228238433312594, Test Loss Force: 11.945544430180354, time: 9.80440640449524


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.64900538311827, Training Loss Force: 5.206468963761683, time: 0.6040689945220947
Validation Loss Energy: 14.219983881314256, Validation Loss Force: 4.096597474005911, time: 0.05537295341491699
Test Loss Energy: 12.352161154452297, Test Loss Force: 10.001160118797275, time: 9.946472406387329


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.703713032382012, Training Loss Force: 4.204130951047331, time: 0.5938961505889893
Validation Loss Energy: 7.1349237595883706, Validation Loss Force: 5.131358363325724, time: 0.056513071060180664
Test Loss Energy: 9.246376388413797, Test Loss Force: 10.870221651257445, time: 10.09098744392395


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.366764848039156, Training Loss Force: 4.095962744471987, time: 0.6573331356048584
Validation Loss Energy: 6.347746912272497, Validation Loss Force: 4.035317589031709, time: 0.05717206001281738
Test Loss Energy: 9.083049106147007, Test Loss Force: 10.426699560873534, time: 9.335948944091797


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.311015580344406, Training Loss Force: 3.8215502656859925, time: 0.5968117713928223
Validation Loss Energy: 5.571984530715175, Validation Loss Force: 4.063611712066461, time: 0.049681901931762695
Test Loss Energy: 8.698126390905706, Test Loss Force: 10.11144837061026, time: 9.525669813156128


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 8.830422459566133, Training Loss Force: 4.647113119435829, time: 0.5953848361968994
Validation Loss Energy: 40.000923098901744, Validation Loss Force: 7.42229254323352, time: 0.053389549255371094
Test Loss Energy: 38.913972042876296, Test Loss Force: 12.737097882694298, time: 10.535473346710205


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 16.14870142116641, Training Loss Force: 7.806116345902742, time: 0.6415181159973145
Validation Loss Energy: 33.228125725997444, Validation Loss Force: 7.858635446931905, time: 0.05271506309509277
Test Loss Energy: 27.47250335788075, Test Loss Force: 12.230100890854365, time: 7.65453839302063


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 14.652549709524283, Training Loss Force: 6.723784275511974, time: 0.6156017780303955
Validation Loss Energy: 13.545474504469802, Validation Loss Force: 5.910682560541307, time: 0.04590964317321777
Test Loss Energy: 12.283261305137875, Test Loss Force: 10.808233037205317, time: 7.735855340957642


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.28843966122453, Training Loss Force: 6.695795109006028, time: 0.5729379653930664
Validation Loss Energy: 4.5918470549212005, Validation Loss Force: 4.375299529153259, time: 0.048442840576171875
Test Loss Energy: 9.162962558466953, Test Loss Force: 9.847993651681321, time: 8.51521897315979


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 9.748338296283482, Training Loss Force: 6.3736528530498875, time: 0.5842759609222412
Validation Loss Energy: 24.915013645461087, Validation Loss Force: 6.517450639135027, time: 0.05056428909301758
Test Loss Energy: 19.981649079687347, Test Loss Force: 11.559935917285735, time: 8.659720420837402


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 10.41590622135652, Training Loss Force: 6.139650482201442, time: 0.5675647258758545
Validation Loss Energy: 9.21406083728745, Validation Loss Force: 5.661297570485103, time: 0.051841020584106445
Test Loss Energy: 14.929245131504256, Test Loss Force: 10.8013718430447, time: 8.221280813217163

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–‚â–â–â–â–â–ƒâ–ƒâ–‚â–â–â–â–ˆâ–…â–‚â–â–„â–‚
wandb:   test_error_force â–â–â–â–â–â–â–…â–‚â–ˆâ–†â–â–ƒâ–‚â–‚â–‡â–†â–ƒâ–â–…â–ƒ
wandb:          test_loss â–â–â–â–â–â–â–ƒâ–â–…â–„â–‚â–‚â–‚â–â–ˆâ–†â–‚â–â–„â–ƒ
wandb: train_error_energy â–‚â–â–â–â–â–â–„â–…â–ˆâ–†â–„â–„â–„â–„â–„â–ˆâ–‡â–…â–…â–…
wandb:  train_error_force â–‚â–â–â–â–â–â–„â–†â–…â–†â–„â–ƒâ–‚â–‚â–ƒâ–ˆâ–†â–†â–†â–†
wandb:         train_loss â–‚â–â–â–â–â–â–„â–…â–‡â–†â–„â–ƒâ–ƒâ–ƒâ–„â–ˆâ–‡â–†â–…â–…
wandb: valid_error_energy â–â–â–â–â–â–â–â–‚â–ƒâ–…â–ƒâ–‚â–‚â–‚â–ˆâ–‡â–ƒâ–‚â–…â–‚
wandb:  valid_error_force â–â–â–â–â–â–â–†â–ƒâ–ˆâ–†â–‚â–ƒâ–‚â–‚â–†â–‡â–„â–‚â–…â–„
wandb:         valid_loss â–â–â–â–â–â–â–ƒâ–‚â–…â–†â–ƒâ–ƒâ–‚â–‚â–ˆâ–‡â–„â–‚â–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1269
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 14.92925
wandb:   test_error_force 10.80137
wandb:          test_loss 4.61325
wandb: train_error_energy 10.41591
wandb:  train_error_force 6.13965
wandb:         train_loss 2.75139
wandb: valid_error_energy 9.21406
wandb:  valid_error_force 5.6613
wandb:         valid_loss 2.5109
wandb: 
wandb: ğŸš€ View run al_79_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/g7gh1e4e
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_135216-g7gh1e4e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7894200086593628, Uncertainty Bias: -0.49196386337280273
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:974: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
0.00018596649 0.60019493
2.3986232 13.079956
(48745, 22, 3)
Found uncertainty sample 0 after 261 steps.
Found uncertainty sample 1 after 500 steps.
Found uncertainty sample 2 after 256 steps.
Found uncertainty sample 3 after 103 steps.
Found uncertainty sample 4 after 812 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 682 steps.
Found uncertainty sample 7 after 2734 steps.
Found uncertainty sample 8 after 775 steps.
Found uncertainty sample 9 after 26 steps.
Found uncertainty sample 10 after 196 steps.
Found uncertainty sample 11 after 1414 steps.
Found uncertainty sample 12 after 604 steps.
Found uncertainty sample 13 after 5 steps.
Found uncertainty sample 14 after 1167 steps.
Found uncertainty sample 15 after 639 steps.
Found uncertainty sample 16 after 317 steps.
Found uncertainty sample 17 after 418 steps.
Found uncertainty sample 18 after 532 steps.
Found uncertainty sample 19 after 1065 steps.
Found uncertainty sample 20 after 3761 steps.
Found uncertainty sample 21 after 2076 steps.
Found uncertainty sample 22 after 1715 steps.
Found uncertainty sample 23 after 198 steps.
Found uncertainty sample 24 after 230 steps.
Found uncertainty sample 25 after 1029 steps.
Found uncertainty sample 26 after 46 steps.
Found uncertainty sample 27 after 882 steps.
Found uncertainty sample 28 after 381 steps.
Found uncertainty sample 29 after 158 steps.
Found uncertainty sample 30 after 955 steps.
Found uncertainty sample 31 after 584 steps.
Found uncertainty sample 32 after 348 steps.
Found uncertainty sample 33 after 3804 steps.
Found uncertainty sample 34 after 944 steps.
Found uncertainty sample 35 after 227 steps.
Found uncertainty sample 36 after 865 steps.
Found uncertainty sample 37 after 1000 steps.
Found uncertainty sample 38 after 478 steps.
Found uncertainty sample 39 after 280 steps.
Found uncertainty sample 40 after 93 steps.
Found uncertainty sample 41 after 571 steps.
Found uncertainty sample 42 after 1727 steps.
Found uncertainty sample 43 after 2345 steps.
Found uncertainty sample 44 after 1073 steps.
Found uncertainty sample 45 after 175 steps.
Found uncertainty sample 46 after 1052 steps.
Found uncertainty sample 47 after 1330 steps.
Found uncertainty sample 48 after 414 steps.
Found uncertainty sample 49 after 181 steps.
Found uncertainty sample 50 after 1351 steps.
Found uncertainty sample 51 after 152 steps.
Found uncertainty sample 52 after 215 steps.
Found uncertainty sample 53 after 1212 steps.
Found uncertainty sample 54 after 1010 steps.
Found uncertainty sample 55 after 903 steps.
Found uncertainty sample 56 after 286 steps.
Found uncertainty sample 57 after 35 steps.
Found uncertainty sample 58 after 1112 steps.
Found uncertainty sample 59 after 1619 steps.
Found uncertainty sample 60 after 1243 steps.
Found uncertainty sample 61 after 471 steps.
Found uncertainty sample 62 after 495 steps.
Found uncertainty sample 63 after 567 steps.
Found uncertainty sample 64 after 303 steps.
Found uncertainty sample 65 after 1580 steps.
Found uncertainty sample 66 after 254 steps.
Found uncertainty sample 67 after 476 steps.
Found uncertainty sample 68 after 3468 steps.
Found uncertainty sample 69 after 1142 steps.
Found uncertainty sample 70 after 1578 steps.
Found uncertainty sample 71 after 587 steps.
Found uncertainty sample 72 after 940 steps.
Found uncertainty sample 73 after 321 steps.
Found uncertainty sample 74 after 204 steps.
Found uncertainty sample 75 after 262 steps.
Found uncertainty sample 76 after 1068 steps.
Found uncertainty sample 77 after 815 steps.
Found uncertainty sample 78 after 711 steps.
Found uncertainty sample 79 after 982 steps.
Found uncertainty sample 80 after 46 steps.
Found uncertainty sample 81 after 528 steps.
Found uncertainty sample 82 after 543 steps.
Found uncertainty sample 83 after 511 steps.
Found uncertainty sample 84 after 407 steps.
Found uncertainty sample 85 after 251 steps.
Found uncertainty sample 86 after 1636 steps.
Found uncertainty sample 87 after 114 steps.
Found uncertainty sample 88 after 2477 steps.
Found uncertainty sample 89 after 436 steps.
Found uncertainty sample 90 after 2288 steps.
Found uncertainty sample 91 after 533 steps.
Found uncertainty sample 92 after 3836 steps.
Found uncertainty sample 93 after 248 steps.
Found uncertainty sample 94 after 675 steps.
Found uncertainty sample 95 after 872 steps.
Found uncertainty sample 96 after 3990 steps.
Found uncertainty sample 97 after 284 steps.
Found uncertainty sample 98 after 3856 steps.
Found uncertainty sample 99 after 474 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_142910-jl2wts76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/jl2wts76
Training model 6. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.16156481322788, Training Loss Force: 3.4088366523758196, time: 0.627389669418335
Validation Loss Energy: 3.4540208567098145, Validation Loss Force: 3.0913868957076023, time: 0.05822873115539551
Test Loss Energy: 8.739589894694225, Test Loss Force: 9.919012294681224, time: 9.369038581848145


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9234614733707112, Training Loss Force: 3.1574337257738216, time: 0.678433895111084
Validation Loss Energy: 1.8150244719947786, Validation Loss Force: 3.1159511992134914, time: 0.059201717376708984
Test Loss Energy: 9.436309630500007, Test Loss Force: 9.920334217281212, time: 9.482790470123291


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7742314676311626, Training Loss Force: 3.121834118048904, time: 0.6228892803192139
Validation Loss Energy: 1.3217503560748742, Validation Loss Force: 3.0635069372842763, time: 0.05488443374633789
Test Loss Energy: 8.94821592012931, Test Loss Force: 9.983000417041819, time: 7.727775812149048


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7648593517599998, Training Loss Force: 3.09987823600452, time: 0.6609961986541748
Validation Loss Energy: 1.5291241913670226, Validation Loss Force: 3.4671251586168106, time: 0.051207780838012695
Test Loss Energy: 8.945976507383538, Test Loss Force: 10.030374044938993, time: 7.535926103591919


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7498664685459364, Training Loss Force: 3.085571815875591, time: 0.6809124946594238
Validation Loss Energy: 2.1394384431115014, Validation Loss Force: 3.2592453633578278, time: 0.05334758758544922
Test Loss Energy: 9.09612453684249, Test Loss Force: 9.951103763703506, time: 7.547245740890503


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.189164244775802, Training Loss Force: 3.159967824934933, time: 0.6793596744537354
Validation Loss Energy: 1.2241691655783558, Validation Loss Force: 2.9944061325630784, time: 0.05674242973327637
Test Loss Energy: 8.872805803228257, Test Loss Force: 9.98707816294023, time: 7.5219886302948


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 8.193090068254914, Training Loss Force: 5.744816940320317, time: 0.6573460102081299
Validation Loss Energy: 9.260315008294445, Validation Loss Force: 6.504127230788438, time: 0.059795379638671875
Test Loss Energy: 9.756980541142882, Test Loss Force: 11.395919652380778, time: 7.767828464508057


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 14.013534950219478, Training Loss Force: 6.504382145533708, time: 0.691704511642456
Validation Loss Energy: 4.404320889618612, Validation Loss Force: 5.8348759631559215, time: 0.057578086853027344
Test Loss Energy: 12.08220290630145, Test Loss Force: 11.039887253897932, time: 7.926825046539307


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.389284147671782, Training Loss Force: 5.789412604209864, time: 0.6267220973968506
Validation Loss Energy: 13.641627495064338, Validation Loss Force: 5.156521535499586, time: 0.05131864547729492
Test Loss Energy: 19.2069438659497, Test Loss Force: 10.661665779427205, time: 7.567810535430908


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.727355458243965, Training Loss Force: 5.46622855518279, time: 0.6327075958251953
Validation Loss Energy: 21.512617516888902, Validation Loss Force: 5.289497545425347, time: 0.052379608154296875
Test Loss Energy: 24.59360158464631, Test Loss Force: 11.02500276113314, time: 7.539515256881714


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.950725740117933, Training Loss Force: 5.169454610011715, time: 0.5992331504821777
Validation Loss Energy: 2.5804500507925545, Validation Loss Force: 7.214986232359874, time: 0.05357503890991211
Test Loss Energy: 8.985800462110573, Test Loss Force: 11.928155527401607, time: 7.75789999961853


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.017248731209985, Training Loss Force: 5.3057456612201745, time: 0.6648893356323242
Validation Loss Energy: 1.850730471555456, Validation Loss Force: 5.4788665205796345, time: 0.05399036407470703
Test Loss Energy: 9.001288828935893, Test Loss Force: 10.92387247859647, time: 7.9677393436431885


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.134909478648233, Training Loss Force: 5.8679709935057955, time: 0.6563124656677246
Validation Loss Energy: 19.328459427189564, Validation Loss Force: 5.884052444034073, time: 0.06516313552856445
Test Loss Energy: 14.362613070867841, Test Loss Force: 10.769745055384796, time: 9.412591695785522


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.886286355071679, Training Loss Force: 5.797912879753556, time: 0.6979799270629883
Validation Loss Energy: 12.901210723055009, Validation Loss Force: 4.918389130732843, time: 0.06351280212402344
Test Loss Energy: 17.061335611129554, Test Loss Force: 10.44136372076972, time: 10.276017904281616


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 9.302789714909737, Training Loss Force: 5.153271347900227, time: 0.690619945526123
Validation Loss Energy: 11.236374530298924, Validation Loss Force: 5.1560307727019605, time: 0.06520438194274902
Test Loss Energy: 13.262753434451446, Test Loss Force: 10.631602949899873, time: 9.242985725402832


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.285695580414657, Training Loss Force: 5.416954006670089, time: 0.7286200523376465
Validation Loss Energy: 12.628240617062133, Validation Loss Force: 4.463538412963231, time: 0.05777716636657715
Test Loss Energy: 10.915422970262458, Test Loss Force: 10.517482634365509, time: 8.977839946746826


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 15.338424446719294, Training Loss Force: 5.337216278723689, time: 0.632274866104126
Validation Loss Energy: 7.1626311494236035, Validation Loss Force: 6.526932336706924, time: 0.058803558349609375
Test Loss Energy: 9.005976828190992, Test Loss Force: 11.74272699638661, time: 9.41472578048706


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.717388977689774, Training Loss Force: 6.2419627198988055, time: 0.6872167587280273
Validation Loss Energy: 14.05533296271112, Validation Loss Force: 4.529171479740322, time: 0.061696529388427734
Test Loss Energy: 11.360147217556829, Test Loss Force: 10.128899135774134, time: 9.636563301086426


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 10.620270167442301, Training Loss Force: 6.012288428531891, time: 0.6978006362915039
Validation Loss Energy: 12.21091321308769, Validation Loss Force: 6.143776853212287, time: 0.06749153137207031
Test Loss Energy: 16.755990525830317, Test Loss Force: 11.079175576245726, time: 10.005771160125732


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.462059481247396, Training Loss Force: 5.237578598849017, time: 0.6663515567779541
Validation Loss Energy: 19.39381282151937, Validation Loss Force: 6.43689673555846, time: 0.06174349784851074
Test Loss Energy: 24.886549076772873, Test Loss Force: 11.585101377938829, time: 9.779644012451172

wandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–â–‚â–†â–ˆâ–â–â–ƒâ–…â–ƒâ–‚â–â–‚â–„â–ˆ
wandb:   test_error_force â–â–â–â–â–â–â–†â–…â–„â–…â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–‡â–‚â–…â–‡
wandb:          test_loss â–â–â–â–â–â–â–ƒâ–„â–…â–‡â–„â–ƒâ–„â–„â–ƒâ–‚â–„â–‚â–…â–ˆ
wandb: train_error_energy â–‚â–â–â–â–â–‚â–„â–‡â–…â–†â–†â–‡â–…â–…â–…â–†â–ˆâ–†â–†â–†
wandb:  train_error_force â–‚â–â–â–â–â–â–†â–ˆâ–‡â–†â–…â–†â–‡â–‡â–…â–†â–†â–‡â–‡â–…
wandb:         train_loss â–‚â–â–â–â–â–â–†â–ˆâ–†â–†â–†â–†â–†â–†â–…â–†â–‡â–‡â–‡â–†
wandb: valid_error_energy â–‚â–â–â–â–â–â–„â–‚â–…â–ˆâ–â–â–‡â–…â–„â–…â–ƒâ–…â–…â–‡
wandb:  valid_error_force â–â–â–â–‚â–â–â–‡â–†â–…â–…â–ˆâ–…â–†â–„â–…â–ƒâ–‡â–„â–†â–‡
wandb:         valid_loss â–‚â–â–â–‚â–â–â–†â–„â–†â–‡â–…â–„â–‡â–…â–…â–…â–†â–…â–†â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1358
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 24.88655
wandb:   test_error_force 11.5851
wandb:          test_loss 5.54184
wandb: train_error_energy 11.46206
wandb:  train_error_force 5.23758
wandb:         train_loss 2.51956
wandb: valid_error_energy 19.39381
wandb:  valid_error_force 6.4369
wandb:         valid_loss 3.45165
wandb: 
wandb: ğŸš€ View run al_79_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/jl2wts76
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_142910-jl2wts76/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.17598167061805725, Uncertainty Bias: 0.07947926223278046
0.0 0.0008535385
1.510195 5.1440563
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1853 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1304 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3246 steps.
Found uncertainty sample 23 after 1734 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2418 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3442 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2937 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3036 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2533 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3493 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3966 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_163557-x24uua94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/x24uua94
Training model 7. Added 11 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0862909103473086, Training Loss Force: 3.375210908240859, time: 0.679267168045044
Validation Loss Energy: 2.4883132322485437, Validation Loss Force: 3.3529908551465937, time: 0.06469440460205078
Test Loss Energy: 8.571247105330308, Test Loss Force: 9.868477814138219, time: 10.123650312423706


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7987897111703532, Training Loss Force: 3.135375742158501, time: 0.6926603317260742
Validation Loss Energy: 3.605609446539961, Validation Loss Force: 3.6181869132476923, time: 0.06349754333496094
Test Loss Energy: 10.634204364386573, Test Loss Force: 10.040128240581609, time: 11.30318021774292


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.59832292897252, Training Loss Force: 3.154240924673886, time: 0.6971898078918457
Validation Loss Energy: 1.7320313392591462, Validation Loss Force: 3.542411600877309, time: 0.06258511543273926
Test Loss Energy: 8.614717480664599, Test Loss Force: 9.916659523521455, time: 9.203105926513672


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0583178012479673, Training Loss Force: 3.1177232520603066, time: 0.6642122268676758
Validation Loss Energy: 2.016712227976515, Validation Loss Force: 3.338977729120493, time: 0.059992074966430664
Test Loss Energy: 9.81302895326455, Test Loss Force: 9.914924616106775, time: 9.93167495727539


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8962700545517632, Training Loss Force: 3.0938045570296273, time: 0.6899363994598389
Validation Loss Energy: 2.277374408262805, Validation Loss Force: 2.9445701056746882, time: 0.06388306617736816
Test Loss Energy: 8.64892591072369, Test Loss Force: 10.000036495312711, time: 9.731825828552246


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6579467744272016, Training Loss Force: 3.0936884065890875, time: 0.6802399158477783
Validation Loss Energy: 1.2052994584777108, Validation Loss Force: 2.994774649999589, time: 0.06271147727966309
Test Loss Energy: 9.312004759320104, Test Loss Force: 9.945119153851019, time: 10.824159383773804


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 8.99554866021817, Training Loss Force: 4.564322699123921, time: 0.6748788356781006
Validation Loss Energy: 23.978900086508496, Validation Loss Force: 5.533997619758187, time: 0.06525731086730957
Test Loss Energy: 17.844889384290088, Test Loss Force: 10.861980314092929, time: 9.063573360443115


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 17.447216140399686, Training Loss Force: 6.9000507391745485, time: 0.6472935676574707
Validation Loss Energy: 2.498639959229237, Validation Loss Force: 7.593776509917742, time: 0.05390763282775879
Test Loss Energy: 8.501177226416024, Test Loss Force: 12.521149619054206, time: 8.470597743988037


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.705331851119931, Training Loss Force: 6.732618921142978, time: 0.652108907699585
Validation Loss Energy: 7.561024327912369, Validation Loss Force: 7.248515084346243, time: 0.05639767646789551
Test Loss Energy: 12.234131566127457, Test Loss Force: 12.1770646630007, time: 8.251675605773926


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.362411382528036, Training Loss Force: 6.012824087643358, time: 0.6792118549346924
Validation Loss Energy: 14.008399205470752, Validation Loss Force: 5.462186152189037, time: 0.05438518524169922
Test Loss Energy: 11.747855474849791, Test Loss Force: 10.622484930499438, time: 8.316485404968262


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.556102117243874, Training Loss Force: 5.353774184262377, time: 0.6660664081573486
Validation Loss Energy: 17.73501140795622, Validation Loss Force: 5.320411816300231, time: 0.06498837471008301
Test Loss Energy: 12.751102704093901, Test Loss Force: 10.6103989995194, time: 11.032018899917603


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 15.217664770395032, Training Loss Force: 5.767540652898439, time: 0.6842923164367676
Validation Loss Energy: 49.607210292681486, Validation Loss Force: 6.7862492613480905, time: 0.06325268745422363
Test Loss Energy: 38.95549637381329, Test Loss Force: 11.059925928839675, time: 8.736656188964844


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 14.364508737828135, Training Loss Force: 6.72020373881581, time: 0.6316020488739014
Validation Loss Energy: 5.550101497729976, Validation Loss Force: 5.701268908870601, time: 0.0548093318939209
Test Loss Energy: 11.134889564957968, Test Loss Force: 10.733341102883632, time: 8.13812255859375


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 15.270157043416958, Training Loss Force: 7.181097013663408, time: 0.658062219619751
Validation Loss Energy: 12.033900594179228, Validation Loss Force: 5.51976260392817, time: 0.05577564239501953
Test Loss Energy: 17.615806564884327, Test Loss Force: 10.470407639601428, time: 7.908650875091553


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.947922034044778, Training Loss Force: 5.78923105118065, time: 0.6559474468231201
Validation Loss Energy: 12.93995649046132, Validation Loss Force: 3.8919580714930424, time: 0.053179025650024414
Test Loss Energy: 10.849694470520522, Test Loss Force: 9.533945765482637, time: 9.246109008789062


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 8.181696486790912, Training Loss Force: 5.342648023264281, time: 0.703249454498291
Validation Loss Energy: 6.465855303324661, Validation Loss Force: 4.882907915674979, time: 0.06813979148864746
Test Loss Energy: 10.793772361934296, Test Loss Force: 10.409809576878512, time: 10.460064172744751


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.8208289615310225, Training Loss Force: 4.1208606330269895, time: 0.6981041431427002
Validation Loss Energy: 5.203410090903329, Validation Loss Force: 3.7555496166828037, time: 0.06741738319396973
Test Loss Energy: 8.695724427351793, Test Loss Force: 9.896448313800024, time: 10.298920154571533


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.0548875928462005, Training Loss Force: 3.8473738569402776, time: 0.6462106704711914
Validation Loss Energy: 5.568078245888165, Validation Loss Force: 3.9480831657390167, time: 0.06254982948303223
Test Loss Energy: 8.861093569365442, Test Loss Force: 9.941856703452677, time: 9.983619928359985


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.946932609325562, Training Loss Force: 3.868743968958657, time: 0.6355531215667725
Validation Loss Energy: 4.6467343313849625, Validation Loss Force: 4.630248575827907, time: 0.06308126449584961
Test Loss Energy: 10.981189386712785, Test Loss Force: 10.234348430309154, time: 8.62016224861145


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 20.007751004551707, Training Loss Force: 7.426171610641206, time: 0.6052918434143066
Validation Loss Energy: 7.506630040937691, Validation Loss Force: 6.955614308439664, time: 0.05238652229309082
Test Loss Energy: 11.328162513143889, Test Loss Force: 11.766104146335827, time: 8.035101890563965

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–ƒâ–â–‚â–‚â–‚â–ˆâ–‚â–ƒâ–‚â–‚â–â–â–‚â–‚
wandb:   test_error_force â–‚â–‚â–‚â–‚â–‚â–‚â–„â–ˆâ–‡â–„â–„â–…â–„â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–†
wandb:          test_loss â–â–‚â–â–â–â–â–„â–„â–„â–‚â–ƒâ–ˆâ–‚â–ƒâ–â–‚â–â–â–‚â–ƒ
wandb: train_error_energy â–‚â–â–â–â–â–â–„â–‡â–…â–…â–…â–†â–†â–†â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ˆ
wandb:  train_error_force â–â–â–â–â–â–â–ƒâ–‡â–‡â–†â–…â–…â–‡â–ˆâ–…â–…â–ƒâ–‚â–‚â–ˆ
wandb:         train_loss â–â–â–â–â–â–â–„â–‡â–†â–…â–…â–†â–†â–‡â–…â–„â–ƒâ–ƒâ–ƒâ–ˆ
wandb: valid_error_energy â–â–â–â–â–â–â–„â–â–‚â–ƒâ–ƒâ–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚
wandb:  valid_error_force â–‚â–‚â–‚â–‚â–â–â–…â–ˆâ–‡â–…â–…â–‡â–…â–…â–‚â–„â–‚â–ƒâ–„â–‡
wandb:         valid_loss â–â–‚â–â–â–â–â–…â–„â–„â–„â–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1367
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 11.32816
wandb:   test_error_force 11.7661
wandb:          test_loss 4.69506
wandb: train_error_energy 20.00775
wandb:  train_error_force 7.42617
wandb:         train_loss 3.82375
wandb: valid_error_energy 7.50663
wandb:  valid_error_force 6.95561
wandb:         valid_loss 2.82972
wandb: 
wandb: ğŸš€ View run al_79_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/x24uua94
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_163557-x24uua94/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.3627738058567047, Uncertainty Bias: -0.01262781023979187
0.000289917 0.85121536
1.3590275 12.0395355
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1122 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1300 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3391 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2969 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 672 steps.
Found uncertainty sample 13 after 1464 steps.
Found uncertainty sample 14 after 3402 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2522 steps.
Found uncertainty sample 17 after 3063 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1271 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 269 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1491 steps.
Found uncertainty sample 27 after 741 steps.
Found uncertainty sample 28 after 3969 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1827 steps.
Found uncertainty sample 31 after 134 steps.
Found uncertainty sample 32 after 2542 steps.
Found uncertainty sample 33 after 412 steps.
Found uncertainty sample 34 after 596 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3303 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 410 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3860 steps.
Found uncertainty sample 44 after 2486 steps.
Found uncertainty sample 45 after 2027 steps.
Found uncertainty sample 46 after 2764 steps.
Found uncertainty sample 47 after 1502 steps.
Found uncertainty sample 48 after 2286 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 396 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2447 steps.
Found uncertainty sample 62 after 2589 steps.
Found uncertainty sample 63 after 2567 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1778 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 725 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1938 steps.
Found uncertainty sample 77 after 1608 steps.
Found uncertainty sample 78 after 867 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3410 steps.
Found uncertainty sample 90 after 1153 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1364 steps.
Found uncertainty sample 94 after 2410 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 786 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_181945-qy4u7j5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/qy4u7j5f
Training model 8. Added 41 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.239078023975645, Training Loss Force: 3.476582322097356, time: 0.7407565116882324
Validation Loss Energy: 1.6432206967497185, Validation Loss Force: 3.4385965649713963, time: 0.06677889823913574
Test Loss Energy: 9.28502594176454, Test Loss Force: 9.866550949598452, time: 9.668399572372437


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0535128361642685, Training Loss Force: 3.1922734274915716, time: 0.6818015575408936
Validation Loss Energy: 2.182758391448034, Validation Loss Force: 3.276123573284581, time: 0.06275010108947754
Test Loss Energy: 8.705786414707662, Test Loss Force: 9.829828703794155, time: 9.14685344696045


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0449213698377906, Training Loss Force: 3.1717517835432503, time: 0.6782748699188232
Validation Loss Energy: 1.682458841304962, Validation Loss Force: 3.4075885503860768, time: 0.05780386924743652
Test Loss Energy: 8.80882880733012, Test Loss Force: 9.806799244138556, time: 9.203105449676514


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8428205094534027, Training Loss Force: 3.159918841488904, time: 0.6581494808197021
Validation Loss Energy: 1.989486638505784, Validation Loss Force: 3.0822170462745775, time: 0.0610356330871582
Test Loss Energy: 9.754048657664258, Test Loss Force: 9.694693130744671, time: 9.169825315475464


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8270240819048527, Training Loss Force: 3.1484864711067555, time: 0.6491460800170898
Validation Loss Energy: 2.155654434998266, Validation Loss Force: 3.2290142414226493, time: 0.059839487075805664
Test Loss Energy: 8.638777709605101, Test Loss Force: 9.81337831765709, time: 9.03125


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.8865336852686814, Training Loss Force: 3.1551962363909336, time: 0.7039709091186523
Validation Loss Energy: 3.3334770218740664, Validation Loss Force: 3.244141047182108, time: 0.05899643898010254
Test Loss Energy: 8.525339834199755, Test Loss Force: 9.908249088376424, time: 9.654745101928711


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 15.567973491104993, Training Loss Force: 6.057627916702683, time: 0.6384367942810059
Validation Loss Energy: 12.860691173232237, Validation Loss Force: 8.818266430400808, time: 0.059389591217041016
Test Loss Energy: 11.211838770995671, Test Loss Force: 12.75785020408809, time: 9.495112657546997


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 11.659432952265957, Training Loss Force: 6.7268212751752685, time: 0.6532034873962402
Validation Loss Energy: 5.597115638532024, Validation Loss Force: 5.324444131863837, time: 0.06189370155334473
Test Loss Energy: 11.456297107104623, Test Loss Force: 10.634678236971704, time: 9.73284649848938


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.481857384098992, Training Loss Force: 6.032752073758329, time: 0.7153916358947754
Validation Loss Energy: 8.696033093420331, Validation Loss Force: 8.523876443246262, time: 0.05965542793273926
Test Loss Energy: 10.282263319101988, Test Loss Force: 13.397516201060284, time: 9.900742292404175


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.016958422354575, Training Loss Force: 6.75493263744784, time: 0.7103612422943115
Validation Loss Energy: 23.29048992022206, Validation Loss Force: 6.464647323208003, time: 0.05900120735168457
Test Loss Energy: 23.30352015024673, Test Loss Force: 11.5774306706811, time: 9.897090435028076


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 8.51950134877515, Training Loss Force: 5.9896414546616175, time: 0.6605832576751709
Validation Loss Energy: 5.849590608326267, Validation Loss Force: 5.19480392841322, time: 0.06263446807861328
Test Loss Energy: 9.022995517283974, Test Loss Force: 10.083007463141866, time: 9.680230617523193


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 10.426522949849506, Training Loss Force: 6.032958761332373, time: 0.6780307292938232
Validation Loss Energy: 10.266633031590025, Validation Loss Force: 6.270950995871755, time: 0.06297993659973145
Test Loss Energy: 10.665972363922435, Test Loss Force: 11.138902034988217, time: 9.898584365844727


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.42143002960757, Training Loss Force: 6.507161998699612, time: 0.7101569175720215
Validation Loss Energy: 46.67818828279036, Validation Loss Force: 9.955951679042819, time: 0.07061624526977539
Test Loss Energy: 44.42481725463613, Test Loss Force: 14.175965991695305, time: 9.778586626052856


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 13.624407153994866, Training Loss Force: 6.818867416770264, time: 0.7351040840148926
Validation Loss Energy: 16.694283430863834, Validation Loss Force: 7.007993216974548, time: 0.062453269958496094
Test Loss Energy: 18.410850345768434, Test Loss Force: 11.670409061433105, time: 9.917562007904053


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.695736418691121, Training Loss Force: 5.266585968230469, time: 0.7206542491912842
Validation Loss Energy: 6.208453556007619, Validation Loss Force: 5.8789528752540345, time: 0.06199359893798828
Test Loss Energy: 9.023601289278375, Test Loss Force: 10.742068530291126, time: 9.985420227050781


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.485603206614686, Training Loss Force: 5.1674832136712165, time: 0.7077033519744873
Validation Loss Energy: 3.8564269785464913, Validation Loss Force: 5.273139601958054, time: 0.06498432159423828
Test Loss Energy: 8.39741618602929, Test Loss Force: 10.309560625816266, time: 9.719226121902466


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 10.184807839010084, Training Loss Force: 5.510744331455572, time: 0.6757862567901611
Validation Loss Energy: 4.75078584192385, Validation Loss Force: 4.988663513187651, time: 0.06715798377990723
Test Loss Energy: 8.825208811364156, Test Loss Force: 10.661568635057614, time: 10.19405484199524


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.16422065170686, Training Loss Force: 4.991283134718895, time: 0.7104542255401611
Validation Loss Energy: 9.2142220497491, Validation Loss Force: 5.689604385661173, time: 0.062109947204589844
Test Loss Energy: 10.763289338241492, Test Loss Force: 10.97854716431622, time: 9.938778400421143


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 9.773673835631074, Training Loss Force: 5.399001585704543, time: 0.6584336757659912
Validation Loss Energy: 13.61903459284192, Validation Loss Force: 4.354810182352422, time: 0.061995506286621094
Test Loss Energy: 10.913817812508851, Test Loss Force: 9.884483720017416, time: 9.614304780960083


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 13.454733163584647, Training Loss Force: 5.430024073784349, time: 0.6898229122161865
Validation Loss Energy: 2.605487414898967, Validation Loss Force: 7.417183845018499, time: 0.06729674339294434
Test Loss Energy: 8.150235911969531, Test Loss Force: 11.789101765469365, time: 9.62171483039856

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–‚â–‚â–â–„â–â–â–ˆâ–ƒâ–â–â–â–‚â–‚â–
wandb:   test_error_force â–â–â–â–â–â–â–†â–‚â–‡â–„â–‚â–ƒâ–ˆâ–„â–ƒâ–‚â–ƒâ–ƒâ–â–„
wandb:          test_loss â–â–â–â–â–â–â–ƒâ–‚â–ƒâ–„â–â–‚â–ˆâ–ƒâ–‚â–â–‚â–‚â–â–‚
wandb: train_error_energy â–‚â–â–â–â–â–‚â–ˆâ–†â–†â–…â–„â–…â–†â–‡â–†â–†â–…â–„â–…â–‡
wandb:  train_error_force â–‚â–â–â–â–â–â–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–ˆâ–…â–…â–†â–…â–…â–…
wandb:         train_loss â–‚â–â–â–â–â–â–ˆâ–‡â–‡â–‡â–†â–†â–‡â–ˆâ–†â–†â–†â–…â–…â–†
wandb: valid_error_energy â–â–â–â–â–â–â–ƒâ–‚â–‚â–„â–‚â–‚â–ˆâ–ƒâ–‚â–â–â–‚â–ƒâ–
wandb:  valid_error_force â–â–â–â–â–â–â–‡â–ƒâ–‡â–„â–ƒâ–„â–ˆâ–…â–„â–ƒâ–ƒâ–„â–‚â–…
wandb:         valid_loss â–â–â–â–â–â–â–…â–‚â–„â–„â–‚â–ƒâ–ˆâ–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1403
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.15024
wandb:   test_error_force 11.7891
wandb:          test_loss 4.49009
wandb: train_error_energy 13.45473
wandb:  train_error_force 5.43002
wandb:         train_loss 2.7173
wandb: valid_error_energy 2.60549
wandb:  valid_error_force 7.41718
wandb:         valid_loss 2.65617
wandb: 
wandb: ğŸš€ View run al_79_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/qy4u7j5f
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_181945-qy4u7j5f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.5411252379417419, Uncertainty Bias: -0.16278770565986633
8.773804e-05 0.010512531
-0.23825687 8.657159
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 174 steps.
Found uncertainty sample 2 after 462 steps.
Found uncertainty sample 3 after 1006 steps.
Found uncertainty sample 4 after 181 steps.
Found uncertainty sample 5 after 557 steps.
Found uncertainty sample 6 after 1506 steps.
Found uncertainty sample 7 after 523 steps.
Found uncertainty sample 8 after 2060 steps.
Found uncertainty sample 9 after 982 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 62 steps.
Found uncertainty sample 12 after 224 steps.
Found uncertainty sample 13 after 1247 steps.
Found uncertainty sample 14 after 1362 steps.
Found uncertainty sample 15 after 2373 steps.
Found uncertainty sample 16 after 1223 steps.
Found uncertainty sample 17 after 2573 steps.
Found uncertainty sample 18 after 95 steps.
Found uncertainty sample 19 after 1215 steps.
Found uncertainty sample 20 after 863 steps.
Found uncertainty sample 21 after 496 steps.
Found uncertainty sample 22 after 247 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1075 steps.
Found uncertainty sample 25 after 825 steps.
Found uncertainty sample 26 after 1368 steps.
Found uncertainty sample 27 after 2248 steps.
Found uncertainty sample 28 after 1325 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 311 steps.
Found uncertainty sample 31 after 7 steps.
Found uncertainty sample 32 after 84 steps.
Found uncertainty sample 33 after 2946 steps.
Found uncertainty sample 34 after 542 steps.
Found uncertainty sample 35 after 2023 steps.
Found uncertainty sample 36 after 1266 steps.
Found uncertainty sample 37 after 89 steps.
Found uncertainty sample 38 after 105 steps.
Found uncertainty sample 39 after 218 steps.
Found uncertainty sample 40 after 1041 steps.
Found uncertainty sample 41 after 1927 steps.
Found uncertainty sample 42 after 1689 steps.
Found uncertainty sample 43 after 1223 steps.
Found uncertainty sample 44 after 482 steps.
Found uncertainty sample 45 after 1074 steps.
Found uncertainty sample 46 after 2002 steps.
Found uncertainty sample 47 after 1291 steps.
Found uncertainty sample 48 after 137 steps.
Found uncertainty sample 49 after 1379 steps.
Found uncertainty sample 50 after 122 steps.
Found uncertainty sample 51 after 2918 steps.
Found uncertainty sample 52 after 1484 steps.
Found uncertainty sample 53 after 2684 steps.
Found uncertainty sample 54 after 856 steps.
Found uncertainty sample 55 after 1710 steps.
Found uncertainty sample 56 after 919 steps.
Found uncertainty sample 57 after 2500 steps.
Found uncertainty sample 58 after 82 steps.
Found uncertainty sample 59 after 244 steps.
Found uncertainty sample 60 after 963 steps.
Found uncertainty sample 61 after 3000 steps.
Found uncertainty sample 62 after 1203 steps.
Found uncertainty sample 63 after 994 steps.
Found uncertainty sample 64 after 450 steps.
Found uncertainty sample 65 after 352 steps.
Found uncertainty sample 66 after 444 steps.
Found uncertainty sample 67 after 1514 steps.
Found uncertainty sample 68 after 1342 steps.
Found uncertainty sample 69 after 694 steps.
Found uncertainty sample 70 after 157 steps.
Found uncertainty sample 71 after 248 steps.
Found uncertainty sample 72 after 326 steps.
Found uncertainty sample 73 after 17 steps.
Found uncertainty sample 74 after 233 steps.
Found uncertainty sample 75 after 654 steps.
Found uncertainty sample 76 after 1639 steps.
Found uncertainty sample 77 after 1331 steps.
Found uncertainty sample 78 after 3404 steps.
Found uncertainty sample 79 after 116 steps.
Found uncertainty sample 80 after 6 steps.
Found uncertainty sample 81 after 1185 steps.
Found uncertainty sample 82 after 817 steps.
Found uncertainty sample 83 after 364 steps.
Found uncertainty sample 84 after 97 steps.
Found uncertainty sample 85 after 738 steps.
Found uncertainty sample 86 after 468 steps.
Found uncertainty sample 87 after 280 steps.
Found uncertainty sample 88 after 738 steps.
Found uncertainty sample 89 after 208 steps.
Found uncertainty sample 90 after 1191 steps.
Found uncertainty sample 91 after 1227 steps.
Found uncertainty sample 92 after 1383 steps.
Found uncertainty sample 93 after 3858 steps.
Found uncertainty sample 94 after 499 steps.
Found uncertainty sample 95 after 1394 steps.
Found uncertainty sample 96 after 531 steps.
Found uncertainty sample 97 after 66 steps.
Found uncertainty sample 98 after 294 steps.
Found uncertainty sample 99 after 181 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_190118-dld6agse
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/dld6agse
Training model 9. Added 96 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3891126668334945, Training Loss Force: 3.4605655056081512, time: 0.7238368988037109
Validation Loss Energy: 1.936203136565567, Validation Loss Force: 3.6302811879087598, time: 0.06544256210327148
Test Loss Energy: 9.107613056996264, Test Loss Force: 9.66476860790214, time: 10.295087099075317


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9369759631349754, Training Loss Force: 3.187721653021017, time: 0.7655694484710693
Validation Loss Energy: 1.3755962646104183, Validation Loss Force: 3.2451418336584803, time: 0.07052493095397949
Test Loss Energy: 8.977281891367113, Test Loss Force: 9.721150361564296, time: 8.659361839294434


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.4348172849925462, Training Loss Force: 3.2108671774248543, time: 0.7029356956481934
Validation Loss Energy: 1.645596576536768, Validation Loss Force: 3.0860221279747644, time: 0.054779767990112305
Test Loss Energy: 9.23300191888437, Test Loss Force: 9.675373870668247, time: 8.010468006134033


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6045482775076045, Training Loss Force: 3.164416834900296, time: 0.6832797527313232
Validation Loss Energy: 2.1547758938830075, Validation Loss Force: 3.1027000470047557, time: 0.05825924873352051
Test Loss Energy: 8.511391223352717, Test Loss Force: 9.822120644078643, time: 8.23361325263977


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.44179636850105, Training Loss Force: 3.156536341681483, time: 0.683983325958252
Validation Loss Energy: 2.097082429507691, Validation Loss Force: 3.2098997652633434, time: 0.05971956253051758
Test Loss Energy: 8.695810613135146, Test Loss Force: 9.711291826190996, time: 7.851726531982422


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.530818209668417, Training Loss Force: 3.1293671005331856, time: 0.7213003635406494
Validation Loss Energy: 1.5424723716560964, Validation Loss Force: 3.2319897692196826, time: 0.05806756019592285
Test Loss Energy: 8.803291368418167, Test Loss Force: 9.738715884110624, time: 7.889289855957031


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.067495218051143, Training Loss Force: 6.599273444159047, time: 0.7445354461669922
Validation Loss Energy: 15.404208762808345, Validation Loss Force: 7.8088769089062975, time: 0.058687686920166016
Test Loss Energy: 20.58140800921654, Test Loss Force: 12.523908963089916, time: 7.9958837032318115


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 12.275539118891897, Training Loss Force: 6.205860085826226, time: 0.6954507827758789
Validation Loss Energy: 20.389482360918393, Validation Loss Force: 5.982941147755479, time: 0.056656837463378906
Test Loss Energy: 25.327782375487736, Test Loss Force: 11.361935794064713, time: 7.854094743728638


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.544734930747248, Training Loss Force: 5.5493926328727365, time: 0.7261214256286621
Validation Loss Energy: 12.044863041571546, Validation Loss Force: 5.56149993131002, time: 0.054358720779418945
Test Loss Energy: 18.769469548844064, Test Loss Force: 10.691382131100244, time: 7.850721597671509


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.515925243362124, Training Loss Force: 5.63227100808949, time: 0.7583625316619873
Validation Loss Energy: 4.938806555399545, Validation Loss Force: 5.37128570407779, time: 0.0562131404876709
Test Loss Energy: 8.872354127609297, Test Loss Force: 10.63947954334529, time: 8.065946102142334


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 13.615034967003995, Training Loss Force: 5.453180914475371, time: 0.7072227001190186
Validation Loss Energy: 10.335419538811745, Validation Loss Force: 8.663533195557294, time: 0.05753159523010254
Test Loss Energy: 11.258489463290248, Test Loss Force: 13.039240542668416, time: 7.831719636917114


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 22.15388324775943, Training Loss Force: 9.02840088578509, time: 0.6648354530334473
Validation Loss Energy: 30.969072423727006, Validation Loss Force: 7.396607434581604, time: 0.0547938346862793
Test Loss Energy: 31.23694226845046, Test Loss Force: 11.836132590136055, time: 7.823508024215698


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 17.630253083958817, Training Loss Force: 8.090768164215582, time: 0.6825921535491943
Validation Loss Energy: 9.803230927940204, Validation Loss Force: 6.8905993712116675, time: 0.0562286376953125
Test Loss Energy: 10.844813786676738, Test Loss Force: 11.071491480859871, time: 7.80965518951416


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 16.159102404872485, Training Loss Force: 6.48989329514066, time: 0.722578763961792
Validation Loss Energy: 3.274753935367979, Validation Loss Force: 6.1379162012914685, time: 0.059900760650634766
Test Loss Energy: 9.26644299609238, Test Loss Force: 10.6076160642123, time: 8.109009981155396


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.615053199026882, Training Loss Force: 6.608937697267115, time: 0.717435359954834
Validation Loss Energy: 19.04520556936116, Validation Loss Force: 6.183047897133842, time: 0.06218767166137695
Test Loss Energy: 14.882246058758286, Test Loss Force: 10.205219808600656, time: 9.799010753631592


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 10.141246581062177, Training Loss Force: 5.831524105551707, time: 0.684502363204956
Validation Loss Energy: 5.806551111779031, Validation Loss Force: 5.522710966089399, time: 0.0630497932434082
Test Loss Energy: 11.134356842433114, Test Loss Force: 10.75973586509846, time: 10.167387962341309


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.400803833617549, Training Loss Force: 5.405977225378441, time: 0.7380986213684082
Validation Loss Energy: 15.8948833834514, Validation Loss Force: 3.9477324618341805, time: 0.05618453025817871
Test Loss Energy: 18.34619596468062, Test Loss Force: 9.887738877126873, time: 8.025938987731934


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 23.89499307932802, Training Loss Force: 7.2004265412268875, time: 0.6860020160675049
Validation Loss Energy: 31.46395192852176, Validation Loss Force: 8.252592833364643, time: 0.06172370910644531
Test Loss Energy: 34.92729772255893, Test Loss Force: 13.504142508379383, time: 7.8747642040252686


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 12.847415510835706, Training Loss Force: 7.662005543613247, time: 0.7510149478912354
Validation Loss Energy: 12.770318228327692, Validation Loss Force: 6.35984207761015, time: 0.05708622932434082
Test Loss Energy: 12.369949957027444, Test Loss Force: 10.81219696769337, time: 7.871879816055298


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 10.753968297264526, Training Loss Force: 5.420613164112164, time: 0.7625632286071777
Validation Loss Energy: 15.027880983335292, Validation Loss Force: 5.19888144581345, time: 0.055141448974609375
Test Loss Energy: 12.675010590070507, Test Loss Force: 10.153256062608031, time: 8.044838190078735

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–„â–…â–„â–â–‚â–‡â–‚â–â–ƒâ–‚â–„â–ˆâ–‚â–‚
wandb:   test_error_force â–â–â–â–â–â–â–†â–„â–ƒâ–ƒâ–‡â–…â–„â–ƒâ–‚â–ƒâ–â–ˆâ–ƒâ–‚
wandb:          test_loss â–â–â–â–â–â–â–…â–…â–ƒâ–‚â–„â–†â–‚â–‚â–‚â–‚â–ƒâ–ˆâ–‚â–‚
wandb: train_error_energy â–‚â–â–â–â–â–â–ƒâ–„â–„â–„â–…â–‡â–†â–†â–„â–„â–ƒâ–ˆâ–…â–„
wandb:  train_error_force â–â–â–â–â–â–â–…â–…â–„â–„â–„â–ˆâ–‡â–…â–…â–„â–„â–†â–†â–„
wandb:         train_loss â–â–â–â–â–â–â–„â–…â–„â–„â–„â–ˆâ–‡â–…â–…â–„â–ƒâ–‡â–†â–„
wandb: valid_error_energy â–â–â–â–â–â–â–„â–…â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–â–…â–‚â–„â–ˆâ–„â–„
wandb:  valid_error_force â–‚â–â–â–â–â–â–‡â–…â–„â–„â–ˆâ–†â–†â–…â–…â–„â–‚â–‡â–…â–„
wandb:         valid_loss â–â–â–â–â–â–â–†â–…â–„â–ƒâ–†â–‡â–„â–ƒâ–…â–ƒâ–ƒâ–ˆâ–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1489
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 12.67501
wandb:   test_error_force 10.15326
wandb:          test_loss 4.24553
wandb: train_error_energy 10.75397
wandb:  train_error_force 5.42061
wandb:         train_loss 2.53342
wandb: valid_error_energy 15.02788
wandb:  valid_error_force 5.19888
wandb:         valid_loss 2.74524
wandb: 
wandb: ğŸš€ View run al_79_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/dld6agse
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_190118-dld6agse/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.563997209072113, Uncertainty Bias: -0.264873206615448
3.8146973e-05 0.0032308102
0.2615543 8.882114
(48745, 22, 3)
Found uncertainty sample 0 after 1062 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2949 steps.
Found uncertainty sample 3 after 1307 steps.
Found uncertainty sample 4 after 2254 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3505 steps.
Found uncertainty sample 7 after 1489 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 13 steps.
Found uncertainty sample 10 after 398 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1392 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2670 steps.
Found uncertainty sample 20 after 1542 steps.
Found uncertainty sample 21 after 880 steps.
Found uncertainty sample 22 after 3386 steps.
Found uncertainty sample 23 after 261 steps.
Found uncertainty sample 24 after 2808 steps.
Found uncertainty sample 25 after 228 steps.
Found uncertainty sample 26 after 823 steps.
Found uncertainty sample 27 after 903 steps.
Found uncertainty sample 28 after 1143 steps.
Found uncertainty sample 29 after 1746 steps.
Found uncertainty sample 30 after 103 steps.
Found uncertainty sample 31 after 1710 steps.
Found uncertainty sample 32 after 1882 steps.
Found uncertainty sample 33 after 25 steps.
Found uncertainty sample 34 after 586 steps.
Found uncertainty sample 35 after 2422 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3968 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2651 steps.
Found uncertainty sample 40 after 2019 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1950 steps.
Found uncertainty sample 43 after 3175 steps.
Found uncertainty sample 44 after 3111 steps.
Found uncertainty sample 45 after 575 steps.
Found uncertainty sample 46 after 1278 steps.
Found uncertainty sample 47 after 1080 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1194 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2035 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3303 steps.
Found uncertainty sample 54 after 77 steps.
Found uncertainty sample 55 after 1415 steps.
Found uncertainty sample 56 after 2651 steps.
Found uncertainty sample 57 after 2022 steps.
Found uncertainty sample 58 after 583 steps.
Found uncertainty sample 59 after 169 steps.
Found uncertainty sample 60 after 2244 steps.
Found uncertainty sample 61 after 802 steps.
Found uncertainty sample 62 after 101 steps.
Found uncertainty sample 63 after 880 steps.
Found uncertainty sample 64 after 2853 steps.
Found uncertainty sample 65 after 2080 steps.
Found uncertainty sample 66 after 3588 steps.
Found uncertainty sample 67 after 337 steps.
Found uncertainty sample 68 after 2707 steps.
Found uncertainty sample 69 after 1736 steps.
Found uncertainty sample 70 after 2923 steps.
Found uncertainty sample 71 after 1997 steps.
Found uncertainty sample 72 after 3369 steps.
Found uncertainty sample 73 after 1080 steps.
Found uncertainty sample 74 after 3755 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2378 steps.
Found uncertainty sample 78 after 269 steps.
Found uncertainty sample 79 after 2561 steps.
Found uncertainty sample 80 after 1583 steps.
Found uncertainty sample 81 after 1558 steps.
Found uncertainty sample 82 after 2332 steps.
Found uncertainty sample 83 after 2597 steps.
Found uncertainty sample 84 after 975 steps.
Found uncertainty sample 85 after 1529 steps.
Found uncertainty sample 86 after 933 steps.
Found uncertainty sample 87 after 179 steps.
Found uncertainty sample 88 after 1950 steps.
Found uncertainty sample 89 after 1184 steps.
Found uncertainty sample 90 after 3501 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1324 steps.
Found uncertainty sample 93 after 723 steps.
Found uncertainty sample 94 after 2524 steps.
Found uncertainty sample 95 after 3693 steps.
Found uncertainty sample 96 after 2366 steps.
Found uncertainty sample 97 after 2862 steps.
Found uncertainty sample 98 after 546 steps.
Found uncertainty sample 99 after 2996 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_201507-hlk2fna1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/hlk2fna1
Training model 10. Added 81 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.633325854615114, Training Loss Force: 3.441060917117672, time: 0.7714264392852783
Validation Loss Energy: 2.2051250618181886, Validation Loss Force: 3.5521294390784623, time: 0.05982708930969238
Test Loss Energy: 9.529003242569868, Test Loss Force: 9.577478516157159, time: 7.878805160522461


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.004304594207371, Training Loss Force: 3.2303466640541383, time: 0.7204163074493408
Validation Loss Energy: 1.6330859662401016, Validation Loss Force: 3.4128083605049158, time: 0.055531978607177734
Test Loss Energy: 9.021579961725223, Test Loss Force: 9.542702533921888, time: 7.912592887878418


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.057052328052943, Training Loss Force: 3.206634649425629, time: 0.7712335586547852
Validation Loss Energy: 1.4705239625622015, Validation Loss Force: 3.3414282030714286, time: 0.056003570556640625
Test Loss Energy: 9.362524354838737, Test Loss Force: 9.548004409861976, time: 7.874476432800293


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.033237464136424, Training Loss Force: 3.188225391444952, time: 0.7918055057525635
Validation Loss Energy: 5.378730869641032, Validation Loss Force: 3.0713478972544044, time: 0.05593466758728027
Test Loss Energy: 11.370134849739259, Test Loss Force: 9.650604392699876, time: 8.013408184051514


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2073655837579893, Training Loss Force: 3.2337761006330106, time: 0.7358736991882324
Validation Loss Energy: 1.638705912814173, Validation Loss Force: 3.2382451022016587, time: 0.05771183967590332
Test Loss Energy: 10.046597383158861, Test Loss Force: 9.723250301818224, time: 8.2601637840271


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6996066956149645, Training Loss Force: 3.1735297594931065, time: 0.732365608215332
Validation Loss Energy: 2.0861714186880835, Validation Loss Force: 3.2392743903287102, time: 0.05665946006774902
Test Loss Energy: 8.749652129201186, Test Loss Force: 9.635243569828699, time: 7.860661745071411


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 12.119938493455605, Training Loss Force: 6.4689421929602675, time: 0.7359969615936279
Validation Loss Energy: 18.1238264731329, Validation Loss Force: 7.40776182277771, time: 0.05566692352294922
Test Loss Energy: 20.67898044450213, Test Loss Force: 11.6242361355192, time: 8.028105974197388


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 14.424374607833807, Training Loss Force: 5.143594296462016, time: 0.7804417610168457
Validation Loss Energy: 24.014483506704337, Validation Loss Force: 5.5593738863047015, time: 0.05537605285644531
Test Loss Energy: 27.178114032904606, Test Loss Force: 11.269038646074177, time: 7.849961042404175


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 15.885459970664519, Training Loss Force: 7.613204606480551, time: 0.760777473449707
Validation Loss Energy: 4.25571016561153, Validation Loss Force: 4.816778964709906, time: 0.0558323860168457
Test Loss Energy: 8.972020772041379, Test Loss Force: 10.235843824997694, time: 7.843809604644775


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 14.401421117923036, Training Loss Force: 7.428614874634945, time: 0.7271559238433838
Validation Loss Energy: 10.537835589902524, Validation Loss Force: 6.524044763222532, time: 0.05821990966796875
Test Loss Energy: 15.71415699992582, Test Loss Force: 11.087152699564395, time: 7.837867259979248


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.992867941935947, Training Loss Force: 5.667060393398299, time: 0.8426704406738281
Validation Loss Energy: 11.544442192411228, Validation Loss Force: 4.2702916546326115, time: 0.08313226699829102
Test Loss Energy: 17.136472863896476, Test Loss Force: 9.900766910771063, time: 8.77506971359253


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 12.15215058008686, Training Loss Force: 5.388110575655559, time: 0.7665412425994873
Validation Loss Energy: 5.76194202042215, Validation Loss Force: 5.269561754121286, time: 0.06260180473327637
Test Loss Energy: 9.400593816592707, Test Loss Force: 10.522829645691218, time: 9.864311695098877


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 19.313642585969777, Training Loss Force: 5.618194994949814, time: 0.7843422889709473
Validation Loss Energy: 15.254246437085481, Validation Loss Force: 7.219300447062224, time: 0.06884098052978516
Test Loss Energy: 13.208877844177039, Test Loss Force: 11.303596710993041, time: 8.337522029876709


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 11.621918044954002, Training Loss Force: 7.379091993274023, time: 0.7565906047821045
Validation Loss Energy: 14.37575698106925, Validation Loss Force: 5.16763228054309, time: 0.055707693099975586
Test Loss Energy: 15.961782204244965, Test Loss Force: 10.395268213770173, time: 8.04624319076538


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.578018990972264, Training Loss Force: 5.333991039685612, time: 0.7760467529296875
Validation Loss Energy: 18.37995210357463, Validation Loss Force: 5.132550533933021, time: 0.055909156799316406
Test Loss Energy: 21.632362842097344, Test Loss Force: 10.709761867277702, time: 7.826683044433594


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.293998923928944, Training Loss Force: 5.401784151683326, time: 0.730370283126831
Validation Loss Energy: 11.767955699740375, Validation Loss Force: 5.474243018433589, time: 0.05780601501464844
Test Loss Energy: 14.299808237996462, Test Loss Force: 10.644349991403203, time: 7.86436915397644


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 16.647684227198823, Training Loss Force: 6.019675699271746, time: 0.742368221282959
Validation Loss Energy: 11.525988709611608, Validation Loss Force: 7.888161821020222, time: 0.057544708251953125
Test Loss Energy: 12.66566705229172, Test Loss Force: 11.849092102305267, time: 8.468377113342285


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 12.055024754810166, Training Loss Force: 6.968425968557689, time: 0.7272400856018066
Validation Loss Energy: 7.730218587769015, Validation Loss Force: 8.801122242179243, time: 0.06636834144592285
Test Loss Energy: 9.163789232243799, Test Loss Force: 12.289083895790233, time: 7.825045347213745


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.15989272550119, Training Loss Force: 6.01527814723333, time: 0.79695725440979
Validation Loss Energy: 8.222840672762356, Validation Loss Force: 5.543061144674032, time: 0.057929277420043945
Test Loss Energy: 14.567061319496677, Test Loss Force: 10.01420758411332, time: 7.8373589515686035


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.062565643810236, Training Loss Force: 4.748855468566583, time: 0.7676465511322021
Validation Loss Energy: 10.33678138330824, Validation Loss Force: 3.8910386705895066, time: 0.055793046951293945
Test Loss Energy: 15.244582633458043, Test Loss Force: 9.744193162715735, time: 7.868745803833008

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–‚â–â–â–†â–ˆâ–â–„â–„â–â–ƒâ–„â–†â–ƒâ–‚â–â–ƒâ–ƒ
wandb:   test_error_force â–â–â–â–â–â–â–†â–…â–ƒâ–…â–‚â–ƒâ–…â–ƒâ–„â–„â–‡â–ˆâ–‚â–‚
wandb:          test_loss â–â–â–â–‚â–‚â–â–‡â–ˆâ–‚â–…â–„â–‚â–„â–„â–†â–„â–…â–…â–ƒâ–ƒ
wandb: train_error_energy â–â–â–â–â–â–â–…â–†â–‡â–†â–…â–…â–ˆâ–…â–…â–…â–‡â–…â–„â–ƒ
wandb:  train_error_force â–â–â–â–â–â–â–†â–„â–ˆâ–ˆâ–…â–„â–…â–ˆâ–„â–…â–…â–‡â–…â–ƒ
wandb:         train_loss â–â–â–â–â–â–â–†â–…â–ˆâ–ˆâ–…â–…â–‡â–‡â–…â–…â–‡â–‡â–…â–„
wandb: valid_error_energy â–â–â–â–‚â–â–â–†â–ˆâ–‚â–„â–„â–‚â–…â–…â–†â–„â–„â–ƒâ–ƒâ–„
wandb:  valid_error_force â–‚â–â–â–â–â–â–†â–„â–ƒâ–…â–‚â–„â–†â–„â–„â–„â–‡â–ˆâ–„â–‚
wandb:         valid_loss â–â–â–â–‚â–â–â–ˆâ–‡â–ƒâ–†â–„â–„â–‡â–…â–†â–…â–‡â–‡â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1561
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 15.24458
wandb:   test_error_force 9.74419
wandb:          test_loss 4.28062
wandb: train_error_energy 7.06257
wandb:  train_error_force 4.74886
wandb:         train_loss 2.06161
wandb: valid_error_energy 10.33678
wandb:  valid_error_force 3.89104
wandb:         valid_loss 1.9937
wandb: 
wandb: ğŸš€ View run al_79_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/hlk2fna1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_201507-hlk2fna1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.5015681385993958, Uncertainty Bias: -0.12128792703151703
0.00011444092 0.02208805
-1.7434446 8.524045
(48745, 22, 3)
Found uncertainty sample 0 after 1585 steps.
Found uncertainty sample 1 after 362 steps.
Found uncertainty sample 2 after 799 steps.
Found uncertainty sample 3 after 1196 steps.
Found uncertainty sample 4 after 189 steps.
Found uncertainty sample 5 after 599 steps.
Found uncertainty sample 6 after 435 steps.
Found uncertainty sample 7 after 263 steps.
Found uncertainty sample 8 after 145 steps.
Found uncertainty sample 9 after 345 steps.
Found uncertainty sample 10 after 2 steps.
Found uncertainty sample 11 after 278 steps.
Found uncertainty sample 12 after 555 steps.
Found uncertainty sample 13 after 68 steps.
Found uncertainty sample 14 after 604 steps.
Found uncertainty sample 15 after 618 steps.
Found uncertainty sample 16 after 1105 steps.
Found uncertainty sample 17 after 529 steps.
Found uncertainty sample 18 after 80 steps.
Found uncertainty sample 19 after 82 steps.
Found uncertainty sample 20 after 840 steps.
Found uncertainty sample 21 after 379 steps.
Found uncertainty sample 22 after 572 steps.
Found uncertainty sample 23 after 1783 steps.
Found uncertainty sample 24 after 589 steps.
Found uncertainty sample 25 after 797 steps.
Found uncertainty sample 26 after 2020 steps.
Found uncertainty sample 27 after 154 steps.
Found uncertainty sample 28 after 417 steps.
Found uncertainty sample 29 after 36 steps.
Found uncertainty sample 30 after 17 steps.
Found uncertainty sample 31 after 358 steps.
Found uncertainty sample 32 after 793 steps.
Found uncertainty sample 33 after 71 steps.
Found uncertainty sample 34 after 494 steps.
Found uncertainty sample 35 after 9 steps.
Found uncertainty sample 36 after 515 steps.
Found uncertainty sample 37 after 829 steps.
Found uncertainty sample 38 after 36 steps.
Found uncertainty sample 39 after 156 steps.
Found uncertainty sample 40 after 87 steps.
Found uncertainty sample 41 after 1836 steps.
Found uncertainty sample 42 after 89 steps.
Found uncertainty sample 43 after 534 steps.
Found uncertainty sample 44 after 244 steps.
Found uncertainty sample 45 after 734 steps.
Found uncertainty sample 46 after 26 steps.
Found uncertainty sample 47 after 426 steps.
Found uncertainty sample 48 after 520 steps.
Found uncertainty sample 49 after 567 steps.
Found uncertainty sample 50 after 950 steps.
Found uncertainty sample 51 after 1025 steps.
Found uncertainty sample 52 after 275 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 2076 steps.
Found uncertainty sample 55 after 244 steps.
Found uncertainty sample 56 after 2383 steps.
Found uncertainty sample 57 after 925 steps.
Found uncertainty sample 58 after 809 steps.
Found uncertainty sample 59 after 636 steps.
Found uncertainty sample 60 after 870 steps.
Found uncertainty sample 61 after 329 steps.
Found uncertainty sample 62 after 1251 steps.
Found uncertainty sample 63 after 1248 steps.
Found uncertainty sample 64 after 125 steps.
Found uncertainty sample 65 after 911 steps.
Found uncertainty sample 66 after 1218 steps.
Found uncertainty sample 67 after 458 steps.
Found uncertainty sample 68 after 76 steps.
Found uncertainty sample 69 after 930 steps.
Found uncertainty sample 70 after 1349 steps.
Found uncertainty sample 71 after 1330 steps.
Found uncertainty sample 72 after 385 steps.
Found uncertainty sample 73 after 897 steps.
Found uncertainty sample 74 after 54 steps.
Found uncertainty sample 75 after 938 steps.
Found uncertainty sample 76 after 271 steps.
Found uncertainty sample 77 after 40 steps.
Found uncertainty sample 78 after 3057 steps.
Found uncertainty sample 79 after 86 steps.
Found uncertainty sample 80 after 1330 steps.
Found uncertainty sample 81 after 129 steps.
Found uncertainty sample 82 after 929 steps.
Found uncertainty sample 83 after 54 steps.
Found uncertainty sample 84 after 1666 steps.
Found uncertainty sample 85 after 798 steps.
Found uncertainty sample 86 after 950 steps.
Found uncertainty sample 87 after 1144 steps.
Found uncertainty sample 88 after 834 steps.
Found uncertainty sample 89 after 162 steps.
Found uncertainty sample 90 after 1159 steps.
Found uncertainty sample 91 after 374 steps.
Found uncertainty sample 92 after 743 steps.
Found uncertainty sample 93 after 630 steps.
Found uncertainty sample 94 after 372 steps.
Found uncertainty sample 95 after 441 steps.
Found uncertainty sample 96 after 48 steps.
Found uncertainty sample 97 after 1265 steps.
Found uncertainty sample 98 after 2383 steps.
Found uncertainty sample 99 after 65 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_204234-1dr55e3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/1dr55e3r
Training model 11. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.6473430506367657, Training Loss Force: 3.4838424515467414, time: 0.8034243583679199
Validation Loss Energy: 2.2883551145250878, Validation Loss Force: 3.7099006604144398, time: 0.05633211135864258
Test Loss Energy: 8.898144437523305, Test Loss Force: 9.403203545615261, time: 7.867214679718018


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8732228343763875, Training Loss Force: 3.2021002902679423, time: 0.8439590930938721
Validation Loss Energy: 2.0679066479896377, Validation Loss Force: 3.31807833708743, time: 0.05994582176208496
Test Loss Energy: 8.600193949740849, Test Loss Force: 9.433752577303052, time: 7.867818117141724


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.874599837503201, Training Loss Force: 3.2011781830778627, time: 0.8030214309692383
Validation Loss Energy: 1.5263437774091089, Validation Loss Force: 3.015939018316306, time: 0.06545352935791016
Test Loss Energy: 8.915971347999195, Test Loss Force: 9.487259334207238, time: 7.840945243835449


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6445721742846304, Training Loss Force: 3.149557737039195, time: 0.8042135238647461
Validation Loss Energy: 1.3739853646742035, Validation Loss Force: 3.1758268212189007, time: 0.08709430694580078
Test Loss Energy: 9.0199183369415, Test Loss Force: 9.52186241326779, time: 8.009716272354126


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7213106206352289, Training Loss Force: 3.140672801342582, time: 0.8521490097045898
Validation Loss Energy: 1.4748771443650897, Validation Loss Force: 3.181881083962104, time: 0.057970523834228516
Test Loss Energy: 9.379170755109413, Test Loss Force: 9.513507904218407, time: 7.810288906097412


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0542084489315613, Training Loss Force: 3.1109094644620088, time: 0.7545676231384277
Validation Loss Energy: 1.780771054607561, Validation Loss Force: 3.0861231084324423, time: 0.06504082679748535
Test Loss Energy: 8.88730724444009, Test Loss Force: 9.42326016465907, time: 7.818902969360352


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 13.353217617545305, Training Loss Force: 6.518201924833386, time: 0.8119649887084961
Validation Loss Energy: 3.221122401552677, Validation Loss Force: 6.988899115042095, time: 0.05930781364440918
Test Loss Energy: 9.963677211874348, Test Loss Force: 11.055373018641927, time: 8.430329322814941


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 12.584753234374158, Training Loss Force: 7.058006188756171, time: 0.7346358299255371
Validation Loss Energy: 18.10021374622214, Validation Loss Force: 6.2274850879100665, time: 0.058217763900756836
Test Loss Energy: 24.697068545542283, Test Loss Force: 11.27134160929368, time: 7.80770468711853


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.163613935880086, Training Loss Force: 5.693458745756194, time: 0.7979843616485596
Validation Loss Energy: 9.002474380090778, Validation Loss Force: 5.955060966663007, time: 0.05735492706298828
Test Loss Energy: 9.939633248273761, Test Loss Force: 10.719299218146396, time: 7.808786630630493


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.062178595111394, Training Loss Force: 5.152764473257137, time: 0.7588975429534912
Validation Loss Energy: 11.367964424791285, Validation Loss Force: 5.08493073305405, time: 0.056972503662109375
Test Loss Energy: 18.425313375969687, Test Loss Force: 10.485311750567204, time: 7.799260377883911


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 18.95821896398159, Training Loss Force: 5.728406625388571, time: 0.9697840213775635
Validation Loss Energy: 7.096810149887348, Validation Loss Force: 7.072960280336169, time: 0.05852556228637695
Test Loss Energy: 9.903668473940016, Test Loss Force: 12.170484027300727, time: 8.414557456970215


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 12.512813183937437, Training Loss Force: 6.558654828067942, time: 0.8370075225830078
Validation Loss Energy: 40.0864618966482, Validation Loss Force: 5.685279705508964, time: 0.06636667251586914
Test Loss Energy: 41.06115038797408, Test Loss Force: 11.26980195124319, time: 9.947821617126465


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 17.698282526288537, Training Loss Force: 6.542427188872007, time: 0.8084347248077393
Validation Loss Energy: 14.041614761968802, Validation Loss Force: 8.462608137067647, time: 0.07006216049194336
Test Loss Energy: 13.242807333915668, Test Loss Force: 12.125359180574751, time: 9.175539016723633


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 10.83126777429006, Training Loss Force: 7.4337729875728495, time: 0.8258428573608398
Validation Loss Energy: 16.141930347475363, Validation Loss Force: 7.022913385766586, time: 0.08479809761047363
Test Loss Energy: 13.785970234447504, Test Loss Force: 11.582138894356845, time: 7.893515348434448


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.259482984389848, Training Loss Force: 5.860645180795611, time: 0.7421329021453857
Validation Loss Energy: 16.348060519920217, Validation Loss Force: 6.025974854904922, time: 0.057672739028930664
Test Loss Energy: 14.769381737103798, Test Loss Force: 10.520687755036521, time: 7.803122043609619


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.420003133410084, Training Loss Force: 5.69535888434877, time: 0.8048126697540283
Validation Loss Energy: 17.858670272808922, Validation Loss Force: 6.073462167642065, time: 0.06039905548095703
Test Loss Energy: 19.857780346250088, Test Loss Force: 10.81363178704776, time: 7.813883543014526


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 11.539779372032529, Training Loss Force: 5.084238463243559, time: 0.8213529586791992
Validation Loss Energy: 3.248174476091444, Validation Loss Force: 4.668483762882605, time: 0.05915641784667969
Test Loss Energy: 8.40459539369934, Test Loss Force: 10.14042867834627, time: 8.00685715675354


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 18.35116814267563, Training Loss Force: 5.769213495487368, time: 0.7716646194458008
Validation Loss Energy: 5.716958622230964, Validation Loss Force: 5.16711991883831, time: 0.05791115760803223
Test Loss Energy: 9.500110887980693, Test Loss Force: 10.110628309290984, time: 7.852697134017944


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.102198994106418, Training Loss Force: 5.8327799099717215, time: 0.8248224258422852
Validation Loss Energy: 13.817639438831002, Validation Loss Force: 5.326933795584456, time: 0.05649161338806152
Test Loss Energy: 18.282969184269973, Test Loss Force: 10.345461024284889, time: 8.249006986618042


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 12.812821745253332, Training Loss Force: 6.147605409378975, time: 0.8411374092102051
Validation Loss Energy: 3.085073557413112, Validation Loss Force: 5.455878157954049, time: 0.06228995323181152
Test Loss Energy: 8.776304460161697, Test Loss Force: 10.413363539660507, time: 7.842386722564697

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–â–„â–â–ƒâ–â–ˆâ–‚â–‚â–‚â–ƒâ–â–â–ƒâ–
wandb:   test_error_force â–â–â–â–â–â–â–…â–†â–„â–„â–ˆâ–†â–ˆâ–‡â–„â–…â–ƒâ–ƒâ–ƒâ–„
wandb:          test_loss â–â–â–â–â–â–â–ƒâ–…â–‚â–„â–„â–ˆâ–„â–„â–ƒâ–„â–‚â–‚â–ƒâ–‚
wandb: train_error_energy â–‚â–â–â–â–â–â–†â–…â–…â–…â–ˆâ–…â–‡â–…â–…â–…â–…â–ˆâ–„â–†
wandb:  train_error_force â–‚â–â–â–â–â–â–‡â–‡â–…â–„â–…â–‡â–‡â–ˆâ–…â–…â–„â–…â–…â–†
wandb:         train_loss â–‚â–â–â–â–â–â–‡â–‡â–†â–…â–‡â–‡â–ˆâ–‡â–†â–†â–…â–‡â–…â–‡
wandb: valid_error_energy â–â–â–â–â–â–â–â–„â–‚â–ƒâ–‚â–ˆâ–ƒâ–„â–„â–„â–â–‚â–ƒâ–
wandb:  valid_error_force â–‚â–â–â–â–â–â–†â–…â–…â–„â–†â–„â–ˆâ–†â–…â–…â–ƒâ–„â–„â–„
wandb:         valid_loss â–‚â–â–â–â–â–â–„â–…â–„â–„â–„â–ˆâ–†â–†â–…â–…â–‚â–ƒâ–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1651
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.7763
wandb:   test_error_force 10.41336
wandb:          test_loss 4.07166
wandb: train_error_energy 12.81282
wandb:  train_error_force 6.14761
wandb:         train_loss 2.91445
wandb: valid_error_energy 3.08507
wandb:  valid_error_force 5.45588
wandb:         valid_loss 2.03201
wandb: 
wandb: ğŸš€ View run al_79_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/1dr55e3r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_204234-1dr55e3r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.764957070350647, Uncertainty Bias: -0.4261380434036255
9.1552734e-05 0.001666069
-6.0016756 8.98437
(48745, 22, 3)
Found uncertainty sample 0 after 66 steps.
Found uncertainty sample 1 after 767 steps.
Found uncertainty sample 2 after 28 steps.
Found uncertainty sample 3 after 402 steps.
Found uncertainty sample 4 after 68 steps.
Found uncertainty sample 5 after 1103 steps.
Found uncertainty sample 6 after 35 steps.
Found uncertainty sample 7 after 222 steps.
Found uncertainty sample 8 after 165 steps.
Found uncertainty sample 9 after 406 steps.
Found uncertainty sample 10 after 268 steps.
Found uncertainty sample 11 after 64 steps.
Found uncertainty sample 12 after 87 steps.
Found uncertainty sample 13 after 84 steps.
Found uncertainty sample 14 after 143 steps.
Found uncertainty sample 15 after 101 steps.
Found uncertainty sample 16 after 326 steps.
Found uncertainty sample 17 after 381 steps.
Found uncertainty sample 18 after 513 steps.
Found uncertainty sample 19 after 24 steps.
Found uncertainty sample 20 after 30 steps.
Found uncertainty sample 21 after 163 steps.
Found uncertainty sample 22 after 34 steps.
Found uncertainty sample 23 after 66 steps.
Found uncertainty sample 24 after 17 steps.
Found uncertainty sample 25 after 44 steps.
Found uncertainty sample 26 after 50 steps.
Found uncertainty sample 27 after 60 steps.
Found uncertainty sample 28 after 40 steps.
Found uncertainty sample 29 after 354 steps.
Found uncertainty sample 30 after 752 steps.
Found uncertainty sample 31 after 129 steps.
Found uncertainty sample 32 after 58 steps.
Found uncertainty sample 33 after 139 steps.
Found uncertainty sample 34 after 195 steps.
Found uncertainty sample 35 after 21 steps.
Found uncertainty sample 36 after 125 steps.
Found uncertainty sample 37 after 68 steps.
Found uncertainty sample 38 after 333 steps.
Found uncertainty sample 39 after 350 steps.
Found uncertainty sample 40 after 56 steps.
Found uncertainty sample 41 after 121 steps.
Found uncertainty sample 42 after 72 steps.
Found uncertainty sample 43 after 208 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 196 steps.
Found uncertainty sample 46 after 540 steps.
Found uncertainty sample 47 after 197 steps.
Found uncertainty sample 48 after 289 steps.
Found uncertainty sample 49 after 30 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 70 steps.
Found uncertainty sample 52 after 348 steps.
Found uncertainty sample 53 after 243 steps.
Found uncertainty sample 54 after 78 steps.
Found uncertainty sample 55 after 30 steps.
Found uncertainty sample 56 after 173 steps.
Found uncertainty sample 57 after 6 steps.
Found uncertainty sample 58 after 241 steps.
Found uncertainty sample 59 after 20 steps.
Found uncertainty sample 60 after 17 steps.
Found uncertainty sample 61 after 74 steps.
Found uncertainty sample 62 after 4 steps.
Found uncertainty sample 63 after 184 steps.
Found uncertainty sample 64 after 240 steps.
Found uncertainty sample 65 after 6 steps.
Found uncertainty sample 66 after 382 steps.
Found uncertainty sample 67 after 30 steps.
Found uncertainty sample 68 after 1830 steps.
Found uncertainty sample 69 after 30 steps.
Found uncertainty sample 70 after 114 steps.
Found uncertainty sample 71 after 38 steps.
Found uncertainty sample 72 after 142 steps.
Found uncertainty sample 73 after 76 steps.
Found uncertainty sample 74 after 62 steps.
Found uncertainty sample 75 after 61 steps.
Found uncertainty sample 76 after 568 steps.
Found uncertainty sample 77 after 89 steps.
Found uncertainty sample 78 after 711 steps.
Found uncertainty sample 79 after 36 steps.
Found uncertainty sample 80 after 80 steps.
Found uncertainty sample 81 after 188 steps.
Found uncertainty sample 82 after 495 steps.
Found uncertainty sample 83 after 97 steps.
Found uncertainty sample 84 after 32 steps.
Found uncertainty sample 85 after 65 steps.
Found uncertainty sample 86 after 526 steps.
Found uncertainty sample 87 after 47 steps.
Found uncertainty sample 88 after 100 steps.
Found uncertainty sample 89 after 44 steps.
Found uncertainty sample 90 after 395 steps.
Found uncertainty sample 91 after 131 steps.
Found uncertainty sample 92 after 251 steps.
Found uncertainty sample 93 after 49 steps.
Found uncertainty sample 94 after 90 steps.
Found uncertainty sample 95 after 75 steps.
Found uncertainty sample 96 after 21 steps.
Found uncertainty sample 97 after 7 steps.
Found uncertainty sample 98 after 60 steps.
Found uncertainty sample 99 after 246 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_205525-118urtjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/118urtjc
Training model 12. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8986270905079468, Training Loss Force: 3.431937850637452, time: 0.8520708084106445
Validation Loss Energy: 1.5648942083071544, Validation Loss Force: 3.253347303020492, time: 0.07491445541381836
Test Loss Energy: 9.000194154771915, Test Loss Force: 9.391493988445426, time: 9.166227579116821


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7634219935654916, Training Loss Force: 3.182775683571314, time: 0.8549604415893555
Validation Loss Energy: 1.6560434335216891, Validation Loss Force: 3.2865358052173104, time: 0.07487845420837402
Test Loss Energy: 9.090291290713726, Test Loss Force: 9.47936006348315, time: 9.42420506477356


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.627273542432025, Training Loss Force: 3.1554916849472074, time: 0.8167955875396729
Validation Loss Energy: 3.1585886666177547, Validation Loss Force: 3.3389286305738164, time: 0.06509613990783691
Test Loss Energy: 10.790119627316074, Test Loss Force: 9.547703599001318, time: 9.306784868240356


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.328316349804155, Training Loss Force: 3.1598672227323474, time: 0.8729643821716309
Validation Loss Energy: 1.3769871117631696, Validation Loss Force: 3.2606795753267486, time: 0.06673097610473633
Test Loss Energy: 9.09794839067161, Test Loss Force: 9.562311357152582, time: 9.849615335464478


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8323395233612054, Training Loss Force: 3.1112700824380704, time: 0.8868772983551025
Validation Loss Energy: 1.2760648820665779, Validation Loss Force: 3.1691812605586858, time: 0.06756162643432617
Test Loss Energy: 9.407615892125774, Test Loss Force: 9.561195954939313, time: 9.711332321166992


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.7915771010558763, Training Loss Force: 3.1476555447519567, time: 0.8997657299041748
Validation Loss Energy: 2.805738453883891, Validation Loss Force: 3.0903169704614193, time: 0.06813836097717285
Test Loss Energy: 10.753792627406451, Test Loss Force: 9.570876243078397, time: 9.929527282714844


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 13.652107430563019, Training Loss Force: 6.149298537916525, time: 0.8118414878845215
Validation Loss Energy: 2.2628739708108414, Validation Loss Force: 5.963888239615022, time: 0.06843066215515137
Test Loss Energy: 8.925708569491212, Test Loss Force: 10.731834702976569, time: 9.898879766464233


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.237118420825743, Training Loss Force: 6.301789830488529, time: 0.7728183269500732
Validation Loss Energy: 3.7286936023270263, Validation Loss Force: 5.769658842343423, time: 0.0625922679901123
Test Loss Energy: 9.480928293132742, Test Loss Force: 10.751411415217968, time: 9.82311725616455


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.748534647480126, Training Loss Force: 7.47224012331549, time: 0.8566677570343018
Validation Loss Energy: 12.129942695539093, Validation Loss Force: 5.552678225086653, time: 0.08610153198242188
Test Loss Energy: 11.584584020750857, Test Loss Force: 10.215656649554337, time: 9.94090461730957


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.967366138728577, Training Loss Force: 6.040577562271344, time: 0.8388094902038574
Validation Loss Energy: 3.4193651875104782, Validation Loss Force: 8.098801489008405, time: 0.0695805549621582
Test Loss Energy: 10.777223120022898, Test Loss Force: 12.490420964479885, time: 9.73616886138916


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 8.40068246096363, Training Loss Force: 4.920176576937802, time: 0.8307793140411377
Validation Loss Energy: 7.524895368309002, Validation Loss Force: 6.4575593189548295, time: 0.06946229934692383
Test Loss Energy: 15.394839740487516, Test Loss Force: 11.716149706094082, time: 10.408830642700195


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.499588221352914, Training Loss Force: 6.600928079287317, time: 0.8135144710540771
Validation Loss Energy: 19.172202690049616, Validation Loss Force: 6.134481529715533, time: 0.06476497650146484
Test Loss Energy: 15.281203817781073, Test Loss Force: 10.59418791159998, time: 9.978087902069092


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.917954288145785, Training Loss Force: 6.49432886125426, time: 0.8684003353118896
Validation Loss Energy: 8.23584944960575, Validation Loss Force: 5.675506534025047, time: 0.0689547061920166
Test Loss Energy: 9.964385402349418, Test Loss Force: 10.571167610524544, time: 9.750876903533936


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 10.91251410354552, Training Loss Force: 6.635716789252814, time: 0.8227279186248779
Validation Loss Energy: 14.991025676977909, Validation Loss Force: 6.052336209753021, time: 0.06892251968383789
Test Loss Energy: 18.834815710506952, Test Loss Force: 10.890332657531598, time: 9.961159229278564


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.949453263054732, Training Loss Force: 6.337289041261914, time: 0.8534679412841797
Validation Loss Energy: 6.70586948504364, Validation Loss Force: 4.276259187743476, time: 0.06988334655761719
Test Loss Energy: 8.841629590665463, Test Loss Force: 9.798976301133433, time: 9.9221830368042


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 10.333256510485558, Training Loss Force: 6.034251143176663, time: 0.8307235240936279
Validation Loss Energy: 16.865336978088976, Validation Loss Force: 5.208716073981643, time: 0.07064533233642578
Test Loss Energy: 21.50918172963562, Test Loss Force: 10.565415192129944, time: 9.713651657104492


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.654067032194725, Training Loss Force: 5.55809443748926, time: 0.8351662158966064
Validation Loss Energy: 20.456992973933946, Validation Loss Force: 7.254057987395823, time: 0.07007932662963867
Test Loss Energy: 24.133994364799545, Test Loss Force: 12.237264546658418, time: 9.907860279083252


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.702369918088886, Training Loss Force: 6.320313377147046, time: 0.931513786315918
Validation Loss Energy: 13.03596118340467, Validation Loss Force: 5.020498743650093, time: 0.06971168518066406
Test Loss Energy: 17.95246149687652, Test Loss Force: 10.194203076569018, time: 9.778326511383057


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.7130667714764, Training Loss Force: 6.0265264913985135, time: 0.8198471069335938
Validation Loss Energy: 14.487324465959784, Validation Loss Force: 6.688862461015967, time: 0.06535482406616211
Test Loss Energy: 16.18558607680363, Test Loss Force: 10.925852797720943, time: 9.897487163543701


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.673031867122535, Training Loss Force: 5.490153271413141, time: 0.831568717956543
Validation Loss Energy: 14.578788044341083, Validation Loss Force: 6.433088870493949, time: 0.06872057914733887
Test Loss Energy: 18.482791207427503, Test Loss Force: 11.21954418199757, time: 9.87021541595459

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–‚â–â–â–‚â–â–â–‚â–‚â–„â–„â–‚â–†â–â–‡â–ˆâ–…â–„â–…
wandb:   test_error_force â–â–â–â–â–â–â–„â–„â–ƒâ–ˆâ–†â–„â–„â–„â–‚â–„â–‡â–ƒâ–„â–…
wandb:          test_loss â–â–â–‚â–â–â–‚â–ƒâ–ƒâ–ƒâ–…â–…â–„â–ƒâ–…â–â–…â–ˆâ–„â–…â–…
wandb: train_error_energy â–‚â–â–â–â–â–‚â–ˆâ–…â–‡â–†â–…â–ˆâ–‡â–†â–†â–†â–…â–†â–‡â–‡
wandb:  train_error_force â–‚â–â–â–â–â–â–†â–†â–ˆâ–†â–„â–‡â–†â–‡â–†â–†â–…â–†â–†â–…
wandb:         train_loss â–‚â–â–â–â–â–â–‡â–†â–ˆâ–†â–„â–‡â–‡â–‡â–†â–†â–…â–†â–†â–†
wandb: valid_error_energy â–â–â–‚â–â–â–‚â–â–‚â–…â–‚â–ƒâ–ˆâ–„â–†â–ƒâ–‡â–ˆâ–…â–†â–†
wandb:  valid_error_force â–â–â–â–â–â–â–…â–…â–„â–ˆâ–†â–…â–…â–…â–ƒâ–„â–‡â–„â–†â–†
wandb:         valid_loss â–â–â–â–â–â–â–„â–„â–…â–†â–…â–‡â–„â–†â–ƒâ–†â–ˆâ–…â–†â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1741
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 18.48279
wandb:   test_error_force 11.21954
wandb:          test_loss 4.99098
wandb: train_error_energy 11.67303
wandb:  train_error_force 5.49015
wandb:         train_loss 2.61819
wandb: valid_error_energy 14.57879
wandb:  valid_error_force 6.43309
wandb:         valid_loss 3.12815
wandb: 
wandb: ğŸš€ View run al_79_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/118urtjc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_205525-118urtjc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.18504279851913452, Uncertainty Bias: 0.05274815857410431
6.866455e-05 0.022388458
0.836636 4.97721
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 263 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3431 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1462 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3203 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2056 steps.
Found uncertainty sample 16 after 2722 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3850 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2896 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3889 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3582 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1837 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 486 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 845 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3385 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3985 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1493 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3505 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1516 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3083 steps.
Found uncertainty sample 97 after 3429 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_225653-hsg8gple
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/hsg8gple
Training model 13. Added 20 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.117504337600952, Training Loss Force: 3.5084792440588104, time: 0.7965068817138672
Validation Loss Energy: 1.591224556476683, Validation Loss Force: 3.1999067079978234, time: 0.06080460548400879
Test Loss Energy: 8.790913081010178, Test Loss Force: 9.489972400366417, time: 7.855229616165161


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.778004164763865, Training Loss Force: 3.192328744580215, time: 0.8138918876647949
Validation Loss Energy: 1.5888614801655243, Validation Loss Force: 3.1555741717201844, time: 0.05802130699157715
Test Loss Energy: 9.007280359019008, Test Loss Force: 9.587290223393003, time: 7.8316099643707275


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.14091245010533, Training Loss Force: 3.1837360070153404, time: 0.8201849460601807
Validation Loss Energy: 1.9906394523415387, Validation Loss Force: 3.222920120902325, time: 0.0630652904510498
Test Loss Energy: 9.340068187793221, Test Loss Force: 9.56752154470006, time: 7.880096435546875


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9783470527472196, Training Loss Force: 3.1484120409083314, time: 0.9197554588317871
Validation Loss Energy: 3.4593795010411394, Validation Loss Force: 3.403905825381577, time: 0.08964872360229492
Test Loss Energy: 11.168799296598767, Test Loss Force: 9.546534751529798, time: 8.011848211288452


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0901632347825756, Training Loss Force: 3.123683146442568, time: 0.8580844402313232
Validation Loss Energy: 1.6465988660298754, Validation Loss Force: 3.169557237411585, time: 0.06063365936279297
Test Loss Energy: 9.807933369212996, Test Loss Force: 9.583158500628329, time: 7.876099586486816


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7627459963538992, Training Loss Force: 3.1047652486780812, time: 0.8554739952087402
Validation Loss Energy: 1.3551911980813145, Validation Loss Force: 3.1746554701767473, time: 0.058188438415527344
Test Loss Energy: 9.56899108645153, Test Loss Force: 9.606625016682523, time: 7.855613708496094


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 11.410255218602257, Training Loss Force: 5.145953155816143, time: 0.8379831314086914
Validation Loss Energy: 13.407707767869404, Validation Loss Force: 6.203293421219888, time: 0.05896878242492676
Test Loss Energy: 10.72409733953513, Test Loss Force: 10.931859954281713, time: 8.051460981369019


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.30914376818235, Training Loss Force: 5.217770817636077, time: 0.8062553405761719
Validation Loss Energy: 8.03978882127804, Validation Loss Force: 4.25481726233636, time: 0.06381583213806152
Test Loss Energy: 9.818112753338474, Test Loss Force: 9.739039418882236, time: 7.868605852127075


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.230802389406884, Training Loss Force: 4.047449555506387, time: 0.8086833953857422
Validation Loss Energy: 7.578159164029804, Validation Loss Force: 4.186062596802508, time: 0.06539392471313477
Test Loss Energy: 10.128348180027071, Test Loss Force: 9.816892694295005, time: 7.866501808166504


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.482432890513727, Training Loss Force: 4.016058930551884, time: 0.9603531360626221
Validation Loss Energy: 14.65323524659058, Validation Loss Force: 4.364128218102062, time: 0.06408381462097168
Test Loss Energy: 19.970149008717357, Test Loss Force: 10.046179100916945, time: 7.895306825637817


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 23.512617514544303, Training Loss Force: 8.424842692843196, time: 0.9558262825012207
Validation Loss Energy: 12.529994091157583, Validation Loss Force: 9.222688376015567, time: 0.05836200714111328
Test Loss Energy: 18.590698279694603, Test Loss Force: 13.180982772231156, time: 7.851121187210083


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 15.553765769957671, Training Loss Force: 8.26472492534375, time: 0.8536319732666016
Validation Loss Energy: 20.68508455890337, Validation Loss Force: 6.838056132847088, time: 0.0584108829498291
Test Loss Energy: 18.095482434903634, Test Loss Force: 10.92018743247014, time: 8.012627601623535


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.463131869600353, Training Loss Force: 6.287138864645387, time: 0.8786041736602783
Validation Loss Energy: 9.651129197063266, Validation Loss Force: 5.334848125038167, time: 0.06834554672241211
Test Loss Energy: 9.637768773177138, Test Loss Force: 10.121090005250899, time: 10.544047117233276


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 11.339523635662903, Training Loss Force: 5.484312505871317, time: 0.8205916881561279
Validation Loss Energy: 13.451480959252471, Validation Loss Force: 5.800810033189575, time: 0.06733155250549316
Test Loss Energy: 19.997443965164628, Test Loss Force: 10.569469799090092, time: 9.84354543685913


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.827904569773471, Training Loss Force: 5.5577734700367305, time: 0.8488967418670654
Validation Loss Energy: 12.911659695396816, Validation Loss Force: 5.4794655005821795, time: 0.06063199043273926
Test Loss Energy: 18.762147291986146, Test Loss Force: 10.57343967519408, time: 7.8442299365997314


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 10.94413615866471, Training Loss Force: 5.366953558436398, time: 0.7882294654846191
Validation Loss Energy: 9.550789135848703, Validation Loss Force: 5.438155920629656, time: 0.06180167198181152
Test Loss Energy: 15.253714558604932, Test Loss Force: 10.346196611225558, time: 7.858682155609131


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 17.205619278645734, Training Loss Force: 6.597573864146599, time: 0.7926533222198486
Validation Loss Energy: 8.760766131509582, Validation Loss Force: 7.859996846090107, time: 0.06161785125732422
Test Loss Energy: 15.896432316662757, Test Loss Force: 12.28624009602883, time: 8.045059204101562


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.011537978732132, Training Loss Force: 5.770737148046555, time: 0.8480002880096436
Validation Loss Energy: 15.377228387734567, Validation Loss Force: 7.8045019055271085, time: 0.05920100212097168
Test Loss Energy: 11.707692988409297, Test Loss Force: 11.620724785316376, time: 7.851910591125488


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.478681945115047, Training Loss Force: 5.339170772828356, time: 0.8898680210113525
Validation Loss Energy: 11.984479177240555, Validation Loss Force: 5.064662719384265, time: 0.05845379829406738
Test Loss Energy: 10.228659664979306, Test Loss Force: 10.048691382460081, time: 7.854779243469238


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.301881849736514, Training Loss Force: 5.346167911875871, time: 0.8592228889465332
Validation Loss Energy: 14.056686791118363, Validation Loss Force: 5.477253727955679, time: 0.06099534034729004
Test Loss Energy: 19.104364709088877, Test Loss Force: 10.245371317802, time: 7.990306377410889

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–ˆâ–‡â–‡â–‚â–ˆâ–‡â–…â–…â–ƒâ–‚â–‡
wandb:   test_error_force â–â–â–â–â–â–â–„â–â–‚â–‚â–ˆâ–„â–‚â–ƒâ–ƒâ–ƒâ–†â–…â–‚â–‚
wandb:          test_loss â–â–â–â–‚â–â–â–ƒâ–‚â–‚â–„â–ˆâ–…â–‚â–…â–…â–„â–†â–„â–‚â–„
wandb: train_error_energy â–‚â–â–â–â–â–â–„â–ƒâ–ƒâ–ƒâ–ˆâ–…â–„â–„â–„â–„â–†â–„â–„â–„
wandb:  train_error_force â–‚â–â–â–â–â–â–„â–„â–‚â–‚â–ˆâ–ˆâ–…â–„â–„â–„â–†â–…â–„â–„
wandb:         train_loss â–‚â–â–â–â–â–â–„â–ƒâ–‚â–‚â–ˆâ–‡â–…â–„â–„â–„â–†â–„â–„â–„
wandb: valid_error_energy â–â–â–â–‚â–â–â–…â–ƒâ–ƒâ–†â–…â–ˆâ–„â–…â–…â–„â–„â–†â–…â–†
wandb:  valid_error_force â–â–â–â–â–â–â–…â–‚â–‚â–‚â–ˆâ–…â–„â–„â–„â–„â–†â–†â–ƒâ–„
wandb:         valid_loss â–â–â–â–‚â–â–â–†â–ƒâ–ƒâ–„â–ˆâ–‡â–„â–…â–…â–„â–†â–‡â–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1759
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 19.10436
wandb:   test_error_force 10.24537
wandb:          test_loss 4.70661
wandb: train_error_energy 11.30188
wandb:  train_error_force 5.34617
wandb:         train_loss 2.54517
wandb: valid_error_energy 14.05669
wandb:  valid_error_force 5.47725
wandb:         valid_loss 2.77339
wandb: 
wandb: ğŸš€ View run al_79_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/hsg8gple
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_225653-hsg8gple/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.4792337715625763, Uncertainty Bias: -0.1661650389432907
3.4332275e-05 0.010681152
-1.4887793 9.346857
(48745, 22, 3)
Found uncertainty sample 0 after 1103 steps.
Found uncertainty sample 1 after 1205 steps.
Found uncertainty sample 2 after 655 steps.
Found uncertainty sample 3 after 924 steps.
Found uncertainty sample 4 after 3370 steps.
Found uncertainty sample 5 after 172 steps.
Found uncertainty sample 6 after 1226 steps.
Found uncertainty sample 7 after 1599 steps.
Found uncertainty sample 8 after 1972 steps.
Found uncertainty sample 9 after 1330 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 267 steps.
Found uncertainty sample 12 after 1602 steps.
Found uncertainty sample 13 after 1301 steps.
Found uncertainty sample 14 after 2461 steps.
Found uncertainty sample 15 after 1029 steps.
Found uncertainty sample 16 after 2740 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1163 steps.
Found uncertainty sample 19 after 973 steps.
Found uncertainty sample 20 after 2874 steps.
Found uncertainty sample 21 after 2330 steps.
Found uncertainty sample 22 after 862 steps.
Found uncertainty sample 23 after 2230 steps.
Found uncertainty sample 24 after 570 steps.
Found uncertainty sample 25 after 2461 steps.
Found uncertainty sample 26 after 516 steps.
Found uncertainty sample 27 after 1756 steps.
Found uncertainty sample 28 after 3338 steps.
Found uncertainty sample 29 after 1914 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3975 steps.
Found uncertainty sample 32 after 1446 steps.
Found uncertainty sample 33 after 2610 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1392 steps.
Found uncertainty sample 36 after 1203 steps.
Found uncertainty sample 37 after 385 steps.
Found uncertainty sample 38 after 1600 steps.
Found uncertainty sample 39 after 58 steps.
Found uncertainty sample 40 after 3662 steps.
Found uncertainty sample 41 after 3554 steps.
Found uncertainty sample 42 after 1341 steps.
Found uncertainty sample 43 after 517 steps.
Found uncertainty sample 44 after 774 steps.
Found uncertainty sample 45 after 797 steps.
Found uncertainty sample 46 after 497 steps.
Found uncertainty sample 47 after 2162 steps.
Found uncertainty sample 48 after 714 steps.
Found uncertainty sample 49 after 906 steps.
Found uncertainty sample 50 after 1043 steps.
Found uncertainty sample 51 after 3254 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1106 steps.
Found uncertainty sample 54 after 2987 steps.
Found uncertainty sample 55 after 2619 steps.
Found uncertainty sample 56 after 2996 steps.
Found uncertainty sample 57 after 2904 steps.
Found uncertainty sample 58 after 1268 steps.
Found uncertainty sample 59 after 208 steps.
Found uncertainty sample 60 after 1074 steps.
Found uncertainty sample 61 after 1854 steps.
Found uncertainty sample 62 after 741 steps.
Found uncertainty sample 63 after 2779 steps.
Found uncertainty sample 64 after 2267 steps.
Found uncertainty sample 65 after 2071 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3120 steps.
Found uncertainty sample 70 after 224 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1830 steps.
Found uncertainty sample 73 after 1137 steps.
Found uncertainty sample 74 after 2083 steps.
Found uncertainty sample 75 after 163 steps.
Found uncertainty sample 76 after 491 steps.
Found uncertainty sample 77 after 98 steps.
Found uncertainty sample 78 after 2309 steps.
Found uncertainty sample 79 after 2391 steps.
Found uncertainty sample 80 after 2366 steps.
Found uncertainty sample 81 after 997 steps.
Found uncertainty sample 82 after 133 steps.
Found uncertainty sample 83 after 1426 steps.
Found uncertainty sample 84 after 1111 steps.
Found uncertainty sample 85 after 2232 steps.
Found uncertainty sample 86 after 226 steps.
Found uncertainty sample 87 after 1492 steps.
Found uncertainty sample 88 after 2941 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2719 steps.
Found uncertainty sample 91 after 977 steps.
Found uncertainty sample 92 after 1496 steps.
Found uncertainty sample 93 after 1673 steps.
Found uncertainty sample 94 after 3482 steps.
Found uncertainty sample 95 after 517 steps.
Found uncertainty sample 96 after 2594 steps.
Found uncertainty sample 97 after 1349 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1437 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_000144-p4wwz81a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/p4wwz81a
Training model 14. Added 89 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4645082298814867, Training Loss Force: 3.430305325757847, time: 0.9094061851501465
Validation Loss Energy: 2.162582674139236, Validation Loss Force: 3.1095430038628358, time: 0.06818222999572754
Test Loss Energy: 10.159557380266062, Test Loss Force: 9.405070203215908, time: 9.887471914291382


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7853181025345266, Training Loss Force: 3.2047130790995233, time: 0.9091775417327881
Validation Loss Energy: 3.9432296463652285, Validation Loss Force: 3.3601036870095378, time: 0.06727862358093262
Test Loss Energy: 11.134058983395901, Test Loss Force: 9.497848914536952, time: 9.990123987197876


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.5043769337959865, Training Loss Force: 3.1740534150365143, time: 0.939720869064331
Validation Loss Energy: 2.5302867002596505, Validation Loss Force: 3.1724055097917203, time: 0.0667731761932373
Test Loss Energy: 9.228609624255062, Test Loss Force: 9.359699581048341, time: 10.47290825843811


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2167468018386116, Training Loss Force: 3.171488550570543, time: 0.9018537998199463
Validation Loss Energy: 1.9813162952015422, Validation Loss Force: 3.250007154497003, time: 0.07141590118408203
Test Loss Energy: 9.849160008988987, Test Loss Force: 9.444818944735516, time: 9.896642446517944


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.5414125592824335, Training Loss Force: 3.2418737186036983, time: 0.8254003524780273
Validation Loss Energy: 1.643197427823969, Validation Loss Force: 3.313856418746066, time: 0.06966495513916016
Test Loss Energy: 10.152922497232588, Test Loss Force: 9.47542120717306, time: 10.062388896942139


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1731100029856707, Training Loss Force: 3.1515204415273375, time: 0.8895003795623779
Validation Loss Energy: 1.582286561291855, Validation Loss Force: 3.2047102381483503, time: 0.0709843635559082
Test Loss Energy: 9.081830609284982, Test Loss Force: 9.511959246137515, time: 10.02935791015625


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 11.452252290310653, Training Loss Force: 5.534658282953277, time: 1.0017807483673096
Validation Loss Energy: 16.31889086180368, Validation Loss Force: 7.438493950291226, time: 0.07556033134460449
Test Loss Energy: 18.326575935712597, Test Loss Force: 11.619224041905106, time: 9.793736934661865


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 17.3617497173575, Training Loss Force: 6.566912013668023, time: 0.9200220108032227
Validation Loss Energy: 9.898501258040284, Validation Loss Force: 6.865419944190153, time: 0.06836605072021484
Test Loss Energy: 15.18998844904648, Test Loss Force: 11.580801009526775, time: 10.093480110168457


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 9.743610062472476, Training Loss Force: 6.972604002665185, time: 1.0717499256134033
Validation Loss Energy: 5.229273334871987, Validation Loss Force: 4.943655621390414, time: 0.06658935546875
Test Loss Energy: 9.461268668694176, Test Loss Force: 9.970101181760151, time: 9.899600267410278


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.389613875922844, Training Loss Force: 6.247578690212621, time: 0.8682136535644531
Validation Loss Energy: 14.675128967694782, Validation Loss Force: 5.541791930542243, time: 0.07443618774414062
Test Loss Energy: 18.51089625054896, Test Loss Force: 10.526172247655637, time: 9.76366639137268


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.286750723741912, Training Loss Force: 5.573753283880236, time: 0.8772075176239014
Validation Loss Energy: 16.11227972400362, Validation Loss Force: 5.206407885614954, time: 0.07490658760070801
Test Loss Energy: 19.81380803502344, Test Loss Force: 10.365890286556349, time: 10.1642324924469


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.923132936860865, Training Loss Force: 5.3954702069640685, time: 0.8716874122619629
Validation Loss Energy: 13.30628063588442, Validation Loss Force: 5.110306554262273, time: 0.06683349609375
Test Loss Energy: 10.89649734726698, Test Loss Force: 10.298105909403619, time: 9.98168683052063


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 18.803777008583744, Training Loss Force: 6.625891764756024, time: 0.9357068538665771
Validation Loss Energy: 15.645200907416239, Validation Loss Force: 8.409051308750804, time: 0.07549095153808594
Test Loss Energy: 18.84115022102322, Test Loss Force: 13.128115511787618, time: 9.817854642868042


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.947695863392305, Training Loss Force: 7.123715408676485, time: 0.9168047904968262
Validation Loss Energy: 2.1112426285046766, Validation Loss Force: 5.302697817734238, time: 0.07100224494934082
Test Loss Energy: 8.929242373137752, Test Loss Force: 10.20280116467952, time: 10.061479806900024


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.2271329187309465, Training Loss Force: 5.40806052705629, time: 0.8529102802276611
Validation Loss Energy: 7.363288336930699, Validation Loss Force: 4.854988767481968, time: 0.07446670532226562
Test Loss Energy: 13.26246079356657, Test Loss Force: 10.166713015317631, time: 10.495518207550049


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.26088720143682, Training Loss Force: 5.5665887505450815, time: 0.8986172676086426
Validation Loss Energy: 9.500902340395042, Validation Loss Force: 5.178671326121606, time: 0.07629203796386719
Test Loss Energy: 9.664475780488138, Test Loss Force: 10.2603439409163, time: 9.78583312034607


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 11.620480926220369, Training Loss Force: 5.260660900533912, time: 0.9213838577270508
Validation Loss Energy: 8.546170968813136, Validation Loss Force: 5.814507971039614, time: 0.07371807098388672
Test Loss Energy: 9.71836619516495, Test Loss Force: 10.556345591027773, time: 9.96868348121643


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.29138457808368, Training Loss Force: 5.23041003782721, time: 0.8811805248260498
Validation Loss Energy: 1.9304119017509906, Validation Loss Force: 5.343531553721913, time: 0.07091379165649414
Test Loss Energy: 8.8380482034385, Test Loss Force: 10.534524798149183, time: 10.032989501953125


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 16.14424652121832, Training Loss Force: 6.265093058211042, time: 0.9062418937683105
Validation Loss Energy: 22.76428264794843, Validation Loss Force: 8.659973161252202, time: 0.06864619255065918
Test Loss Energy: 19.61652225773869, Test Loss Force: 12.08583151804026, time: 9.920580625534058


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.849173884912437, Training Loss Force: 5.831379374200924, time: 0.9529476165771484
Validation Loss Energy: 6.4119070226492765, Validation Loss Force: 4.9070617286103495, time: 0.07578492164611816
Test Loss Energy: 13.289897614741744, Test Loss Force: 10.07955772817308, time: 9.986276626586914

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–â–‚â–‚â–â–‡â–…â–â–‡â–ˆâ–‚â–‡â–â–„â–‚â–‚â–â–ˆâ–„
wandb:   test_error_force â–â–â–â–â–â–â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–†â–‚
wandb:          test_loss â–â–‚â–â–â–â–â–†â–…â–‚â–…â–…â–ƒâ–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‡â–ƒ
wandb: train_error_energy â–‚â–â–â–â–‚â–â–…â–‡â–„â–…â–…â–…â–ˆâ–†â–ƒâ–…â–…â–…â–‡â–„
wandb:  train_error_force â–â–â–â–â–â–â–…â–‡â–ˆâ–†â–…â–…â–‡â–ˆâ–…â–…â–…â–…â–†â–†
wandb:         train_loss â–‚â–â–â–â–â–â–…â–ˆâ–†â–†â–…â–…â–ˆâ–‡â–„â–…â–…â–…â–‡â–…
wandb: valid_error_energy â–â–‚â–â–â–â–â–†â–„â–‚â–…â–†â–…â–†â–â–ƒâ–„â–ƒâ–â–ˆâ–ƒ
wandb:  valid_error_force â–â–â–â–â–â–â–†â–†â–ƒâ–„â–„â–„â–ˆâ–„â–ƒâ–„â–„â–„â–ˆâ–ƒ
wandb:         valid_loss â–â–â–â–â–â–â–†â–…â–ƒâ–…â–…â–„â–‡â–ƒâ–ƒâ–„â–„â–ƒâ–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1839
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 13.2899
wandb:   test_error_force 10.07956
wandb:          test_loss 4.26202
wandb: train_error_energy 8.84917
wandb:  train_error_force 5.83138
wandb:         train_loss 2.54339
wandb: valid_error_energy 6.41191
wandb:  valid_error_force 4.90706
wandb:         valid_loss 2.07101
wandb: 
wandb: ğŸš€ View run al_79_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/p4wwz81a
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_000144-p4wwz81a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.4639635384082794, Uncertainty Bias: -0.19216288626194
0.00016784668 0.020088196
-2.3775926 10.249557
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2585 steps.
Found uncertainty sample 2 after 3571 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2146 steps.
Found uncertainty sample 6 after 2005 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 391 steps.
Found uncertainty sample 10 after 2383 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2734 steps.
Found uncertainty sample 13 after 3782 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1617 steps.
Found uncertainty sample 16 after 758 steps.
Found uncertainty sample 17 after 597 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3847 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2698 steps.
Found uncertainty sample 22 after 2660 steps.
Found uncertainty sample 23 after 2870 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 527 steps.
Found uncertainty sample 26 after 2211 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1390 steps.
Found uncertainty sample 29 after 300 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 344 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3447 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2577 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3960 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1793 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1613 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3381 steps.
Found uncertainty sample 50 after 2039 steps.
Found uncertainty sample 51 after 2150 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3458 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 869 steps.
Found uncertainty sample 57 after 3842 steps.
Found uncertainty sample 58 after 444 steps.
Found uncertainty sample 59 after 3189 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2188 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3791 steps.
Found uncertainty sample 64 after 93 steps.
Found uncertainty sample 65 after 1715 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1010 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2752 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2911 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2751 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2167 steps.
Found uncertainty sample 79 after 1423 steps.
Found uncertainty sample 80 after 21 steps.
Found uncertainty sample 81 after 2955 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2353 steps.
Found uncertainty sample 84 after 975 steps.
Found uncertainty sample 85 after 1752 steps.
Found uncertainty sample 86 after 3734 steps.
Found uncertainty sample 87 after 1467 steps.
Found uncertainty sample 88 after 1010 steps.
Found uncertainty sample 89 after 1810 steps.
Found uncertainty sample 90 after 2777 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2037 steps.
Found uncertainty sample 98 after 3040 steps.
Found uncertainty sample 99 after 1455 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_013946-dojnxs58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/dojnxs58
Training model 15. Added 56 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2029114416367084, Training Loss Force: 3.4789143097472137, time: 0.8856995105743408
Validation Loss Energy: 1.479783380659176, Validation Loss Force: 3.317384945367011, time: 0.06047701835632324
Test Loss Energy: 9.422127233371045, Test Loss Force: 9.405922258943775, time: 7.82169246673584


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0060546777345656, Training Loss Force: 3.223743159877384, time: 0.9353799819946289
Validation Loss Energy: 4.969627082563994, Validation Loss Force: 3.4429132290343527, time: 0.06166672706604004
Test Loss Energy: 9.068574469170795, Test Loss Force: 9.514842408208041, time: 7.8442182540893555


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2617929046850573, Training Loss Force: 3.2572240878968204, time: 0.9288537502288818
Validation Loss Energy: 1.4344750525167953, Validation Loss Force: 3.1712310413815237, time: 0.06012129783630371
Test Loss Energy: 9.691141163824343, Test Loss Force: 9.465176290701871, time: 7.805006980895996


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.974932996116977, Training Loss Force: 3.170654576940784, time: 1.0412418842315674
Validation Loss Energy: 2.1020098750379272, Validation Loss Force: 3.152173568523575, time: 0.09146595001220703
Test Loss Energy: 10.112366532260905, Test Loss Force: 9.483964353129062, time: 7.848086595535278


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.582458774537104, Training Loss Force: 3.1605917834099113, time: 0.9105231761932373
Validation Loss Energy: 2.0568555782772417, Validation Loss Force: 3.2007510693991814, time: 0.06340885162353516
Test Loss Energy: 10.472842618810903, Test Loss Force: 9.501883772725726, time: 7.86409068107605


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.873287128478789, Training Loss Force: 3.1609468070961793, time: 0.9675931930541992
Validation Loss Energy: 1.809128805350762, Validation Loss Force: 3.3468379499717438, time: 0.05971169471740723
Test Loss Energy: 9.480174277114278, Test Loss Force: 9.412769808498714, time: 7.791451930999756


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 17.01785628969315, Training Loss Force: 7.143660988848924, time: 0.884448766708374
Validation Loss Energy: 42.80134922363666, Validation Loss Force: 10.768418842614878, time: 0.0611872673034668
Test Loss Energy: 37.88276642903722, Test Loss Force: 13.928775964493791, time: 9.978824615478516


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 13.216459780571439, Training Loss Force: 8.7908576918464, time: 0.9719552993774414
Validation Loss Energy: 10.75321766536068, Validation Loss Force: 6.067680340598905, time: 0.07186460494995117
Test Loss Energy: 9.784922040188592, Test Loss Force: 10.458249899570541, time: 10.688178062438965


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.635283846918922, Training Loss Force: 6.536409862943487, time: 0.9837028980255127
Validation Loss Energy: 10.067345481999531, Validation Loss Force: 5.954980805770473, time: 0.07040095329284668
Test Loss Energy: 15.046124889002119, Test Loss Force: 10.9517882226329, time: 10.260101795196533


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 8.915561095807073, Training Loss Force: 6.1840520978704525, time: 0.935338020324707
Validation Loss Energy: 8.77297463544251, Validation Loss Force: 4.817983827458521, time: 0.06589651107788086
Test Loss Energy: 12.974701408602023, Test Loss Force: 10.017789367714677, time: 8.76188039779663


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 12.353048614418924, Training Loss Force: 5.506920457828979, time: 0.932732343673706
Validation Loss Energy: 5.032295755001348, Validation Loss Force: 6.4379417218603, time: 0.07847404479980469
Test Loss Energy: 8.915991427859769, Test Loss Force: 11.144727479536224, time: 9.256656646728516


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.181133630568782, Training Loss Force: 4.514122329845506, time: 0.9642746448516846
Validation Loss Energy: 7.968276843710164, Validation Loss Force: 4.301206593514934, time: 0.06485319137573242
Test Loss Energy: 9.595252102618732, Test Loss Force: 9.448039253540733, time: 9.186166048049927


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.004054288850744, Training Loss Force: 4.085034287524795, time: 1.0474178791046143
Validation Loss Energy: 11.304365217993098, Validation Loss Force: 4.306075477059791, time: 0.07290005683898926
Test Loss Energy: 10.259582011399601, Test Loss Force: 9.448176571621152, time: 9.199386358261108


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.212719022749642, Training Loss Force: 5.191962339818615, time: 0.9513208866119385
Validation Loss Energy: 3.7627449474643146, Validation Loss Force: 8.293453066980685, time: 0.07318949699401855
Test Loss Energy: 11.48039322424925, Test Loss Force: 13.145737594628626, time: 9.713701486587524


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.172886936410132, Training Loss Force: 6.2778001355097865, time: 0.8918123245239258
Validation Loss Energy: 6.809139426880321, Validation Loss Force: 4.628534023404264, time: 0.07525300979614258
Test Loss Energy: 8.926410735075464, Test Loss Force: 9.69750445578498, time: 9.62586784362793


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.623467012118102, Training Loss Force: 5.319974108137776, time: 1.0736851692199707
Validation Loss Energy: 7.975455696974876, Validation Loss Force: 4.112468885389353, time: 0.06986427307128906
Test Loss Energy: 9.475258092114306, Test Loss Force: 9.653789979108014, time: 9.965731859207153


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 11.679486971271247, Training Loss Force: 5.136335812923831, time: 0.9071002006530762
Validation Loss Energy: 4.311964630631289, Validation Loss Force: 5.048369127300146, time: 0.07117009162902832
Test Loss Energy: 8.632441016698042, Test Loss Force: 9.640393270643358, time: 9.68919563293457


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 13.700750265265063, Training Loss Force: 5.8435730414583125, time: 0.9157066345214844
Validation Loss Energy: 14.405574161062148, Validation Loss Force: 6.227309179284784, time: 0.07254409790039062
Test Loss Energy: 11.557462028100268, Test Loss Force: 10.627320175847768, time: 9.754190683364868


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.348553457241872, Training Loss Force: 5.400149481588571, time: 0.9047648906707764
Validation Loss Energy: 14.173487891614784, Validation Loss Force: 6.12405638297234, time: 0.07082819938659668
Test Loss Energy: 13.97776854863678, Test Loss Force: 10.80239634961415, time: 10.245987176895142


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 12.153987571305972, Training Loss Force: 5.295639502700522, time: 0.942288875579834
Validation Loss Energy: 9.418760583138864, Validation Loss Force: 6.390886832604547, time: 0.06820201873779297
Test Loss Energy: 9.791555715445966, Test Loss Force: 10.829096744467584, time: 9.51935362815857

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–ˆâ–â–ƒâ–‚â–â–â–â–‚â–â–â–â–‚â–‚â–
wandb:   test_error_force â–â–â–â–â–â–â–ˆâ–ƒâ–ƒâ–‚â–„â–â–â–‡â–â–â–â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–â–â–â–â–â–â–ˆâ–‚â–ƒâ–‚â–‚â–â–â–„â–â–â–â–‚â–ƒâ–‚
wandb: train_error_energy â–‚â–â–â–â–â–‚â–ˆâ–†â–…â–„â–†â–„â–ƒâ–†â–…â–†â–†â–†â–…â–†
wandb:  train_error_force â–â–â–â–â–â–â–†â–ˆâ–…â–…â–„â–ƒâ–‚â–„â–…â–„â–ƒâ–„â–„â–„
wandb:         train_loss â–‚â–â–â–â–â–â–‡â–ˆâ–†â–…â–…â–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…
wandb: valid_error_energy â–â–‚â–â–â–â–â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–â–ƒâ–ƒâ–‚
wandb:  valid_error_force â–â–â–â–â–â–â–ˆâ–„â–„â–ƒâ–„â–‚â–‚â–†â–‚â–‚â–ƒâ–„â–„â–„
wandb:         valid_loss â–â–â–â–â–â–â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1889
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.79156
wandb:   test_error_force 10.8291
wandb:          test_loss 4.27871
wandb: train_error_energy 12.15399
wandb:  train_error_force 5.29564
wandb:         train_loss 2.58529
wandb: valid_error_energy 9.41876
wandb:  valid_error_force 6.39089
wandb:         valid_loss 2.76872
wandb: 
wandb: ğŸš€ View run al_79_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/dojnxs58
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_013946-dojnxs58/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.52567458152771, Uncertainty Bias: -0.17329947650432587
7.05719e-05 0.047344208
-2.4441254 16.984308
(48745, 22, 3)
Found uncertainty sample 0 after 273 steps.
Found uncertainty sample 1 after 271 steps.
Found uncertainty sample 2 after 564 steps.
Found uncertainty sample 3 after 127 steps.
Found uncertainty sample 4 after 758 steps.
Found uncertainty sample 5 after 163 steps.
Found uncertainty sample 6 after 1521 steps.
Found uncertainty sample 7 after 822 steps.
Found uncertainty sample 8 after 205 steps.
Found uncertainty sample 9 after 226 steps.
Found uncertainty sample 10 after 136 steps.
Found uncertainty sample 11 after 89 steps.
Found uncertainty sample 12 after 678 steps.
Found uncertainty sample 13 after 1061 steps.
Found uncertainty sample 14 after 238 steps.
Found uncertainty sample 15 after 422 steps.
Found uncertainty sample 16 after 404 steps.
Found uncertainty sample 17 after 230 steps.
Found uncertainty sample 18 after 117 steps.
Found uncertainty sample 19 after 30 steps.
Found uncertainty sample 20 after 52 steps.
Found uncertainty sample 21 after 583 steps.
Found uncertainty sample 22 after 270 steps.
Found uncertainty sample 23 after 962 steps.
Found uncertainty sample 24 after 79 steps.
Found uncertainty sample 25 after 89 steps.
Found uncertainty sample 26 after 42 steps.
Found uncertainty sample 27 after 1574 steps.
Found uncertainty sample 28 after 9 steps.
Found uncertainty sample 29 after 1713 steps.
Found uncertainty sample 30 after 187 steps.
Found uncertainty sample 31 after 170 steps.
Found uncertainty sample 32 after 206 steps.
Found uncertainty sample 33 after 197 steps.
Found uncertainty sample 34 after 281 steps.
Found uncertainty sample 35 after 2817 steps.
Found uncertainty sample 36 after 1155 steps.
Found uncertainty sample 37 after 55 steps.
Found uncertainty sample 38 after 89 steps.
Found uncertainty sample 39 after 311 steps.
Found uncertainty sample 40 after 213 steps.
Found uncertainty sample 41 after 768 steps.
Found uncertainty sample 42 after 530 steps.
Found uncertainty sample 43 after 1156 steps.
Found uncertainty sample 44 after 760 steps.
Found uncertainty sample 45 after 420 steps.
Found uncertainty sample 46 after 45 steps.
Found uncertainty sample 47 after 58 steps.
Found uncertainty sample 48 after 503 steps.
Found uncertainty sample 49 after 217 steps.
Found uncertainty sample 50 after 535 steps.
Found uncertainty sample 51 after 412 steps.
Found uncertainty sample 52 after 21 steps.
Found uncertainty sample 53 after 50 steps.
Found uncertainty sample 54 after 1674 steps.
Found uncertainty sample 55 after 1388 steps.
Found uncertainty sample 56 after 97 steps.
Found uncertainty sample 57 after 1423 steps.
Found uncertainty sample 58 after 548 steps.
Found uncertainty sample 59 after 191 steps.
Found uncertainty sample 60 after 742 steps.
Found uncertainty sample 61 after 208 steps.
Found uncertainty sample 62 after 713 steps.
Found uncertainty sample 63 after 213 steps.
Found uncertainty sample 64 after 4 steps.
Found uncertainty sample 65 after 247 steps.
Found uncertainty sample 66 after 251 steps.
Found uncertainty sample 67 after 168 steps.
Found uncertainty sample 68 after 21 steps.
Found uncertainty sample 69 after 1109 steps.
Found uncertainty sample 70 after 1127 steps.
Found uncertainty sample 71 after 185 steps.
Found uncertainty sample 72 after 1157 steps.
Found uncertainty sample 73 after 1318 steps.
Found uncertainty sample 74 after 120 steps.
Found uncertainty sample 75 after 413 steps.
Found uncertainty sample 76 after 10 steps.
Found uncertainty sample 77 after 743 steps.
Found uncertainty sample 78 after 129 steps.
Found uncertainty sample 79 after 541 steps.
Found uncertainty sample 80 after 146 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 340 steps.
Found uncertainty sample 83 after 842 steps.
Found uncertainty sample 84 after 584 steps.
Found uncertainty sample 85 after 416 steps.
Found uncertainty sample 86 after 50 steps.
Found uncertainty sample 87 after 41 steps.
Found uncertainty sample 88 after 939 steps.
Found uncertainty sample 89 after 764 steps.
Found uncertainty sample 90 after 1014 steps.
Found uncertainty sample 91 after 221 steps.
Found uncertainty sample 92 after 61 steps.
Found uncertainty sample 93 after 73 steps.
Found uncertainty sample 94 after 325 steps.
Found uncertainty sample 95 after 385 steps.
Found uncertainty sample 96 after 121 steps.
Found uncertainty sample 97 after 209 steps.
Found uncertainty sample 98 after 137 steps.
Found uncertainty sample 99 after 563 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_020306-yue9c079
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/yue9c079
Training model 16. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.771213617173539, Training Loss Force: 3.3136974796645657, time: 0.9788014888763428
Validation Loss Energy: 2.922690746730397, Validation Loss Force: 3.3159581928144783, time: 0.07156133651733398
Test Loss Energy: 10.971261350586584, Test Loss Force: 9.37484988248302, time: 9.067163944244385


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.4034664489061015, Training Loss Force: 3.2046513744821934, time: 0.9190361499786377
Validation Loss Energy: 1.735768451202539, Validation Loss Force: 3.2139427689459543, time: 0.06964540481567383
Test Loss Energy: 9.305286796213252, Test Loss Force: 9.43022301719416, time: 9.73272967338562


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8621266999926671, Training Loss Force: 3.163622178081647, time: 0.9905402660369873
Validation Loss Energy: 1.6365821501676003, Validation Loss Force: 3.1022667328467803, time: 0.07346701622009277
Test Loss Energy: 9.483408244514854, Test Loss Force: 9.364399438892718, time: 9.792229652404785


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6232824111920794, Training Loss Force: 3.141955173673813, time: 0.9266281127929688
Validation Loss Energy: 2.4038787621313213, Validation Loss Force: 3.1975873861738395, time: 0.07320642471313477
Test Loss Energy: 9.152871178783823, Test Loss Force: 9.532855572680948, time: 9.859130620956421


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0307570546969798, Training Loss Force: 3.1898901519545317, time: 0.8907904624938965
Validation Loss Energy: 1.238067895330736, Validation Loss Force: 3.016337373418371, time: 0.06871914863586426
Test Loss Energy: 9.73910450355804, Test Loss Force: 9.384191932692016, time: 9.722367763519287


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.051294554598483, Training Loss Force: 3.154366274206596, time: 0.9825038909912109
Validation Loss Energy: 1.6193467232634924, Validation Loss Force: 3.165335096401075, time: 0.07918882369995117
Test Loss Energy: 9.219805524049715, Test Loss Force: 9.411829995479598, time: 9.726623296737671


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 11.290895178422478, Training Loss Force: 5.994069440564258, time: 1.0359618663787842
Validation Loss Energy: 2.9099228979028977, Validation Loss Force: 6.024555561768778, time: 0.06946134567260742
Test Loss Energy: 9.81988918213693, Test Loss Force: 10.81860958261854, time: 9.910523653030396


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.508355121631787, Training Loss Force: 5.194575017348331, time: 0.9246068000793457
Validation Loss Energy: 14.237890934029767, Validation Loss Force: 7.27773462035147, time: 0.06791114807128906
Test Loss Energy: 11.162880284377191, Test Loss Force: 11.926622668337815, time: 9.771202802658081


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.247569981169978, Training Loss Force: 5.906009561198984, time: 0.954077959060669
Validation Loss Energy: 12.642249178370744, Validation Loss Force: 6.003765166282646, time: 0.08278274536132812
Test Loss Energy: 18.684646612583048, Test Loss Force: 10.963225330695913, time: 9.847426891326904


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.842013617034493, Training Loss Force: 5.679651182581335, time: 1.0145249366760254
Validation Loss Energy: 4.913983176342368, Validation Loss Force: 7.010028635637474, time: 0.07694673538208008
Test Loss Energy: 14.454517417577373, Test Loss Force: 11.817393818030801, time: 10.301850080490112


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.1630055387427, Training Loss Force: 6.55692990025665, time: 0.9195404052734375
Validation Loss Energy: 10.626119452879976, Validation Loss Force: 5.937471440149587, time: 0.06906294822692871
Test Loss Energy: 15.297990044948932, Test Loss Force: 10.894662497545793, time: 9.906254053115845


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.965523706722626, Training Loss Force: 5.074921244960423, time: 1.0076303482055664
Validation Loss Energy: 5.885981204176099, Validation Loss Force: 4.272360696336573, time: 0.07675528526306152
Test Loss Energy: 9.01873004380844, Test Loss Force: 9.871377805799273, time: 9.573486089706421


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.1307875329538115, Training Loss Force: 4.0033281134970204, time: 0.9030392169952393
Validation Loss Energy: 5.449691963741883, Validation Loss Force: 4.083421472633926, time: 0.07298612594604492
Test Loss Energy: 12.319424737655616, Test Loss Force: 9.792604778575047, time: 9.947050094604492


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.2733112403046105, Training Loss Force: 3.9374091431279954, time: 0.9731197357177734
Validation Loss Energy: 7.479008378723641, Validation Loss Force: 3.751179734693971, time: 0.07030510902404785
Test Loss Energy: 9.196157100127177, Test Loss Force: 9.583461116158295, time: 9.773041725158691


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.387491140669612, Training Loss Force: 3.8599089457673106, time: 1.0376505851745605
Validation Loss Energy: 10.829999330936083, Validation Loss Force: 3.925489372840016, time: 0.0699455738067627
Test Loss Energy: 15.703090991561925, Test Loss Force: 9.824376396775982, time: 9.653315305709839


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.5385193548625296, Training Loss Force: 4.1509269786248755, time: 0.8846914768218994
Validation Loss Energy: 2.532533320607489, Validation Loss Force: 4.055395888589163, time: 0.07431292533874512
Test Loss Energy: 8.61489996211001, Test Loss Force: 9.798821738435176, time: 10.023744344711304


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.2365727831729885, Training Loss Force: 3.9796083868787595, time: 0.9741435050964355
Validation Loss Energy: 10.537678830823793, Validation Loss Force: 3.7710408204995733, time: 0.07460141181945801
Test Loss Energy: 15.091397816539171, Test Loss Force: 9.766622884594206, time: 9.817718505859375


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.658280356691673, Training Loss Force: 5.106175010862653, time: 1.0162343978881836
Validation Loss Energy: 16.77743432468936, Validation Loss Force: 6.298390960062728, time: 0.07172584533691406
Test Loss Energy: 14.244149783668702, Test Loss Force: 10.892561536044894, time: 9.762969970703125


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 14.085723761768273, Training Loss Force: 6.2794306894698515, time: 0.9808733463287354
Validation Loss Energy: 9.298769524457882, Validation Loss Force: 7.865800049371277, time: 0.07399702072143555
Test Loss Energy: 14.140947059934723, Test Loss Force: 11.65677644958093, time: 9.97738766670227


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 12.9046181679407, Training Loss Force: 6.6848595449624995, time: 1.0238523483276367
Validation Loss Energy: 6.932156336585317, Validation Loss Force: 5.132590391710142, time: 0.07602238655090332
Test Loss Energy: 9.400538496716726, Test Loss Force: 9.868994956817698, time: 9.850887537002563

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–‚â–â–‚â–â–‚â–ƒâ–ˆâ–…â–†â–â–„â–â–†â–â–†â–…â–…â–‚
wandb:   test_error_force â–â–â–â–â–â–â–…â–ˆâ–…â–ˆâ–…â–‚â–‚â–‚â–‚â–‚â–‚â–…â–‡â–‚
wandb:          test_loss â–‚â–â–â–â–â–â–„â–‡â–ˆâ–ˆâ–†â–‚â–ƒâ–â–„â–‚â–„â–†â–ˆâ–‚
wandb: train_error_energy â–‚â–â–â–â–‚â–‚â–†â–…â–‡â–‡â–†â–…â–„â–„â–„â–„â–„â–‡â–ˆâ–‡
wandb:  train_error_force â–â–â–â–â–â–â–‡â–…â–†â–†â–ˆâ–…â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–‡â–ˆ
wandb:         train_loss â–â–â–â–â–â–â–‡â–…â–‡â–‡â–‡â–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–†â–ˆâ–ˆ
wandb: valid_error_energy â–‚â–â–â–‚â–â–â–‚â–‡â–†â–ƒâ–…â–ƒâ–ƒâ–„â–…â–‚â–…â–ˆâ–…â–„
wandb:  valid_error_force â–â–â–â–â–â–â–…â–‡â–…â–‡â–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–†â–ˆâ–„
wandb:         valid_loss â–‚â–â–â–â–â–â–„â–ˆâ–†â–†â–†â–ƒâ–ƒâ–ƒâ–„â–‚â–„â–ˆâ–ˆâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1978
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.40054
wandb:   test_error_force 9.86899
wandb:          test_loss 3.93129
wandb: train_error_energy 12.90462
wandb:  train_error_force 6.68486
wandb:         train_loss 3.10036
wandb: valid_error_energy 6.93216
wandb:  valid_error_force 5.13259
wandb:         valid_loss 2.18129
wandb: 
wandb: ğŸš€ View run al_79_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/yue9c079
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_020306-yue9c079/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.3236601650714874, Uncertainty Bias: -0.08289732038974762
2.7894974e-05 0.0016536713
1.9798073 13.769785
(48745, 22, 3)
Found uncertainty sample 0 after 3780 steps.
Found uncertainty sample 1 after 1443 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2865 steps.
Found uncertainty sample 5 after 3278 steps.
Found uncertainty sample 6 after 600 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2669 steps.
Found uncertainty sample 10 after 2853 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2309 steps.
Found uncertainty sample 14 after 2468 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 438 steps.
Found uncertainty sample 17 after 998 steps.
Found uncertainty sample 18 after 3299 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3071 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1256 steps.
Found uncertainty sample 29 after 27 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3492 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3863 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1142 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2488 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3039 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2843 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 72 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 643 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 379 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2801 steps.
Found uncertainty sample 56 after 3441 steps.
Found uncertainty sample 57 after 3657 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1634 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2808 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2720 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 604 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3860 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 726 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1663 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3861 steps.
Found uncertainty sample 83 after 1594 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 384 steps.
Found uncertainty sample 87 after 1116 steps.
Found uncertainty sample 88 after 2920 steps.
Found uncertainty sample 89 after 1538 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2694 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1174 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2769 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2829 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_034854-69xvbz6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/69xvbz6s
Training model 17. Added 44 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.2594504257337906, Training Loss Force: 3.3994139311383917, time: 0.9975588321685791
Validation Loss Energy: 1.4460672082537958, Validation Loss Force: 3.229402242409429, time: 0.07547831535339355
Test Loss Energy: 9.812276476111387, Test Loss Force: 9.370564972672401, time: 9.738317966461182


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.756118207933516, Training Loss Force: 3.1727031140636637, time: 0.9821374416351318
Validation Loss Energy: 1.7870193178441542, Validation Loss Force: 3.3138367125266512, time: 0.07302594184875488
Test Loss Energy: 9.460357044889449, Test Loss Force: 9.500385701344205, time: 9.932746171951294


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.721785653409955, Training Loss Force: 3.165417765800706, time: 1.0133535861968994
Validation Loss Energy: 1.8714942024113628, Validation Loss Force: 3.20925691943905, time: 0.07159423828125
Test Loss Energy: 10.083320085959521, Test Loss Force: 9.472346162589096, time: 9.909573316574097


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9235182980998284, Training Loss Force: 3.1511853384995097, time: 0.9703125953674316
Validation Loss Energy: 1.8647672005110247, Validation Loss Force: 3.1505790347695863, time: 0.07082033157348633
Test Loss Energy: 11.038379851396808, Test Loss Force: 9.407984781454733, time: 10.154755115509033


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1874235518599967, Training Loss Force: 3.116566280978652, time: 0.9710202217102051
Validation Loss Energy: 2.0768470368677843, Validation Loss Force: 3.240557409947546, time: 0.08215951919555664
Test Loss Energy: 9.193712132282926, Test Loss Force: 9.397529035773982, time: 10.00533127784729


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1236412884090226, Training Loss Force: 3.1466553469571386, time: 0.9199051856994629
Validation Loss Energy: 2.8618210183229933, Validation Loss Force: 3.3320887910837795, time: 0.06835055351257324
Test Loss Energy: 11.26328836343809, Test Loss Force: 9.434064076282713, time: 9.972756385803223


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.076882680860098, Training Loss Force: 7.2690767394730145, time: 0.9911680221557617
Validation Loss Energy: 25.01306823056185, Validation Loss Force: 10.315484415515122, time: 0.0719916820526123
Test Loss Energy: 25.59712841172606, Test Loss Force: 14.025555189328017, time: 9.688959121704102


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.077702206689226, Training Loss Force: 6.555892504907611, time: 0.9621272087097168
Validation Loss Energy: 8.718577899107228, Validation Loss Force: 8.971180903660379, time: 0.0687103271484375
Test Loss Energy: 9.849145189249809, Test Loss Force: 12.361172199398125, time: 9.932556390762329


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.54306735631074, Training Loss Force: 6.700192778712589, time: 1.1737456321716309
Validation Loss Energy: 13.189976532921708, Validation Loss Force: 6.841691874661796, time: 0.10807943344116211
Test Loss Energy: 17.726900757761644, Test Loss Force: 11.458881626715598, time: 9.681214570999146


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.206146478511503, Training Loss Force: 6.073460762043082, time: 0.9863426685333252
Validation Loss Energy: 8.56108802023713, Validation Loss Force: 6.968842859730087, time: 0.08098435401916504
Test Loss Energy: 13.851132231239607, Test Loss Force: 11.105382634199577, time: 9.828752756118774


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 12.180066744967741, Training Loss Force: 6.533536787076072, time: 0.9609744548797607
Validation Loss Energy: 22.51473822678374, Validation Loss Force: 6.732406971186167, time: 0.07044768333435059
Test Loss Energy: 17.666007148962695, Test Loss Force: 11.271558789820034, time: 10.042083024978638


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 12.23775764168947, Training Loss Force: 5.840722893090623, time: 1.0364301204681396
Validation Loss Energy: 9.626091387618562, Validation Loss Force: 3.9824274321377726, time: 0.07665514945983887
Test Loss Energy: 14.987881364802455, Test Loss Force: 9.560281971541126, time: 9.561769485473633


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 12.016776025196943, Training Loss Force: 5.196790366822453, time: 1.0011804103851318
Validation Loss Energy: 12.34093818882247, Validation Loss Force: 7.18370010401129, time: 0.07097482681274414
Test Loss Energy: 17.13924761523811, Test Loss Force: 11.555190732863378, time: 9.96759843826294


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.811294664409604, Training Loss Force: 4.697948652453002, time: 1.0307488441467285
Validation Loss Energy: 7.298439065547274, Validation Loss Force: 5.008535398446831, time: 0.06936788558959961
Test Loss Energy: 9.442087468151454, Test Loss Force: 10.166370552502809, time: 9.921891212463379


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.577543847418279, Training Loss Force: 4.202832039809886, time: 1.067368984222412
Validation Loss Energy: 6.758692395855505, Validation Loss Force: 4.322717101018997, time: 0.07667994499206543
Test Loss Energy: 9.455583498713262, Test Loss Force: 9.963763593513283, time: 9.68083667755127


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.63566745813505, Training Loss Force: 4.076507011146361, time: 0.9886648654937744
Validation Loss Energy: 5.207455543946546, Validation Loss Force: 4.883548089469521, time: 0.07498288154602051
Test Loss Energy: 8.97116340023338, Test Loss Force: 9.998577445824658, time: 10.468969106674194


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.6478745495105835, Training Loss Force: 3.938942430296822, time: 0.9180724620819092
Validation Loss Energy: 8.209145629611214, Validation Loss Force: 4.19220960124499, time: 0.06934213638305664
Test Loss Energy: 9.917116198121034, Test Loss Force: 9.772147084601336, time: 9.897338151931763


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.249199127943761, Training Loss Force: 4.46628499164858, time: 0.9435153007507324
Validation Loss Energy: 5.830451749895483, Validation Loss Force: 7.483792647993045, time: 0.07462430000305176
Test Loss Energy: 10.306782218503733, Test Loss Force: 11.815462131713083, time: 9.702739477157593


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 17.59852619839554, Training Loss Force: 7.810012166671578, time: 0.9638075828552246
Validation Loss Energy: 8.046946298304743, Validation Loss Force: 7.524022727926111, time: 0.07103800773620605
Test Loss Energy: 9.922437459100696, Test Loss Force: 11.030424356130473, time: 10.107228755950928


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.272451273234534, Training Loss Force: 6.463219248557417, time: 1.087212324142456
Validation Loss Energy: 34.10777929630859, Validation Loss Force: 6.396751937908285, time: 0.07582449913024902
Test Loss Energy: 27.75087923187449, Test Loss Force: 10.890388681555034, time: 9.847530126571655

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–‚â–â–‚â–‡â–â–„â–ƒâ–„â–ƒâ–„â–â–â–â–â–â–â–ˆ
wandb:   test_error_force â–â–â–â–â–â–â–ˆâ–…â–„â–„â–„â–â–„â–‚â–‚â–‚â–‚â–…â–ƒâ–ƒ
wandb:          test_loss â–â–â–â–â–â–â–ˆâ–„â–„â–ƒâ–„â–‚â–„â–‚â–‚â–â–â–ƒâ–ƒâ–†
wandb: train_error_energy â–â–â–â–â–â–â–†â–…â–…â–…â–†â–†â–†â–„â–„â–„â–„â–„â–ˆâ–„
wandb:  train_error_force â–â–â–â–â–â–â–‡â–†â–†â–…â–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–ˆâ–†
wandb:         train_loss â–â–â–â–â–â–â–‡â–†â–†â–…â–†â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ˆâ–…
wandb: valid_error_energy â–â–â–â–â–â–â–†â–ƒâ–„â–ƒâ–†â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ˆ
wandb:  valid_error_force â–â–â–â–â–â–â–ˆâ–‡â–…â–…â–„â–‚â–…â–ƒâ–‚â–ƒâ–‚â–…â–…â–„
wandb:         valid_loss â–â–â–â–â–â–â–ˆâ–…â–…â–„â–†â–‚â–…â–ƒâ–‚â–‚â–‚â–„â–„â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 2017
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 27.75088
wandb:   test_error_force 10.89039
wandb:          test_loss 5.50107
wandb: train_error_energy 8.27245
wandb:  train_error_force 6.46322
wandb:         train_loss 2.71621
wandb: valid_error_energy 34.10778
wandb:  valid_error_force 6.39675
wandb:         valid_loss 4.42289
wandb: 
wandb: ğŸš€ View run al_79_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/69xvbz6s
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_034854-69xvbz6s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6380981802940369, Uncertainty Bias: -0.3168022036552429
7.6293945e-06 0.0029761791
-4.461405 15.480849
(48745, 22, 3)
Found uncertainty sample 0 after 143 steps.
Found uncertainty sample 1 after 4 steps.
Found uncertainty sample 2 after 51 steps.
Found uncertainty sample 3 after 235 steps.
Found uncertainty sample 4 after 2 steps.
Found uncertainty sample 5 after 76 steps.
Found uncertainty sample 6 after 300 steps.
Found uncertainty sample 7 after 537 steps.
Found uncertainty sample 8 after 21 steps.
Found uncertainty sample 9 after 258 steps.
Found uncertainty sample 10 after 426 steps.
Found uncertainty sample 11 after 839 steps.
Found uncertainty sample 12 after 298 steps.
Found uncertainty sample 13 after 258 steps.
Found uncertainty sample 14 after 223 steps.
Found uncertainty sample 15 after 66 steps.
Found uncertainty sample 16 after 21 steps.
Found uncertainty sample 17 after 125 steps.
Found uncertainty sample 18 after 4 steps.
Found uncertainty sample 19 after 57 steps.
Found uncertainty sample 20 after 152 steps.
Found uncertainty sample 21 after 125 steps.
Found uncertainty sample 22 after 92 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 133 steps.
Found uncertainty sample 25 after 214 steps.
Found uncertainty sample 26 after 117 steps.
Found uncertainty sample 27 after 91 steps.
Found uncertainty sample 28 after 105 steps.
Found uncertainty sample 29 after 204 steps.
Found uncertainty sample 30 after 26 steps.
Found uncertainty sample 31 after 139 steps.
Found uncertainty sample 32 after 556 steps.
Found uncertainty sample 33 after 58 steps.
Found uncertainty sample 34 after 63 steps.
Found uncertainty sample 35 after 42 steps.
Found uncertainty sample 36 after 254 steps.
Found uncertainty sample 37 after 164 steps.
Found uncertainty sample 38 after 240 steps.
Found uncertainty sample 39 after 58 steps.
Found uncertainty sample 40 after 423 steps.
Found uncertainty sample 41 after 8 steps.
Found uncertainty sample 42 after 235 steps.
Found uncertainty sample 43 after 150 steps.
Found uncertainty sample 44 after 75 steps.
Found uncertainty sample 45 after 175 steps.
Found uncertainty sample 46 after 62 steps.
Found uncertainty sample 47 after 152 steps.
Found uncertainty sample 48 after 117 steps.
Found uncertainty sample 49 after 208 steps.
Found uncertainty sample 50 after 49 steps.
Found uncertainty sample 51 after 96 steps.
Found uncertainty sample 52 after 306 steps.
Found uncertainty sample 53 after 33 steps.
Found uncertainty sample 54 after 29 steps.
Found uncertainty sample 55 after 70 steps.
Found uncertainty sample 56 after 52 steps.
Found uncertainty sample 57 after 308 steps.
Found uncertainty sample 58 after 108 steps.
Found uncertainty sample 59 after 81 steps.
Found uncertainty sample 60 after 334 steps.
Found uncertainty sample 61 after 39 steps.
Found uncertainty sample 62 after 51 steps.
Found uncertainty sample 63 after 9 steps.
Found uncertainty sample 64 after 283 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 49 steps.
Found uncertainty sample 67 after 172 steps.
Found uncertainty sample 68 after 54 steps.
Found uncertainty sample 69 after 494 steps.
Found uncertainty sample 70 after 22 steps.
Found uncertainty sample 71 after 173 steps.
Found uncertainty sample 72 after 34 steps.
Found uncertainty sample 73 after 26 steps.
Found uncertainty sample 74 after 1045 steps.
Found uncertainty sample 75 after 26 steps.
Found uncertainty sample 76 after 673 steps.
Found uncertainty sample 77 after 75 steps.
Found uncertainty sample 78 after 129 steps.
Found uncertainty sample 79 after 10 steps.
Found uncertainty sample 80 after 70 steps.
Found uncertainty sample 81 after 169 steps.
Found uncertainty sample 82 after 177 steps.
Found uncertainty sample 83 after 238 steps.
Found uncertainty sample 84 after 94 steps.
Found uncertainty sample 85 after 69 steps.
Found uncertainty sample 86 after 178 steps.
Found uncertainty sample 87 after 77 steps.
Found uncertainty sample 88 after 433 steps.
Found uncertainty sample 89 after 67 steps.
Found uncertainty sample 90 after 99 steps.
Found uncertainty sample 91 after 225 steps.
Found uncertainty sample 92 after 18 steps.
Found uncertainty sample 93 after 30 steps.
Found uncertainty sample 94 after 13 steps.
Found uncertainty sample 95 after 140 steps.
Found uncertainty sample 96 after 23 steps.
Found uncertainty sample 97 after 42 steps.
Found uncertainty sample 98 after 19 steps.
Found uncertainty sample 99 after 4 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_040129-6xd93kwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/6xd93kwm
Training model 18. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.9472640610745582, Training Loss Force: 3.3448211849104514, time: 0.9897196292877197
Validation Loss Energy: 1.37275689899612, Validation Loss Force: 3.198520147226131, time: 0.07975196838378906
Test Loss Energy: 9.888598221480395, Test Loss Force: 9.312251280878208, time: 10.119016885757446


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.021046827027043, Training Loss Force: 3.1167733645495304, time: 1.009204387664795
Validation Loss Energy: 2.2041293967321725, Validation Loss Force: 3.1599066452925015, time: 0.0726308822631836
Test Loss Energy: 10.761871092000076, Test Loss Force: 9.314240623349226, time: 9.730973482131958


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1748384733361377, Training Loss Force: 3.1152273355578295, time: 1.1429219245910645
Validation Loss Energy: 3.3025442694600695, Validation Loss Force: 3.500790172785914, time: 0.07960224151611328
Test Loss Energy: 11.864678103139136, Test Loss Force: 9.399844347221725, time: 10.026939153671265


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.373889966641749, Training Loss Force: 3.1423682820760206, time: 1.0423123836517334
Validation Loss Energy: 2.0087435115839107, Validation Loss Force: 3.123286922891509, time: 0.07493090629577637
Test Loss Energy: 9.572854720227737, Test Loss Force: 9.296573764191168, time: 10.097402572631836


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.5711519354970376, Training Loss Force: 3.139049253383645, time: 1.0744240283966064
Validation Loss Energy: 1.8238647710918305, Validation Loss Force: 3.059468386984584, time: 0.0742788314819336
Test Loss Energy: 10.178267170408136, Test Loss Force: 9.367414570320935, time: 9.767098903656006


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.5102588757490483, Training Loss Force: 3.1214575474116155, time: 1.0291531085968018
Validation Loss Energy: 1.386171768694399, Validation Loss Force: 3.061521396510038, time: 0.08142828941345215
Test Loss Energy: 10.114286966209002, Test Loss Force: 9.289743268061708, time: 10.031009912490845


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.877933118412649, Training Loss Force: 6.704447428785821, time: 0.9581084251403809
Validation Loss Energy: 6.47155630146785, Validation Loss Force: 5.987125101007463, time: 0.07102727890014648
Test Loss Energy: 9.341263284576204, Test Loss Force: 10.380931668970263, time: 10.070016384124756


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 11.854731672564913, Training Loss Force: 5.77098388570289, time: 1.1553359031677246
Validation Loss Energy: 3.064959074119444, Validation Loss Force: 4.602297808616175, time: 0.07133769989013672
Test Loss Energy: 9.581112052264935, Test Loss Force: 9.732828302047023, time: 10.4072425365448


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 9.798730175534628, Training Loss Force: 5.902326428511874, time: 1.133763313293457
Validation Loss Energy: 6.074247744388899, Validation Loss Force: 6.096590589160439, time: 0.08325862884521484
Test Loss Energy: 9.703389053382539, Test Loss Force: 11.243306710450614, time: 9.936844110488892


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.738286999582511, Training Loss Force: 5.0258000473025675, time: 1.0469884872436523
Validation Loss Energy: 35.770888021830565, Validation Loss Force: 7.090793184226088, time: 0.07115483283996582
Test Loss Energy: 37.48539744118419, Test Loss Force: 11.851009393237566, time: 10.060083389282227


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.777973464846657, Training Loss Force: 6.433235197860573, time: 1.1364662647247314
Validation Loss Energy: 17.62831458796371, Validation Loss Force: 7.189346325544581, time: 0.07576966285705566
Test Loss Energy: 18.844392694152006, Test Loss Force: 11.239441561125249, time: 9.979036331176758


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.648215368204594, Training Loss Force: 6.032203147080767, time: 1.0410912036895752
Validation Loss Energy: 11.087473445725553, Validation Loss Force: 6.688477466062658, time: 0.0785069465637207
Test Loss Energy: 10.630763666754012, Test Loss Force: 11.077099968716478, time: 9.95583200454712


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.882891038079606, Training Loss Force: 7.175807920016274, time: 0.9616022109985352
Validation Loss Energy: 3.9399633126636138, Validation Loss Force: 5.949396040921458, time: 0.07053685188293457
Test Loss Energy: 8.7370595151625, Test Loss Force: 10.87431495834832, time: 10.110649824142456


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.695261847154011, Training Loss Force: 6.8634223455442855, time: 0.9649145603179932
Validation Loss Energy: 14.650419817909468, Validation Loss Force: 4.431475391964505, time: 0.07708072662353516
Test Loss Energy: 12.123364335494472, Test Loss Force: 9.424701172117265, time: 9.999122619628906


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.649714756444661, Training Loss Force: 6.188334197609166, time: 1.021101474761963
Validation Loss Energy: 13.917571570170225, Validation Loss Force: 6.463737942416033, time: 0.07722711563110352
Test Loss Energy: 10.798670099203562, Test Loss Force: 10.65725483654838, time: 9.663393497467041


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.479446657762905, Training Loss Force: 5.210816559268029, time: 0.9750063419342041
Validation Loss Energy: 14.155620028668952, Validation Loss Force: 5.7103860970506135, time: 0.0658864974975586
Test Loss Energy: 10.788939382914869, Test Loss Force: 10.228516559832705, time: 9.080841541290283


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 12.027954322598026, Training Loss Force: 5.009351865477, time: 1.017120599746704
Validation Loss Energy: 11.342932404744374, Validation Loss Force: 4.657627528672895, time: 0.07262754440307617
Test Loss Energy: 10.214448379151726, Test Loss Force: 9.910812101179005, time: 10.58034634590149


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 13.551872671274452, Training Loss Force: 5.896687075984359, time: 1.0470504760742188
Validation Loss Energy: 11.222927985914637, Validation Loss Force: 4.451766785894613, time: 0.0848088264465332
Test Loss Energy: 11.851717084747222, Test Loss Force: 9.36708072981503, time: 9.199141025543213


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.1503436451767195, Training Loss Force: 4.159667720126621, time: 0.9734935760498047
Validation Loss Energy: 10.746997180100042, Validation Loss Force: 3.7650541378421587, time: 0.06533360481262207
Test Loss Energy: 15.386020037120655, Test Loss Force: 9.425779832755648, time: 7.951679468154907


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.015865531122064, Training Loss Force: 3.87199663949945, time: 0.9530415534973145
Validation Loss Energy: 9.31057187986864, Validation Loss Force: 3.817170964792287, time: 0.06483864784240723
Test Loss Energy: 10.149929889196512, Test Loss Force: 9.288442950197913, time: 8.12178087234497

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–‚â–â–â–â–â–â–â–ˆâ–ƒâ–â–â–‚â–‚â–â–â–‚â–ƒâ–
wandb:   test_error_force â–â–â–â–â–â–â–„â–‚â–†â–ˆâ–†â–†â–…â–â–…â–„â–ƒâ–â–â–
wandb:          test_loss â–â–â–â–â–â–â–‚â–â–ƒâ–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–
wandb: train_error_energy â–â–â–â–â–â–â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–„â–„
wandb:  train_error_force â–â–â–â–â–â–â–‡â–†â–†â–„â–‡â–†â–ˆâ–‡â–†â–…â–„â–†â–ƒâ–‚
wandb:         train_loss â–â–â–â–â–â–â–‡â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–†â–†â–‡â–ƒâ–ƒ
wandb: valid_error_energy â–â–â–â–â–â–â–‚â–â–‚â–ˆâ–„â–ƒâ–‚â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒ
wandb:  valid_error_force â–â–â–‚â–â–â–â–†â–„â–†â–ˆâ–ˆâ–‡â–†â–ƒâ–‡â–…â–„â–ƒâ–‚â–‚
wandb:         valid_loss â–â–â–‚â–â–â–â–„â–‚â–„â–ˆâ–†â–…â–ƒâ–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2107
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.14993
wandb:   test_error_force 9.28844
wandb:          test_loss 3.78718
wandb: train_error_energy 7.01587
wandb:  train_error_force 3.872
wandb:         train_loss 1.76509
wandb: valid_error_energy 9.31057
wandb:  valid_error_force 3.81717
wandb:         valid_loss 1.90031
wandb: 
wandb: ğŸš€ View run al_79_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/6xd93kwm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_040129-6xd93kwm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.20929014682769775, Uncertainty Bias: 0.02957998216152191
0.00033569336 0.0017299652
0.89126503 4.9629335
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3622 steps.
Found uncertainty sample 3 after 2367 steps.
Found uncertainty sample 4 after 1400 steps.
Found uncertainty sample 5 after 825 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2230 steps.
Found uncertainty sample 8 after 3290 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1253 steps.
Found uncertainty sample 13 after 1171 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2948 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1761 steps.
Found uncertainty sample 22 after 2680 steps.
Found uncertainty sample 23 after 1210 steps.
Found uncertainty sample 24 after 413 steps.
Found uncertainty sample 25 after 1474 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3190 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3946 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2357 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1359 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1964 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1997 steps.
Found uncertainty sample 42 after 2387 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1169 steps.
Found uncertainty sample 45 after 3002 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2762 steps.
Found uncertainty sample 51 after 3313 steps.
Found uncertainty sample 52 after 2984 steps.
Found uncertainty sample 53 after 3116 steps.
Found uncertainty sample 54 after 1393 steps.
Found uncertainty sample 55 after 1958 steps.
Found uncertainty sample 56 after 1458 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2523 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2621 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2736 steps.
Found uncertainty sample 64 after 2882 steps.
Found uncertainty sample 65 after 3945 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3063 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1944 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2634 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3008 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2307 steps.
Found uncertainty sample 81 after 27 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 857 steps.
Found uncertainty sample 85 after 1711 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 635 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3847 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 519 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3511 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2757 steps.
Found uncertainty sample 98 after 1269 steps.
Found uncertainty sample 99 after 1095 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_054406-2er7fegg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/2er7fegg
Training model 19. Added 50 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.985197209606763, Training Loss Force: 3.3536488228255332, time: 1.0772552490234375
Validation Loss Energy: 1.354255430995553, Validation Loss Force: 3.208584235949202, time: 0.07488012313842773
Test Loss Energy: 9.915210397382987, Test Loss Force: 9.166729500206703, time: 7.801165580749512


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9544381301775644, Training Loss Force: 3.1905472787088645, time: 1.007936716079712
Validation Loss Energy: 3.1904997159243846, Validation Loss Force: 3.242929727028261, time: 0.06833672523498535
Test Loss Energy: 9.476908865566038, Test Loss Force: 9.20470192484533, time: 7.801314115524292


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8555302801841544, Training Loss Force: 3.1550291431418787, time: 0.9611220359802246
Validation Loss Energy: 1.3556033030031405, Validation Loss Force: 3.2170717157845314, time: 0.07262325286865234
Test Loss Energy: 10.394465350436452, Test Loss Force: 9.309136673466307, time: 7.960808277130127


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.837163960894254, Training Loss Force: 3.1551174281836927, time: 1.024034023284912
Validation Loss Energy: 1.3943560288202614, Validation Loss Force: 3.238855215661501, time: 0.0661916732788086
Test Loss Energy: 10.44583726282373, Test Loss Force: 9.360519516460455, time: 7.833950042724609


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.3950877572350855, Training Loss Force: 3.188448956012214, time: 0.9904780387878418
Validation Loss Energy: 1.5248641966017051, Validation Loss Force: 3.1965456285746163, time: 0.0658268928527832
Test Loss Energy: 10.27251800224584, Test Loss Force: 9.354030788324817, time: 7.820421934127808


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.4683023072991004, Training Loss Force: 3.151343988424051, time: 0.9740369319915771
Validation Loss Energy: 2.225097927535046, Validation Loss Force: 3.233163012949576, time: 0.06633257865905762
Test Loss Energy: 11.36605027687478, Test Loss Force: 9.323486811576384, time: 7.8147125244140625


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 12.71543236319337, Training Loss Force: 5.544550257685608, time: 0.9711015224456787
Validation Loss Energy: 19.175162408337286, Validation Loss Force: 6.522934089522645, time: 0.07172179222106934
Test Loss Energy: 25.360316170356473, Test Loss Force: 11.310117881207177, time: 8.04031777381897


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 13.1344578944674, Training Loss Force: 6.368346152845943, time: 0.9615471363067627
Validation Loss Energy: 11.737644194243517, Validation Loss Force: 5.3331816691500435, time: 0.06554102897644043
Test Loss Energy: 11.241007370559412, Test Loss Force: 9.736462211213055, time: 7.827984571456909


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 13.23642136111036, Training Loss Force: 6.460783797406101, time: 1.0231163501739502
Validation Loss Energy: 8.054030739851582, Validation Loss Force: 8.270420615864207, time: 0.06844329833984375
Test Loss Energy: 13.155846750537608, Test Loss Force: 12.429944332218957, time: 8.392080068588257


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.351596271288743, Training Loss Force: 6.61896478891242, time: 1.091484546661377
Validation Loss Energy: 4.013812202918003, Validation Loss Force: 8.482444395263478, time: 0.06717514991760254
Test Loss Energy: 11.44536161317123, Test Loss Force: 12.461314138699938, time: 8.026130676269531


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.5478617039364835, Training Loss Force: 5.467919532320227, time: 0.9813454151153564
Validation Loss Energy: 4.694417370301377, Validation Loss Force: 4.003925692838809, time: 0.06688761711120605
Test Loss Energy: 11.674764423295173, Test Loss Force: 9.324655486508462, time: 7.899717569351196


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.094243860146887, Training Loss Force: 4.050087757408501, time: 1.0459365844726562
Validation Loss Energy: 8.76289930192757, Validation Loss Force: 4.603591071015725, time: 0.06618070602416992
Test Loss Energy: 14.42349505423892, Test Loss Force: 9.668160728686676, time: 7.8868489265441895


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.525529792000305, Training Loss Force: 4.576405080632959, time: 0.98435378074646
Validation Loss Energy: 13.291545727821795, Validation Loss Force: 4.001113158856596, time: 0.06651806831359863
Test Loss Energy: 17.98011751775585, Test Loss Force: 9.710563070879623, time: 7.9346067905426025


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 10.912699490017511, Training Loss Force: 5.818040996887126, time: 1.2139966487884521
Validation Loss Energy: 2.0075079204931576, Validation Loss Force: 7.169199666559327, time: 0.10203719139099121
Test Loss Energy: 10.133642025888221, Test Loss Force: 11.185710185845753, time: 7.956230401992798


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 9.044729187293221, Training Loss Force: 6.151145093134704, time: 0.9631180763244629
Validation Loss Energy: 19.147266417735455, Validation Loss Force: 4.591851953642411, time: 0.06650328636169434
Test Loss Energy: 23.045732475330745, Test Loss Force: 9.754526913683886, time: 7.922783851623535


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.9870058254359, Training Loss Force: 5.499502544131258, time: 1.015139102935791
Validation Loss Energy: 8.551449563586498, Validation Loss Force: 4.9848910525173435, time: 0.06669855117797852
Test Loss Energy: 13.500327903784335, Test Loss Force: 9.97032035348494, time: 7.89094614982605


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 9.513094433939372, Training Loss Force: 6.296997948434896, time: 0.9792215824127197
Validation Loss Energy: 14.042769524159583, Validation Loss Force: 5.346273724254014, time: 0.06592130661010742
Test Loss Energy: 12.345241105688734, Test Loss Force: 9.900448556845967, time: 8.025813579559326


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.799353883062098, Training Loss Force: 5.965393063899572, time: 1.0459201335906982
Validation Loss Energy: 13.064822222084953, Validation Loss Force: 4.60729316823592, time: 0.06796813011169434
Test Loss Energy: 10.978264171650467, Test Loss Force: 9.532772390016548, time: 7.87287712097168


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.684527792399134, Training Loss Force: 5.170103855670149, time: 1.0436747074127197
Validation Loss Energy: 19.823973093711924, Validation Loss Force: 5.220458754061291, time: 0.0661466121673584
Test Loss Energy: 23.524221535123548, Test Loss Force: 10.415433877741902, time: 8.358708620071411


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 12.292206397876013, Training Loss Force: 5.206865752320816, time: 1.0165579319000244
Validation Loss Energy: 2.079223361993126, Validation Loss Force: 5.781187760042981, time: 0.0675818920135498
Test Loss Energy: 9.52858167275208, Test Loss Force: 10.461048466018529, time: 8.057590246200562

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–‚â–ˆâ–‚â–ƒâ–‚â–‚â–ƒâ–…â–â–‡â–ƒâ–‚â–‚â–‡â–
wandb:   test_error_force â–â–â–â–â–â–â–†â–‚â–ˆâ–ˆâ–â–‚â–‚â–…â–‚â–ƒâ–ƒâ–‚â–„â–„
wandb:          test_loss â–â–â–â–â–â–‚â–ˆâ–‚â–†â–†â–‚â–ƒâ–„â–„â–…â–ƒâ–ƒâ–‚â–†â–ƒ
wandb: train_error_energy â–‚â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–‡â–„â–„â–„â–‡â–…â–†â–†â–‡â–‡â–‡
wandb:  train_error_force â–â–â–â–â–â–â–†â–‡â–ˆâ–ˆâ–†â–ƒâ–„â–†â–‡â–†â–‡â–‡â–…â–…
wandb:         train_loss â–‚â–â–â–â–â–â–‡â–ˆâ–ˆâ–ˆâ–…â–ƒâ–„â–‡â–‡â–†â–‡â–‡â–†â–†
wandb: valid_error_energy â–â–‚â–â–â–â–â–ˆâ–…â–„â–‚â–‚â–„â–†â–â–ˆâ–„â–†â–…â–ˆâ–
wandb:  valid_error_force â–â–â–â–â–â–â–…â–„â–ˆâ–ˆâ–‚â–ƒâ–‚â–†â–ƒâ–ƒâ–„â–ƒâ–„â–„
wandb:         valid_loss â–â–â–â–â–â–â–ˆâ–…â–ˆâ–‡â–‚â–„â–„â–…â–†â–„â–†â–…â–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2152
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.52858
wandb:   test_error_force 10.46105
wandb:          test_loss 4.13796
wandb: train_error_energy 12.29221
wandb:  train_error_force 5.20687
wandb:         train_loss 2.56484
wandb: valid_error_energy 2.07922
wandb:  valid_error_force 5.78119
wandb:         valid_loss 2.07355
wandb: 
wandb: ğŸš€ View run al_79_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/2er7fegg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_054406-2er7fegg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.1574798971414566, Uncertainty Bias: 0.06653986871242523
0.0001449585 0.0032958984
1.4485468 8.868119
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3752 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2331 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2011 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2715 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2052 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1528 steps.
Found uncertainty sample 17 after 3382 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3768 steps.
Found uncertainty sample 21 after 2230 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 68 steps.
Found uncertainty sample 24 after 639 steps.
Found uncertainty sample 25 after 1448 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3430 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 161 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1691 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 441 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2721 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3645 steps.
Found uncertainty sample 44 after 3179 steps.
Found uncertainty sample 45 after 1841 steps.
Found uncertainty sample 46 after 389 steps.
Found uncertainty sample 47 after 3063 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3025 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2981 steps.
Found uncertainty sample 52 after 1043 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 861 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1386 steps.
Found uncertainty sample 60 after 765 steps.
Found uncertainty sample 61 after 2804 steps.
Found uncertainty sample 62 after 2932 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 846 steps.
Found uncertainty sample 68 after 2561 steps.
Found uncertainty sample 69 after 3174 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 936 steps.
Found uncertainty sample 74 after 3220 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3943 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 152 steps.
Found uncertainty sample 79 after 1605 steps.
Found uncertainty sample 80 after 3663 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2130 steps.
Found uncertainty sample 83 after 1187 steps.
Found uncertainty sample 84 after 3780 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 648 steps.
Found uncertainty sample 87 after 1943 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2432 steps.
Found uncertainty sample 91 after 1344 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3462 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3396 steps.
Found uncertainty sample 97 after 2141 steps.
Found uncertainty sample 98 after 1794 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_073213-vxajpeog
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/vxajpeog
Training model 20. Added 50 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.178389041196656, Training Loss Force: 3.356842197168619, time: 1.0813524723052979
Validation Loss Energy: 1.7026063909668, Validation Loss Force: 3.2073616710034853, time: 0.06702446937561035
Test Loss Energy: 10.975881308679208, Test Loss Force: 9.155257301351584, time: 8.400596857070923


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.980434042933852, Training Loss Force: 3.1803918404432485, time: 0.9913573265075684
Validation Loss Energy: 1.497081767264295, Validation Loss Force: 3.2181494344508224, time: 0.06921124458312988
Test Loss Energy: 9.759910638605112, Test Loss Force: 9.244171735370932, time: 7.846669435501099


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8327342229047818, Training Loss Force: 3.1643106747243435, time: 1.0134429931640625
Validation Loss Energy: 4.609579980364598, Validation Loss Force: 3.351595276274491, time: 0.06779932975769043
Test Loss Energy: 9.676293375328608, Test Loss Force: 9.253138321099225, time: 8.043646335601807


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.173826155810426, Training Loss Force: 3.154322456478886, time: 1.0605604648590088
Validation Loss Energy: 1.4148223850317816, Validation Loss Force: 3.243922386080807, time: 0.0689997673034668
Test Loss Energy: 10.277780012248158, Test Loss Force: 9.20618196352345, time: 7.847113847732544


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.3181163521221606, Training Loss Force: 3.1421862909745815, time: 1.0570135116577148
Validation Loss Energy: 1.8040602432492943, Validation Loss Force: 3.2947763449698058, time: 0.06728315353393555
Test Loss Energy: 9.735340383071344, Test Loss Force: 9.301484922231156, time: 7.831036329269409


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.848710914109847, Training Loss Force: 3.158852982961694, time: 1.0666706562042236
Validation Loss Energy: 5.2817014532881235, Validation Loss Force: 3.095063385976016, time: 0.07320523262023926
Test Loss Energy: 13.47119613906004, Test Loss Force: 9.263806010501074, time: 7.863929748535156


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 12.356779017082783, Training Loss Force: 5.984276927053545, time: 1.0178711414337158
Validation Loss Energy: 4.252804555926319, Validation Loss Force: 4.253071981570578, time: 0.06852960586547852
Test Loss Energy: 12.34162888053377, Test Loss Force: 9.583830821552187, time: 8.03712010383606


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 15.403727197214575, Training Loss Force: 6.870983952402261, time: 1.040884256362915
Validation Loss Energy: 11.27558255885218, Validation Loss Force: 8.365492325086118, time: 0.06640219688415527
Test Loss Energy: 14.886783505691369, Test Loss Force: 11.919781768546265, time: 7.857752084732056


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.025865673098489, Training Loss Force: 6.646232081912849, time: 1.0003104209899902
Validation Loss Energy: 45.50900069405906, Validation Loss Force: 6.185012952346655, time: 0.0657954216003418
Test Loss Energy: 38.36208103876888, Test Loss Force: 10.259519132430729, time: 7.864160060882568


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.937747699665122, Training Loss Force: 6.198173896121033, time: 1.0215413570404053
Validation Loss Energy: 15.218084077110225, Validation Loss Force: 5.480786373955823, time: 0.06682562828063965
Test Loss Energy: 13.962090691534081, Test Loss Force: 10.03723508054985, time: 8.012163639068604


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 10.684359994370759, Training Loss Force: 6.444601439760271, time: 1.0546441078186035
Validation Loss Energy: 15.109681611459909, Validation Loss Force: 6.305656654294352, time: 0.07051444053649902
Test Loss Energy: 19.889256539618927, Test Loss Force: 11.052555678037258, time: 8.383374691009521


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 9.274697989385476, Training Loss Force: 6.0513785646169, time: 1.0507032871246338
Validation Loss Energy: 2.975278073585871, Validation Loss Force: 4.722071542210733, time: 0.06529903411865234
Test Loss Energy: 9.548855033978787, Test Loss Force: 9.82085556156703, time: 7.882958173751831


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.095625375185024, Training Loss Force: 6.167143311274748, time: 1.0029346942901611
Validation Loss Energy: 5.927961686265303, Validation Loss Force: 6.347059755288164, time: 0.06705164909362793
Test Loss Energy: 9.58520746247172, Test Loss Force: 10.550847477119119, time: 7.8643012046813965


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.757973022990033, Training Loss Force: 6.624523989426212, time: 1.1897056102752686
Validation Loss Energy: 20.832507565686072, Validation Loss Force: 5.225294905241696, time: 0.06579041481018066
Test Loss Energy: 26.68460728922353, Test Loss Force: 10.275403896968085, time: 7.886235952377319


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 9.427731610000654, Training Loss Force: 5.704990671971598, time: 1.0584912300109863
Validation Loss Energy: 7.962552019968361, Validation Loss Force: 4.105767212104364, time: 0.0668644905090332
Test Loss Energy: 13.838916280131262, Test Loss Force: 9.300198193014294, time: 7.84329891204834


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.233798086627964, Training Loss Force: 4.048110044413378, time: 1.0148980617523193
Validation Loss Energy: 3.219796740792396, Validation Loss Force: 4.81975827788242, time: 0.06668734550476074
Test Loss Energy: 10.350411386084245, Test Loss Force: 9.612280043556435, time: 7.832264423370361


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 13.355778989853643, Training Loss Force: 5.8856460096613405, time: 1.0036718845367432
Validation Loss Energy: 16.952061266368347, Validation Loss Force: 6.154710353615634, time: 0.06605672836303711
Test Loss Energy: 22.9978133010312, Test Loss Force: 10.829182608488189, time: 8.018247842788696


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 12.037275800184844, Training Loss Force: 5.123331237427698, time: 1.0448517799377441
Validation Loss Energy: 12.472002584130443, Validation Loss Force: 6.034328287914402, time: 0.0710291862487793
Test Loss Energy: 10.612668298894626, Test Loss Force: 10.743827173537278, time: 7.8297624588012695


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 12.832652696966635, Training Loss Force: 5.606788799298528, time: 1.058629035949707
Validation Loss Energy: 2.495466478561474, Validation Loss Force: 5.925467791830912, time: 0.07376694679260254
Test Loss Energy: 10.883611131718409, Test Loss Force: 10.621581873044889, time: 7.82772970199585


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 15.768692308935758, Training Loss Force: 7.0936448176194915, time: 1.0049278736114502
Validation Loss Energy: 24.883927251336402, Validation Loss Force: 7.729685963171955, time: 0.0688924789428711
Test Loss Energy: 25.855916554270195, Test Loss Force: 11.829594044733698, time: 7.999180555343628

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–‚â–‚â–‚â–ˆâ–‚â–„â–â–â–…â–‚â–â–„â–â–â–…
wandb:   test_error_force â–â–â–â–â–â–â–‚â–ˆâ–„â–ƒâ–†â–ƒâ–…â–„â–â–‚â–…â–…â–…â–ˆ
wandb:          test_loss â–â–â–â–â–â–‚â–‚â–…â–ˆâ–ƒâ–…â–‚â–‚â–†â–‚â–‚â–…â–ƒâ–ƒâ–‡
wandb: train_error_energy â–‚â–â–â–â–â–‚â–†â–ˆâ–…â–‡â–…â–…â–…â–„â–…â–„â–‡â–†â–‡â–ˆ
wandb:  train_error_force â–â–â–â–â–â–â–†â–ˆâ–‡â–†â–‡â–†â–†â–‡â–†â–ƒâ–†â–…â–…â–ˆ
wandb:         train_loss â–â–â–â–â–â–â–†â–ˆâ–†â–†â–†â–†â–†â–†â–…â–ƒâ–†â–…â–†â–ˆ
wandb: valid_error_energy â–â–â–‚â–â–â–‚â–â–ƒâ–ˆâ–ƒâ–ƒâ–â–‚â–„â–‚â–â–ƒâ–ƒâ–â–…
wandb:  valid_error_force â–â–â–â–â–â–â–ƒâ–ˆâ–…â–„â–…â–ƒâ–…â–„â–‚â–ƒâ–…â–…â–…â–‡
wandb:         valid_loss â–â–â–â–â–â–â–‚â–…â–ˆâ–„â–„â–‚â–ƒâ–„â–‚â–‚â–…â–„â–ƒâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2197
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 25.85592
wandb:   test_error_force 11.82959
wandb:          test_loss 5.68851
wandb: train_error_energy 15.76869
wandb:  train_error_force 7.09364
wandb:         train_loss 3.42881
wandb: valid_error_energy 24.88393
wandb:  valid_error_force 7.72969
wandb:         valid_loss 4.25163
wandb: 
wandb: ğŸš€ View run al_79_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/vxajpeog
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_073213-vxajpeog/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.08967961370944977, Uncertainty Bias: 0.11734534054994583
0.00026512146 0.0028817654
2.1607504 4.888942
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2329 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_094818-jf1glh56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/jf1glh56
Training model 21. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7621611605971164, Training Loss Force: 3.418425338157041, time: 1.110201358795166
Validation Loss Energy: 1.32181181275915, Validation Loss Force: 3.1650495232214224, time: 0.08153843879699707
Test Loss Energy: 9.928888909390206, Test Loss Force: 9.046658098767287, time: 10.070852756500244


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8402504723657713, Training Loss Force: 3.165704002701819, time: 1.0465562343597412
Validation Loss Energy: 1.517033034073998, Validation Loss Force: 3.168976738948151, time: 0.08060336112976074
Test Loss Energy: 10.12222665313179, Test Loss Force: 9.105816762845732, time: 10.165858268737793


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8096939009180582, Training Loss Force: 3.136309574604365, time: 0.9925806522369385
Validation Loss Energy: 2.0299977825682967, Validation Loss Force: 3.088564675617541, time: 0.0810394287109375
Test Loss Energy: 9.637344134955203, Test Loss Force: 9.108551270528114, time: 10.341774940490723


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6619966738550565, Training Loss Force: 3.1201012518947797, time: 1.0093798637390137
Validation Loss Energy: 1.6194529364460999, Validation Loss Force: 3.1255558101539407, time: 0.08175373077392578
Test Loss Energy: 10.492155774721635, Test Loss Force: 9.134263000383942, time: 10.127209901809692


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7406654233306735, Training Loss Force: 3.118729426011787, time: 1.0385775566101074
Validation Loss Energy: 1.316147332355893, Validation Loss Force: 3.1985893973305144, time: 0.07690691947937012
Test Loss Energy: 10.526645775161885, Test Loss Force: 9.16347692652566, time: 10.114690065383911


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.196493262525724, Training Loss Force: 3.108236390995798, time: 1.060220718383789
Validation Loss Energy: 2.1857782304051065, Validation Loss Force: 3.117975929757413, time: 0.11245274543762207
Test Loss Energy: 10.039242147951205, Test Loss Force: 9.120019053306141, time: 10.262916803359985


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.879759847465413, Training Loss Force: 7.333061884593408, time: 1.041395902633667
Validation Loss Energy: 20.32064909317603, Validation Loss Force: 7.302425511266819, time: 0.07459473609924316
Test Loss Energy: 14.792317741003298, Test Loss Force: 11.25098304622477, time: 10.691819190979004


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 16.66511932011341, Training Loss Force: 6.497793213307177, time: 1.0816349983215332
Validation Loss Energy: 17.4376234034209, Validation Loss Force: 7.128822179651657, time: 0.08155202865600586
Test Loss Energy: 19.86158782543247, Test Loss Force: 11.225068097547782, time: 10.312978744506836


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 9.979228269128816, Training Loss Force: 5.682225288292491, time: 1.1435949802398682
Validation Loss Energy: 14.544020038557626, Validation Loss Force: 6.123227831080342, time: 0.07722854614257812
Test Loss Energy: 21.449292347026734, Test Loss Force: 10.69693831618951, time: 10.17662763595581


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.492673099711748, Training Loss Force: 6.574166949007241, time: 1.0341930389404297
Validation Loss Energy: 17.532389610574604, Validation Loss Force: 6.389369787713342, time: 0.07764554023742676
Test Loss Energy: 13.59172160835448, Test Loss Force: 10.409439759567144, time: 10.131601572036743


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 13.949591796740773, Training Loss Force: 7.302826105968699, time: 1.1219987869262695
Validation Loss Energy: 2.132675090473091, Validation Loss Force: 5.352292916606734, time: 0.08362674713134766
Test Loss Energy: 8.636060996801481, Test Loss Force: 10.106972776735848, time: 10.292322874069214


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.188315992721973, Training Loss Force: 5.996963201523496, time: 1.036383867263794
Validation Loss Energy: 2.2136077542668806, Validation Loss Force: 5.521054307643697, time: 0.07934927940368652
Test Loss Energy: 8.509609389872793, Test Loss Force: 10.022610837886944, time: 10.169642210006714


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.518291473626153, Training Loss Force: 5.6568179319698615, time: 0.9939436912536621
Validation Loss Energy: 15.696295460317412, Validation Loss Force: 5.052980827981456, time: 0.07656669616699219
Test Loss Energy: 11.636154269559384, Test Loss Force: 9.716234437705104, time: 10.177135705947876


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.730092481344888, Training Loss Force: 6.192182931116421, time: 1.03135347366333
Validation Loss Energy: 2.275184791216324, Validation Loss Force: 8.663564814576016, time: 0.07595396041870117
Test Loss Energy: 9.586354304169422, Test Loss Force: 12.069533017908473, time: 10.255378246307373


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.887003822357224, Training Loss Force: 6.264145245737126, time: 1.0108752250671387
Validation Loss Energy: 21.269623131320824, Validation Loss Force: 5.073180259554295, time: 0.0778958797454834
Test Loss Energy: 15.074481769761812, Test Loss Force: 9.927187544575876, time: 10.178492546081543


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.987920722516211, Training Loss Force: 6.278518513290051, time: 1.0968914031982422
Validation Loss Energy: 5.051919364162818, Validation Loss Force: 5.127998285913673, time: 0.07894110679626465
Test Loss Energy: 11.280691232585252, Test Loss Force: 9.849469278945573, time: 10.326722145080566


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 11.867654025249283, Training Loss Force: 5.203620774640446, time: 1.0003941059112549
Validation Loss Energy: 13.970933340315234, Validation Loss Force: 4.476672552535782, time: 0.08041930198669434
Test Loss Energy: 10.882856220360132, Test Loss Force: 9.420743686210567, time: 10.102543354034424


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 13.460317827953839, Training Loss Force: 6.093743757675573, time: 1.0741722583770752
Validation Loss Energy: 20.1283457840167, Validation Loss Force: 5.271623225074285, time: 0.08735299110412598
Test Loss Energy: 26.20025385625381, Test Loss Force: 10.15415116459529, time: 10.088912010192871


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 10.119445260238095, Training Loss Force: 6.367937698473715, time: 1.0495014190673828
Validation Loss Energy: 20.197427550525923, Validation Loss Force: 4.743403691728906, time: 0.08446526527404785
Test Loss Energy: 27.344151863187356, Test Loss Force: 9.973308834564067, time: 10.343956708908081


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 9.191261999989482, Training Loss Force: 5.32803373921318, time: 0.9987728595733643
Validation Loss Energy: 7.003012330849289, Validation Loss Force: 7.552884879952124, time: 0.07663989067077637
Test Loss Energy: 9.574874989228093, Test Loss Force: 11.524505660819692, time: 10.12761640548706

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–…â–†â–ƒâ–â–â–‚â–â–ƒâ–‚â–‚â–ˆâ–ˆâ–
wandb:   test_error_force â–â–â–â–â–â–â–†â–†â–…â–„â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–‚â–„â–ƒâ–‡
wandb:          test_loss â–â–â–â–â–â–â–†â–ˆâ–‡â–„â–‚â–‚â–ƒâ–†â–„â–ƒâ–‚â–ˆâ–ˆâ–…
wandb: train_error_energy â–‚â–â–â–â–â–â–‡â–ˆâ–…â–†â–‡â–„â–…â–…â–†â–†â–†â–‡â–…â–…
wandb:  train_error_force â–‚â–â–â–â–â–â–ˆâ–‡â–…â–‡â–ˆâ–†â–…â–†â–†â–†â–„â–†â–†â–…
wandb:         train_loss â–‚â–â–â–â–â–â–ˆâ–ˆâ–…â–‡â–ˆâ–…â–…â–†â–†â–†â–…â–†â–†â–…
wandb: valid_error_energy â–â–â–â–â–â–â–ˆâ–‡â–†â–‡â–â–â–†â–â–ˆâ–‚â–…â–ˆâ–ˆâ–ƒ
wandb:  valid_error_force â–â–â–â–â–â–â–†â–†â–…â–…â–„â–„â–ƒâ–ˆâ–ƒâ–„â–ƒâ–„â–ƒâ–‡
wandb:         valid_loss â–â–â–â–â–â–â–ˆâ–‡â–†â–‡â–ƒâ–ƒâ–…â–†â–†â–ƒâ–„â–†â–†â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2198
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.57487
wandb:   test_error_force 11.52451
wandb:          test_loss 4.49689
wandb: train_error_energy 9.19126
wandb:  train_error_force 5.32803
wandb:         train_loss 2.39786
wandb: valid_error_energy 7.00301
wandb:  valid_error_force 7.55288
wandb:         valid_loss 2.99587
wandb: 
wandb: ğŸš€ View run al_79_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/jf1glh56
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_094818-jf1glh56/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6109594106674194, Uncertainty Bias: -0.3579155504703522
0.000111579895 0.02238655
-1.5488883 26.067604
(48745, 22, 3)
Found uncertainty sample 0 after 1861 steps.
Found uncertainty sample 1 after 799 steps.
Found uncertainty sample 2 after 551 steps.
Found uncertainty sample 3 after 2030 steps.
Found uncertainty sample 4 after 1533 steps.
Found uncertainty sample 5 after 1695 steps.
Found uncertainty sample 6 after 889 steps.
Found uncertainty sample 7 after 262 steps.
Found uncertainty sample 8 after 213 steps.
Found uncertainty sample 9 after 1466 steps.
Found uncertainty sample 10 after 2579 steps.
Found uncertainty sample 11 after 992 steps.
Found uncertainty sample 12 after 51 steps.
Found uncertainty sample 13 after 2244 steps.
Found uncertainty sample 14 after 427 steps.
Found uncertainty sample 15 after 674 steps.
Found uncertainty sample 16 after 3120 steps.
Found uncertainty sample 17 after 750 steps.
Found uncertainty sample 18 after 508 steps.
Found uncertainty sample 19 after 425 steps.
Found uncertainty sample 20 after 1377 steps.
Found uncertainty sample 21 after 3483 steps.
Found uncertainty sample 22 after 512 steps.
Found uncertainty sample 23 after 452 steps.
Found uncertainty sample 24 after 122 steps.
Found uncertainty sample 25 after 144 steps.
Found uncertainty sample 26 after 100 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 243 steps.
Found uncertainty sample 29 after 1856 steps.
Found uncertainty sample 30 after 676 steps.
Found uncertainty sample 31 after 1929 steps.
Found uncertainty sample 32 after 52 steps.
Found uncertainty sample 33 after 2217 steps.
Found uncertainty sample 34 after 221 steps.
Found uncertainty sample 35 after 179 steps.
Found uncertainty sample 36 after 1679 steps.
Found uncertainty sample 37 after 192 steps.
Found uncertainty sample 38 after 2165 steps.
Found uncertainty sample 39 after 238 steps.
Found uncertainty sample 40 after 1388 steps.
Found uncertainty sample 41 after 572 steps.
Found uncertainty sample 42 after 107 steps.
Found uncertainty sample 43 after 954 steps.
Found uncertainty sample 44 after 620 steps.
Found uncertainty sample 45 after 71 steps.
Found uncertainty sample 46 after 1811 steps.
Found uncertainty sample 47 after 2190 steps.
Found uncertainty sample 48 after 268 steps.
Found uncertainty sample 49 after 755 steps.
Found uncertainty sample 50 after 685 steps.
Found uncertainty sample 51 after 2692 steps.
Found uncertainty sample 52 after 1134 steps.
Found uncertainty sample 53 after 46 steps.
Found uncertainty sample 54 after 178 steps.
Found uncertainty sample 55 after 422 steps.
Found uncertainty sample 56 after 930 steps.
Found uncertainty sample 57 after 390 steps.
Found uncertainty sample 58 after 3443 steps.
Found uncertainty sample 59 after 250 steps.
Found uncertainty sample 60 after 243 steps.
Found uncertainty sample 61 after 1458 steps.
Found uncertainty sample 62 after 19 steps.
Found uncertainty sample 63 after 86 steps.
Found uncertainty sample 64 after 1687 steps.
Found uncertainty sample 65 after 401 steps.
Found uncertainty sample 66 after 642 steps.
Found uncertainty sample 67 after 161 steps.
Found uncertainty sample 68 after 408 steps.
Found uncertainty sample 69 after 436 steps.
Found uncertainty sample 70 after 584 steps.
Found uncertainty sample 71 after 566 steps.
Found uncertainty sample 72 after 644 steps.
Found uncertainty sample 73 after 2520 steps.
Found uncertainty sample 74 after 777 steps.
Found uncertainty sample 75 after 128 steps.
Found uncertainty sample 76 after 1205 steps.
Found uncertainty sample 77 after 1050 steps.
Found uncertainty sample 78 after 418 steps.
Found uncertainty sample 79 after 1091 steps.
Found uncertainty sample 80 after 235 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 115 steps.
Found uncertainty sample 83 after 1816 steps.
Found uncertainty sample 84 after 198 steps.
Found uncertainty sample 85 after 307 steps.
Found uncertainty sample 86 after 794 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 34 steps.
Found uncertainty sample 89 after 517 steps.
Found uncertainty sample 90 after 117 steps.
Found uncertainty sample 91 after 676 steps.
Found uncertainty sample 92 after 775 steps.
Found uncertainty sample 93 after 349 steps.
Found uncertainty sample 94 after 259 steps.
Found uncertainty sample 95 after 591 steps.
Found uncertainty sample 96 after 417 steps.
Found uncertainty sample 97 after 1078 steps.
Found uncertainty sample 98 after 176 steps.
Found uncertainty sample 99 after 181 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_102444-22xnwfp3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/22xnwfp3
Training model 22. Added 98 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9841304385672682, Training Loss Force: 3.3393723947185148, time: 1.1202974319458008
Validation Loss Energy: 2.4977319144521433, Validation Loss Force: 3.208798109663866, time: 0.08051753044128418
Test Loss Energy: 11.539306849676155, Test Loss Force: 9.085911050529283, time: 10.040000677108765


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.04128399863036, Training Loss Force: 3.142000665718567, time: 1.1788010597229004
Validation Loss Energy: 1.3805002185457589, Validation Loss Force: 3.1129466130929146, time: 0.07846999168395996
Test Loss Energy: 10.562666186471128, Test Loss Force: 9.107552066634808, time: 9.957866668701172


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8147894447112516, Training Loss Force: 3.138978797998165, time: 1.0654301643371582
Validation Loss Energy: 2.5093201734790904, Validation Loss Force: 3.127487798998583, time: 0.07851195335388184
Test Loss Energy: 9.678192782780814, Test Loss Force: 9.084905238841637, time: 10.163877725601196


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0136366853945926, Training Loss Force: 3.128608514458427, time: 1.056417465209961
Validation Loss Energy: 3.1825211464220735, Validation Loss Force: 3.236292405126445, time: 0.07802796363830566
Test Loss Energy: 9.869646213939834, Test Loss Force: 9.084031634336316, time: 9.993791341781616


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9096644744516122, Training Loss Force: 3.0892216516547197, time: 1.0716056823730469
Validation Loss Energy: 1.4192870684094931, Validation Loss Force: 3.092810642226665, time: 0.09072470664978027
Test Loss Energy: 10.851228071037596, Test Loss Force: 9.070226296512095, time: 9.982281684875488


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1959029562662917, Training Loss Force: 3.06077293747278, time: 1.1123278141021729
Validation Loss Energy: 1.633433107438603, Validation Loss Force: 3.0139167371329902, time: 0.07973599433898926
Test Loss Energy: 10.970720570003426, Test Loss Force: 9.078117136119623, time: 10.223803043365479


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 16.536174728149874, Training Loss Force: 6.361435986653479, time: 1.0954608917236328
Validation Loss Energy: 19.9425319444463, Validation Loss Force: 7.977288709384154, time: 0.07813668251037598
Test Loss Energy: 22.870944088028686, Test Loss Force: 11.812720834370463, time: 10.008692741394043


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.330830594337808, Training Loss Force: 7.208899200140694, time: 1.0397002696990967
Validation Loss Energy: 8.944174253627382, Validation Loss Force: 5.276073045286506, time: 0.07849931716918945
Test Loss Energy: 10.071964700970485, Test Loss Force: 10.237534744180888, time: 10.698470115661621


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.306210713560478, Training Loss Force: 4.167666936850408, time: 1.0934250354766846
Validation Loss Energy: 6.404978672173733, Validation Loss Force: 4.070687024178316, time: 0.07890772819519043
Test Loss Energy: 9.497504064149297, Test Loss Force: 9.292948892361363, time: 9.994320392608643


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.450894121330451, Training Loss Force: 4.011216845576118, time: 1.110194444656372
Validation Loss Energy: 8.602825124949835, Validation Loss Force: 3.849992730905762, time: 0.08338761329650879
Test Loss Energy: 10.138481262959878, Test Loss Force: 9.187945803478643, time: 9.961366415023804


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 10.445569595420235, Training Loss Force: 4.473935419893107, time: 1.0805017948150635
Validation Loss Energy: 35.1348523106961, Validation Loss Force: 7.077502062905658, time: 0.07906866073608398
Test Loss Energy: 26.10944848320465, Test Loss Force: 11.215732212126449, time: 10.199827194213867


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.200935563618874, Training Loss Force: 6.546095651632236, time: 1.088350772857666
Validation Loss Energy: 6.267445960845706, Validation Loss Force: 7.324698215257392, time: 0.08266139030456543
Test Loss Energy: 9.62643257737209, Test Loss Force: 11.393323857084045, time: 10.026155233383179


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 13.504720122199007, Training Loss Force: 6.600088614582903, time: 1.0578689575195312
Validation Loss Energy: 2.4617033786335893, Validation Loss Force: 5.552137139062048, time: 0.08048653602600098
Test Loss Energy: 8.533707610133332, Test Loss Force: 10.300174027788398, time: 10.000321865081787


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.379510921969429, Training Loss Force: 6.034661988555844, time: 1.0802490711212158
Validation Loss Energy: 2.4915983814929894, Validation Loss Force: 6.616107321606376, time: 0.07679271697998047
Test Loss Energy: 8.608400433937893, Test Loss Force: 10.609479042525907, time: 10.176328659057617


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.7232241762473, Training Loss Force: 5.950672664987603, time: 1.0882432460784912
Validation Loss Energy: 28.61911310661667, Validation Loss Force: 5.786329858629891, time: 0.0776987075805664
Test Loss Energy: 34.56913698942573, Test Loss Force: 11.298888519959895, time: 9.963677406311035


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.679112582771996, Training Loss Force: 6.164535617309189, time: 1.1132221221923828
Validation Loss Energy: 2.4474783829151385, Validation Loss Force: 5.573402265167298, time: 0.07641792297363281
Test Loss Energy: 9.931105532939828, Test Loss Force: 9.926547856922872, time: 10.147906303405762


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 11.851764537595336, Training Loss Force: 6.368134554940933, time: 1.1424283981323242
Validation Loss Energy: 6.987452878939294, Validation Loss Force: 5.347227193536877, time: 0.08465719223022461
Test Loss Energy: 9.05443827064348, Test Loss Force: 9.986642435561667, time: 10.052738904953003


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.784339500662238, Training Loss Force: 5.167828136612695, time: 1.122663974761963
Validation Loss Energy: 2.69208556110717, Validation Loss Force: 7.919392059413178, time: 0.0796971321105957
Test Loss Energy: 8.87382513361442, Test Loss Force: 11.55729581199477, time: 9.961724996566772


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.488417517080235, Training Loss Force: 4.817425209331303, time: 1.0886304378509521
Validation Loss Energy: 2.3912806985275914, Validation Loss Force: 3.889890143134811, time: 0.07991838455200195
Test Loss Energy: 10.736391912670705, Test Loss Force: 9.285943786315668, time: 10.162652492523193


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 9.0934417773919, Training Loss Force: 6.224564228480986, time: 1.092041254043579
Validation Loss Energy: 12.637395881666102, Validation Loss Force: 6.84504193196228, time: 0.07896280288696289
Test Loss Energy: 17.025878307940026, Test Loss Force: 10.793833809292117, time: 10.020838499069214

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–â–â–‚â–‚â–…â–â–â–â–†â–â–â–â–ˆâ–â–â–â–‚â–ƒ
wandb:   test_error_force â–â–â–â–â–â–â–ˆâ–„â–‚â–â–†â–‡â–„â–…â–‡â–ƒâ–ƒâ–‡â–‚â–…
wandb:          test_loss â–â–â–â–â–â–â–†â–‚â–â–â–†â–ƒâ–‚â–‚â–ˆâ–‚â–‚â–ƒâ–â–„
wandb: train_error_energy â–‚â–â–â–â–â–â–ˆâ–„â–„â–„â–…â–…â–‡â–„â–…â–†â–†â–†â–„â–„
wandb:  train_error_force â–â–â–â–â–â–â–‡â–ˆâ–ƒâ–ƒâ–ƒâ–‡â–‡â–†â–†â–†â–‡â–…â–„â–†
wandb:         train_loss â–‚â–â–â–â–â–â–ˆâ–‡â–ƒâ–ƒâ–„â–‡â–ˆâ–†â–†â–‡â–‡â–†â–„â–†
wandb: valid_error_energy â–â–â–â–â–â–â–…â–ƒâ–‚â–‚â–ˆâ–‚â–â–â–‡â–â–‚â–â–â–ƒ
wandb:  valid_error_force â–â–â–â–â–â–â–ˆâ–„â–‚â–‚â–‡â–‡â–…â–†â–…â–…â–„â–ˆâ–‚â–†
wandb:         valid_loss â–â–â–â–â–â–â–‡â–ƒâ–‚â–‚â–ˆâ–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–„â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2286
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 17.02588
wandb:   test_error_force 10.79383
wandb:          test_loss 4.75103
wandb: train_error_energy 9.09344
wandb:  train_error_force 6.22456
wandb:         train_loss 2.6913
wandb: valid_error_energy 12.6374
wandb:  valid_error_force 6.84504
wandb:         valid_loss 3.13608
wandb: 
wandb: ğŸš€ View run al_79_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/22xnwfp3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_102444-22xnwfp3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7540026307106018, Uncertainty Bias: -0.4433102309703827
7.343292e-05 0.015945435
-0.9228206 20.847446
(48745, 22, 3)
Found uncertainty sample 0 after 25 steps.
Found uncertainty sample 1 after 44 steps.
Found uncertainty sample 2 after 40 steps.
Found uncertainty sample 3 after 7 steps.
Found uncertainty sample 4 after 109 steps.
Found uncertainty sample 5 after 91 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 11 steps.
Found uncertainty sample 8 after 27 steps.
Found uncertainty sample 9 after 2 steps.
Found uncertainty sample 10 after 170 steps.
Found uncertainty sample 11 after 276 steps.
Found uncertainty sample 12 after 7 steps.
Found uncertainty sample 13 after 102 steps.
Found uncertainty sample 14 after 27 steps.
Found uncertainty sample 15 after 98 steps.
Found uncertainty sample 16 after 138 steps.
Found uncertainty sample 17 after 29 steps.
Found uncertainty sample 18 after 108 steps.
Found uncertainty sample 19 after 15 steps.
Found uncertainty sample 20 after 123 steps.
Found uncertainty sample 21 after 68 steps.
Found uncertainty sample 22 after 39 steps.
Found uncertainty sample 23 after 13 steps.
Found uncertainty sample 24 after 54 steps.
Found uncertainty sample 25 after 66 steps.
Found uncertainty sample 26 after 8 steps.
Found uncertainty sample 27 after 156 steps.
Found uncertainty sample 28 after 54 steps.
Found uncertainty sample 29 after 71 steps.
Found uncertainty sample 30 after 40 steps.
Found uncertainty sample 31 after 156 steps.
Found uncertainty sample 32 after 9 steps.
Found uncertainty sample 33 after 51 steps.
Found uncertainty sample 34 after 3 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 141 steps.
Found uncertainty sample 37 after 4 steps.
Found uncertainty sample 38 after 29 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 24 steps.
Found uncertainty sample 41 after 86 steps.
Found uncertainty sample 42 after 23 steps.
Found uncertainty sample 43 after 2 steps.
Found uncertainty sample 44 after 7 steps.
Found uncertainty sample 45 after 182 steps.
Found uncertainty sample 46 after 181 steps.
Found uncertainty sample 47 after 148 steps.
Found uncertainty sample 48 after 41 steps.
Found uncertainty sample 49 after 26 steps.
Found uncertainty sample 50 after 126 steps.
Found uncertainty sample 51 after 140 steps.
Found uncertainty sample 52 after 128 steps.
Found uncertainty sample 53 after 61 steps.
Found uncertainty sample 54 after 247 steps.
Found uncertainty sample 55 after 46 steps.
Found uncertainty sample 56 after 53 steps.
Found uncertainty sample 57 after 182 steps.
Found uncertainty sample 58 after 237 steps.
Found uncertainty sample 59 after 100 steps.
Found uncertainty sample 60 after 32 steps.
Found uncertainty sample 61 after 47 steps.
Found uncertainty sample 62 after 23 steps.
Found uncertainty sample 63 after 80 steps.
Found uncertainty sample 64 after 156 steps.
Found uncertainty sample 65 after 95 steps.
Found uncertainty sample 66 after 113 steps.
Found uncertainty sample 67 after 7 steps.
Found uncertainty sample 68 after 7 steps.
Found uncertainty sample 69 after 55 steps.
Found uncertainty sample 70 after 35 steps.
Found uncertainty sample 71 after 52 steps.
Found uncertainty sample 72 after 5 steps.
Found uncertainty sample 73 after 36 steps.
Found uncertainty sample 74 after 16 steps.
Found uncertainty sample 75 after 43 steps.
Found uncertainty sample 76 after 101 steps.
Found uncertainty sample 77 after 122 steps.
Found uncertainty sample 78 after 378 steps.
Found uncertainty sample 79 after 28 steps.
Found uncertainty sample 80 after 347 steps.
Found uncertainty sample 81 after 15 steps.
Found uncertainty sample 82 after 35 steps.
Found uncertainty sample 83 after 158 steps.
Found uncertainty sample 84 after 118 steps.
Found uncertainty sample 85 after 337 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 77 steps.
Found uncertainty sample 88 after 137 steps.
Found uncertainty sample 89 after 47 steps.
Found uncertainty sample 90 after 139 steps.
Found uncertainty sample 91 after 211 steps.
Found uncertainty sample 92 after 50 steps.
Found uncertainty sample 93 after 8 steps.
Found uncertainty sample 94 after 12 steps.
Found uncertainty sample 95 after 12 steps.
Found uncertainty sample 96 after 106 steps.
Found uncertainty sample 97 after 30 steps.
Found uncertainty sample 98 after 29 steps.
Found uncertainty sample 99 after 39 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_103507-323nhipr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/323nhipr
Training model 23. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8637291860224043, Training Loss Force: 3.3043459641962025, time: 1.163315773010254
Validation Loss Energy: 2.07504119009431, Validation Loss Force: 3.148859583624732, time: 0.0846247673034668
Test Loss Energy: 10.741511265196328, Test Loss Force: 9.07582558848272, time: 10.088508367538452


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0713253979794093, Training Loss Force: 3.091560742416594, time: 1.1558592319488525
Validation Loss Energy: 1.8081684333243755, Validation Loss Force: 3.1683921211055175, time: 0.0784749984741211
Test Loss Energy: 11.098339177765272, Test Loss Force: 9.178540925596282, time: 10.079488039016724


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.4635516765797645, Training Loss Force: 3.160422847297818, time: 1.0958964824676514
Validation Loss Energy: 1.330800298172817, Validation Loss Force: 3.1533441402237177, time: 0.08688902854919434
Test Loss Energy: 10.64605821116297, Test Loss Force: 9.075160099188157, time: 10.29967451095581


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1658766588953924, Training Loss Force: 3.072605787917892, time: 1.171929121017456
Validation Loss Energy: 1.5370145282202605, Validation Loss Force: 3.1171251109508225, time: 0.08422255516052246
Test Loss Energy: 10.239275298764902, Test Loss Force: 9.080979103818041, time: 10.14950942993164


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1068054781668595, Training Loss Force: 3.0368196378559063, time: 1.1825275421142578
Validation Loss Energy: 2.3080440770808877, Validation Loss Force: 3.121928195763058, time: 0.08574891090393066
Test Loss Energy: 11.952937754635842, Test Loss Force: 9.115988032954164, time: 10.117294549942017


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9719860601516273, Training Loss Force: 3.044756284695884, time: 1.3617703914642334
Validation Loss Energy: 1.3059059989926634, Validation Loss Force: 3.0324701983791313, time: 0.08166718482971191
Test Loss Energy: 10.590480673170708, Test Loss Force: 9.10120022289937, time: 10.08180046081543


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.351742772781611, Training Loss Force: 6.905312561610259, time: 1.130570888519287
Validation Loss Energy: 8.406637575208947, Validation Loss Force: 5.633477510062031, time: 0.07867980003356934
Test Loss Energy: 9.869502152831453, Test Loss Force: 10.160029298958586, time: 10.094110012054443


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 13.85352152366782, Training Loss Force: 6.102657245668304, time: 1.093682050704956
Validation Loss Energy: 7.296624534677108, Validation Loss Force: 8.076236197760085, time: 0.08186912536621094
Test Loss Energy: 11.17999452767895, Test Loss Force: 11.97328166117856, time: 10.362934112548828


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 13.820984509827076, Training Loss Force: 7.574916145272227, time: 1.1142725944519043
Validation Loss Energy: 19.469533691283573, Validation Loss Force: 6.7352818525292415, time: 0.08551955223083496
Test Loss Energy: 21.634882141798904, Test Loss Force: 10.924837561649131, time: 10.125008821487427


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.533671935212146, Training Loss Force: 5.518547712161222, time: 1.1504967212677002
Validation Loss Energy: 8.249248788131101, Validation Loss Force: 5.792331682789229, time: 0.08460426330566406
Test Loss Energy: 9.30917645546597, Test Loss Force: 10.213504835550058, time: 10.160560846328735


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 13.092423979161818, Training Loss Force: 6.071000854157106, time: 1.103454351425171
Validation Loss Energy: 16.984557601525047, Validation Loss Force: 5.005036152818576, time: 0.08902788162231445
Test Loss Energy: 20.781757033117934, Test Loss Force: 9.990201942921976, time: 10.317330360412598


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.544878701002439, Training Loss Force: 5.031284213605227, time: 1.1347665786743164
Validation Loss Energy: 9.94903958341493, Validation Loss Force: 4.438419997287701, time: 0.08122587203979492
Test Loss Energy: 14.668369900563077, Test Loss Force: 9.649192465132653, time: 10.650149583816528


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.775083030164604, Training Loss Force: 4.807074179374087, time: 1.1663072109222412
Validation Loss Energy: 6.847431839905523, Validation Loss Force: 3.7368770274435916, time: 0.07942914962768555
Test Loss Energy: 13.407126456838455, Test Loss Force: 9.23935925590261, time: 10.110757112503052


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.757745449547715, Training Loss Force: 5.206653736103434, time: 1.2883102893829346
Validation Loss Energy: 1.98778015783868, Validation Loss Force: 6.221998074816114, time: 0.07909011840820312
Test Loss Energy: 9.248776980978624, Test Loss Force: 10.492817449495538, time: 10.112604856491089


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 12.455569454199335, Training Loss Force: 6.604335486713221, time: 1.0852224826812744
Validation Loss Energy: 4.506560095978793, Validation Loss Force: 9.284003888053117, time: 0.08356428146362305
Test Loss Energy: 8.769808998324558, Test Loss Force: 12.797971640130855, time: 10.132510900497437


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.866423511315485, Training Loss Force: 6.458122238431423, time: 1.1491320133209229
Validation Loss Energy: 9.05202271844263, Validation Loss Force: 4.434021836317336, time: 0.0817103385925293
Test Loss Energy: 15.03553838640301, Test Loss Force: 9.413550013206677, time: 10.272448778152466


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 14.28429498512335, Training Loss Force: 7.104386295380068, time: 1.1211559772491455
Validation Loss Energy: 16.252068741787333, Validation Loss Force: 6.212245834231915, time: 0.07986211776733398
Test Loss Energy: 21.57354905172269, Test Loss Force: 10.781308280454127, time: 10.120290279388428


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.595595167673931, Training Loss Force: 5.59714328216426, time: 1.093116044998169
Validation Loss Energy: 10.332761759885951, Validation Loss Force: 7.0483780519640336, time: 0.08303165435791016
Test Loss Energy: 15.686865554889373, Test Loss Force: 11.115039783400395, time: 10.150938510894775


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 12.59345972170405, Training Loss Force: 5.741981961150105, time: 1.073312759399414
Validation Loss Energy: 28.31949217588599, Validation Loss Force: 6.313884056567238, time: 0.0840461254119873
Test Loss Energy: 33.7439262351392, Test Loss Force: 11.113940362070121, time: 10.295233249664307


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 16.172107304398565, Training Loss Force: 6.869848996793364, time: 1.131248950958252
Validation Loss Energy: 25.748668223606465, Validation Loss Force: 6.528914537443972, time: 0.08560681343078613
Test Loss Energy: 24.58129764774854, Test Loss Force: 10.434565867237568, time: 10.040412425994873

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–…â–â–„â–ƒâ–‚â–â–â–ƒâ–…â–ƒâ–ˆâ–…
wandb:   test_error_force â–â–â–â–â–â–â–ƒâ–†â–„â–ƒâ–ƒâ–‚â–â–„â–ˆâ–‚â–„â–…â–…â–„
wandb:          test_loss â–â–â–â–â–â–â–‚â–„â–…â–‚â–„â–ƒâ–‚â–‚â–…â–‚â–…â–„â–ˆâ–…
wandb: train_error_energy â–â–â–‚â–â–â–â–‡â–‡â–‡â–†â–†â–„â–„â–†â–†â–†â–‡â–…â–†â–ˆ
wandb:  train_error_force â–â–â–â–â–â–â–‡â–†â–ˆâ–…â–†â–„â–„â–„â–‡â–†â–‡â–…â–…â–‡
wandb:         train_loss â–â–â–â–â–â–â–‡â–‡â–ˆâ–…â–†â–„â–„â–…â–‡â–‡â–ˆâ–…â–†â–ˆ
wandb: valid_error_energy â–â–â–â–â–â–â–ƒâ–ƒâ–†â–ƒâ–…â–ƒâ–‚â–â–‚â–ƒâ–…â–ƒâ–ˆâ–‡
wandb:  valid_error_force â–â–â–â–â–â–â–„â–‡â–…â–„â–ƒâ–ƒâ–‚â–…â–ˆâ–ƒâ–…â–…â–…â–…
wandb:         valid_loss â–â–â–â–â–â–â–„â–†â–‡â–„â–…â–„â–‚â–„â–‡â–ƒâ–†â–†â–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2376
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 24.5813
wandb:   test_error_force 10.43457
wandb:          test_loss 5.13644
wandb: train_error_energy 16.17211
wandb:  train_error_force 6.86985
wandb:         train_loss 3.38092
wandb: valid_error_energy 25.74867
wandb:  valid_error_force 6.52891
wandb:         valid_loss 3.90771
wandb: 
wandb: ğŸš€ View run al_79_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/323nhipr
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_103507-323nhipr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.532855212688446, Uncertainty Bias: -0.26961830258369446
4.196167e-05 0.014457703
-3.7221348 20.547611
(48745, 22, 3)
Found uncertainty sample 0 after 953 steps.
Found uncertainty sample 1 after 1115 steps.
Found uncertainty sample 2 after 44 steps.
Found uncertainty sample 3 after 522 steps.
Found uncertainty sample 4 after 678 steps.
Found uncertainty sample 5 after 1068 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1148 steps.
Found uncertainty sample 8 after 1404 steps.
Found uncertainty sample 9 after 390 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2470 steps.
Found uncertainty sample 12 after 40 steps.
Found uncertainty sample 13 after 851 steps.
Found uncertainty sample 14 after 38 steps.
Found uncertainty sample 15 after 2829 steps.
Found uncertainty sample 16 after 2118 steps.
Found uncertainty sample 17 after 1836 steps.
Found uncertainty sample 18 after 2040 steps.
Found uncertainty sample 19 after 792 steps.
Found uncertainty sample 20 after 308 steps.
Found uncertainty sample 21 after 2026 steps.
Found uncertainty sample 22 after 675 steps.
Found uncertainty sample 23 after 575 steps.
Found uncertainty sample 24 after 185 steps.
Found uncertainty sample 25 after 941 steps.
Found uncertainty sample 26 after 111 steps.
Found uncertainty sample 27 after 1408 steps.
Found uncertainty sample 28 after 1802 steps.
Found uncertainty sample 29 after 1717 steps.
Found uncertainty sample 30 after 770 steps.
Found uncertainty sample 31 after 1415 steps.
Found uncertainty sample 32 after 100 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1274 steps.
Found uncertainty sample 36 after 1503 steps.
Found uncertainty sample 37 after 676 steps.
Found uncertainty sample 38 after 1027 steps.
Found uncertainty sample 39 after 260 steps.
Found uncertainty sample 40 after 238 steps.
Found uncertainty sample 41 after 3383 steps.
Found uncertainty sample 42 after 954 steps.
Found uncertainty sample 43 after 1422 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 473 steps.
Found uncertainty sample 46 after 1016 steps.
Found uncertainty sample 47 after 334 steps.
Found uncertainty sample 48 after 551 steps.
Found uncertainty sample 49 after 598 steps.
Found uncertainty sample 50 after 336 steps.
Found uncertainty sample 51 after 1401 steps.
Found uncertainty sample 52 after 3458 steps.
Found uncertainty sample 53 after 511 steps.
Found uncertainty sample 54 after 654 steps.
Found uncertainty sample 55 after 1428 steps.
Found uncertainty sample 56 after 782 steps.
Found uncertainty sample 57 after 393 steps.
Found uncertainty sample 58 after 171 steps.
Found uncertainty sample 59 after 652 steps.
Found uncertainty sample 60 after 482 steps.
Found uncertainty sample 61 after 2155 steps.
Found uncertainty sample 62 after 978 steps.
Found uncertainty sample 63 after 187 steps.
Found uncertainty sample 64 after 3196 steps.
Found uncertainty sample 65 after 2234 steps.
Found uncertainty sample 66 after 2172 steps.
Found uncertainty sample 67 after 211 steps.
Found uncertainty sample 68 after 1457 steps.
Found uncertainty sample 69 after 733 steps.
Found uncertainty sample 70 after 697 steps.
Found uncertainty sample 71 after 165 steps.
Found uncertainty sample 72 after 239 steps.
Found uncertainty sample 73 after 1030 steps.
Found uncertainty sample 74 after 1867 steps.
Found uncertainty sample 75 after 931 steps.
Found uncertainty sample 76 after 3039 steps.
Found uncertainty sample 77 after 641 steps.
Found uncertainty sample 78 after 3546 steps.
Found uncertainty sample 79 after 1697 steps.
Found uncertainty sample 80 after 1532 steps.
Found uncertainty sample 81 after 1643 steps.
Found uncertainty sample 82 after 1215 steps.
Found uncertainty sample 83 after 3084 steps.
Found uncertainty sample 84 after 496 steps.
Found uncertainty sample 85 after 2473 steps.
Found uncertainty sample 86 after 157 steps.
Found uncertainty sample 87 after 527 steps.
Found uncertainty sample 88 after 100 steps.
Found uncertainty sample 89 after 490 steps.
Found uncertainty sample 90 after 1171 steps.
Found uncertainty sample 91 after 24 steps.
Found uncertainty sample 92 after 462 steps.
Found uncertainty sample 93 after 433 steps.
Found uncertainty sample 94 after 1832 steps.
Found uncertainty sample 95 after 2216 steps.
Found uncertainty sample 96 after 385 steps.
Found uncertainty sample 97 after 738 steps.
Found uncertainty sample 98 after 1173 steps.
Found uncertainty sample 99 after 1229 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_112215-bxdwzuce
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/bxdwzuce
Training model 24. Added 95 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9160699500601974, Training Loss Force: 3.2720215796291416, time: 1.151111125946045
Validation Loss Energy: 1.469004913648682, Validation Loss Force: 3.1298762595923773, time: 0.08629131317138672
Test Loss Energy: 10.29721728464031, Test Loss Force: 8.987381380404063, time: 10.071621417999268


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.805595631595824, Training Loss Force: 3.086181326292777, time: 1.2568299770355225
Validation Loss Energy: 1.5271603608345126, Validation Loss Force: 3.0708999982673704, time: 0.08190274238586426
Test Loss Energy: 10.54036653135325, Test Loss Force: 8.989232434843196, time: 10.161957502365112


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9024003075459774, Training Loss Force: 3.0554592680515498, time: 1.1798431873321533
Validation Loss Energy: 2.451300498804989, Validation Loss Force: 3.1037292237972336, time: 0.08664703369140625
Test Loss Energy: 10.958623246756932, Test Loss Force: 9.075962612779767, time: 10.26967477798462


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0383052127105903, Training Loss Force: 3.05765644283586, time: 1.144740104675293
Validation Loss Energy: 1.342800216783298, Validation Loss Force: 3.137065132968656, time: 0.08915090560913086
Test Loss Energy: 10.215796886815603, Test Loss Force: 9.089685374159252, time: 10.10430121421814


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.655967647933282, Training Loss Force: 3.05013176703668, time: 1.1633434295654297
Validation Loss Energy: 1.4703424872082702, Validation Loss Force: 3.1247562052509137, time: 0.08141779899597168
Test Loss Energy: 10.27399102742877, Test Loss Force: 9.118843103738092, time: 10.05231237411499


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.7275272119063323, Training Loss Force: 3.0489622334952826, time: 1.3398385047912598
Validation Loss Energy: 4.133581705798788, Validation Loss Force: 3.049414875045944, time: 0.08080625534057617
Test Loss Energy: 12.612432828432464, Test Loss Force: 9.079216911855237, time: 10.093658685684204


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.758616532931237, Training Loss Force: 6.435858218229081, time: 1.2081859111785889
Validation Loss Energy: 2.1726184838807745, Validation Loss Force: 5.599150166518365, time: 0.0835869312286377
Test Loss Energy: 10.182060743844062, Test Loss Force: 10.17038188470538, time: 10.159976959228516


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 9.898147775108834, Training Loss Force: 5.650416611324774, time: 1.1924412250518799
Validation Loss Energy: 17.846704923583346, Validation Loss Force: 7.84291678658257, time: 0.0838165283203125
Test Loss Energy: 23.053128383214638, Test Loss Force: 12.307030609261478, time: 10.26880693435669


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.254231011092049, Training Loss Force: 7.489117531922499, time: 1.2053163051605225
Validation Loss Energy: 4.576736949347687, Validation Loss Force: 5.864540614783859, time: 0.0826871395111084
Test Loss Energy: 13.550579606170082, Test Loss Force: 10.403750537240933, time: 10.098946332931519


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.606115190813542, Training Loss Force: 5.66704434304272, time: 1.1150872707366943
Validation Loss Energy: 22.974651550255167, Validation Loss Force: 6.403992025188128, time: 0.08451414108276367
Test Loss Energy: 28.213361714283245, Test Loss Force: 10.914073030987527, time: 10.656852722167969


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.373036434649753, Training Loss Force: 6.302470478593463, time: 1.1640465259552002
Validation Loss Energy: 7.6821839542711805, Validation Loss Force: 5.399945004511864, time: 0.09154868125915527
Test Loss Energy: 9.346291592234703, Test Loss Force: 9.795321104330728, time: 10.258359670639038


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.708707435040486, Training Loss Force: 5.26732455672685, time: 1.1597020626068115
Validation Loss Energy: 8.34931184892813, Validation Loss Force: 4.509599752489853, time: 0.09403181076049805
Test Loss Energy: 15.412264988466752, Test Loss Force: 9.763636100930137, time: 10.154236316680908


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 12.328379171843974, Training Loss Force: 5.0959182900073285, time: 1.1893126964569092
Validation Loss Energy: 19.869583750887188, Validation Loss Force: 6.187426908557658, time: 0.08278584480285645
Test Loss Energy: 24.419982399221126, Test Loss Force: 11.083918317136513, time: 10.096611738204956


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 15.441628853549437, Training Loss Force: 7.629185985025316, time: 1.3483467102050781
Validation Loss Energy: 10.509506285142717, Validation Loss Force: 5.628264157348424, time: 0.08098554611206055
Test Loss Energy: 10.544738023321612, Test Loss Force: 10.387898900276621, time: 10.091827630996704


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 9.391917386718013, Training Loss Force: 5.628532979735507, time: 1.1925022602081299
Validation Loss Energy: 5.251453408497854, Validation Loss Force: 4.293339247251014, time: 0.0859520435333252
Test Loss Energy: 8.609155704364738, Test Loss Force: 9.44047973629589, time: 10.162696599960327


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.676448625688636, Training Loss Force: 5.79016851276449, time: 1.2487242221832275
Validation Loss Energy: 17.39691859286872, Validation Loss Force: 6.008243933483838, time: 0.08318018913269043
Test Loss Energy: 22.336987038800185, Test Loss Force: 10.798702499313006, time: 10.296316862106323


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 13.751684224744093, Training Loss Force: 6.42218342640299, time: 1.1403977870941162
Validation Loss Energy: 7.723309609509167, Validation Loss Force: 7.11112643995563, time: 0.08243751525878906
Test Loss Energy: 9.175923287738723, Test Loss Force: 10.593338588523832, time: 10.109532117843628


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.430912904144956, Training Loss Force: 6.809306431631574, time: 1.1721398830413818
Validation Loss Energy: 16.040710297796096, Validation Loss Force: 4.869753958548441, time: 0.08666396141052246
Test Loss Energy: 20.982465396056963, Test Loss Force: 10.042719060213868, time: 10.114960432052612


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.684198923168784, Training Loss Force: 5.193892517572674, time: 1.1806650161743164
Validation Loss Energy: 11.114445359371786, Validation Loss Force: 5.447472620364421, time: 0.08298921585083008
Test Loss Energy: 17.63988704622485, Test Loss Force: 10.264262908558173, time: 10.264529943466187


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.153463046290574, Training Loss Force: 5.057266037858695, time: 1.2127761840820312
Validation Loss Energy: 5.503404660460877, Validation Loss Force: 5.712372528501435, time: 0.08902812004089355
Test Loss Energy: 12.497679498324628, Test Loss Force: 10.5029961854323, time: 10.126387596130371

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–†â–ƒâ–ˆâ–â–ƒâ–‡â–‚â–â–†â–â–…â–„â–‚
wandb:   test_error_force â–â–â–â–â–â–â–ƒâ–ˆâ–„â–…â–ƒâ–ƒâ–…â–„â–‚â–…â–„â–ƒâ–„â–„
wandb:          test_loss â–â–â–â–â–â–‚â–‚â–ˆâ–ƒâ–ˆâ–‚â–ƒâ–‡â–ƒâ–â–†â–ƒâ–…â–„â–ƒ
wandb: train_error_energy â–‚â–â–â–â–â–‚â–ˆâ–…â–†â–†â–†â–†â–†â–ˆâ–…â–†â–‡â–†â–†â–†
wandb:  train_error_force â–â–â–â–â–â–â–†â–…â–ˆâ–…â–†â–„â–„â–ˆâ–…â–…â–†â–‡â–„â–„
wandb:         train_loss â–â–â–â–â–â–â–‡â–…â–‡â–…â–†â–…â–…â–ˆâ–…â–†â–‡â–†â–…â–…
wandb: valid_error_energy â–â–â–â–â–â–‚â–â–†â–‚â–ˆâ–ƒâ–ƒâ–‡â–„â–‚â–†â–ƒâ–†â–„â–‚
wandb:  valid_error_force â–â–â–â–â–â–â–…â–ˆâ–…â–†â–„â–ƒâ–†â–…â–ƒâ–…â–‡â–„â–…â–…
wandb:         valid_loss â–â–â–â–â–â–â–ƒâ–ˆâ–„â–ˆâ–„â–ƒâ–‡â–…â–ƒâ–†â–†â–…â–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2461
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 12.49768
wandb:   test_error_force 10.503
wandb:          test_loss 4.35069
wandb: train_error_energy 11.15346
wandb:  train_error_force 5.05727
wandb:         train_loss 2.43857
wandb: valid_error_energy 5.5034
wandb:  valid_error_force 5.71237
wandb:         valid_loss 2.27967
wandb: 
wandb: ğŸš€ View run al_79_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/bxdwzuce
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_112215-bxdwzuce/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.43249526619911194, Uncertainty Bias: -0.3203548192977905
6.1035156e-05 0.10198593
-1.7734818 18.464426
(48745, 22, 3)
Found uncertainty sample 0 after 1412 steps.
Found uncertainty sample 1 after 1287 steps.
Found uncertainty sample 2 after 467 steps.
Found uncertainty sample 3 after 54 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 226 steps.
Found uncertainty sample 6 after 2039 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1967 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1952 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3846 steps.
Found uncertainty sample 13 after 735 steps.
Found uncertainty sample 14 after 2670 steps.
Found uncertainty sample 15 after 166 steps.
Found uncertainty sample 16 after 2061 steps.
Found uncertainty sample 17 after 2797 steps.
Found uncertainty sample 18 after 2552 steps.
Found uncertainty sample 19 after 2176 steps.
Found uncertainty sample 20 after 1189 steps.
Found uncertainty sample 21 after 1644 steps.
Found uncertainty sample 22 after 2832 steps.
Found uncertainty sample 23 after 623 steps.
Found uncertainty sample 24 after 2434 steps.
Found uncertainty sample 25 after 3198 steps.
Found uncertainty sample 26 after 1602 steps.
Found uncertainty sample 27 after 355 steps.
Found uncertainty sample 28 after 2197 steps.
Found uncertainty sample 29 after 1953 steps.
Found uncertainty sample 30 after 1452 steps.
Found uncertainty sample 31 after 1137 steps.
Found uncertainty sample 32 after 1008 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2939 steps.
Found uncertainty sample 35 after 1290 steps.
Found uncertainty sample 36 after 1991 steps.
Found uncertainty sample 37 after 2119 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1119 steps.
Found uncertainty sample 41 after 2357 steps.
Found uncertainty sample 42 after 3015 steps.
Found uncertainty sample 43 after 2551 steps.
Found uncertainty sample 44 after 3697 steps.
Found uncertainty sample 45 after 3011 steps.
Found uncertainty sample 46 after 1360 steps.
Found uncertainty sample 47 after 1853 steps.
Found uncertainty sample 48 after 2327 steps.
Found uncertainty sample 49 after 1356 steps.
Found uncertainty sample 50 after 482 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2729 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 161 steps.
Found uncertainty sample 57 after 246 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1274 steps.
Found uncertainty sample 60 after 1013 steps.
Found uncertainty sample 61 after 1669 steps.
Found uncertainty sample 62 after 1344 steps.
Found uncertainty sample 63 after 1621 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1839 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 799 steps.
Found uncertainty sample 68 after 743 steps.
Found uncertainty sample 69 after 2145 steps.
Found uncertainty sample 70 after 162 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1679 steps.
Found uncertainty sample 73 after 38 steps.
Found uncertainty sample 74 after 3385 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 867 steps.
Found uncertainty sample 77 after 259 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1297 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1746 steps.
Found uncertainty sample 83 after 1816 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 290 steps.
Found uncertainty sample 86 after 52 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3217 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1649 steps.
Found uncertainty sample 93 after 305 steps.
Found uncertainty sample 94 after 2972 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2353 steps.
Found uncertainty sample 97 after 1750 steps.
Found uncertainty sample 98 after 183 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_123849-a02cis7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/a02cis7r
Training model 25. Added 75 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5007895400109352, Training Loss Force: 3.249068829534659, time: 1.2545561790466309
Validation Loss Energy: 2.0878602528253727, Validation Loss Force: 3.1461451354012993, time: 0.08874678611755371
Test Loss Energy: 10.522461301959957, Test Loss Force: 9.013486859258313, time: 10.546963214874268


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.661010532974015, Training Loss Force: 3.136871517918377, time: 1.2108325958251953
Validation Loss Energy: 1.378504212321662, Validation Loss Force: 3.192514203687594, time: 0.08609509468078613
Test Loss Energy: 10.389116403871043, Test Loss Force: 9.107197185643322, time: 11.146713495254517


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9452377948224495, Training Loss Force: 3.1530469008719764, time: 1.2135593891143799
Validation Loss Energy: 1.2464220520149412, Validation Loss Force: 3.1068767635094963, time: 0.08756613731384277
Test Loss Energy: 10.608785872308825, Test Loss Force: 9.052367587483198, time: 10.74756669998169


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.834535996131891, Training Loss Force: 3.084149696080165, time: 1.3224353790283203
Validation Loss Energy: 4.039297800015168, Validation Loss Force: 3.254841078985949, time: 0.08613944053649902
Test Loss Energy: 9.865732986731858, Test Loss Force: 9.153534196567447, time: 10.597051620483398


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.221908282707963, Training Loss Force: 3.113572579750368, time: 1.18341064453125
Validation Loss Energy: 2.7744663536915004, Validation Loss Force: 3.0312521981509066, time: 0.0849149227142334
Test Loss Energy: 12.037206867264455, Test Loss Force: 9.076724057320734, time: 10.766401290893555


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9943906683318233, Training Loss Force: 3.0658167421162195, time: 1.2899110317230225
Validation Loss Energy: 1.7641223609029728, Validation Loss Force: 3.026735354525761, time: 0.08444714546203613
Test Loss Energy: 10.274405159397597, Test Loss Force: 8.981979352312203, time: 10.570211172103882


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.081297516913281, Training Loss Force: 6.438631982119692, time: 1.1628057956695557
Validation Loss Energy: 4.000705896988693, Validation Loss Force: 4.354204076937206, time: 0.08663177490234375
Test Loss Energy: 13.438098998246959, Test Loss Force: 9.357707398671357, time: 10.564507722854614


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 13.494829390918804, Training Loss Force: 6.999105969920167, time: 1.176795244216919
Validation Loss Energy: 15.347281168960446, Validation Loss Force: 5.210292571534811, time: 0.08700823783874512
Test Loss Energy: 14.101418660610175, Test Loss Force: 9.44506077974929, time: 10.747713565826416


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.165256710026437, Training Loss Force: 5.916965190223836, time: 1.1620526313781738
Validation Loss Energy: 24.20566634472135, Validation Loss Force: 5.735791533255244, time: 0.08866548538208008
Test Loss Energy: 19.890688178651693, Test Loss Force: 10.190167276408149, time: 10.628971099853516


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.498050955367995, Training Loss Force: 6.09569349463185, time: 1.2605512142181396
Validation Loss Energy: 2.7324110547692655, Validation Loss Force: 5.769017109864859, time: 0.08619046211242676
Test Loss Energy: 9.351922090528355, Test Loss Force: 10.185640242463606, time: 10.746612310409546


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 9.960102048714125, Training Loss Force: 7.157164940392513, time: 1.2306926250457764
Validation Loss Energy: 37.82505898954993, Validation Loss Force: 8.1166056685785, time: 0.09337759017944336
Test Loss Energy: 39.03141514631852, Test Loss Force: 12.319045980935815, time: 10.576844453811646


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 16.20688271467335, Training Loss Force: 7.647545124778329, time: 1.2390093803405762
Validation Loss Energy: 12.388380967730429, Validation Loss Force: 4.7846017144393205, time: 0.08397293090820312
Test Loss Energy: 11.609515643826516, Test Loss Force: 9.425513016828475, time: 10.56540584564209


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 15.582488028106924, Training Loss Force: 7.070717105722899, time: 1.1948518753051758
Validation Loss Energy: 8.063055520336036, Validation Loss Force: 7.302111770440208, time: 0.08639073371887207
Test Loss Energy: 10.618827430062009, Test Loss Force: 11.16951473839367, time: 10.698310375213623


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.579887905762897, Training Loss Force: 5.960192233382478, time: 1.149599552154541
Validation Loss Energy: 1.823288447674883, Validation Loss Force: 6.727726465738765, time: 0.08644247055053711
Test Loss Energy: 9.130560784251427, Test Loss Force: 10.799454771284125, time: 10.557537317276001


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.0652924499253, Training Loss Force: 5.912017411336403, time: 1.196319818496704
Validation Loss Energy: 5.176825621571011, Validation Loss Force: 5.358880583289007, time: 0.08715033531188965
Test Loss Energy: 9.09503315958084, Test Loss Force: 10.14336056648812, time: 10.585487604141235


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 16.479385921518276, Training Loss Force: 7.484262922410648, time: 1.39540696144104
Validation Loss Energy: 4.627231186231439, Validation Loss Force: 8.92382630173421, time: 0.08502674102783203
Test Loss Energy: 9.851674132507252, Test Loss Force: 12.898034169319873, time: 10.542569875717163


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 13.708041641517092, Training Loss Force: 6.602642991876383, time: 1.2243268489837646
Validation Loss Energy: 7.619953272043865, Validation Loss Force: 6.213312864779201, time: 0.08934450149536133
Test Loss Energy: 14.243103518476534, Test Loss Force: 10.522003177096412, time: 10.550964832305908


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.342452221972605, Training Loss Force: 6.659792933550174, time: 1.1647067070007324
Validation Loss Energy: 2.1983202927186354, Validation Loss Force: 5.789625139320476, time: 0.09016680717468262
Test Loss Energy: 8.907911042016126, Test Loss Force: 10.337670966364941, time: 10.732831478118896


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 13.50442836748428, Training Loss Force: 6.778763880045935, time: 1.271594762802124
Validation Loss Energy: 9.300270759839727, Validation Loss Force: 4.759556334243654, time: 0.08933520317077637
Test Loss Energy: 15.160878060560199, Test Loss Force: 9.636601212756595, time: 10.581407070159912


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 12.577462026041838, Training Loss Force: 5.0964192687174865, time: 1.1981971263885498
Validation Loss Energy: 17.585958463025328, Validation Loss Force: 6.359367792329323, time: 0.08972477912902832
Test Loss Energy: 14.600778646342482, Test Loss Force: 10.361325694971988, time: 10.62820839881897

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–‚â–â–‚â–‚â–„â–â–ˆâ–‚â–â–â–â–â–‚â–â–‚â–‚
wandb:   test_error_force â–â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–‡â–‚â–…â–„â–ƒâ–ˆâ–„â–ƒâ–‚â–ƒ
wandb:          test_loss â–â–â–â–â–â–â–‚â–‚â–ƒâ–‚â–ˆâ–‚â–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–ƒ
wandb: train_error_energy â–‚â–â–â–â–‚â–‚â–‡â–‡â–†â–…â–…â–ˆâ–ˆâ–„â–…â–ˆâ–‡â–…â–‡â–†
wandb:  train_error_force â–â–â–â–â–â–â–†â–‡â–…â–†â–‡â–ˆâ–‡â–…â–…â–ˆâ–†â–†â–‡â–„
wandb:         train_loss â–â–â–â–â–â–â–†â–‡â–†â–…â–†â–ˆâ–‡â–…â–…â–ˆâ–‡â–†â–‡â–…
wandb: valid_error_energy â–â–â–â–‚â–â–â–‚â–„â–…â–â–ˆâ–ƒâ–‚â–â–‚â–‚â–‚â–â–ƒâ–„
wandb:  valid_error_force â–â–â–â–â–â–â–ƒâ–„â–„â–„â–‡â–ƒâ–†â–…â–„â–ˆâ–…â–„â–ƒâ–…
wandb:         valid_loss â–â–â–â–â–â–â–‚â–„â–…â–ƒâ–ˆâ–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2528
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 14.60078
wandb:   test_error_force 10.36133
wandb:          test_loss 4.44403
wandb: train_error_energy 12.57746
wandb:  train_error_force 5.09642
wandb:         train_loss 2.54697
wandb: valid_error_energy 17.58596
wandb:  valid_error_force 6.35937
wandb:         valid_loss 3.30473
wandb: 
wandb: ğŸš€ View run al_79_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/a02cis7r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_123849-a02cis7r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.5318414568901062, Uncertainty Bias: -0.2688511908054352
0.00035190582 0.00065732
-3.5202508 12.754841
(48745, 22, 3)
Found uncertainty sample 0 after 30 steps.
Found uncertainty sample 1 after 1688 steps.
Found uncertainty sample 2 after 1865 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1715 steps.
Found uncertainty sample 5 after 401 steps.
Found uncertainty sample 6 after 1388 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2010 steps.
Found uncertainty sample 9 after 1932 steps.
Found uncertainty sample 10 after 634 steps.
Found uncertainty sample 11 after 2932 steps.
Found uncertainty sample 12 after 746 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1979 steps.
Found uncertainty sample 15 after 3314 steps.
Found uncertainty sample 16 after 735 steps.
Found uncertainty sample 17 after 2391 steps.
Found uncertainty sample 18 after 1177 steps.
Found uncertainty sample 19 after 71 steps.
Found uncertainty sample 20 after 2260 steps.
Found uncertainty sample 21 after 1707 steps.
Found uncertainty sample 22 after 3249 steps.
Found uncertainty sample 23 after 33 steps.
Found uncertainty sample 24 after 1326 steps.
Found uncertainty sample 25 after 1843 steps.
Found uncertainty sample 26 after 1201 steps.
Found uncertainty sample 27 after 397 steps.
Found uncertainty sample 28 after 3463 steps.
Found uncertainty sample 29 after 1458 steps.
Found uncertainty sample 30 after 134 steps.
Found uncertainty sample 31 after 1360 steps.
Found uncertainty sample 32 after 1125 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2493 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2963 steps.
Found uncertainty sample 37 after 2124 steps.
Found uncertainty sample 38 after 1740 steps.
Found uncertainty sample 39 after 7 steps.
Found uncertainty sample 40 after 1879 steps.
Found uncertainty sample 41 after 354 steps.
Found uncertainty sample 42 after 3421 steps.
Found uncertainty sample 43 after 701 steps.
Found uncertainty sample 44 after 2283 steps.
Found uncertainty sample 45 after 3291 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1545 steps.
Found uncertainty sample 48 after 1795 steps.
Found uncertainty sample 49 after 3335 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2507 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 350 steps.
Found uncertainty sample 54 after 231 steps.
Found uncertainty sample 55 after 820 steps.
Found uncertainty sample 56 after 987 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 861 steps.
Found uncertainty sample 59 after 1966 steps.
Found uncertainty sample 60 after 923 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1007 steps.
Found uncertainty sample 63 after 1132 steps.
Found uncertainty sample 64 after 758 steps.
Found uncertainty sample 65 after 1286 steps.
Found uncertainty sample 66 after 1704 steps.
Found uncertainty sample 67 after 420 steps.
Found uncertainty sample 68 after 37 steps.
Found uncertainty sample 69 after 265 steps.
Found uncertainty sample 70 after 388 steps.
Found uncertainty sample 71 after 354 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3519 steps.
Found uncertainty sample 74 after 1963 steps.
Found uncertainty sample 75 after 1490 steps.
Found uncertainty sample 76 after 187 steps.
Found uncertainty sample 77 after 109 steps.
Found uncertainty sample 78 after 1841 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 916 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 240 steps.
Found uncertainty sample 83 after 1620 steps.
Found uncertainty sample 84 after 2023 steps.
Found uncertainty sample 85 after 327 steps.
Found uncertainty sample 86 after 172 steps.
Found uncertainty sample 87 after 739 steps.
Found uncertainty sample 88 after 2804 steps.
Found uncertainty sample 89 after 486 steps.
Found uncertainty sample 90 after 273 steps.
Found uncertainty sample 91 after 1997 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1787 steps.
Found uncertainty sample 95 after 1199 steps.
Found uncertainty sample 96 after 20 steps.
Found uncertainty sample 97 after 3109 steps.
Found uncertainty sample 98 after 689 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_134418-1eg4txkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_79_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/1eg4txkj
Training model 26. Added 84 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3690957487069264, Training Loss Force: 3.3936601282461822, time: 1.175537347793579
Validation Loss Energy: 1.7048171059148576, Validation Loss Force: 3.1394697370755305, time: 0.07278895378112793
Test Loss Energy: 10.625039409594434, Test Loss Force: 8.969717267887406, time: 7.968280076980591


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7087079532529104, Training Loss Force: 3.1761761972552933, time: 1.283313274383545
Validation Loss Energy: 1.3698795682924412, Validation Loss Force: 3.123181600385485, time: 0.0756533145904541
Test Loss Energy: 10.000015869854439, Test Loss Force: 8.982562983299172, time: 7.976060152053833


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.068946153779236, Training Loss Force: 3.139609407655052, time: 1.1528494358062744
Validation Loss Energy: 1.5457103707088917, Validation Loss Force: 3.088140824898267, time: 0.07413244247436523
Test Loss Energy: 9.749780899206911, Test Loss Force: 8.99481073762375, time: 8.165994882583618


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.124426503403352, Training Loss Force: 3.118894855452405, time: 1.238053798675537
Validation Loss Energy: 1.5026721545092447, Validation Loss Force: 3.1072116579049713, time: 0.07650446891784668
Test Loss Energy: 10.18847546654837, Test Loss Force: 8.982731269877982, time: 8.617700576782227


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.056236021744778, Training Loss Force: 3.1710298761010423, time: 1.285564661026001
Validation Loss Energy: 1.4111708893749983, Validation Loss Force: 3.085016888115473, time: 0.07961773872375488
Test Loss Energy: 10.252766451590023, Test Loss Force: 9.00509618221111, time: 7.995474100112915


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.172026302075873, Training Loss Force: 3.097720543057488, time: 1.2837491035461426
Validation Loss Energy: 2.528837346788807, Validation Loss Force: 3.249565044907763, time: 0.07260417938232422
Test Loss Energy: 10.105549885919158, Test Loss Force: 9.097856660309944, time: 8.013520002365112


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 12.922771464175298, Training Loss Force: 5.91396712867359, time: 1.4439444541931152
Validation Loss Energy: 16.876157807904484, Validation Loss Force: 6.009213212276061, time: 0.07410788536071777
Test Loss Energy: 13.319526624150843, Test Loss Force: 10.535355277120228, time: 8.032143831253052


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 19.312087648364972, Training Loss Force: 7.97152390295327, time: 1.2325007915496826
Validation Loss Energy: 22.487803276215732, Validation Loss Force: 9.317795712300828, time: 0.07879757881164551
Test Loss Energy: 17.666075306705874, Test Loss Force: 12.064141444774211, time: 8.005831241607666


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 13.556695341755363, Training Loss Force: 7.33311641240261, time: 1.1923420429229736
Validation Loss Energy: 3.715903820588653, Validation Loss Force: 5.124411753980214, time: 0.0755167007446289
Test Loss Energy: 11.18468990416104, Test Loss Force: 9.944301559379456, time: 8.000373840332031


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.199640345095016, Training Loss Force: 5.344957266246605, time: 1.2714629173278809
Validation Loss Energy: 7.35493646260524, Validation Loss Force: 4.12831201779126, time: 0.07535457611083984
Test Loss Energy: 9.280703381049543, Test Loss Force: 9.283760961843948, time: 8.198412656784058


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.152441787582128, Training Loss Force: 3.9692485903764387, time: 1.1958599090576172
Validation Loss Energy: 5.646511448518915, Validation Loss Force: 3.973128323265536, time: 0.07647275924682617
Test Loss Energy: 12.649587859118336, Test Loss Force: 9.466555622304067, time: 7.999767303466797


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.279190835833677, Training Loss Force: 3.9221424980790327, time: 1.198561429977417
Validation Loss Energy: 7.38305245032325, Validation Loss Force: 3.7871355690363795, time: 0.07444548606872559
Test Loss Energy: 9.584402976334585, Test Loss Force: 9.218044768361196, time: 8.013383388519287


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.513195780140046, Training Loss Force: 3.857009038409424, time: 1.2104904651641846
Validation Loss Energy: 10.676374097762709, Validation Loss Force: 3.774310160234658, time: 0.08030152320861816
Test Loss Energy: 17.348799249499255, Test Loss Force: 9.469330853958205, time: 8.179115056991577


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.514601525759494, Training Loss Force: 3.8578921958362438, time: 1.2179017066955566
Validation Loss Energy: 8.348521373460086, Validation Loss Force: 3.88238864227765, time: 0.07442831993103027
Test Loss Energy: 9.969356109813349, Test Loss Force: 9.199349886559634, time: 7.998306035995483


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.713281424828138, Training Loss Force: 3.872998407415181, time: 1.2049775123596191
Validation Loss Energy: 9.77176332423769, Validation Loss Force: 4.562762011080113, time: 0.07410597801208496
Test Loss Energy: 17.48895094985521, Test Loss Force: 9.785636110994407, time: 8.616055011749268


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.6521911806483764, Training Loss Force: 3.9105095232859153, time: 1.3153233528137207
Validation Loss Energy: 6.6559668800806175, Validation Loss Force: 3.847991603291309, time: 0.07654500007629395
Test Loss Energy: 9.56878815675052, Test Loss Force: 9.486318201494543, time: 8.20048189163208


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.5609621421224125, Training Loss Force: 3.800169054008539, time: 1.2542297840118408
Validation Loss Energy: 7.849950459564138, Validation Loss Force: 3.66809797963826, time: 0.07671236991882324
Test Loss Energy: 16.645137776255613, Test Loss Force: 9.358394273530385, time: 7.968412399291992


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.822342073319043, Training Loss Force: 3.770988042481034, time: 1.2340569496154785
Validation Loss Energy: 5.2652234911511755, Validation Loss Force: 4.0716549669556645, time: 0.0769491195678711
Test Loss Energy: 9.963172268199806, Test Loss Force: 9.381877609848647, time: 8.010899543762207


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 13.020195325342828, Training Loss Force: 4.913260365139913, time: 1.1789679527282715
Validation Loss Energy: 33.50881532594134, Validation Loss Force: 7.113560436389767, time: 0.07480669021606445
Test Loss Energy: 41.187324155104164, Test Loss Force: 12.466240303008227, time: 8.01079273223877


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 17.20969875785495, Training Loss Force: 6.9877419903859845, time: 1.3929471969604492
Validation Loss Energy: 5.343931690177145, Validation Loss Force: 5.079016195199916, time: 0.07642769813537598
Test Loss Energy: 12.864455951234106, Test Loss Force: 9.648990472740508, time: 7.988264083862305

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–â–‚â–ƒâ–â–â–‚â–â–ƒâ–â–ƒâ–â–ƒâ–â–ˆâ–‚
wandb:   test_error_force â–â–â–â–â–â–â–„â–‡â–ƒâ–‚â–‚â–â–‚â–â–ƒâ–‚â–‚â–‚â–ˆâ–‚
wandb:          test_loss â–â–â–â–â–â–â–ƒâ–„â–‚â–â–‚â–â–‚â–â–ƒâ–â–‚â–â–ˆâ–‚
wandb: train_error_energy â–‚â–â–â–â–â–â–…â–ˆâ–†â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–‡
wandb:  train_error_force â–â–â–â–â–â–â–…â–ˆâ–‡â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‡
wandb:         train_loss â–â–â–â–â–â–â–…â–ˆâ–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–‡
wandb: valid_error_energy â–â–â–â–â–â–â–„â–†â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ˆâ–‚
wandb:  valid_error_force â–â–â–â–â–â–â–„â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–†â–ƒ
wandb:         valid_loss â–â–â–â–â–â–â–…â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2603
wandb:                 lr 0.001
wandb:    max_uncertainty 8
wandb:  test_error_energy 12.86446
wandb:   test_error_force 9.64899
wandb:          test_loss 4.08948
wandb: train_error_energy 17.2097
wandb:  train_error_force 6.98774
wandb:         train_loss 3.4898
wandb: valid_error_energy 5.34393
wandb:  valid_error_force 5.07902
wandb:         valid_loss 2.05707
wandb: 
wandb: ğŸš€ View run al_79_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/1eg4txkj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_134418-1eg4txkj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.2872513234615326, Uncertainty Bias: -0.07323348522186279
0.00016975403 0.0052337646
-0.67663336 10.534443
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1136 steps.
Found uncertainty sample 2 after 2673 steps.
Found uncertainty sample 3 after 142 steps.
Found uncertainty sample 4 after 2341 steps.
Found uncertainty sample 5 after 3799 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3033 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 396 steps.
Found uncertainty sample 10 after 3725 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3051 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2847 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2044 steps.
Found uncertainty sample 25 after 3995 steps.
Found uncertainty sample 26 after 2195 steps.
Found uncertainty sample 27 after 2972 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1524 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1717 steps.
Found uncertainty sample 36 after 3648 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2900 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3961 steps.
Found uncertainty sample 46 after 2061 steps.
Found uncertainty sample 47 after 1804 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3594 steps.
Found uncertainty sample 52 after 2096 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1413 steps.
Found uncertainty sample 56 after 2683 steps.
Found uncertainty sample 57 after 870 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1262 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 614 steps.
Found uncertainty sample 63 after 971 steps.
Found uncertainty sample 64 after 3879 steps.
Found uncertainty sample 65 after 3659 steps.
slurmstepd: error: *** JOB 5124882 ON aimat01 CANCELLED AT 2024-12-08T15:02:07 ***
