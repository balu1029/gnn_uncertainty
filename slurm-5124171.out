wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_100557-sj72vvvh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/sj72vvvh
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
71
Uncertainty Slope: 0.04418594762682915, Uncertainty Bias: 0.25516363978385925
0.0013618469 0.0016099215
3.8687825 7.085009
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 11.451025565463892, Test Loss Force: 12.623542293419828, time: 6.5448455810546875

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.45103
wandb:   test_error_force 12.62354
wandb:          test_loss 10.20482
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_72 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/sj72vvvh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_100557-sj72vvvh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 931 steps.
Found uncertainty sample 1 after 1324 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 701 steps.
Found uncertainty sample 5 after 1851 steps.
Found uncertainty sample 6 after 3684 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 724 steps.
Found uncertainty sample 9 after 1626 steps.
Found uncertainty sample 10 after 3580 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1459 steps.
Found uncertainty sample 13 after 1258 steps.
Found uncertainty sample 14 after 829 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2579 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1848 steps.
Found uncertainty sample 19 after 3056 steps.
Found uncertainty sample 20 after 319 steps.
Found uncertainty sample 21 after 1579 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3342 steps.
Found uncertainty sample 24 after 1375 steps.
Found uncertainty sample 25 after 583 steps.
Found uncertainty sample 26 after 1038 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2513 steps.
Found uncertainty sample 31 after 1973 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1257 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2447 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 268 steps.
Found uncertainty sample 39 after 1705 steps.
Found uncertainty sample 40 after 3327 steps.
Found uncertainty sample 41 after 3163 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2417 steps.
Found uncertainty sample 44 after 1725 steps.
Found uncertainty sample 45 after 1654 steps.
Found uncertainty sample 46 after 1959 steps.
Found uncertainty sample 47 after 342 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2104 steps.
Found uncertainty sample 50 after 3153 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1995 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1201 steps.
Found uncertainty sample 57 after 1900 steps.
Found uncertainty sample 58 after 1439 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3145 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 971 steps.
Found uncertainty sample 64 after 1925 steps.
Found uncertainty sample 65 after 1992 steps.
Found uncertainty sample 66 after 2557 steps.
Found uncertainty sample 67 after 361 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2293 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2619 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2623 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1769 steps.
Found uncertainty sample 79 after 1666 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1588 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3210 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2273 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2321 steps.
Found uncertainty sample 94 after 1990 steps.
Found uncertainty sample 95 after 2538 steps.
Found uncertainty sample 96 after 1460 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1056 steps.
Found uncertainty sample 99 after 860 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_103402-h9sojrrm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/h9sojrrm
Training model 0. Added 59 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.048210257690049, Training Loss Force: 4.068071206016022, time: 0.4618716239929199
Validation Loss Energy: 4.043862294837542, Validation Loss Force: 4.580736755215987, time: 0.0417790412902832
Test Loss Energy: 12.517264800232349, Test Loss Force: 12.04507474979962, time: 8.601829767227173


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.518098943072858, Training Loss Force: 4.108648699298767, time: 0.4557013511657715
Validation Loss Energy: 5.751938609041344, Validation Loss Force: 4.218546239817891, time: 0.04357719421386719
Test Loss Energy: 10.358443153110809, Test Loss Force: 12.014863018733047, time: 8.944753885269165


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.36889817881709, Training Loss Force: 3.786399280517348, time: 0.4505739212036133
Validation Loss Energy: 5.269709383765036, Validation Loss Force: 4.217628842936668, time: 0.03850054740905762
Test Loss Energy: 13.038198562982952, Test Loss Force: 12.007503423407037, time: 9.02732515335083


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.496787691466379, Training Loss Force: 3.7339723991520226, time: 0.41614532470703125
Validation Loss Energy: 4.083304571332314, Validation Loss Force: 4.153305516075925, time: 0.041101932525634766
Test Loss Energy: 10.098356721207143, Test Loss Force: 12.10590088634993, time: 8.719699144363403


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.486517481213725, Training Loss Force: 3.751126492027078, time: 0.43372583389282227
Validation Loss Energy: 2.630238315149143, Validation Loss Force: 4.103839565308067, time: 0.040289878845214844
Test Loss Energy: 9.954878521013697, Test Loss Force: 11.889420539047252, time: 8.795149087905884


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.354771949235365, Training Loss Force: 3.708971561032548, time: 0.42008066177368164
Validation Loss Energy: 4.685698537223428, Validation Loss Force: 4.172072962371303, time: 0.042974233627319336
Test Loss Energy: 12.048585162693577, Test Loss Force: 12.031615027132478, time: 8.899669885635376


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.310418494428517, Training Loss Force: 3.71082911652991, time: 0.4479515552520752
Validation Loss Energy: 6.163137267443271, Validation Loss Force: 4.156641990558507, time: 0.04593467712402344
Test Loss Energy: 10.406184345980135, Test Loss Force: 11.918231902689275, time: 9.1458740234375


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.322658324611476, Training Loss Force: 3.7101189091654705, time: 0.452239990234375
Validation Loss Energy: 3.495847251750036, Validation Loss Force: 4.139500474366693, time: 0.04077434539794922
Test Loss Energy: 11.425519866355817, Test Loss Force: 11.741659368946113, time: 8.98332953453064


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.516998223508494, Training Loss Force: 3.69994585688349, time: 0.453646183013916
Validation Loss Energy: 1.9269496192009594, Validation Loss Force: 4.1474034476939625, time: 0.03932476043701172
Test Loss Energy: 10.4188308389573, Test Loss Force: 11.887070369968812, time: 8.752676010131836


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.3511547095772825, Training Loss Force: 3.704578917308798, time: 0.46633243560791016
Validation Loss Energy: 5.632813287999729, Validation Loss Force: 4.141752550108607, time: 0.040778160095214844
Test Loss Energy: 10.10546937994774, Test Loss Force: 11.900999008209524, time: 9.189737319946289


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.389764244701313, Training Loss Force: 3.7259389169642243, time: 0.4680287837982178
Validation Loss Energy: 5.530972882079904, Validation Loss Force: 4.1403996123779505, time: 0.04761910438537598
Test Loss Energy: 12.286435084252242, Test Loss Force: 11.914126559806453, time: 9.224865913391113


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.234926961514112, Training Loss Force: 3.745603637447636, time: 0.45075368881225586
Validation Loss Energy: 3.8024479695289686, Validation Loss Force: 4.128280621441684, time: 0.04467201232910156
Test Loss Energy: 9.702442931015684, Test Loss Force: 11.778249025183372, time: 8.907050371170044


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.48768666741696, Training Loss Force: 3.708886047833507, time: 0.4136793613433838
Validation Loss Energy: 2.3161726142529813, Validation Loss Force: 4.094995592170107, time: 0.04601430892944336
Test Loss Energy: 9.733411144948429, Test Loss Force: 11.699049237968387, time: 9.063098669052124


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.376770737188426, Training Loss Force: 3.7203690791949917, time: 0.4367644786834717
Validation Loss Energy: 4.781567401987762, Validation Loss Force: 4.1143825040294555, time: 0.046783447265625
Test Loss Energy: 11.875776642182863, Test Loss Force: 11.864675841473467, time: 8.222513437271118


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.3727963733317985, Training Loss Force: 3.728284868368659, time: 0.43950557708740234
Validation Loss Energy: 5.6119839254130595, Validation Loss Force: 4.249283488721763, time: 0.03297781944274902
Test Loss Energy: 9.918393535596325, Test Loss Force: 12.019567502499791, time: 9.069381713867188


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.351690612358989, Training Loss Force: 3.734895272044834, time: 0.44946789741516113
Validation Loss Energy: 3.4049038284936253, Validation Loss Force: 4.076404945176596, time: 0.041382789611816406
Test Loss Energy: 11.062606067944627, Test Loss Force: 11.804273680966688, time: 8.744274854660034


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.280553502421786, Training Loss Force: 3.6851426223810866, time: 0.4288954734802246
Validation Loss Energy: 1.9053404692652514, Validation Loss Force: 4.066640903127662, time: 0.03504467010498047
Test Loss Energy: 10.227600734459381, Test Loss Force: 11.707934021347825, time: 7.192168951034546


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.258893761231422, Training Loss Force: 3.681826559236881, time: 0.43022632598876953
Validation Loss Energy: 5.144702034564593, Validation Loss Force: 4.127783178569682, time: 0.03481698036193848
Test Loss Energy: 9.878818182227167, Test Loss Force: 11.667323687798708, time: 7.165364503860474


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.292364393483136, Training Loss Force: 3.680036513725762, time: 0.4511752128601074
Validation Loss Energy: 5.687544473392195, Validation Loss Force: 4.131362807759617, time: 0.04251980781555176
Test Loss Energy: 12.354728075040097, Test Loss Force: 11.696159430797692, time: 7.124405145645142


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.283633960992086, Training Loss Force: 3.6719972256461575, time: 0.44304370880126953
Validation Loss Energy: 3.627877808482188, Validation Loss Force: 4.080722945254427, time: 0.03427767753601074
Test Loss Energy: 9.726990392690073, Test Loss Force: 11.656225381916395, time: 7.300579786300659

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–‚â–ˆâ–‚â–‚â–†â–‚â–…â–ƒâ–‚â–†â–â–â–†â–â–„â–‚â–â–‡â–
wandb:   test_error_force â–‡â–‡â–†â–ˆâ–…â–‡â–…â–‚â–…â–…â–…â–ƒâ–‚â–„â–‡â–ƒâ–‚â–â–‚â–
wandb:          test_loss â–ˆâ–„â–ˆâ–ƒâ–ƒâ–†â–ƒâ–†â–ƒâ–‚â–…â–â–‚â–…â–â–ƒâ–‚â–‚â–†â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–
wandb:  train_error_force â–‡â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‡â–‡â–…â–‚â–†â–ˆâ–„â–â–‡â–‡â–„â–‚â–†â–‡â–ƒâ–â–†â–‡â–„
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–â–â–‚â–‚â–
wandb:         valid_loss â–…â–ˆâ–†â–„â–‚â–…â–‡â–ƒâ–â–†â–†â–ƒâ–â–„â–†â–‚â–â–…â–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 853
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.72699
wandb:   test_error_force 11.65623
wandb:          test_loss 8.78587
wandb: train_error_energy 4.28363
wandb:  train_error_force 3.672
wandb:         train_loss 1.50037
wandb: valid_error_energy 3.62788
wandb:  valid_error_force 4.08072
wandb:         valid_loss 1.46754
wandb: 
wandb: ğŸš€ View run al_72_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/h9sojrrm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_103402-h9sojrrm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.057774543762207, Uncertainty Bias: -0.06838321685791016
6.484985e-05 0.034160614
3.0800931 16.888077
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 531 steps.
Found uncertainty sample 2 after 2278 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 825 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 271 steps.
Found uncertainty sample 7 after 471 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1094 steps.
Found uncertainty sample 10 after 1108 steps.
Found uncertainty sample 11 after 487 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2207 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2862 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2208 steps.
Found uncertainty sample 26 after 1517 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1899 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1876 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1587 steps.
Found uncertainty sample 37 after 2695 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2994 steps.
Found uncertainty sample 40 after 3621 steps.
Found uncertainty sample 41 after 2121 steps.
Found uncertainty sample 42 after 2189 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2580 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1017 steps.
Found uncertainty sample 49 after 1138 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 678 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1115 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1208 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2350 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2339 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 463 steps.
Found uncertainty sample 71 after 1897 steps.
Found uncertainty sample 72 after 2583 steps.
Found uncertainty sample 73 after 3833 steps.
Found uncertainty sample 74 after 2004 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3014 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1616 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3620 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1506 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1634 steps.
Found uncertainty sample 93 after 3770 steps.
Found uncertainty sample 94 after 1268 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2893 steps.
Found uncertainty sample 99 after 2664 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_110850-dc23hgdn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dc23hgdn
Training model 1. Added 42 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.282772356688055, Training Loss Force: 4.537539688438129, time: 0.47671985626220703
Validation Loss Energy: 4.493196607185937, Validation Loss Force: 5.392606274800376, time: 0.04161429405212402
Test Loss Energy: 10.12834787691724, Test Loss Force: 11.849171531070976, time: 9.267262697219849


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.89654717423572, Training Loss Force: 4.3586075899195444, time: 0.44661974906921387
Validation Loss Energy: 2.7786165725678758, Validation Loss Force: 4.325797951322053, time: 0.040824174880981445
Test Loss Energy: 9.87342713137446, Test Loss Force: 11.076698534718002, time: 8.421444416046143


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.5925982431968153, Training Loss Force: 4.066954890480829, time: 0.4584031105041504
Validation Loss Energy: 1.7742229673659762, Validation Loss Force: 4.533930810065383, time: 0.0396726131439209
Test Loss Energy: 9.55552119794694, Test Loss Force: 10.964667788418076, time: 9.380818843841553


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.8634768656168075, Training Loss Force: 4.136570442647655, time: 0.49027442932128906
Validation Loss Energy: 4.546120609790054, Validation Loss Force: 4.381110303185391, time: 0.04242515563964844
Test Loss Energy: 10.54479413128316, Test Loss Force: 11.062688686358413, time: 9.134058713912964


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.10812205561648, Training Loss Force: 4.284874718242653, time: 0.42934465408325195
Validation Loss Energy: 1.6577503038597985, Validation Loss Force: 4.370268097131875, time: 0.03746843338012695
Test Loss Energy: 9.397148772831475, Test Loss Force: 11.029213483646531, time: 7.561871290206909


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9045219096511778, Training Loss Force: 3.9769922055251876, time: 0.4257774353027344
Validation Loss Energy: 1.9787030501049336, Validation Loss Force: 4.192236989549939, time: 0.04753899574279785
Test Loss Energy: 9.453900203908155, Test Loss Force: 10.917590196235896, time: 7.590092658996582


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9811933500231118, Training Loss Force: 3.903876763580076, time: 0.4574704170227051
Validation Loss Energy: 1.8589482433877804, Validation Loss Force: 4.203264010994575, time: 0.037558555603027344
Test Loss Energy: 9.407150679155384, Test Loss Force: 10.908247730999593, time: 8.100547313690186


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.928790039335574, Training Loss Force: 3.9080758901438606, time: 0.41736769676208496
Validation Loss Energy: 1.7266184193235012, Validation Loss Force: 4.2018683207878995, time: 0.03792858123779297
Test Loss Energy: 9.320562062836887, Test Loss Force: 10.88266404406332, time: 7.68114161491394


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.942014546795258, Training Loss Force: 3.9077846548059263, time: 0.4404184818267822
Validation Loss Energy: 1.6741554531860283, Validation Loss Force: 4.192676983782293, time: 0.03509211540222168
Test Loss Energy: 9.186949747264363, Test Loss Force: 10.889140423970721, time: 7.647723913192749


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9147186137555878, Training Loss Force: 3.954896714364895, time: 0.44547438621520996
Validation Loss Energy: 1.8889264131731844, Validation Loss Force: 4.208616086586095, time: 0.03871488571166992
Test Loss Energy: 9.369904561633335, Test Loss Force: 10.86940812312086, time: 7.637126922607422


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8989833685311164, Training Loss Force: 3.9424097547125148, time: 0.544893741607666
Validation Loss Energy: 1.8058369760319386, Validation Loss Force: 4.2133014907547075, time: 0.05713677406311035
Test Loss Energy: 9.191205040912763, Test Loss Force: 10.948031670565554, time: 7.6964874267578125


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9113014535174846, Training Loss Force: 3.896091924187192, time: 0.46915268898010254
Validation Loss Energy: 1.625478864540484, Validation Loss Force: 4.187036774315941, time: 0.037032127380371094
Test Loss Energy: 9.286841924064479, Test Loss Force: 10.898511600702973, time: 7.581979751586914


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.032501772662715, Training Loss Force: 3.8943416174606873, time: 0.4223356246948242
Validation Loss Energy: 1.766443575414697, Validation Loss Force: 4.187544014630365, time: 0.03714585304260254
Test Loss Energy: 9.198207983220579, Test Loss Force: 10.89338103311356, time: 7.5143537521362305


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9001988637314493, Training Loss Force: 3.8877582928267596, time: 0.4660012722015381
Validation Loss Energy: 1.7943883305594883, Validation Loss Force: 4.172915987757785, time: 0.04264998435974121
Test Loss Energy: 9.237951012285656, Test Loss Force: 10.904530345385787, time: 9.257116079330444


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.914796130452014, Training Loss Force: 3.8864783508136194, time: 0.4792170524597168
Validation Loss Energy: 1.6597921799279562, Validation Loss Force: 4.1812798862171245, time: 0.045029640197753906
Test Loss Energy: 9.22367770085996, Test Loss Force: 10.896571613839086, time: 9.317838430404663


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9146982633861438, Training Loss Force: 3.8826544615230705, time: 0.4780302047729492
Validation Loss Energy: 1.765194178836896, Validation Loss Force: 4.192550062369113, time: 0.04363298416137695
Test Loss Energy: 9.16468371868494, Test Loss Force: 10.886959096395243, time: 9.220053434371948


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8693887821356863, Training Loss Force: 3.9174455771828876, time: 0.44579434394836426
Validation Loss Energy: 1.6623656785820167, Validation Loss Force: 4.189702569330989, time: 0.04328155517578125
Test Loss Energy: 9.115625289759953, Test Loss Force: 10.973601251236559, time: 10.044148206710815


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9184190568621278, Training Loss Force: 3.904535482533487, time: 0.5046050548553467
Validation Loss Energy: 1.7718172499133722, Validation Loss Force: 4.187519966362605, time: 0.0473787784576416
Test Loss Energy: 9.14648135771803, Test Loss Force: 10.922019390989844, time: 9.627147912979126


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9311029196592646, Training Loss Force: 3.8851976692208154, time: 0.48725247383117676
Validation Loss Energy: 1.8321902034562112, Validation Loss Force: 4.209086809160587, time: 0.04848504066467285
Test Loss Energy: 9.212008802376687, Test Loss Force: 10.943707020724329, time: 10.477132320404053


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.935516063082164, Training Loss Force: 3.8858035837767626, time: 0.501671552658081
Validation Loss Energy: 1.6568062980156375, Validation Loss Force: 4.19443562469683, time: 0.04693460464477539
Test Loss Energy: 9.073759964925019, Test Loss Force: 10.957481791087782, time: 10.254596471786499

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–
wandb:   test_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–‚â–‚
wandb:          test_loss â–‚â–â–ƒâ–…â–†â–‡â–‡â–†â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡
wandb: train_error_energy â–ˆâ–ƒâ–‚â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–†â–ƒâ–„â–…â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–„â–â–ˆâ–â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb:  valid_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–ˆâ–„â–ƒâ–‡â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 890
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.07376
wandb:   test_error_force 10.95748
wandb:          test_loss 11.35642
wandb: train_error_energy 1.93552
wandb:  train_error_force 3.8858
wandb:         train_loss 0.925
wandb: valid_error_energy 1.65681
wandb:  valid_error_force 4.19444
wandb:         valid_loss 0.89826
wandb: 
wandb: ğŸš€ View run al_72_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dc23hgdn
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_110850-dc23hgdn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 5.599960803985596, Uncertainty Bias: -0.2632487714290619
0.00048828125 0.0061712265
2.6584246 8.674829
(48745, 22, 3)
Found uncertainty sample 0 after 3670 steps.
Found uncertainty sample 1 after 246 steps.
Found uncertainty sample 2 after 1860 steps.
Found uncertainty sample 3 after 42 steps.
Found uncertainty sample 4 after 138 steps.
Found uncertainty sample 5 after 125 steps.
Found uncertainty sample 6 after 56 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 764 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 783 steps.
Found uncertainty sample 11 after 20 steps.
Found uncertainty sample 12 after 3805 steps.
Found uncertainty sample 13 after 1690 steps.
Found uncertainty sample 14 after 75 steps.
Found uncertainty sample 15 after 101 steps.
Found uncertainty sample 16 after 83 steps.
Found uncertainty sample 17 after 632 steps.
Found uncertainty sample 18 after 651 steps.
Found uncertainty sample 19 after 45 steps.
Found uncertainty sample 20 after 950 steps.
Found uncertainty sample 21 after 64 steps.
Found uncertainty sample 22 after 652 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 71 steps.
Found uncertainty sample 25 after 949 steps.
Found uncertainty sample 26 after 350 steps.
Found uncertainty sample 27 after 907 steps.
Found uncertainty sample 28 after 1221 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 139 steps.
Found uncertainty sample 31 after 1649 steps.
Found uncertainty sample 32 after 1400 steps.
Found uncertainty sample 33 after 22 steps.
Found uncertainty sample 34 after 457 steps.
Found uncertainty sample 35 after 1560 steps.
Found uncertainty sample 36 after 1122 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 291 steps.
Found uncertainty sample 39 after 694 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1117 steps.
Found uncertainty sample 42 after 46 steps.
Found uncertainty sample 43 after 609 steps.
Found uncertainty sample 44 after 1105 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1119 steps.
Found uncertainty sample 47 after 3444 steps.
Found uncertainty sample 48 after 26 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 151 steps.
Found uncertainty sample 51 after 960 steps.
Found uncertainty sample 52 after 2755 steps.
Found uncertainty sample 53 after 935 steps.
Found uncertainty sample 54 after 51 steps.
Found uncertainty sample 55 after 1450 steps.
Found uncertainty sample 56 after 296 steps.
Found uncertainty sample 57 after 910 steps.
Found uncertainty sample 58 after 1253 steps.
Found uncertainty sample 59 after 129 steps.
Found uncertainty sample 60 after 902 steps.
Found uncertainty sample 61 after 1204 steps.
Found uncertainty sample 62 after 441 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 569 steps.
Found uncertainty sample 65 after 1825 steps.
Found uncertainty sample 66 after 1758 steps.
Found uncertainty sample 67 after 3019 steps.
Found uncertainty sample 68 after 3410 steps.
Found uncertainty sample 69 after 2006 steps.
Found uncertainty sample 70 after 127 steps.
Found uncertainty sample 71 after 540 steps.
Found uncertainty sample 72 after 930 steps.
Found uncertainty sample 73 after 2740 steps.
Found uncertainty sample 74 after 416 steps.
Found uncertainty sample 75 after 3531 steps.
Found uncertainty sample 76 after 302 steps.
Found uncertainty sample 77 after 2084 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1688 steps.
Found uncertainty sample 80 after 211 steps.
Found uncertainty sample 81 after 274 steps.
Found uncertainty sample 82 after 21 steps.
Found uncertainty sample 83 after 1335 steps.
Found uncertainty sample 84 after 26 steps.
Found uncertainty sample 85 after 965 steps.
Found uncertainty sample 86 after 1241 steps.
Found uncertainty sample 87 after 1172 steps.
Found uncertainty sample 88 after 6 steps.
Found uncertainty sample 89 after 37 steps.
Found uncertainty sample 90 after 53 steps.
Found uncertainty sample 91 after 2458 steps.
Did not find any uncertainty samples for sample 92.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 187 steps.
Found uncertainty sample 95 after 130 steps.
Found uncertainty sample 96 after 1189 steps.
Found uncertainty sample 97 after 746 steps.
Found uncertainty sample 98 after 110 steps.
Found uncertainty sample 99 after 590 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_112538-g6qgyafh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g6qgyafh
Training model 2. Added 91 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.951190188615746, Training Loss Force: 4.544189227898406, time: 0.4905407428741455
Validation Loss Energy: 2.1023884125860044, Validation Loss Force: 4.362052050985431, time: 0.04439520835876465
Test Loss Energy: 9.298582776158678, Test Loss Force: 11.24211364683512, time: 8.66460108757019


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.030725813706659, Training Loss Force: 4.209999917865031, time: 0.47003698348999023
Validation Loss Energy: 1.5717839813531655, Validation Loss Force: 4.30770608321542, time: 0.04287147521972656
Test Loss Energy: 9.117266242453123, Test Loss Force: 11.190350746080505, time: 8.666495084762573


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9327727262306253, Training Loss Force: 3.9764783805660207, time: 0.5338864326477051
Validation Loss Energy: 1.9644809490853798, Validation Loss Force: 4.2031535670981945, time: 0.0476229190826416
Test Loss Energy: 9.195434630847398, Test Loss Force: 11.064403420647958, time: 9.615891218185425


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8788442164205363, Training Loss Force: 3.943559311627212, time: 0.5215072631835938
Validation Loss Energy: 1.909448715007619, Validation Loss Force: 4.205121517009904, time: 0.0502011775970459
Test Loss Energy: 8.938811643803387, Test Loss Force: 11.075564055238221, time: 10.253367185592651


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9891325101649695, Training Loss Force: 3.930769863892558, time: 0.5059082508087158
Validation Loss Energy: 1.734762988674102, Validation Loss Force: 4.203019965610638, time: 0.047185420989990234
Test Loss Energy: 8.921476699237994, Test Loss Force: 11.069771281266892, time: 9.6848464012146


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.900225478851139, Training Loss Force: 3.9561811972381182, time: 0.5263400077819824
Validation Loss Energy: 2.0873491158008957, Validation Loss Force: 4.195646499512385, time: 0.04776310920715332
Test Loss Energy: 9.086702903981257, Test Loss Force: 11.074952249026548, time: 10.127363443374634


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.934255810485639, Training Loss Force: 3.9663257305773123, time: 0.5142254829406738
Validation Loss Energy: 2.145323254634654, Validation Loss Force: 4.184144302110339, time: 0.05167078971862793
Test Loss Energy: 9.057498262326856, Test Loss Force: 11.122191445381544, time: 9.859862327575684


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9318048265505312, Training Loss Force: 3.9846869565217613, time: 0.5274145603179932
Validation Loss Energy: 1.6863341194534027, Validation Loss Force: 4.220866897656751, time: 0.04632711410522461
Test Loss Energy: 8.918791388612982, Test Loss Force: 11.151829743941192, time: 9.93558382987976


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8980443806952083, Training Loss Force: 3.919192562342454, time: 0.468219518661499
Validation Loss Energy: 1.6706398413755474, Validation Loss Force: 4.194741126765043, time: 0.04666757583618164
Test Loss Energy: 8.76001052299869, Test Loss Force: 11.131598281819745, time: 10.239086151123047


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9131437766010908, Training Loss Force: 3.9100465636481077, time: 0.496751070022583
Validation Loss Energy: 2.079471972094554, Validation Loss Force: 4.195253265800677, time: 0.044706106185913086
Test Loss Energy: 8.994874847684864, Test Loss Force: 11.210841339129077, time: 9.918318033218384


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.887275037732541, Training Loss Force: 3.9088883177626235, time: 0.5479722023010254
Validation Loss Energy: 2.191888494438511, Validation Loss Force: 4.217036988346792, time: 0.04762697219848633
Test Loss Energy: 9.115643942672703, Test Loss Force: 11.210171937386066, time: 9.90553879737854


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9054756904912726, Training Loss Force: 3.936899938297075, time: 0.5169854164123535
Validation Loss Energy: 1.5341307401113495, Validation Loss Force: 4.1919965068723375, time: 0.047358036041259766
Test Loss Energy: 8.779709218294622, Test Loss Force: 11.192983273625668, time: 10.05435037612915


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8872448624718294, Training Loss Force: 3.937876565171114, time: 0.5228672027587891
Validation Loss Energy: 1.934709416267397, Validation Loss Force: 4.259940434045867, time: 0.047949790954589844
Test Loss Energy: 8.821116942879181, Test Loss Force: 11.265473132475963, time: 9.931058168411255


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8668689691922806, Training Loss Force: 3.9555323752612623, time: 0.5922582149505615
Validation Loss Energy: 2.0076333388896015, Validation Loss Force: 4.182078377774421, time: 0.04958844184875488
Test Loss Energy: 9.156689737796373, Test Loss Force: 11.2096490729256, time: 9.883190155029297


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9128322085943703, Training Loss Force: 3.9090738658070627, time: 0.5139455795288086
Validation Loss Energy: 2.153107322637998, Validation Loss Force: 4.1793083735990795, time: 0.04622316360473633
Test Loss Energy: 9.046050466144841, Test Loss Force: 11.276888509895624, time: 10.380740404129028


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9073812499448686, Training Loss Force: 3.916881529556999, time: 0.5306906700134277
Validation Loss Energy: 1.6441865241701803, Validation Loss Force: 4.212428627702671, time: 0.04842734336853027
Test Loss Energy: 8.746417103247815, Test Loss Force: 11.253244627957343, time: 9.982331037521362


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8581924791664366, Training Loss Force: 3.902864988073515, time: 0.501441478729248
Validation Loss Energy: 1.885948658684692, Validation Loss Force: 4.201983218067198, time: 0.044975996017456055
Test Loss Energy: 8.885417569145114, Test Loss Force: 11.280296919336218, time: 9.858301877975464


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8863156749001866, Training Loss Force: 3.905797727480152, time: 0.481046199798584
Validation Loss Energy: 1.972602806183096, Validation Loss Force: 4.178709838934826, time: 0.04758620262145996
Test Loss Energy: 9.164896949457015, Test Loss Force: 11.298058101610815, time: 10.189007997512817


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8826338872609627, Training Loss Force: 3.9075987545440487, time: 0.46327805519104004
Validation Loss Energy: 2.1873050727387335, Validation Loss Force: 4.193195357554012, time: 0.04741358757019043
Test Loss Energy: 9.112090758649815, Test Loss Force: 11.306910083843189, time: 10.105576992034912


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8909020200303641, Training Loss Force: 3.923656073115711, time: 0.4916977882385254
Validation Loss Energy: 1.7144193788292745, Validation Loss Force: 4.212269641932479, time: 0.04478812217712402
Test Loss Energy: 8.866284404515943, Test Loss Force: 11.275670950342464, time: 9.972529172897339

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–‡â–ƒâ–ƒâ–…â–…â–ƒâ–â–„â–†â–â–‚â–†â–…â–â–ƒâ–†â–†â–ƒ
wandb:   test_error_force â–†â–…â–â–â–â–â–ƒâ–„â–ƒâ–…â–…â–…â–‡â–…â–‡â–†â–‡â–ˆâ–ˆâ–‡
wandb:          test_loss â–â–„â–†â–†â–…â–†â–†â–‡â–†â–†â–‡â–ˆâ–†â–‡â–†â–†â–†â–‡â–†â–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‡â–â–†â–…â–ƒâ–‡â–ˆâ–ƒâ–‚â–‡â–ˆâ–â–…â–†â–ˆâ–‚â–…â–†â–ˆâ–ƒ
wandb:  valid_error_force â–ˆâ–†â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–„â–â–â–‚â–‚â–â–‚â–‚
wandb:         valid_loss â–ˆâ–‚â–„â–…â–ƒâ–…â–†â–ƒâ–‚â–…â–‡â–â–…â–…â–‡â–‚â–„â–„â–‡â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 971
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.86628
wandb:   test_error_force 11.27567
wandb:          test_loss 11.20292
wandb: train_error_energy 1.8909
wandb:  train_error_force 3.92366
wandb:         train_loss 0.88737
wandb: valid_error_energy 1.71442
wandb:  valid_error_force 4.21227
wandb:         valid_loss 0.88137
wandb: 
wandb: ğŸš€ View run al_72_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g6qgyafh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_112538-g6qgyafh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 4.562163352966309, Uncertainty Bias: -0.11697909235954285
0.0003709793 0.0011081696
2.8285322 8.763061
(48745, 22, 3)
Found uncertainty sample 0 after 483 steps.
Found uncertainty sample 1 after 2247 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 402 steps.
Found uncertainty sample 4 after 1909 steps.
Found uncertainty sample 5 after 3959 steps.
Found uncertainty sample 6 after 704 steps.
Found uncertainty sample 7 after 1233 steps.
Found uncertainty sample 8 after 274 steps.
Found uncertainty sample 9 after 1420 steps.
Found uncertainty sample 10 after 1087 steps.
Found uncertainty sample 11 after 65 steps.
Found uncertainty sample 12 after 1481 steps.
Found uncertainty sample 13 after 2238 steps.
Found uncertainty sample 14 after 1521 steps.
Found uncertainty sample 15 after 1450 steps.
Found uncertainty sample 16 after 234 steps.
Found uncertainty sample 17 after 3098 steps.
Found uncertainty sample 18 after 2167 steps.
Found uncertainty sample 19 after 402 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 431 steps.
Found uncertainty sample 22 after 2742 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 297 steps.
Found uncertainty sample 25 after 2627 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2774 steps.
Found uncertainty sample 28 after 886 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3223 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3 steps.
Found uncertainty sample 34 after 10 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1043 steps.
Found uncertainty sample 37 after 1516 steps.
Found uncertainty sample 38 after 56 steps.
Found uncertainty sample 39 after 1488 steps.
Found uncertainty sample 40 after 1531 steps.
Found uncertainty sample 41 after 24 steps.
Found uncertainty sample 42 after 3984 steps.
Found uncertainty sample 43 after 1072 steps.
Found uncertainty sample 44 after 2664 steps.
Found uncertainty sample 45 after 1518 steps.
Found uncertainty sample 46 after 10 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 21 steps.
Found uncertainty sample 49 after 456 steps.
Found uncertainty sample 50 after 1151 steps.
Found uncertainty sample 51 after 3443 steps.
Found uncertainty sample 52 after 1146 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 43 steps.
Found uncertainty sample 55 after 369 steps.
Found uncertainty sample 56 after 66 steps.
Found uncertainty sample 57 after 1377 steps.
Found uncertainty sample 58 after 1010 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2484 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 68 steps.
Found uncertainty sample 63 after 1401 steps.
Found uncertainty sample 64 after 3275 steps.
Did not find any uncertainty samples for sample 65.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 2496 steps.
Found uncertainty sample 68 after 1247 steps.
Found uncertainty sample 69 after 820 steps.
Found uncertainty sample 70 after 32 steps.
Found uncertainty sample 71 after 245 steps.
Found uncertainty sample 72 after 1846 steps.
Found uncertainty sample 73 after 1193 steps.
Found uncertainty sample 74 after 954 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1116 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2886 steps.
Found uncertainty sample 79 after 1949 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 17 steps.
Found uncertainty sample 82 after 128 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 646 steps.
Found uncertainty sample 86 after 727 steps.
Found uncertainty sample 87 after 604 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 961 steps.
Found uncertainty sample 90 after 30 steps.
Found uncertainty sample 91 after 312 steps.
Found uncertainty sample 92 after 1762 steps.
Found uncertainty sample 93 after 1673 steps.
Found uncertainty sample 94 after 3589 steps.
Found uncertainty sample 95 after 2459 steps.
Found uncertainty sample 96 after 398 steps.
Found uncertainty sample 97 after 1210 steps.
Found uncertainty sample 98 after 777 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_114809-ni4zy0ah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ni4zy0ah
Training model 3. Added 82 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 9.88796598790933, Training Loss Force: 6.1068473575440105, time: 0.534684419631958
Validation Loss Energy: 2.0966760583163726, Validation Loss Force: 5.295223705182026, time: 0.04966115951538086
Test Loss Energy: 8.885607591030503, Test Loss Force: 12.10947384246033, time: 9.908453464508057


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.7323955404652116, Training Loss Force: 5.175405896591675, time: 0.5648989677429199
Validation Loss Energy: 1.8515442716165356, Validation Loss Force: 5.6867896249875, time: 0.047844648361206055
Test Loss Energy: 8.658759635391421, Test Loss Force: 11.776440172959331, time: 9.502004861831665


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.239058933141301, Training Loss Force: 4.749157152072386, time: 0.5444810390472412
Validation Loss Energy: 5.794870111052806, Validation Loss Force: 5.1974171735098285, time: 0.04663896560668945
Test Loss Energy: 10.651390253526197, Test Loss Force: 11.70840548770721, time: 9.952815055847168


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.5764013734496745, Training Loss Force: 4.539630532921645, time: 0.5799424648284912
Validation Loss Energy: 8.19681822035436, Validation Loss Force: 4.452492241972045, time: 0.04977679252624512
Test Loss Energy: 11.846366137656922, Test Loss Force: 11.652700974674646, time: 10.352228879928589


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.810502631151239, Training Loss Force: 4.191185154484975, time: 0.5985805988311768
Validation Loss Energy: 3.533796086283071, Validation Loss Force: 4.625505277681353, time: 0.05098390579223633
Test Loss Energy: 10.061619156698251, Test Loss Force: 11.924360051368582, time: 10.289299726486206


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9340874596852227, Training Loss Force: 4.261067868659649, time: 0.5633366107940674
Validation Loss Energy: 2.9065624864871284, Validation Loss Force: 4.382991857468481, time: 0.051491737365722656
Test Loss Energy: 8.96678971188454, Test Loss Force: 11.289485647265659, time: 10.491801738739014


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.8312943806934197, Training Loss Force: 4.011582461566181, time: 0.5930657386779785
Validation Loss Energy: 2.9641819133714242, Validation Loss Force: 4.200952705259844, time: 0.05205965042114258
Test Loss Energy: 9.368367272502763, Test Loss Force: 11.411289256110633, time: 10.293360710144043


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.7515850848037826, Training Loss Force: 3.94930072062895, time: 0.6112170219421387
Validation Loss Energy: 1.9788353155776148, Validation Loss Force: 4.19902439045611, time: 0.05193352699279785
Test Loss Energy: 8.79790246498204, Test Loss Force: 11.323281451578623, time: 10.296283483505249


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.673752545689273, Training Loss Force: 3.960510438734045, time: 0.5474488735198975
Validation Loss Energy: 3.120287235492143, Validation Loss Force: 4.1836980731419, time: 0.04931473731994629
Test Loss Energy: 9.267688203925463, Test Loss Force: 11.299169805884134, time: 10.518398761749268


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.813864315652459, Training Loss Force: 3.95786689039094, time: 0.5492250919342041
Validation Loss Energy: 2.444458543958066, Validation Loss Force: 4.198610671182976, time: 0.05089569091796875
Test Loss Energy: 8.756155105830551, Test Loss Force: 11.282784924113413, time: 10.473182439804077


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.7873086178728146, Training Loss Force: 3.9556520746194455, time: 0.5919816493988037
Validation Loss Energy: 2.9558970624588894, Validation Loss Force: 4.1876838508540075, time: 0.04984164237976074
Test Loss Energy: 9.210084525928561, Test Loss Force: 11.308921609290689, time: 10.510911464691162


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.830038422123364, Training Loss Force: 3.9438161771382525, time: 0.6744844913482666
Validation Loss Energy: 2.4826959577042236, Validation Loss Force: 4.2283405648706704, time: 0.04968452453613281
Test Loss Energy: 8.747880020883645, Test Loss Force: 11.250400599697759, time: 10.680566787719727


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.8333228055208988, Training Loss Force: 3.9518691012664293, time: 0.5863714218139648
Validation Loss Energy: 2.7026656855759286, Validation Loss Force: 4.204366223266917, time: 0.051039695739746094
Test Loss Energy: 9.203310053822538, Test Loss Force: 11.387097976468395, time: 10.408093690872192


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.773998053487415, Training Loss Force: 3.9687614911692486, time: 0.5799994468688965
Validation Loss Energy: 2.536104265700733, Validation Loss Force: 4.19930762560973, time: 0.05223441123962402
Test Loss Energy: 8.718625002375143, Test Loss Force: 11.374357248976033, time: 10.577887773513794


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.7797875086357116, Training Loss Force: 3.941157844913368, time: 0.5964391231536865
Validation Loss Energy: 3.071301582072051, Validation Loss Force: 4.2041199511915215, time: 0.05065560340881348
Test Loss Energy: 9.3063651863844, Test Loss Force: 11.337451202032744, time: 10.390725374221802


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.8972280305748637, Training Loss Force: 3.9470853313157157, time: 0.572368860244751
Validation Loss Energy: 2.373228242859788, Validation Loss Force: 4.203991248425175, time: 0.05505108833312988
Test Loss Energy: 8.808568638834725, Test Loss Force: 11.184889014678166, time: 10.498002290725708


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9357710341073826, Training Loss Force: 3.973517940290512, time: 0.5459232330322266
Validation Loss Energy: 2.6458144672450836, Validation Loss Force: 4.200063364691009, time: 0.05477261543273926
Test Loss Energy: 9.129723734791867, Test Loss Force: 11.314146458027587, time: 10.579834699630737


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.8575085681049353, Training Loss Force: 3.9570655918528943, time: 0.5903844833374023
Validation Loss Energy: 2.5063957482510477, Validation Loss Force: 4.187833039181779, time: 0.05040740966796875
Test Loss Energy: 8.66944341759374, Test Loss Force: 11.230831796291366, time: 10.397469520568848


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.787239556699827, Training Loss Force: 3.936840883958218, time: 0.5329759120941162
Validation Loss Energy: 3.0110620073476233, Validation Loss Force: 4.18911472278574, time: 0.04875802993774414
Test Loss Energy: 9.34526883903905, Test Loss Force: 11.26833749707367, time: 9.817023754119873


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.8604628613625063, Training Loss Force: 3.9340995433747517, time: 0.5763888359069824
Validation Loss Energy: 2.460940068801349, Validation Loss Force: 4.193275518446546, time: 0.0518646240234375
Test Loss Energy: 8.729080685102312, Test Loss Force: 11.19166896607731, time: 10.927731037139893

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–…â–ˆâ–„â–‚â–ƒâ–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–ƒâ–
wandb:   test_error_force â–ˆâ–…â–…â–…â–‡â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–â–‚â–â–‚â–
wandb:          test_loss â–â–†â–ˆâ–‡â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–…â–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–â–…â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  valid_error_force â–†â–ˆâ–†â–‚â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–‚â–‚â–†â–ˆâ–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1044
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.72908
wandb:   test_error_force 11.19167
wandb:          test_loss 8.52151
wandb: train_error_energy 2.86046
wandb:  train_error_force 3.9341
wandb:         train_loss 1.25209
wandb: valid_error_energy 2.46094
wandb:  valid_error_force 4.19328
wandb:         valid_loss 1.19467
wandb: 
wandb: ğŸš€ View run al_72_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ni4zy0ah
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_114809-ni4zy0ah/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.8858492374420166, Uncertainty Bias: -0.06750091910362244
0.00012922287 0.025008202
2.6341763 7.060985
(48745, 22, 3)
Found uncertainty sample 0 after 1057 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 887 steps.
Found uncertainty sample 4 after 71 steps.
Found uncertainty sample 5 after 17 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 371 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2373 steps.
Found uncertainty sample 14 after 1491 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3034 steps.
Found uncertainty sample 17 after 740 steps.
Found uncertainty sample 18 after 96 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1689 steps.
Found uncertainty sample 22 after 2872 steps.
Found uncertainty sample 23 after 3116 steps.
Found uncertainty sample 24 after 2572 steps.
Found uncertainty sample 25 after 814 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 135 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 10 steps.
Found uncertainty sample 31 after 1237 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1229 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 15 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 199 steps.
Found uncertainty sample 43 after 1200 steps.
Found uncertainty sample 44 after 395 steps.
Found uncertainty sample 45 after 2962 steps.
Found uncertainty sample 46 after 1063 steps.
Found uncertainty sample 47 after 876 steps.
Found uncertainty sample 48 after 2943 steps.
Found uncertainty sample 49 after 1231 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1015 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 168 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 5 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 189 steps.
Found uncertainty sample 61 after 2792 steps.
Found uncertainty sample 62 after 1629 steps.
Found uncertainty sample 63 after 569 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 382 steps.
Found uncertainty sample 67 after 989 steps.
Found uncertainty sample 68 after 1328 steps.
Found uncertainty sample 69 after 176 steps.
Found uncertainty sample 70 after 1863 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 133 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2042 steps.
Found uncertainty sample 76 after 3731 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1745 steps.
Found uncertainty sample 79 after 71 steps.
Found uncertainty sample 80 after 3109 steps.
Found uncertainty sample 81 after 1372 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 285 steps.
Found uncertainty sample 90 after 676 steps.
Found uncertainty sample 91 after 943 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 439 steps.
Found uncertainty sample 94 after 3370 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 114 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_121750-2717o0ne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2717o0ne
Training model 4. Added 53 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.13833733345405, Training Loss Force: 4.479587991473292, time: 0.5622091293334961
Validation Loss Energy: 4.920872337048229, Validation Loss Force: 4.555917606872584, time: 0.047649383544921875
Test Loss Energy: 9.833039252462775, Test Loss Force: 11.044026838865332, time: 8.831666946411133


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.399782956044359, Training Loss Force: 4.228533758983653, time: 0.5233945846557617
Validation Loss Energy: 1.5551921239480753, Validation Loss Force: 4.2793647543217315, time: 0.04715085029602051
Test Loss Energy: 8.750448032666842, Test Loss Force: 11.320175293936197, time: 8.752393245697021


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.708339056840084, Training Loss Force: 4.541811045691866, time: 0.5619947910308838
Validation Loss Energy: 2.9537376170816816, Validation Loss Force: 4.386831564220859, time: 0.04754829406738281
Test Loss Energy: 8.820964898324146, Test Loss Force: 11.143507527747001, time: 8.979035377502441


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.916054932616799, Training Loss Force: 4.509847958605831, time: 0.5488893985748291
Validation Loss Energy: 3.2943882326484535, Validation Loss Force: 4.369455354749238, time: 0.045853614807128906
Test Loss Energy: 9.38051543892618, Test Loss Force: 11.500289269693669, time: 8.701572895050049


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9076317150969837, Training Loss Force: 4.050484405255703, time: 0.535759687423706
Validation Loss Energy: 1.8804567468695292, Validation Loss Force: 4.259960919607292, time: 0.045252084732055664
Test Loss Energy: 8.519869771940265, Test Loss Force: 11.203142200169086, time: 8.742175817489624


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.825044845399084, Training Loss Force: 3.994545443329796, time: 0.5762197971343994
Validation Loss Energy: 3.3265957659228866, Validation Loss Force: 4.252794981153044, time: 0.046298980712890625
Test Loss Energy: 8.869087433673304, Test Loss Force: 11.191310890774515, time: 8.71782660484314


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.784869198529235, Training Loss Force: 4.0054092991862715, time: 0.5524873733520508
Validation Loss Energy: 2.3481191792883873, Validation Loss Force: 4.288523581632033, time: 0.04911065101623535
Test Loss Energy: 8.720862675736804, Test Loss Force: 11.223597618487444, time: 9.18796157836914


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9046076613310774, Training Loss Force: 4.007072923995255, time: 0.5567662715911865
Validation Loss Energy: 2.625336253901543, Validation Loss Force: 4.233628066409872, time: 0.052674055099487305
Test Loss Energy: 9.064690125998212, Test Loss Force: 11.273451547508843, time: 10.033978700637817


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.7675836440288974, Training Loss Force: 4.018245634681084, time: 0.5952854156494141
Validation Loss Energy: 3.900333326078824, Validation Loss Force: 4.2557177363624925, time: 0.059056758880615234
Test Loss Energy: 9.465047030679756, Test Loss Force: 11.305658939720624, time: 10.028902053833008


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.807755300349553, Training Loss Force: 3.9982002901572256, time: 0.6538486480712891
Validation Loss Energy: 3.277440215944452, Validation Loss Force: 4.243115998717855, time: 0.06937575340270996
Test Loss Energy: 9.584212408851497, Test Loss Force: 11.271489130517377, time: 10.387412071228027


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.8721070127549204, Training Loss Force: 4.078794662260572, time: 0.5954587459564209
Validation Loss Energy: 2.299424109103731, Validation Loss Force: 4.267185197377773, time: 0.049063920974731445
Test Loss Energy: 8.690407465868521, Test Loss Force: 11.263752816302285, time: 9.782811880111694


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9008899200128866, Training Loss Force: 4.03626886343299, time: 0.5480813980102539
Validation Loss Energy: 3.4784946452078835, Validation Loss Force: 4.294982768217106, time: 0.04896688461303711
Test Loss Energy: 9.024525326596535, Test Loss Force: 11.235444381820223, time: 10.013838768005371


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.780405397875638, Training Loss Force: 4.012134772621973, time: 0.5973875522613525
Validation Loss Energy: 2.2673038621345016, Validation Loss Force: 4.240434616862593, time: 0.05262923240661621
Test Loss Energy: 8.68688750268324, Test Loss Force: 11.136777155789943, time: 9.910254001617432


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.899322666410262, Training Loss Force: 4.0179702565673265, time: 0.5433464050292969
Validation Loss Energy: 3.048483338673955, Validation Loss Force: 4.271025794806736, time: 0.05192089080810547
Test Loss Energy: 9.10520847270811, Test Loss Force: 11.24813327753129, time: 9.985370397567749


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.896972202715726, Training Loss Force: 4.033294945215783, time: 0.5390875339508057
Validation Loss Energy: 3.7783943577092653, Validation Loss Force: 4.306339339997716, time: 0.05149531364440918
Test Loss Energy: 9.634614808119336, Test Loss Force: 11.48010536317327, time: 10.071110725402832


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9215529232996453, Training Loss Force: 4.301566802211314, time: 0.5914459228515625
Validation Loss Energy: 2.431443309709441, Validation Loss Force: 4.345029885455836, time: 0.05067849159240723
Test Loss Energy: 9.055196996522413, Test Loss Force: 11.357605930734376, time: 9.87393569946289


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.906812028617982, Training Loss Force: 4.107905230347757, time: 0.6076915264129639
Validation Loss Energy: 2.062253857716542, Validation Loss Force: 4.266013512331901, time: 0.046935319900512695
Test Loss Energy: 8.721976277943991, Test Loss Force: 11.209445956695458, time: 9.86505913734436


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.742531170230439, Training Loss Force: 3.9919426000632914, time: 0.5726494789123535
Validation Loss Energy: 3.4567868528405294, Validation Loss Force: 4.237788862070679, time: 0.049677371978759766
Test Loss Energy: 8.979867096472635, Test Loss Force: 11.168919304776159, time: 10.089629173278809


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9418687885688897, Training Loss Force: 4.003321731409371, time: 0.5691266059875488
Validation Loss Energy: 2.7577598216762578, Validation Loss Force: 4.254222735716733, time: 0.05075335502624512
Test Loss Energy: 8.828769379608879, Test Loss Force: 11.172451942615657, time: 9.796854496002197


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.996523872009254, Training Loss Force: 3.9771878426368006, time: 0.555936336517334
Validation Loss Energy: 2.6007823045109397, Validation Loss Force: 4.215908946453522, time: 0.05283355712890625
Test Loss Energy: 9.09865485575225, Test Loss Force: 11.25538595436143, time: 9.843952178955078

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–ƒâ–†â–â–ƒâ–‚â–„â–†â–‡â–‚â–„â–‚â–„â–‡â–„â–‚â–ƒâ–ƒâ–„
wandb:   test_error_force â–â–…â–ƒâ–ˆâ–ƒâ–ƒâ–„â–…â–…â–„â–„â–„â–‚â–„â–ˆâ–†â–„â–ƒâ–ƒâ–„
wandb:          test_loss â–ˆâ–â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–
wandb: train_error_energy â–‡â–ˆâ–â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚
wandb:  train_error_force â–‡â–„â–ˆâ–ˆâ–‚â–â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–…â–ƒâ–â–â–
wandb:         train_loss â–ˆâ–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–
wandb: valid_error_energy â–ˆâ–â–„â–…â–‚â–…â–ƒâ–ƒâ–†â–…â–ƒâ–…â–‚â–„â–†â–ƒâ–‚â–…â–„â–ƒ
wandb:  valid_error_force â–ˆâ–‚â–…â–„â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–„â–‚â–â–‚â–
wandb:         valid_loss â–ˆâ–â–ƒâ–ƒâ–â–ƒâ–‚â–‚â–„â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1091
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.09865
wandb:   test_error_force 11.25539
wandb:          test_loss 8.17687
wandb: train_error_energy 2.99652
wandb:  train_error_force 3.97719
wandb:         train_loss 1.32368
wandb: valid_error_energy 2.60078
wandb:  valid_error_force 4.21591
wandb:         valid_loss 1.22015
wandb: 
wandb: ğŸš€ View run al_72_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2717o0ne
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_121750-2717o0ne/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.8561389446258545, Uncertainty Bias: -0.08973845839500427
0.00031471252 0.0017700195
2.5451226 7.0861297
(48745, 22, 3)
Found uncertainty sample 0 after 3488 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2426 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 367 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2382 steps.
Found uncertainty sample 12 after 34 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 597 steps.
Found uncertainty sample 18 after 2801 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3332 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3190 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1459 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2174 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 849 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2582 steps.
Found uncertainty sample 35 after 4 steps.
Found uncertainty sample 36 after 3217 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 961 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 107 steps.
Found uncertainty sample 43 after 273 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1185 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 764 steps.
Found uncertainty sample 48 after 3000 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 425 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 5 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1421 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 846 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 435 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1133 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 324 steps.
Found uncertainty sample 69 after 2999 steps.
Found uncertainty sample 70 after 2928 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 548 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3981 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 413 steps.
Found uncertainty sample 77 after 591 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2512 steps.
Found uncertainty sample 81 after 809 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 162 steps.
Found uncertainty sample 86 after 10 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 866 steps.
Found uncertainty sample 89 after 1683 steps.
Found uncertainty sample 90 after 3375 steps.
Found uncertainty sample 91 after 2869 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1719 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1048 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1375 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_125021-ruvlehgf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ruvlehgf
Training model 5. Added 45 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.605146773415909, Training Loss Force: 4.481334904262536, time: 0.6051921844482422
Validation Loss Energy: 6.1492934813026485, Validation Loss Force: 5.047534563341208, time: 0.052060842514038086
Test Loss Energy: 10.362065315605037, Test Loss Force: 11.57385403062043, time: 9.999328851699829


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.445971883224383, Training Loss Force: 4.356785634977299, time: 0.5794036388397217
Validation Loss Energy: 4.765703116016991, Validation Loss Force: 4.411120314658663, time: 0.051458120346069336
Test Loss Energy: 10.270035108366741, Test Loss Force: 11.448989921800209, time: 10.11834168434143


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.235508024897416, Training Loss Force: 4.099503801180592, time: 0.5914285182952881
Validation Loss Energy: 4.785456986628828, Validation Loss Force: 4.337103754537391, time: 0.04903674125671387
Test Loss Energy: 9.515405861406643, Test Loss Force: 11.186830754915853, time: 10.289207696914673


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.382616796033182, Training Loss Force: 4.097314177948859, time: 0.5908653736114502
Validation Loss Energy: 5.481253088485688, Validation Loss Force: 4.313934139227021, time: 0.053870439529418945
Test Loss Energy: 10.790576917461776, Test Loss Force: 11.4509609797535, time: 10.092652559280396


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.291344663635349, Training Loss Force: 4.114750693647502, time: 0.6413004398345947
Validation Loss Energy: 4.541004118154925, Validation Loss Force: 4.364050729239279, time: 0.05323004722595215
Test Loss Energy: 9.383907135356953, Test Loss Force: 11.074688977152794, time: 10.126918315887451


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.27433536961944, Training Loss Force: 4.111670109310369, time: 0.5908083915710449
Validation Loss Energy: 5.393279626297662, Validation Loss Force: 4.314105149131093, time: 0.051779747009277344
Test Loss Energy: 10.674995980931456, Test Loss Force: 11.283240582129244, time: 10.257972478866577


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.262451084333489, Training Loss Force: 4.097802980020949, time: 0.5931720733642578
Validation Loss Energy: 4.881988960109735, Validation Loss Force: 4.343590997434851, time: 0.05809164047241211
Test Loss Energy: 9.492213142132222, Test Loss Force: 11.116027478446535, time: 9.964262008666992


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.369883102178566, Training Loss Force: 4.0795459594458325, time: 0.5785884857177734
Validation Loss Energy: 5.337699626120918, Validation Loss Force: 4.307076820209028, time: 0.05330204963684082
Test Loss Energy: 10.588296892737208, Test Loss Force: 11.31308256116964, time: 10.293407440185547


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.238933053662282, Training Loss Force: 4.055354645315134, time: 0.6508419513702393
Validation Loss Energy: 5.006870278573584, Validation Loss Force: 4.286896315513593, time: 0.052857398986816406
Test Loss Energy: 9.617457294723227, Test Loss Force: 10.940132134037455, time: 10.302927255630493


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.281824654599842, Training Loss Force: 4.083855621801199, time: 0.5978226661682129
Validation Loss Energy: 5.361886839428179, Validation Loss Force: 4.306548648994887, time: 0.049402475357055664
Test Loss Energy: 10.898877514892346, Test Loss Force: 11.226153412612788, time: 9.980681419372559


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.362034633310016, Training Loss Force: 4.068274156572027, time: 0.6257467269897461
Validation Loss Energy: 4.858641654820914, Validation Loss Force: 4.338470943093387, time: 0.057373762130737305
Test Loss Energy: 9.611887963993706, Test Loss Force: 10.966381286952151, time: 9.798504829406738


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.356824967007825, Training Loss Force: 4.091741542383042, time: 0.6452162265777588
Validation Loss Energy: 5.428773533496843, Validation Loss Force: 4.311405063067572, time: 0.07330822944641113
Test Loss Energy: 10.706350538656263, Test Loss Force: 11.194657200005343, time: 10.168778657913208


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.284837807297285, Training Loss Force: 4.097521186031521, time: 0.5777156352996826
Validation Loss Energy: 5.110729848308681, Validation Loss Force: 4.2640068179887995, time: 0.05287623405456543
Test Loss Energy: 9.6312897398929, Test Loss Force: 10.888525768526623, time: 9.768318891525269


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.311547404319107, Training Loss Force: 4.055150296891713, time: 0.5627529621124268
Validation Loss Energy: 5.380602626481701, Validation Loss Force: 4.306490755016946, time: 0.0550541877746582
Test Loss Energy: 10.15335100127069, Test Loss Force: 11.122876277746629, time: 10.384413957595825


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.231408512733772, Training Loss Force: 4.071446128037801, time: 0.5941066741943359
Validation Loss Energy: 5.087596750738244, Validation Loss Force: 4.270321714967312, time: 0.05212211608886719
Test Loss Energy: 9.64501660957642, Test Loss Force: 10.915778336229675, time: 10.012381315231323


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.3646669815637695, Training Loss Force: 4.088987310605536, time: 0.6618647575378418
Validation Loss Energy: 5.129813930129568, Validation Loss Force: 4.272659740999554, time: 0.05307960510253906
Test Loss Energy: 10.155760267439941, Test Loss Force: 11.078715422877924, time: 9.88839316368103


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.317153180476143, Training Loss Force: 4.052175220618226, time: 0.6266686916351318
Validation Loss Energy: 5.277663570995869, Validation Loss Force: 4.285526454927845, time: 0.0538029670715332
Test Loss Energy: 9.84861218226804, Test Loss Force: 10.911608598828822, time: 10.075488805770874


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.291153004260618, Training Loss Force: 4.0647233568512355, time: 0.6688001155853271
Validation Loss Energy: 5.063551600346085, Validation Loss Force: 4.260897020696772, time: 0.05246853828430176
Test Loss Energy: 10.397765517024368, Test Loss Force: 11.108750245056761, time: 9.955514669418335


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.364978047268004, Training Loss Force: 4.058881792624423, time: 0.5781426429748535
Validation Loss Energy: 4.925769276905473, Validation Loss Force: 4.389722700411586, time: 0.0532989501953125
Test Loss Energy: 9.76562876828285, Test Loss Force: 10.872449060853864, time: 10.035510301589966


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.274957782456968, Training Loss Force: 4.047872510488413, time: 0.5931997299194336
Validation Loss Energy: 5.612052507510005, Validation Loss Force: 4.257345893157516, time: 0.052202463150024414
Test Loss Energy: 10.789808636628283, Test Loss Force: 11.140346539867553, time: 10.274164199829102

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–‚â–‡â–â–‡â–‚â–‡â–‚â–ˆâ–‚â–‡â–‚â–…â–‚â–…â–ƒâ–†â–ƒâ–‡
wandb:   test_error_force â–ˆâ–‡â–„â–‡â–ƒâ–…â–ƒâ–…â–‚â–…â–‚â–„â–â–ƒâ–â–ƒâ–â–ƒâ–â–„
wandb:          test_loss â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–â–â–‚
wandb: train_error_energy â–ˆâ–‚â–â–‚â–â–â–â–‚â–â–â–‚â–‚â–â–â–â–‚â–â–â–‚â–
wandb:  train_error_force â–ˆâ–†â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–‚â–…â–â–…â–‚â–„â–ƒâ–…â–‚â–…â–ƒâ–…â–ƒâ–„â–„â–ƒâ–ƒâ–†
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–
wandb:         valid_loss â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1131
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.78981
wandb:   test_error_force 11.14035
wandb:          test_loss 7.53462
wandb: train_error_energy 4.27496
wandb:  train_error_force 4.04787
wandb:         train_loss 1.69177
wandb: valid_error_energy 5.61205
wandb:  valid_error_force 4.25735
wandb:         valid_loss 2.1033
wandb: 
wandb: ğŸš€ View run al_72_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ruvlehgf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_125021-ruvlehgf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.897738456726074, Uncertainty Bias: -0.22318387031555176
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:925: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
0.00027370453 0.18409824
2.3096347 6.6654725
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1905 steps.
Found uncertainty sample 3 after 2532 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2441 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 135 steps.
Found uncertainty sample 8 after 407 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1840 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1558 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 861 steps.
Found uncertainty sample 22 after 1722 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1602 steps.
Found uncertainty sample 28 after 1053 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1676 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1167 steps.
Found uncertainty sample 49 after 1666 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3841 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1441 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1132 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3187 steps.
Found uncertainty sample 70 after 2957 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1429 steps.
Found uncertainty sample 74 after 970 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2773 steps.
Found uncertainty sample 77 after 2228 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1640 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2203 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 984 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1389 steps.
Found uncertainty sample 93 after 2264 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2504 steps.
Found uncertainty sample 97 after 2542 steps.
Found uncertainty sample 98 after 2249 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_132747-zaoz5av8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zaoz5av8
Training model 6. Added 31 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.309036278446564, Training Loss Force: 4.352227990574544, time: 0.7395246028900146
Validation Loss Energy: 2.6780008469506535, Validation Loss Force: 4.498781149365806, time: 0.05443286895751953
Test Loss Energy: 9.3176802810819, Test Loss Force: 10.861940853856014, time: 9.746784210205078


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.7645207129178933, Training Loss Force: 4.345635605713609, time: 0.6120834350585938
Validation Loss Energy: 2.42006224432278, Validation Loss Force: 4.390273138540319, time: 0.0501554012298584
Test Loss Energy: 8.865668340776933, Test Loss Force: 10.940140630439215, time: 9.794382810592651


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.8188586044178012, Training Loss Force: 4.094196877943664, time: 0.5670511722564697
Validation Loss Energy: 3.6173252949875243, Validation Loss Force: 4.2440757027368035, time: 0.05126237869262695
Test Loss Energy: 9.706176353471227, Test Loss Force: 10.908584140944228, time: 9.899772882461548


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.96386464895603, Training Loss Force: 4.073670850914598, time: 0.6304244995117188
Validation Loss Energy: 2.297122823480567, Validation Loss Force: 4.24841151634631, time: 0.053373098373413086
Test Loss Energy: 9.083973992172698, Test Loss Force: 10.965359060701283, time: 9.6201753616333


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.8601998394975556, Training Loss Force: 4.069873054106334, time: 0.5943489074707031
Validation Loss Energy: 1.6404732934926884, Validation Loss Force: 4.446685921322833, time: 0.05522561073303223
Test Loss Energy: 8.631903775505076, Test Loss Force: 11.092065704242744, time: 9.758212089538574


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.943578039403518, Training Loss Force: 4.44737300007206, time: 0.6142573356628418
Validation Loss Energy: 2.8073284229203885, Validation Loss Force: 4.337224441214484, time: 0.05557107925415039
Test Loss Energy: 8.546133476458511, Test Loss Force: 11.0633829990664, time: 9.955582857131958


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.8636538923163153, Training Loss Force: 4.088929260157386, time: 0.6224546432495117
Validation Loss Energy: 3.560229585934451, Validation Loss Force: 4.2717659470477995, time: 0.05654788017272949
Test Loss Energy: 8.922758476106516, Test Loss Force: 10.931776575761731, time: 9.834480285644531


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.847610032706481, Training Loss Force: 4.068808346539869, time: 0.6000442504882812
Validation Loss Energy: 1.9969144915429295, Validation Loss Force: 4.2627692228757335, time: 0.05354881286621094
Test Loss Energy: 8.682928247081444, Test Loss Force: 11.066976104985796, time: 9.844383955001831


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.789651158745388, Training Loss Force: 4.0592818623792155, time: 0.6055314540863037
Validation Loss Energy: 3.204771472163481, Validation Loss Force: 4.262359066308934, time: 0.05661749839782715
Test Loss Energy: 9.58008758766454, Test Loss Force: 11.074201161515383, time: 10.388232946395874


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.8537560562011044, Training Loss Force: 4.09209711391565, time: 0.628288745880127
Validation Loss Energy: 3.7995096274793054, Validation Loss Force: 4.255099606813396, time: 0.05819082260131836
Test Loss Energy: 9.654013212504552, Test Loss Force: 11.050709888382748, time: 9.782646417617798


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.909774925228301, Training Loss Force: 4.051919908877615, time: 0.6237561702728271
Validation Loss Energy: 2.343028739943332, Validation Loss Force: 4.236730738289229, time: 0.05420064926147461
Test Loss Energy: 8.874225247919318, Test Loss Force: 10.987156779926803, time: 9.877696752548218


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.845153116395526, Training Loss Force: 4.0316439754079365, time: 0.5794715881347656
Validation Loss Energy: 2.42510592314719, Validation Loss Force: 4.241625006116722, time: 0.05216789245605469
Test Loss Energy: 8.767800709157417, Test Loss Force: 10.948307099475189, time: 9.950424194335938


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.8957103144848113, Training Loss Force: 4.06378435888966, time: 0.6348757743835449
Validation Loss Energy: 3.2505658313841352, Validation Loss Force: 4.269720062935015, time: 0.05539703369140625
Test Loss Energy: 8.942876150796975, Test Loss Force: 10.952036110516866, time: 9.961830615997314


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9296787424466233, Training Loss Force: 4.069069585592723, time: 0.6221404075622559
Validation Loss Energy: 2.101195796640415, Validation Loss Force: 4.251880256301573, time: 0.06023716926574707
Test Loss Energy: 8.69303547474557, Test Loss Force: 11.03072114728843, time: 9.893918514251709


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.817190914822247, Training Loss Force: 4.073983550612502, time: 0.6099798679351807
Validation Loss Energy: 2.7990462440376045, Validation Loss Force: 4.231534976438151, time: 0.05480241775512695
Test Loss Energy: 9.038030940092264, Test Loss Force: 11.11640074654676, time: 9.575271606445312


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.8877700470846417, Training Loss Force: 4.049328509429647, time: 0.5622286796569824
Validation Loss Energy: 3.6296377854116013, Validation Loss Force: 4.248342488911072, time: 0.05012106895446777
Test Loss Energy: 9.660949787748809, Test Loss Force: 11.180797218473232, time: 9.90185832977295


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.8962406522095607, Training Loss Force: 4.082069876936229, time: 0.6515355110168457
Validation Loss Energy: 2.6704712897811054, Validation Loss Force: 4.229736700415637, time: 0.05745506286621094
Test Loss Energy: 9.051043323942663, Test Loss Force: 11.042755493638264, time: 9.89083218574524


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.8277213389358264, Training Loss Force: 4.065263760659034, time: 0.7112429141998291
Validation Loss Energy: 2.2830637162758327, Validation Loss Force: 4.237586678486176, time: 0.07026791572570801
Test Loss Energy: 8.706513910947427, Test Loss Force: 10.944205351941301, time: 8.49562931060791


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.8526605992292025, Training Loss Force: 4.043024511203115, time: 0.5720047950744629
Validation Loss Energy: 3.4140521903540684, Validation Loss Force: 4.229133267030173, time: 0.051105499267578125
Test Loss Energy: 9.008865525513375, Test Loss Force: 10.860706357458078, time: 8.485701322555542


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.953791051658619, Training Loss Force: 4.054471155662295, time: 0.5971627235412598
Validation Loss Energy: 2.0393347451953407, Validation Loss Force: 4.278814316192998, time: 0.04769635200500488
Test Loss Energy: 8.799590255139117, Test Loss Force: 11.021112761464764, time: 8.877944707870483

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–ƒâ–ˆâ–„â–‚â–â–ƒâ–‚â–‡â–ˆâ–ƒâ–‚â–ƒâ–‚â–„â–ˆâ–„â–‚â–„â–ƒ
wandb:   test_error_force â–â–ƒâ–‚â–ƒâ–†â–…â–ƒâ–†â–†â–…â–„â–ƒâ–ƒâ–…â–‡â–ˆâ–…â–ƒâ–â–…
wandb:          test_loss â–â–†â–†â–†â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–†â–‡â–ˆâ–‡â–†â–†â–†â–‡â–ˆâ–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–†â–†â–‚â–‚â–‚â–ˆâ–‚â–‚â–â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–„â–‡â–ƒâ–â–…â–‡â–‚â–†â–ˆâ–ƒâ–„â–†â–‚â–…â–‡â–„â–ƒâ–‡â–‚
wandb:  valid_error_force â–ˆâ–…â–â–‚â–‡â–„â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–‚
wandb:         valid_loss â–†â–ƒâ–‡â–‚â–â–…â–ˆâ–â–…â–ˆâ–‚â–ƒâ–†â–‚â–„â–‡â–ƒâ–‚â–‡â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1158
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.79959
wandb:   test_error_force 11.02111
wandb:          test_loss 8.30898
wandb: train_error_energy 2.95379
wandb:  train_error_force 4.05447
wandb:         train_loss 1.33512
wandb: valid_error_energy 2.03933
wandb:  valid_error_force 4.27881
wandb:         valid_loss 1.10527
wandb: 
wandb: ğŸš€ View run al_72_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zaoz5av8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_132747-zaoz5av8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5012896060943604, Uncertainty Bias: -0.04112550616264343
0.00019073486 0.017974377
2.8856373 6.9196095
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2192 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1855 steps.
Found uncertainty sample 6 after 2039 steps.
Found uncertainty sample 7 after 1151 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3662 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 673 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3114 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 408 steps.
Found uncertainty sample 25 after 2200 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 875 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3755 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1490 steps.
Found uncertainty sample 34 after 1020 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3205 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3231 steps.
Found uncertainty sample 42 after 2973 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2150 steps.
Found uncertainty sample 45 after 853 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 304 steps.
Found uncertainty sample 50 after 1593 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1322 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3773 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 718 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 828 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1083 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 263 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 932 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1719 steps.
Found uncertainty sample 74 after 946 steps.
Found uncertainty sample 75 after 140 steps.
Found uncertainty sample 76 after 2179 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2142 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2166 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2160 steps.
Found uncertainty sample 85 after 1052 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3947 steps.
Found uncertainty sample 88 after 2151 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1320 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1621 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_140246-r6bw6p2z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/r6bw6p2z
Training model 7. Added 39 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.387528181714038, Training Loss Force: 4.62651680501416, time: 0.6277949810028076
Validation Loss Energy: 1.962969916261114, Validation Loss Force: 4.40382122005515, time: 0.0546727180480957
Test Loss Energy: 9.029287615739882, Test Loss Force: 11.062834323637922, time: 8.966396808624268


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.0436902301848825, Training Loss Force: 4.464995278587893, time: 0.5771946907043457
Validation Loss Energy: 1.6879553735049029, Validation Loss Force: 4.5356253222658935, time: 0.049517154693603516
Test Loss Energy: 8.965746421831954, Test Loss Force: 11.183512467023201, time: 8.784729957580566


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.4404790566493317, Training Loss Force: 4.801289794214022, time: 0.597895622253418
Validation Loss Energy: 3.458090135351645, Validation Loss Force: 4.479251283914771, time: 0.04915881156921387
Test Loss Energy: 9.521862753683449, Test Loss Force: 11.052763117079925, time: 9.154734134674072


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.4683663721034987, Training Loss Force: 4.296509880097594, time: 0.602837085723877
Validation Loss Energy: 6.735367134812131, Validation Loss Force: 4.432121577825988, time: 0.050787925720214844
Test Loss Energy: 10.07427900516094, Test Loss Force: 10.733692453811377, time: 8.88372802734375


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1974019086349954, Training Loss Force: 4.319437407168626, time: 0.6112525463104248
Validation Loss Energy: 3.4541041349703914, Validation Loss Force: 4.551670415583158, time: 0.04901385307312012
Test Loss Energy: 9.09737085452388, Test Loss Force: 11.09283132237294, time: 8.99868392944336


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0766395443820658, Training Loss Force: 4.323093945109621, time: 0.5889565944671631
Validation Loss Energy: 1.7249164477066024, Validation Loss Force: 4.5719070329033675, time: 0.052670955657958984
Test Loss Energy: 8.829183931268243, Test Loss Force: 10.83140219318771, time: 9.110848188400269


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2641674002122496, Training Loss Force: 4.853643857559994, time: 0.6180398464202881
Validation Loss Energy: 2.0664511711172806, Validation Loss Force: 6.642085685523479, time: 0.05142974853515625
Test Loss Energy: 8.741566389971588, Test Loss Force: 12.1414096809051, time: 9.03505825996399


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.5352599132484013, Training Loss Force: 4.727873807937604, time: 0.5918710231781006
Validation Loss Energy: 3.4702089036187647, Validation Loss Force: 4.406260337879643, time: 0.0544891357421875
Test Loss Energy: 8.967296180434698, Test Loss Force: 10.915519830175128, time: 9.283633470535278


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.577448590989047, Training Loss Force: 4.640838468440515, time: 0.6028923988342285
Validation Loss Energy: 1.6018049036145876, Validation Loss Force: 4.496844818472818, time: 0.05552864074707031
Test Loss Energy: 8.64110402393975, Test Loss Force: 10.94214199004927, time: 8.903012990951538


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.212662998379281, Training Loss Force: 4.328530605678023, time: 0.6343600749969482
Validation Loss Energy: 1.7112268599495348, Validation Loss Force: 4.31305326008573, time: 0.07337069511413574
Test Loss Energy: 8.74235030427757, Test Loss Force: 10.787585498548884, time: 9.154292345046997


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.964902485217479, Training Loss Force: 4.0973063236528295, time: 0.6070914268493652
Validation Loss Energy: 2.008045054140422, Validation Loss Force: 4.265390929399887, time: 0.04966425895690918
Test Loss Energy: 8.944941079533676, Test Loss Force: 10.921836461874529, time: 8.92589545249939


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8900878759473443, Training Loss Force: 4.08217853932107, time: 0.633061408996582
Validation Loss Energy: 1.8275381996594877, Validation Loss Force: 4.273953894075686, time: 0.052991390228271484
Test Loss Energy: 8.672754892510014, Test Loss Force: 10.856163683046198, time: 8.900186777114868


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.021627948218304, Training Loss Force: 4.108696647388189, time: 0.5876929759979248
Validation Loss Energy: 2.212687128683042, Validation Loss Force: 4.265457730143665, time: 0.05121970176696777
Test Loss Energy: 8.988491662392782, Test Loss Force: 10.945311968632666, time: 9.253527402877808


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9884575173805923, Training Loss Force: 4.06419729090225, time: 0.5975215435028076
Validation Loss Energy: 1.7791810299037771, Validation Loss Force: 4.253352544694447, time: 0.050873517990112305
Test Loss Energy: 8.626165078659417, Test Loss Force: 10.959967883941417, time: 8.99347710609436


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9360675076168394, Training Loss Force: 4.075107235253842, time: 0.5888381004333496
Validation Loss Energy: 2.1725409950179917, Validation Loss Force: 4.263558362328902, time: 0.05053210258483887
Test Loss Energy: 8.911814338879676, Test Loss Force: 11.025043764898586, time: 9.631071090698242


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.919609046609303, Training Loss Force: 4.109417568046702, time: 0.6719450950622559
Validation Loss Energy: 1.8786814057690469, Validation Loss Force: 4.278857514007308, time: 0.060658931732177734
Test Loss Energy: 8.601599274176955, Test Loss Force: 10.919036020808809, time: 10.101989507675171


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.000641451531182, Training Loss Force: 4.093351684462865, time: 0.6968948841094971
Validation Loss Energy: 2.1165869106760895, Validation Loss Force: 4.2548408652658285, time: 0.053156137466430664
Test Loss Energy: 9.069516851628643, Test Loss Force: 11.076673721680821, time: 10.277511596679688


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9797981018063202, Training Loss Force: 4.08379477159736, time: 0.6265013217926025
Validation Loss Energy: 1.8934628516831713, Validation Loss Force: 4.323180698180818, time: 0.055129289627075195
Test Loss Energy: 8.679656885254037, Test Loss Force: 10.983309943098526, time: 10.103511333465576


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9472880812867157, Training Loss Force: 4.1110622082182395, time: 0.64898681640625
Validation Loss Energy: 2.063638414465921, Validation Loss Force: 4.264657457233201, time: 0.07777070999145508
Test Loss Energy: 8.824977571204823, Test Loss Force: 11.064916786112605, time: 10.603714942932129


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9835635103103886, Training Loss Force: 4.121600687696995, time: 0.6184327602386475
Validation Loss Energy: 1.7670377680306053, Validation Loss Force: 4.268025996072796, time: 0.05510425567626953
Test Loss Energy: 8.648313708137621, Test Loss Force: 11.021537940621169, time: 10.085266351699829

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–…â–ˆâ–ƒâ–‚â–‚â–ƒâ–â–‚â–ƒâ–â–ƒâ–â–‚â–â–ƒâ–â–‚â–
wandb:   test_error_force â–ƒâ–ƒâ–ƒâ–â–ƒâ–â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚
wandb:          test_loss â–â–â–…â–ˆâ–†â–‡â–†â–„â–ƒâ–…â–…â–†â–…â–…â–…â–…â–†â–†â–…â–…
wandb: train_error_energy â–ˆâ–‡â–ƒâ–…â–…â–‚â–‚â–†â–†â–‚â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–†â–…â–ˆâ–ƒâ–ƒâ–ƒâ–ˆâ–‡â–†â–ƒâ–â–â–â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‡â–ƒâ–…â–†â–‚â–ƒâ–†â–†â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–â–„â–ˆâ–„â–â–‚â–„â–â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–
wandb:  valid_error_force â–â–‚â–‚â–‚â–‚â–‚â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–â–ƒâ–ˆâ–ƒâ–â–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1193
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.64831
wandb:   test_error_force 11.02154
wandb:          test_loss 10.32489
wandb: train_error_energy 1.98356
wandb:  train_error_force 4.1216
wandb:         train_loss 0.94398
wandb: valid_error_energy 1.76704
wandb:  valid_error_force 4.26803
wandb:         valid_loss 0.96395
wandb: 
wandb: ğŸš€ View run al_72_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/r6bw6p2z
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_140246-r6bw6p2z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.911371946334839, Uncertainty Bias: 0.01010960340499878
1.04904175e-05 0.0019435883
3.0697398 7.520006
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 201 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1205 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 419 steps.
Found uncertainty sample 9 after 1959 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1305 steps.
Found uncertainty sample 13 after 3266 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2489 steps.
Found uncertainty sample 16 after 649 steps.
Found uncertainty sample 17 after 551 steps.
Found uncertainty sample 18 after 2151 steps.
Found uncertainty sample 19 after 373 steps.
Found uncertainty sample 20 after 1179 steps.
Found uncertainty sample 21 after 531 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 416 steps.
Found uncertainty sample 24 after 2352 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 285 steps.
Found uncertainty sample 27 after 528 steps.
Found uncertainty sample 28 after 134 steps.
Found uncertainty sample 29 after 730 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 871 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 4 steps.
Found uncertainty sample 35 after 2265 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2036 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 405 steps.
Found uncertainty sample 40 after 2007 steps.
Found uncertainty sample 41 after 2991 steps.
Found uncertainty sample 42 after 2182 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3073 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2822 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1087 steps.
Found uncertainty sample 50 after 1098 steps.
Found uncertainty sample 51 after 1411 steps.
Found uncertainty sample 52 after 2060 steps.
Did not find any uncertainty samples for sample 53.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1666 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2544 steps.
Found uncertainty sample 59 after 697 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1211 steps.
Found uncertainty sample 62 after 3006 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3511 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2170 steps.
Found uncertainty sample 67 after 1152 steps.
Found uncertainty sample 68 after 1485 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 482 steps.
Found uncertainty sample 71 after 146 steps.
Found uncertainty sample 72 after 36 steps.
Found uncertainty sample 73 after 2250 steps.
Found uncertainty sample 74 after 26 steps.
Found uncertainty sample 75 after 3662 steps.
Found uncertainty sample 76 after 127 steps.
Found uncertainty sample 77 after 3539 steps.
Found uncertainty sample 78 after 713 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 729 steps.
Found uncertainty sample 82 after 135 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 725 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1709 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3173 steps.
Found uncertainty sample 89 after 1577 steps.
Found uncertainty sample 90 after 983 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1119 steps.
Found uncertainty sample 95 after 1726 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 253 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_143034-cluuvmym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/cluuvmym
Training model 8. Added 63 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.79798954773442, Training Loss Force: 5.590748180501615, time: 0.6464166641235352
Validation Loss Energy: 5.177894433471464, Validation Loss Force: 4.72841672219309, time: 0.05467391014099121
Test Loss Energy: 9.704888192643313, Test Loss Force: 11.29660330498687, time: 8.899569988250732


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.8509755167661175, Training Loss Force: 4.897017741344427, time: 0.635260820388794
Validation Loss Energy: 3.0178698938152193, Validation Loss Force: 4.555531943911838, time: 0.05791306495666504
Test Loss Energy: 9.395644172930494, Test Loss Force: 11.128499706586348, time: 9.014434099197388


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0130575626666998, Training Loss Force: 4.631811290160942, time: 0.6788699626922607
Validation Loss Energy: 5.9648962628386375, Validation Loss Force: 4.447011463614179, time: 0.05311012268066406
Test Loss Energy: 9.9446028645423, Test Loss Force: 11.007287931346724, time: 9.152209520339966


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.335871436683083, Training Loss Force: 4.21077372834322, time: 0.6249561309814453
Validation Loss Energy: 3.5492802760217437, Validation Loss Force: 4.3527195417413065, time: 0.05310845375061035
Test Loss Energy: 9.155448176607733, Test Loss Force: 11.238654506135077, time: 8.95013427734375


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.323574366097361, Training Loss Force: 4.246040373845339, time: 0.6133909225463867
Validation Loss Energy: 3.037281744618912, Validation Loss Force: 4.341605679329758, time: 0.05267834663391113
Test Loss Energy: 9.016861180500863, Test Loss Force: 11.128616189363232, time: 8.97145414352417


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.246881141923355, Training Loss Force: 4.1973627108211655, time: 0.5829916000366211
Validation Loss Energy: 1.6182745156585636, Validation Loss Force: 4.511347705285386, time: 0.051711082458496094
Test Loss Energy: 8.729012912075458, Test Loss Force: 11.074877716650434, time: 9.206351518630981


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.2713055284880355, Training Loss Force: 4.8941909509701444, time: 0.6142685413360596
Validation Loss Energy: 5.959875073597965, Validation Loss Force: 4.658748890491788, time: 0.05208444595336914
Test Loss Energy: 11.04558489335102, Test Loss Force: 11.200316633629896, time: 8.982818841934204


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1281140726716905, Training Loss Force: 4.644423682524212, time: 0.5962886810302734
Validation Loss Energy: 2.01844971532219, Validation Loss Force: 4.819481722803178, time: 0.05243802070617676
Test Loss Energy: 8.745670340880793, Test Loss Force: 11.065114404396713, time: 8.998696565628052


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2638233290645973, Training Loss Force: 5.3220015404006675, time: 0.6020903587341309
Validation Loss Energy: 2.463228662283195, Validation Loss Force: 6.233775936620819, time: 0.05714583396911621
Test Loss Energy: 8.61741915688893, Test Loss Force: 12.19617282340033, time: 9.578230142593384


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.5467289880160573, Training Loss Force: 4.819356972414172, time: 0.6807029247283936
Validation Loss Energy: 1.6361771149911577, Validation Loss Force: 5.427030479422521, time: 0.052201032638549805
Test Loss Energy: 8.6258338169187, Test Loss Force: 11.664820149808426, time: 8.937234878540039


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.492969817462945, Training Loss Force: 4.551443092652081, time: 0.62544846534729
Validation Loss Energy: 4.526683820042017, Validation Loss Force: 4.552207938901428, time: 0.05148482322692871
Test Loss Energy: 9.968296778255802, Test Loss Force: 11.1405618504394, time: 8.922852039337158


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.44074023702298, Training Loss Force: 4.56650944373842, time: 0.6245627403259277
Validation Loss Energy: 6.5671267895766405, Validation Loss Force: 4.415502443450522, time: 0.05771923065185547
Test Loss Energy: 11.220117386006313, Test Loss Force: 11.246126186813791, time: 9.233704090118408


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.4459419552737116, Training Loss Force: 4.934694952919802, time: 0.6707816123962402
Validation Loss Energy: 1.5499698644686308, Validation Loss Force: 4.527438223108421, time: 0.05844998359680176
Test Loss Energy: 8.856688488164448, Test Loss Force: 10.840003125867408, time: 10.424915552139282


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0823847851266364, Training Loss Force: 4.250376504758379, time: 0.6212739944458008
Validation Loss Energy: 3.897161181425937, Validation Loss Force: 4.295964293812356, time: 0.05413508415222168
Test Loss Energy: 9.834116183043504, Test Loss Force: 10.9085482527401, time: 10.165360689163208


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.33850611646835, Training Loss Force: 4.27391665266103, time: 0.6742331981658936
Validation Loss Energy: 5.324600890942571, Validation Loss Force: 4.416549433774674, time: 0.05555319786071777
Test Loss Energy: 11.063191871995928, Test Loss Force: 11.227426035564383, time: 10.155214548110962


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.19128757841226, Training Loss Force: 4.239644252729121, time: 0.6387326717376709
Validation Loss Energy: 5.902825457058099, Validation Loss Force: 4.359630301354321, time: 0.0579228401184082
Test Loss Energy: 11.115465372920875, Test Loss Force: 11.284293809521095, time: 10.098757028579712


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.370147630340564, Training Loss Force: 4.172227606093149, time: 0.6507389545440674
Validation Loss Energy: 6.257640725004776, Validation Loss Force: 4.343805650491525, time: 0.05916452407836914
Test Loss Energy: 10.954458121288756, Test Loss Force: 10.999476492525535, time: 10.041027545928955


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.384224951881436, Training Loss Force: 4.205855351013954, time: 0.6264498233795166
Validation Loss Energy: 6.651873775840173, Validation Loss Force: 4.339571819350854, time: 0.06049013137817383
Test Loss Energy: 11.30337320712927, Test Loss Force: 11.137671847413127, time: 10.960775375366211


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.3168922097630125, Training Loss Force: 4.1737961098239795, time: 0.668586254119873
Validation Loss Energy: 6.253679886237012, Validation Loss Force: 4.304085482902634, time: 0.057949066162109375
Test Loss Energy: 11.140199820719102, Test Loss Force: 11.06059554509118, time: 10.846347093582153


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.270291281661793, Training Loss Force: 4.153659003345085, time: 0.7095956802368164
Validation Loss Energy: 6.001934603233973, Validation Loss Force: 4.2812244870285205, time: 0.05972933769226074
Test Loss Energy: 11.045902808932667, Test Loss Force: 10.9751292045843, time: 11.229759454727173

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–„â–‚â–‚â–â–‡â–â–â–â–…â–ˆâ–‚â–„â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡
wandb:   test_error_force â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ˆâ–…â–ƒâ–ƒâ–â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚
wandb:          test_loss â–…â–†â–ˆâ–‚â–â–â–ƒâ–…â–ˆâ–†â–ˆâ–‡â–„â–‡â–„â–‚â–ƒâ–‚â–‚â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–„â–„â–„â–„â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–â–„â–„â–„â–„â–„â–„
wandb:  train_error_force â–ˆâ–…â–ƒâ–â–â–â–…â–ƒâ–‡â–„â–ƒâ–ƒâ–…â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–†â–ƒâ–‡â–„â–ƒâ–â–‡â–‚â–‚â–â–…â–ˆâ–â–„â–†â–‡â–‡â–ˆâ–‡â–‡
wandb:  valid_error_force â–ƒâ–‚â–‚â–â–â–‚â–‚â–ƒâ–ˆâ–…â–‚â–â–‚â–â–â–â–â–â–â–
wandb:         valid_loss â–…â–‚â–ˆâ–‚â–‚â–â–„â–‚â–ƒâ–‚â–…â–ˆâ–â–„â–„â–„â–„â–„â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1249
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.0459
wandb:   test_error_force 10.97513
wandb:          test_loss 7.69547
wandb: train_error_energy 4.27029
wandb:  train_error_force 4.15366
wandb:         train_loss 1.7292
wandb: valid_error_energy 6.00193
wandb:  valid_error_force 4.28122
wandb:         valid_loss 2.28915
wandb: 
wandb: ğŸš€ View run al_72_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/cluuvmym
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_143034-cluuvmym/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.289289951324463, Uncertainty Bias: -0.1006927490234375
4.196167e-05 0.14293861
2.4239535 6.5137744
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 552 steps.
Found uncertainty sample 3 after 3378 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 609 steps.
Found uncertainty sample 9 after 3064 steps.
Found uncertainty sample 10 after 2594 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2632 steps.
Found uncertainty sample 25 after 1143 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 476 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1677 steps.
Found uncertainty sample 30 after 1445 steps.
Found uncertainty sample 31 after 491 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1600 steps.
Found uncertainty sample 38 after 305 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2548 steps.
Found uncertainty sample 42 after 1877 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 553 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3513 steps.
Found uncertainty sample 49 after 469 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 828 steps.
Found uncertainty sample 55 after 3521 steps.
Found uncertainty sample 56 after 2532 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2117 steps.
Found uncertainty sample 59 after 2702 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1368 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2479 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1579 steps.
Found uncertainty sample 70 after 1543 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1116 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3535 steps.
Found uncertainty sample 77 after 1698 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2160 steps.
Found uncertainty sample 80 after 1360 steps.
Found uncertainty sample 81 after 2506 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1867 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2474 steps.
Found uncertainty sample 89 after 1183 steps.
Found uncertainty sample 90 after 3282 steps.
Found uncertainty sample 91 after 3784 steps.
Found uncertainty sample 92 after 2130 steps.
Found uncertainty sample 93 after 1927 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_150551-k3wqts28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/k3wqts28
Training model 9. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.431295402779299, Training Loss Force: 4.6144466698037245, time: 0.6686680316925049
Validation Loss Energy: 2.6869562659961503, Validation Loss Force: 4.29278168370961, time: 0.058554649353027344
Test Loss Energy: 9.136027136912897, Test Loss Force: 10.828589473842177, time: 9.029140949249268


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.830806326378773, Training Loss Force: 4.335017703083063, time: 0.6521196365356445
Validation Loss Energy: 3.881693914542355, Validation Loss Force: 4.419895928368822, time: 0.05653953552246094
Test Loss Energy: 9.452741718129666, Test Loss Force: 10.777168513620829, time: 9.027118682861328


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.859671810295543, Training Loss Force: 4.169150717671603, time: 0.6685154438018799
Validation Loss Energy: 2.8733602901378363, Validation Loss Force: 3.8854716079375926, time: 0.05655336380004883
Test Loss Energy: 9.225721355949672, Test Loss Force: 10.758802473344558, time: 9.20181393623352


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9533452740465562, Training Loss Force: 4.1620380677456446, time: 0.6293256282806396
Validation Loss Energy: 1.879196105499859, Validation Loss Force: 4.475934626986177, time: 0.05688357353210449
Test Loss Energy: 8.742605935451937, Test Loss Force: 10.795441046845491, time: 9.069713830947876


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.8900526690849255, Training Loss Force: 4.155390095741508, time: 0.6381535530090332
Validation Loss Energy: 4.341330460265391, Validation Loss Force: 4.660439171978526, time: 0.057782888412475586
Test Loss Energy: 9.040329104849967, Test Loss Force: 10.851471263050776, time: 9.072003364562988


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.968423068154615, Training Loss Force: 4.1819143249234205, time: 0.6737837791442871
Validation Loss Energy: 2.1395903034690247, Validation Loss Force: 4.235099464126163, time: 0.05710458755493164
Test Loss Energy: 8.762175785753062, Test Loss Force: 10.827423083891912, time: 9.26117205619812


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0436751379023184, Training Loss Force: 4.485806614692293, time: 0.6798529624938965
Validation Loss Energy: 1.4232783571829624, Validation Loss Force: 4.240561983614064, time: 0.057916879653930664
Test Loss Energy: 8.449158132568046, Test Loss Force: 11.112501779490582, time: 9.06646203994751


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.4626574344595684, Training Loss Force: 4.7674027550388125, time: 0.6453495025634766
Validation Loss Energy: 1.576484638358274, Validation Loss Force: 4.637604451063631, time: 0.05811047554016113
Test Loss Energy: 8.369602676276013, Test Loss Force: 11.164199241164049, time: 9.061524868011475


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1857206962279196, Training Loss Force: 4.763672921932563, time: 0.6605696678161621
Validation Loss Energy: 2.7924780609055997, Validation Loss Force: 4.355494221968712, time: 0.06258869171142578
Test Loss Energy: 9.487941182106281, Test Loss Force: 10.969966581964332, time: 9.258660078048706


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.4565748302788517, Training Loss Force: 4.883481788373582, time: 0.6274826526641846
Validation Loss Energy: 5.259698401633269, Validation Loss Force: 6.301116207739739, time: 0.06002497673034668
Test Loss Energy: 10.11502132672066, Test Loss Force: 11.91823764312317, time: 9.747580528259277


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 5.01787059872905, Training Loss Force: 4.925734757756899, time: 0.6157145500183105
Validation Loss Energy: 6.604511380493895, Validation Loss Force: 4.788624009891359, time: 0.05757737159729004
Test Loss Energy: 11.10930503864062, Test Loss Force: 11.350434921019474, time: 9.152466058731079


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.3714460836904765, Training Loss Force: 4.539763633773916, time: 0.6293075084686279
Validation Loss Energy: 2.681308485778838, Validation Loss Force: 4.456714716986275, time: 0.058817148208618164
Test Loss Energy: 9.441809833534885, Test Loss Force: 11.166022749914282, time: 9.206650495529175


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.176052371178641, Training Loss Force: 4.373540475486158, time: 0.7458047866821289
Validation Loss Energy: 3.9027370395091148, Validation Loss Force: 4.574594204156424, time: 0.05728650093078613
Test Loss Energy: 9.532705015695704, Test Loss Force: 10.805704149906612, time: 9.122782230377197


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 6.197896545682399, Training Loss Force: 4.330874096394131, time: 0.6398236751556396
Validation Loss Energy: 8.735548405394967, Validation Loss Force: 4.202857194464965, time: 0.05787372589111328
Test Loss Energy: 11.236554477279817, Test Loss Force: 10.599582170753681, time: 9.083319425582886


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 6.073412876296494, Training Loss Force: 4.279076560706398, time: 0.6778464317321777
Validation Loss Energy: 7.575932917908818, Validation Loss Force: 4.313364328882591, time: 0.06072640419006348
Test Loss Energy: 11.239727580226097, Test Loss Force: 10.665423016989097, time: 9.1219801902771


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.074728370309429, Training Loss Force: 4.285144800011725, time: 0.6373517513275146
Validation Loss Energy: 7.129247255051233, Validation Loss Force: 5.348591264724831, time: 0.059827327728271484
Test Loss Energy: 10.593441692499047, Test Loss Force: 10.641053224308633, time: 9.287971019744873


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.090650058756734, Training Loss Force: 4.2431316398676175, time: 0.6270589828491211
Validation Loss Energy: 1.7196935758870064, Validation Loss Force: 4.253839744785736, time: 0.058316946029663086
Test Loss Energy: 8.914046982949733, Test Loss Force: 10.622920420053362, time: 9.180408716201782


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 6.009551142575258, Training Loss Force: 4.263791882522477, time: 0.6602988243103027
Validation Loss Energy: 4.87619911697732, Validation Loss Force: 4.1491028586156835, time: 0.05764603614807129
Test Loss Energy: 10.364305712291957, Test Loss Force: 10.696609101605965, time: 9.120250225067139


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.852228640608183, Training Loss Force: 4.670347519926886, time: 0.6279699802398682
Validation Loss Energy: 2.677322374063012, Validation Loss Force: 4.62683416714425, time: 0.0575556755065918
Test Loss Energy: 9.11824268512965, Test Loss Force: 11.078793298788645, time: 9.296525955200195


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.410446753267025, Training Loss Force: 5.278705043469966, time: 0.624737024307251
Validation Loss Energy: 2.036276495810595, Validation Loss Force: 4.783063961317543, time: 0.05731487274169922
Test Loss Energy: 8.846461040146048, Test Loss Force: 10.953439387795802, time: 9.172566652297974

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–â–â–„â–…â–ˆâ–„â–„â–ˆâ–ˆâ–†â–‚â–†â–ƒâ–‚
wandb:   test_error_force â–‚â–‚â–‚â–‚â–‚â–‚â–„â–„â–ƒâ–ˆâ–…â–„â–‚â–â–â–â–â–‚â–„â–ƒ
wandb:          test_loss â–ƒâ–„â–„â–„â–„â–„â–…â–†â–‡â–ˆâ–…â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–†â–†
wandb: train_error_energy â–†â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‚â–ƒ
wandb:  train_error_force â–„â–‚â–â–â–â–â–ƒâ–…â–…â–†â–†â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–„â–ˆ
wandb:         train_loss â–…â–â–â–â–â–â–‚â–‚â–â–‚â–ˆâ–†â–„â–„â–„â–„â–„â–„â–‚â–„
wandb: valid_error_energy â–‚â–ƒâ–‚â–â–„â–‚â–â–â–‚â–…â–†â–‚â–ƒâ–ˆâ–‡â–†â–â–„â–‚â–‚
wandb:  valid_error_force â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–…â–‚â–‚â–ƒâ–„
wandb:         valid_loss â–‚â–ƒâ–‚â–‚â–„â–‚â–â–â–‚â–ˆâ–†â–‚â–ƒâ–†â–…â–…â–‚â–ƒâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1285
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.84646
wandb:   test_error_force 10.95344
wandb:          test_loss 9.76473
wandb: train_error_energy 3.41045
wandb:  train_error_force 5.27871
wandb:         train_loss 2.16565
wandb: valid_error_energy 2.03628
wandb:  valid_error_force 4.78306
wandb:         valid_loss 1.31547
wandb: 
wandb: ğŸš€ View run al_72_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/k3wqts28
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_150551-k3wqts28/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.243990421295166, Uncertainty Bias: 0.0690382868051529
8.010864e-05 0.006269932
3.455774 7.1760335
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1326 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3097 steps.
Found uncertainty sample 4 after 268 steps.
Found uncertainty sample 5 after 45 steps.
Found uncertainty sample 6 after 3694 steps.
Found uncertainty sample 7 after 46 steps.
Found uncertainty sample 8 after 1722 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 667 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 347 steps.
Found uncertainty sample 16 after 3693 steps.
Found uncertainty sample 17 after 2699 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2479 steps.
Found uncertainty sample 21 after 820 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1281 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1223 steps.
Found uncertainty sample 30 after 114 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1298 steps.
Found uncertainty sample 33 after 22 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 116 steps.
Found uncertainty sample 37 after 2564 steps.
Found uncertainty sample 38 after 331 steps.
Found uncertainty sample 39 after 118 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 61 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1598 steps.
Found uncertainty sample 44 after 1105 steps.
Found uncertainty sample 45 after 1793 steps.
Found uncertainty sample 46 after 837 steps.
Found uncertainty sample 47 after 2472 steps.
Found uncertainty sample 48 after 3344 steps.
Found uncertainty sample 49 after 130 steps.
Found uncertainty sample 50 after 1446 steps.
Found uncertainty sample 51 after 864 steps.
Found uncertainty sample 52 after 1467 steps.
Found uncertainty sample 53 after 2008 steps.
Found uncertainty sample 54 after 942 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 314 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2341 steps.
Found uncertainty sample 62 after 3438 steps.
Found uncertainty sample 63 after 191 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1432 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 191 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 68 steps.
Found uncertainty sample 72 after 2467 steps.
Found uncertainty sample 73 after 1266 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 450 steps.
Found uncertainty sample 76 after 3699 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 296 steps.
Found uncertainty sample 79 after 1240 steps.
Found uncertainty sample 80 after 365 steps.
Found uncertainty sample 81 after 411 steps.
Found uncertainty sample 82 after 1341 steps.
Found uncertainty sample 83 after 577 steps.
Found uncertainty sample 84 after 1848 steps.
Found uncertainty sample 85 after 2737 steps.
Found uncertainty sample 86 after 1795 steps.
Found uncertainty sample 87 after 3124 steps.
Found uncertainty sample 88 after 2327 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 134 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2225 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2694 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_153403-glnvpjmg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/glnvpjmg
Training model 10. Added 61 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.446300241460591, Training Loss Force: 5.0165761403556735, time: 0.6524932384490967
Validation Loss Energy: 2.487876132715088, Validation Loss Force: 5.100766740043289, time: 0.06268024444580078
Test Loss Energy: 9.119336505922869, Test Loss Force: 11.070639770210887, time: 9.612854242324829


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.807873699896418, Training Loss Force: 4.865592547896659, time: 0.6435866355895996
Validation Loss Energy: 4.291251724007941, Validation Loss Force: 5.219308667922573, time: 0.06201362609863281
Test Loss Energy: 9.189233959643325, Test Loss Force: 10.990887096672372, time: 9.13520622253418


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.376878794165814, Training Loss Force: 4.938989780296765, time: 0.6441614627838135
Validation Loss Energy: 5.109930911413093, Validation Loss Force: 4.493114887609382, time: 0.06026911735534668
Test Loss Energy: 9.772825318498533, Test Loss Force: 10.828962741942403, time: 9.371870517730713


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.220978674917183, Training Loss Force: 4.242703891145205, time: 0.6498105525970459
Validation Loss Energy: 4.329257116504041, Validation Loss Force: 4.269620529826786, time: 0.058182477951049805
Test Loss Energy: 10.109793698699766, Test Loss Force: 10.839856411382192, time: 9.108714580535889


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.328316922543593, Training Loss Force: 4.207916067807761, time: 0.6776711940765381
Validation Loss Energy: 6.12140328009861, Validation Loss Force: 4.1771660737461085, time: 0.0797569751739502
Test Loss Energy: 10.691809851716013, Test Loss Force: 10.80359156764107, time: 9.218337297439575


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.16093254401328, Training Loss Force: 4.19936036108579, time: 0.7338478565216064
Validation Loss Energy: 2.7242690461138426, Validation Loss Force: 4.271986389502269, time: 0.06280231475830078
Test Loss Energy: 9.329416791710658, Test Loss Force: 10.597927116458473, time: 10.133256912231445


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.2953671428777955, Training Loss Force: 4.19937214134394, time: 0.7195556163787842
Validation Loss Energy: 4.466457160128053, Validation Loss Force: 4.3114727544879345, time: 0.06528663635253906
Test Loss Energy: 9.677917829520453, Test Loss Force: 10.625704204067993, time: 10.493254661560059


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.2942967828966125, Training Loss Force: 4.196635691288231, time: 0.6757030487060547
Validation Loss Energy: 3.3588963749003176, Validation Loss Force: 4.456901981738, time: 0.06847667694091797
Test Loss Energy: 9.721799725415789, Test Loss Force: 10.771377628256912, time: 10.672515630722046


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.336269047434002, Training Loss Force: 4.210181917226845, time: 0.6351377964019775
Validation Loss Energy: 5.511530970941511, Validation Loss Force: 4.124160128896291, time: 0.06412434577941895
Test Loss Energy: 10.789548237303098, Test Loss Force: 10.661046474744605, time: 10.80768632888794


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.297613545858133, Training Loss Force: 4.1829829234649365, time: 0.675562858581543
Validation Loss Energy: 3.7806992060387636, Validation Loss Force: 4.414139485608297, time: 0.060855865478515625
Test Loss Energy: 9.212168960948768, Test Loss Force: 10.56581438777889, time: 10.48943543434143


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.424166218931316, Training Loss Force: 4.186024075040261, time: 0.7135238647460938
Validation Loss Energy: 4.335524250950752, Validation Loss Force: 4.373493905048931, time: 0.060826778411865234
Test Loss Energy: 9.878725715075445, Test Loss Force: 10.51087819288564, time: 10.537363767623901


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.3316477454711855, Training Loss Force: 4.183179572130669, time: 0.75604248046875
Validation Loss Energy: 3.6691575507691567, Validation Loss Force: 4.199139287735409, time: 0.08963990211486816
Test Loss Energy: 9.862086850581521, Test Loss Force: 10.680713364492687, time: 10.567800998687744


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.5029600819587134, Training Loss Force: 4.201462479761214, time: 0.6787312030792236
Validation Loss Energy: 5.196565464026655, Validation Loss Force: 4.287898994677706, time: 0.06824946403503418
Test Loss Energy: 10.667906503098175, Test Loss Force: 10.654722927477808, time: 10.99196743965149


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.300787827074492, Training Loss Force: 4.195016573800202, time: 0.7119622230529785
Validation Loss Energy: 3.9742006978723246, Validation Loss Force: 4.213963931463843, time: 0.06616330146789551
Test Loss Energy: 9.274734075911967, Test Loss Force: 10.535726959722872, time: 10.696137189865112


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.362993724105206, Training Loss Force: 4.182152844698796, time: 0.6469488143920898
Validation Loss Energy: 4.748975096429166, Validation Loss Force: 4.031869000634152, time: 0.061707258224487305
Test Loss Energy: 9.79881660888417, Test Loss Force: 10.605846308493376, time: 10.713640451431274


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.378432383305183, Training Loss Force: 4.206564879620394, time: 0.7212882041931152
Validation Loss Energy: 4.122348938063314, Validation Loss Force: 4.049229511930985, time: 0.06977391242980957
Test Loss Energy: 9.78917685352449, Test Loss Force: 10.680950802082286, time: 10.487424612045288


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.342621098350006, Training Loss Force: 4.180527407648339, time: 0.71163010597229
Validation Loss Energy: 5.8299182346218394, Validation Loss Force: 4.368460914343526, time: 0.06179213523864746
Test Loss Energy: 10.619749410896539, Test Loss Force: 10.675373767699798, time: 10.670855522155762


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.369281296398525, Training Loss Force: 4.178045198042463, time: 0.7514173984527588
Validation Loss Energy: 3.9671720349465414, Validation Loss Force: 4.791371079144671, time: 0.0678255558013916
Test Loss Energy: 9.19845561929022, Test Loss Force: 10.584821071669943, time: 10.45421028137207


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.441559404274491, Training Loss Force: 4.189482588119752, time: 0.6914639472961426
Validation Loss Energy: 4.368269418878027, Validation Loss Force: 4.540277994070054, time: 0.06458902359008789
Test Loss Energy: 9.627885037718714, Test Loss Force: 10.607973127594576, time: 10.334744453430176


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.350365759216167, Training Loss Force: 4.179553659568258, time: 0.7093849182128906
Validation Loss Energy: 3.7778654071531137, Validation Loss Force: 4.187655571872475, time: 0.06391692161560059
Test Loss Energy: 9.928764527104775, Test Loss Force: 10.69335435019736, time: 10.77795958518982

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–„â–…â–ˆâ–‚â–ƒâ–„â–ˆâ–â–„â–„â–‡â–‚â–„â–„â–‡â–â–ƒâ–„
wandb:   test_error_force â–ˆâ–‡â–…â–…â–…â–‚â–‚â–„â–ƒâ–‚â–â–ƒâ–ƒâ–â–‚â–ƒâ–ƒâ–‚â–‚â–ƒ
wandb:          test_loss â–…â–ˆâ–„â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–
wandb: train_error_energy â–„â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:  train_error_force â–ˆâ–‡â–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–†â–‚â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–
wandb: valid_error_energy â–â–„â–†â–…â–ˆâ–â–…â–ƒâ–‡â–ƒâ–…â–ƒâ–†â–„â–…â–„â–‡â–„â–…â–ƒ
wandb:  valid_error_force â–‡â–ˆâ–„â–‚â–‚â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–â–ƒâ–…â–„â–‚
wandb:         valid_loss â–â–ˆâ–†â–ƒâ–†â–â–„â–‚â–„â–‚â–ƒâ–‚â–„â–‚â–ƒâ–‚â–…â–ƒâ–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1339
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.92876
wandb:   test_error_force 10.69335
wandb:          test_loss 6.83303
wandb: train_error_energy 4.35037
wandb:  train_error_force 4.17955
wandb:         train_loss 1.75819
wandb: valid_error_energy 3.77787
wandb:  valid_error_force 4.18766
wandb:         valid_loss 1.57099
wandb: 
wandb: ğŸš€ View run al_72_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/glnvpjmg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_153403-glnvpjmg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3495213985443115, Uncertainty Bias: -0.13789546489715576
4.196167e-05 0.01522541
2.3762395 6.397533
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3284 steps.
Found uncertainty sample 5 after 119 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 452 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2667 steps.
Found uncertainty sample 12 after 3240 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 518 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2896 steps.
Found uncertainty sample 18 after 463 steps.
Found uncertainty sample 19 after 1051 steps.
Found uncertainty sample 20 after 2453 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1003 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2579 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3566 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1913 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3317 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2648 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2114 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2664 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2077 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 440 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1988 steps.
Found uncertainty sample 61 after 2625 steps.
Found uncertainty sample 62 after 2512 steps.
Found uncertainty sample 63 after 1270 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1845 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2270 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2830 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2670 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3168 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 449 steps.
Found uncertainty sample 85 after 2496 steps.
Found uncertainty sample 86 after 2199 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1446 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1919 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_161116-p74jfn1h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/p74jfn1h
Training model 11. Added 34 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.358423727160294, Training Loss Force: 4.7243937846253745, time: 0.6771945953369141
Validation Loss Energy: 2.0211227470844797, Validation Loss Force: 5.607415645215205, time: 0.06118464469909668
Test Loss Energy: 8.7057972240706, Test Loss Force: 11.009169376043952, time: 8.98158597946167


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9439994150103796, Training Loss Force: 4.723629822320754, time: 0.7134747505187988
Validation Loss Energy: 2.294443668316764, Validation Loss Force: 4.245965050440001, time: 0.057207584381103516
Test Loss Energy: 8.841672699878437, Test Loss Force: 10.589827695317371, time: 9.027604341506958


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.98598234646019, Training Loss Force: 4.212382618043099, time: 0.6647191047668457
Validation Loss Energy: 4.055470037414757, Validation Loss Force: 4.705826046662133, time: 0.058362722396850586
Test Loss Energy: 9.084264124240807, Test Loss Force: 10.574825208889765, time: 9.45943284034729


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.991302432780802, Training Loss Force: 4.187309927217768, time: 0.7005472183227539
Validation Loss Energy: 2.632791216907205, Validation Loss Force: 4.222760698742866, time: 0.06132864952087402
Test Loss Energy: 8.73799237530839, Test Loss Force: 10.605250152075499, time: 9.659238338470459


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9068958817496333, Training Loss Force: 4.185953856584011, time: 0.6796839237213135
Validation Loss Energy: 2.3262133783830166, Validation Loss Force: 4.1756746358066845, time: 0.06029057502746582
Test Loss Energy: 9.059940567467816, Test Loss Force: 10.706342387333393, time: 9.159738063812256


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.8679305962247272, Training Loss Force: 4.176326683562892, time: 0.660698652267456
Validation Loss Energy: 3.7691769684135847, Validation Loss Force: 4.228120122416202, time: 0.06444787979125977
Test Loss Energy: 9.75944455827428, Test Loss Force: 10.75065567380508, time: 9.342052459716797


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0504136316082424, Training Loss Force: 4.191046781538137, time: 0.6454269886016846
Validation Loss Energy: 2.355587613777378, Validation Loss Force: 4.144524335637117, time: 0.06168508529663086
Test Loss Energy: 8.840360360212374, Test Loss Force: 10.82543600774979, time: 9.216688394546509


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9708292916332724, Training Loss Force: 4.197288674106898, time: 0.6634142398834229
Validation Loss Energy: 2.0423162850593135, Validation Loss Force: 4.1511269211521675, time: 0.06021451950073242
Test Loss Energy: 8.611768669667658, Test Loss Force: 10.76211615863099, time: 9.298989534378052


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.971046898939895, Training Loss Force: 4.197397481643974, time: 0.6817493438720703
Validation Loss Energy: 3.4263332844285697, Validation Loss Force: 4.365760605610859, time: 0.05838966369628906
Test Loss Energy: 9.081109562289798, Test Loss Force: 10.721483311016188, time: 9.421844005584717


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.955640213599062, Training Loss Force: 4.201977221535314, time: 0.6744332313537598
Validation Loss Energy: 2.229485400386407, Validation Loss Force: 4.235248652453935, time: 0.05934286117553711
Test Loss Energy: 8.635193848535584, Test Loss Force: 10.709694250468994, time: 9.106431484222412


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.8631556816486277, Training Loss Force: 4.185502661575782, time: 0.6838135719299316
Validation Loss Energy: 2.9665091399500887, Validation Loss Force: 4.075919303769327, time: 0.05886030197143555
Test Loss Energy: 9.295456160934195, Test Loss Force: 10.804703477096428, time: 9.30162239074707


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9806012462044147, Training Loss Force: 4.207443738711138, time: 0.6490654945373535
Validation Loss Energy: 3.720870678557718, Validation Loss Force: 4.041885215490849, time: 0.060944557189941406
Test Loss Energy: 9.695039398753696, Test Loss Force: 10.809486401024499, time: 9.333473205566406


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9111605914046566, Training Loss Force: 4.198641684334488, time: 0.6592874526977539
Validation Loss Energy: 2.571962125618933, Validation Loss Force: 4.506161518207582, time: 0.059465885162353516
Test Loss Energy: 9.018993059204641, Test Loss Force: 10.779946417304718, time: 9.201747417449951


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0121553128541283, Training Loss Force: 4.192299181560231, time: 0.6647920608520508
Validation Loss Energy: 2.4397691317448267, Validation Loss Force: 4.314124298677643, time: 0.06221199035644531
Test Loss Energy: 8.802437953359282, Test Loss Force: 10.65759257551305, time: 9.224653005599976


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9928140844181605, Training Loss Force: 4.196126185814588, time: 0.657355785369873
Validation Loss Energy: 2.535740758320006, Validation Loss Force: 4.005431492938145, time: 0.06290626525878906
Test Loss Energy: 8.792560331393014, Test Loss Force: 10.71136647943361, time: 9.811519384384155


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.942775071300672, Training Loss Force: 4.2009139401150435, time: 0.6570818424224854
Validation Loss Energy: 1.8171241307063046, Validation Loss Force: 4.2725622119136375, time: 0.058925628662109375
Test Loss Energy: 8.678326725061458, Test Loss Force: 10.707346702124791, time: 9.087838411331177


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9196524806069113, Training Loss Force: 4.198919332046049, time: 0.724409818649292
Validation Loss Energy: 3.403094419013816, Validation Loss Force: 4.291122575903302, time: 0.059478759765625
Test Loss Energy: 9.379964860900602, Test Loss Force: 10.771230167655185, time: 9.146615028381348


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0353598535611197, Training Loss Force: 4.211800488398713, time: 0.6896297931671143
Validation Loss Energy: 3.8076077703129805, Validation Loss Force: 4.075572162570825, time: 0.06270003318786621
Test Loss Energy: 9.654676729253591, Test Loss Force: 10.774176539783786, time: 9.34361457824707


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9583695366392777, Training Loss Force: 4.204955012272273, time: 0.6892518997192383
Validation Loss Energy: 2.511328203837067, Validation Loss Force: 4.16141980242268, time: 0.05904746055603027
Test Loss Energy: 9.040983663537657, Test Loss Force: 10.762147439565666, time: 9.268783569335938


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.052314136071321, Training Loss Force: 4.196163506199117, time: 0.6514477729797363
Validation Loss Energy: 2.5185945660761284, Validation Loss Force: 4.285591696987602, time: 0.05916261672973633
Test Loss Energy: 8.878890546579603, Test Loss Force: 10.690316243043867, time: 9.19242262840271

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–„â–‚â–„â–ˆâ–‚â–â–„â–â–…â–ˆâ–ƒâ–‚â–‚â–â–†â–‡â–„â–ƒ
wandb:   test_error_force â–ˆâ–â–â–â–ƒâ–„â–…â–„â–ƒâ–ƒâ–…â–…â–„â–‚â–ƒâ–ƒâ–„â–„â–„â–ƒ
wandb:          test_loss â–ˆâ–…â–†â–ƒâ–‚â–„â–â–ƒâ–…â–ƒâ–ƒâ–„â–‚â–ƒâ–„â–‚â–‚â–ƒâ–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–ˆâ–„â–ƒâ–‡â–ƒâ–‚â–†â–‚â–…â–‡â–ƒâ–ƒâ–ƒâ–â–†â–‡â–ƒâ–ƒ
wandb:  valid_error_force â–ˆâ–‚â–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚
wandb:         valid_loss â–…â–‚â–ˆâ–ƒâ–‚â–†â–‚â–â–†â–‚â–ƒâ–†â–ƒâ–‚â–‚â–â–„â–†â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1369
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.87889
wandb:   test_error_force 10.69032
wandb:          test_loss 8.02682
wandb: train_error_energy 3.05231
wandb:  train_error_force 4.19616
wandb:         train_loss 1.39041
wandb: valid_error_energy 2.51859
wandb:  valid_error_force 4.28559
wandb:         valid_loss 1.29246
wandb: 
wandb: ğŸš€ View run al_72_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/p74jfn1h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_161116-p74jfn1h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0035288333892822, Uncertainty Bias: 0.014249593019485474
2.2888184e-05 0.021389008
2.8197823 6.3966947
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1843 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3565 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 371 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2704 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3631 steps.
Found uncertainty sample 24 after 1688 steps.
Found uncertainty sample 25 after 5 steps.
Found uncertainty sample 26 after 1977 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 146 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2618 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3725 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1394 steps.
Found uncertainty sample 37 after 1754 steps.
Found uncertainty sample 38 after 2089 steps.
Found uncertainty sample 39 after 737 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3639 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 414 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 187 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3047 steps.
Found uncertainty sample 57 after 3808 steps.
Found uncertainty sample 58 after 3867 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1595 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1990 steps.
Found uncertainty sample 68 after 1534 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2881 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 412 steps.
Found uncertainty sample 80 after 3243 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1209 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3321 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2498 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2828 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2969 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1224 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_164751-0oyotf19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0oyotf19
Training model 12. Added 34 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.807233307956173, Training Loss Force: 4.7027619876369435, time: 0.6969344615936279
Validation Loss Energy: 2.123113009339514, Validation Loss Force: 4.580019983235246, time: 0.060873985290527344
Test Loss Energy: 8.828761477768715, Test Loss Force: 10.698754895382656, time: 10.118269681930542


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9265403167138078, Training Loss Force: 4.262436529868405, time: 0.7223818302154541
Validation Loss Energy: 3.921751425887326, Validation Loss Force: 4.191417567092925, time: 0.06383991241455078
Test Loss Energy: 9.622758480505544, Test Loss Force: 10.744843482151575, time: 10.066658973693848


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.953251130543791, Training Loss Force: 4.215763993900186, time: 0.7032830715179443
Validation Loss Energy: 2.8950351274715933, Validation Loss Force: 4.708389191200908, time: 0.06432986259460449
Test Loss Energy: 8.733548486722421, Test Loss Force: 10.616859776265288, time: 10.372633934020996


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0273037833093537, Training Loss Force: 4.210995544261467, time: 0.76261305809021
Validation Loss Energy: 1.8485110168434207, Validation Loss Force: 4.309022948544437, time: 0.06557059288024902
Test Loss Energy: 8.637697335230357, Test Loss Force: 10.652536815430215, time: 10.252968311309814


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.91030028921094, Training Loss Force: 4.206853812115948, time: 0.7326905727386475
Validation Loss Energy: 4.162079571102064, Validation Loss Force: 4.503719060345901, time: 0.06375265121459961
Test Loss Energy: 9.899005576842248, Test Loss Force: 10.78747588937035, time: 10.166231632232666


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9979914347555723, Training Loss Force: 4.2166654395735, time: 0.717099666595459
Validation Loss Energy: 2.359487663868303, Validation Loss Force: 4.259957579570104, time: 0.07459354400634766
Test Loss Energy: 8.690645220557633, Test Loss Force: 10.625298400624708, time: 10.296765089035034


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.943081380250315, Training Loss Force: 4.222243023342558, time: 0.7505795955657959
Validation Loss Energy: 1.8931623596707416, Validation Loss Force: 4.437595008102039, time: 0.06323528289794922
Test Loss Energy: 8.509017553935829, Test Loss Force: 10.652318184639894, time: 10.193305969238281


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9466292284803304, Training Loss Force: 4.240016236719381, time: 0.7622158527374268
Validation Loss Energy: 3.6182281070396884, Validation Loss Force: 4.339866187961771, time: 0.06680798530578613
Test Loss Energy: 9.268016182753536, Test Loss Force: 10.701420848947464, time: 10.747309684753418


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.057617738166816, Training Loss Force: 4.236082902651802, time: 0.8912677764892578
Validation Loss Energy: 2.358036306375146, Validation Loss Force: 4.4100991539554375, time: 0.06206631660461426
Test Loss Energy: 8.692223658013727, Test Loss Force: 10.666727214658744, time: 10.273277282714844


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.966854461840455, Training Loss Force: 4.218854398733867, time: 0.7062969207763672
Validation Loss Energy: 2.404347592018072, Validation Loss Force: 4.240377168222944, time: 0.06461977958679199
Test Loss Energy: 8.631301356371745, Test Loss Force: 10.613023109937687, time: 10.219168424606323


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9750908138948087, Training Loss Force: 4.212956940615359, time: 0.6877388954162598
Validation Loss Energy: 3.880540043028157, Validation Loss Force: 4.5391423814258225, time: 0.06407475471496582
Test Loss Energy: 9.686527804199605, Test Loss Force: 10.762648904471984, time: 10.383661031723022


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0191401352614773, Training Loss Force: 4.220771974811974, time: 0.7461252212524414
Validation Loss Energy: 2.1444115914839394, Validation Loss Force: 4.06753670110173, time: 0.06951904296875
Test Loss Energy: 8.731224042342275, Test Loss Force: 10.6229669310913, time: 10.266107082366943


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.111224272309826, Training Loss Force: 4.2277856936016684, time: 0.6825582981109619
Validation Loss Energy: 1.8499867566080572, Validation Loss Force: 4.295549238524346, time: 0.06191086769104004
Test Loss Energy: 8.788990970631545, Test Loss Force: 10.583217280242197, time: 10.274959087371826


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9980453055068996, Training Loss Force: 4.204612414371716, time: 0.7210891246795654
Validation Loss Energy: 3.74280637279593, Validation Loss Force: 4.269342638732668, time: 0.06389093399047852
Test Loss Energy: 9.86503585277082, Test Loss Force: 10.654943610088527, time: 10.275280714035034


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9333263082254986, Training Loss Force: 4.228071155446748, time: 0.722158670425415
Validation Loss Energy: 2.179634788668959, Validation Loss Force: 4.454365334827591, time: 0.06386542320251465
Test Loss Energy: 8.676347553091118, Test Loss Force: 10.693318751113381, time: 10.086014986038208


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.895776878881978, Training Loss Force: 4.232985321798827, time: 0.7649924755096436
Validation Loss Energy: 1.7663222763974527, Validation Loss Force: 4.1632577135531665, time: 0.06762099266052246
Test Loss Energy: 8.65726921869897, Test Loss Force: 10.648771412555766, time: 10.281675815582275


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.042140195608216, Training Loss Force: 4.236889076294634, time: 0.6880710124969482
Validation Loss Energy: 3.8110984431791173, Validation Loss Force: 4.167551220024946, time: 0.06602931022644043
Test Loss Energy: 9.843427777709207, Test Loss Force: 10.69521150413896, time: 10.46269154548645


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0720777459868063, Training Loss Force: 4.210917012902228, time: 0.7196311950683594
Validation Loss Energy: 2.5693597913104753, Validation Loss Force: 4.3826990475415855, time: 0.06248736381530762
Test Loss Energy: 8.5801093979602, Test Loss Force: 10.613733986432193, time: 10.175894498825073


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9886066033228165, Training Loss Force: 4.226679468224037, time: 0.7324056625366211
Validation Loss Energy: 2.3170255484164577, Validation Loss Force: 4.311497470763133, time: 0.06412434577941895
Test Loss Energy: 8.599594477767727, Test Loss Force: 10.586277808196813, time: 10.299237966537476


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9829647061255526, Training Loss Force: 4.204857831195165, time: 0.9357407093048096
Validation Loss Energy: 3.783205903949046, Validation Loss Force: 4.146420808752984, time: 0.06574130058288574
Test Loss Energy: 9.666619755605835, Test Loss Force: 10.709381716252674, time: 10.594200372695923

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‡â–‚â–‚â–ˆâ–‚â–â–…â–‚â–‚â–‡â–‚â–‚â–ˆâ–‚â–‚â–ˆâ–â–â–‡
wandb:   test_error_force â–…â–‡â–‚â–ƒâ–ˆâ–‚â–ƒâ–…â–„â–‚â–‡â–‚â–â–ƒâ–…â–ƒâ–…â–‚â–â–…
wandb:          test_loss â–„â–…â–‡â–„â–ˆâ–„â–„â–„â–ƒâ–ƒâ–†â–„â–‚â–…â–„â–…â–„â–‚â–â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‡â–„â–â–ˆâ–ƒâ–â–†â–ƒâ–ƒâ–‡â–‚â–â–‡â–‚â–â–‡â–ƒâ–ƒâ–‡
wandb:  valid_error_force â–‡â–‚â–ˆâ–„â–†â–ƒâ–…â–„â–…â–ƒâ–†â–â–ƒâ–ƒâ–…â–‚â–‚â–„â–„â–‚
wandb:         valid_loss â–„â–‡â–…â–‚â–ˆâ–ƒâ–‚â–†â–ƒâ–ƒâ–‡â–‚â–‚â–†â–ƒâ–â–†â–„â–ƒâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1399
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.66662
wandb:   test_error_force 10.70938
wandb:          test_loss 8.39959
wandb: train_error_energy 2.98296
wandb:  train_error_force 4.20486
wandb:         train_loss 1.38066
wandb: valid_error_energy 3.78321
wandb:  valid_error_force 4.14642
wandb:         valid_loss 1.69405
wandb: 
wandb: ğŸš€ View run al_72_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0oyotf19
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_164751-0oyotf19/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0115678310394287, Uncertainty Bias: 0.005932837724685669
0.00044250488 0.009210587
2.8451784 6.2950487
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 900 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2362 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1385 steps.
Found uncertainty sample 9 after 1128 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2119 steps.
Found uncertainty sample 12 after 3642 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2113 steps.
Found uncertainty sample 15 after 1202 steps.
Found uncertainty sample 16 after 3914 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 173 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2219 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3980 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 219 steps.
Found uncertainty sample 34 after 594 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1659 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3064 steps.
Found uncertainty sample 44 after 3523 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 534 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2779 steps.
Found uncertainty sample 54 after 2877 steps.
Found uncertainty sample 55 after 2971 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1260 steps.
Found uncertainty sample 59 after 2404 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 978 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 905 steps.
Found uncertainty sample 65 after 444 steps.
Found uncertainty sample 66 after 25 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 386 steps.
Found uncertainty sample 70 after 868 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 168 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2283 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1008 steps.
Found uncertainty sample 89 after 2991 steps.
Found uncertainty sample 90 after 1266 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 438 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1552 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_172320-whu6vsts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/whu6vsts
Training model 13. Added 36 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.594992445586535, Training Loss Force: 4.569539436408545, time: 0.6829192638397217
Validation Loss Energy: 3.386515699088336, Validation Loss Force: 4.396088588624515, time: 0.06373429298400879
Test Loss Energy: 9.028224409039705, Test Loss Force: 10.644321107367814, time: 9.325854539871216


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0551430759364604, Training Loss Force: 4.510207431433701, time: 0.7538087368011475
Validation Loss Energy: 3.307501997994152, Validation Loss Force: 4.386345922813591, time: 0.06072545051574707
Test Loss Energy: 9.69801230465068, Test Loss Force: 10.677953027189377, time: 9.39223051071167


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0224833263676647, Training Loss Force: 4.258729252441709, time: 0.6889133453369141
Validation Loss Energy: 2.5051068278998443, Validation Loss Force: 4.5127556422950885, time: 0.06090521812438965
Test Loss Energy: 8.742284809237685, Test Loss Force: 10.6378809560802, time: 9.531190872192383


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.003637609393391, Training Loss Force: 4.240668201744874, time: 0.7166240215301514
Validation Loss Energy: 3.0245664457098513, Validation Loss Force: 4.48897569085573, time: 0.06073641777038574
Test Loss Energy: 9.247270604387703, Test Loss Force: 10.717017304738928, time: 9.400501251220703


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0017384766182817, Training Loss Force: 4.251088177615678, time: 0.7264478206634521
Validation Loss Energy: 2.550161146214008, Validation Loss Force: 4.1947386774044375, time: 0.06148481369018555
Test Loss Energy: 8.739062555866315, Test Loss Force: 10.611834523021251, time: 9.390835762023926


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.903009290598917, Training Loss Force: 4.242024385496858, time: 0.7180864810943604
Validation Loss Energy: 3.4086873112866574, Validation Loss Force: 4.31082122456695, time: 0.06412410736083984
Test Loss Energy: 9.255732246441456, Test Loss Force: 10.612677513433521, time: 9.522944927215576


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0692822376473594, Training Loss Force: 4.24424726683964, time: 0.7242307662963867
Validation Loss Energy: 2.836056082782262, Validation Loss Force: 4.599911240710122, time: 0.06352090835571289
Test Loss Energy: 8.715916314987233, Test Loss Force: 10.56491289716901, time: 9.395009756088257


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9240052740333815, Training Loss Force: 4.227576255501374, time: 0.7118020057678223
Validation Loss Energy: 2.9490988620991407, Validation Loss Force: 4.1141738630397215, time: 0.06844615936279297
Test Loss Energy: 9.202470957205803, Test Loss Force: 10.71821976475922, time: 9.41094970703125


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.977878317278459, Training Loss Force: 4.2369656938238105, time: 0.6904504299163818
Validation Loss Energy: 2.296166682167953, Validation Loss Force: 4.285010975855022, time: 0.06210064888000488
Test Loss Energy: 8.70429257986895, Test Loss Force: 10.574879428243893, time: 9.73507046699524


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9377466818489095, Training Loss Force: 4.245808360636113, time: 0.7313940525054932
Validation Loss Energy: 3.1722282651515616, Validation Loss Force: 4.303453325197346, time: 0.06307458877563477
Test Loss Energy: 9.08082673283703, Test Loss Force: 10.674351196370043, time: 9.349667072296143


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.985349767697326, Training Loss Force: 4.250416102754829, time: 0.7021965980529785
Validation Loss Energy: 2.5092353365344917, Validation Loss Force: 4.3750953415464435, time: 0.06312394142150879
Test Loss Energy: 8.611681628181934, Test Loss Force: 10.654845416492595, time: 9.414868354797363


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.941222210739022, Training Loss Force: 4.239424391688535, time: 0.6929082870483398
Validation Loss Energy: 3.75141108793659, Validation Loss Force: 4.523715862995946, time: 0.066497802734375
Test Loss Energy: 9.374899592495492, Test Loss Force: 10.662869325979665, time: 10.04841947555542


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.003486624867843, Training Loss Force: 4.246834053893507, time: 0.7206339836120605
Validation Loss Energy: 2.6402272530354636, Validation Loss Force: 4.206902647508182, time: 0.0609128475189209
Test Loss Energy: 8.65858621692999, Test Loss Force: 10.557732374468609, time: 9.345174789428711


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.047388994044768, Training Loss Force: 4.239310978870209, time: 0.7013204097747803
Validation Loss Energy: 3.2637376020423474, Validation Loss Force: 4.376057272256852, time: 0.060787200927734375
Test Loss Energy: 9.05299035694434, Test Loss Force: 10.638192762832922, time: 9.400936126708984


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.985778000050571, Training Loss Force: 4.236704572190482, time: 0.6807382106781006
Validation Loss Energy: 2.243368710300432, Validation Loss Force: 4.22018775676167, time: 0.061244964599609375
Test Loss Energy: 8.7924670878138, Test Loss Force: 10.621004145704804, time: 9.596224784851074


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.923978449823602, Training Loss Force: 4.231438130204283, time: 0.7320172786712646
Validation Loss Energy: 3.0177702493724166, Validation Loss Force: 4.294984772239419, time: 0.062343597412109375
Test Loss Energy: 9.190812634924061, Test Loss Force: 10.664342570334316, time: 9.470499277114868


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0228330455800556, Training Loss Force: 4.229891485161277, time: 0.699566125869751
Validation Loss Energy: 2.4078736692784117, Validation Loss Force: 4.445886316419806, time: 0.06260275840759277
Test Loss Energy: 8.703379326265972, Test Loss Force: 10.529021559352756, time: 9.28866171836853


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9146045166960297, Training Loss Force: 4.2215822099175355, time: 0.6863999366760254
Validation Loss Energy: 3.4789936467639078, Validation Loss Force: 4.50820940634268, time: 0.06110525131225586
Test Loss Energy: 9.533774727599196, Test Loss Force: 10.652749178841848, time: 9.560481309890747


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0354441056396024, Training Loss Force: 4.235497665833926, time: 0.752387285232544
Validation Loss Energy: 2.5894720479126834, Validation Loss Force: 4.690026557412827, time: 0.061798095703125
Test Loss Energy: 8.639551173616718, Test Loss Force: 10.553033146160036, time: 9.482386827468872


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9637143675434148, Training Loss Force: 4.25269857036106, time: 0.7150661945343018
Validation Loss Energy: 3.1035116760416623, Validation Loss Force: 4.404439572273391, time: 0.062337398529052734
Test Loss Energy: 9.109182648308488, Test Loss Force: 10.767183516162325, time: 9.451473236083984

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–‚â–…â–‚â–…â–‚â–…â–‚â–„â–â–†â–â–„â–‚â–…â–‚â–‡â–â–„
wandb:   test_error_force â–„â–…â–„â–‡â–ƒâ–ƒâ–‚â–‡â–‚â–…â–…â–…â–‚â–„â–„â–…â–â–…â–‚â–ˆ
wandb:          test_loss â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–â–ƒâ–â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‡â–‚â–â–‚â–â–â–â–â–â–‚â–â–‚â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–†â–†â–‚â–…â–‚â–†â–„â–„â–â–…â–‚â–ˆâ–ƒâ–†â–â–…â–‚â–‡â–ƒâ–…
wandb:  valid_error_force â–„â–„â–†â–†â–‚â–ƒâ–‡â–â–ƒâ–ƒâ–„â–†â–‚â–„â–‚â–ƒâ–…â–†â–ˆâ–…
wandb:         valid_loss â–ˆâ–†â–ƒâ–…â–‚â–…â–…â–‚â–â–…â–‚â–‡â–‚â–…â–â–„â–‚â–†â–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1431
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.10918
wandb:   test_error_force 10.76718
wandb:          test_loss 8.06507
wandb: train_error_energy 2.96371
wandb:  train_error_force 4.2527
wandb:         train_loss 1.3915
wandb: valid_error_energy 3.10351
wandb:  valid_error_force 4.40444
wandb:         valid_loss 1.44499
wandb: 
wandb: ğŸš€ View run al_72_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/whu6vsts
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_172320-whu6vsts/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1322803497314453, Uncertainty Bias: -0.005586892366409302
0.0002593994 0.018035889
2.9324658 6.612795
(48745, 22, 3)
Found uncertainty sample 0 after 3618 steps.
Found uncertainty sample 1 after 3190 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1347 steps.
Found uncertainty sample 6 after 684 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3601 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2497 steps.
Found uncertainty sample 13 after 1088 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3542 steps.
Found uncertainty sample 16 after 460 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1133 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2842 steps.
Found uncertainty sample 26 after 113 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1167 steps.
Found uncertainty sample 30 after 874 steps.
Found uncertainty sample 31 after 3021 steps.
Found uncertainty sample 32 after 1070 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2372 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 601 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3087 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3422 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2815 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 790 steps.
Found uncertainty sample 57 after 1537 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3946 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 378 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1044 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 893 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3660 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2410 steps.
Found uncertainty sample 71 after 1032 steps.
Found uncertainty sample 72 after 582 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1122 steps.
Found uncertainty sample 76 after 2175 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1134 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3133 steps.
Found uncertainty sample 82 after 3811 steps.
Found uncertainty sample 83 after 3549 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 453 steps.
Found uncertainty sample 86 after 1742 steps.
Found uncertainty sample 87 after 362 steps.
Found uncertainty sample 88 after 762 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1809 steps.
Found uncertainty sample 91 after 2831 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 948 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_175801-x6j622rz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/x6j622rz
Training model 14. Added 44 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.131532952878349, Training Loss Force: 5.1261996807280745, time: 0.8839397430419922
Validation Loss Energy: 3.849301788545948, Validation Loss Force: 4.9294243909358775, time: 0.0744776725769043
Test Loss Energy: 9.32253294358751, Test Loss Force: 10.906929408411768, time: 11.382898807525635


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.894061733408561, Training Loss Force: 4.7322311414755065, time: 0.825087308883667
Validation Loss Energy: 6.323813764460741, Validation Loss Force: 4.641528549422317, time: 0.07296919822692871
Test Loss Energy: 10.077276570208577, Test Loss Force: 10.658952480106619, time: 11.50752305984497


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.347093558897127, Training Loss Force: 4.343548535396849, time: 0.817110538482666
Validation Loss Energy: 2.3921660310518007, Validation Loss Force: 4.253044815934775, time: 0.07303690910339355
Test Loss Energy: 8.808308461012874, Test Loss Force: 10.687130460780145, time: 11.645039081573486


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.254587864709718, Training Loss Force: 4.297354901353744, time: 0.9317631721496582
Validation Loss Energy: 6.116194603437067, Validation Loss Force: 4.250430234823291, time: 0.07394886016845703
Test Loss Energy: 10.809775721690901, Test Loss Force: 10.757066250899525, time: 11.928811311721802


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.334129712814874, Training Loss Force: 4.294792599085216, time: 0.8445844650268555
Validation Loss Energy: 2.203598664822853, Validation Loss Force: 4.276285908040988, time: 0.07067584991455078
Test Loss Energy: 8.613947332208221, Test Loss Force: 10.569153161232967, time: 11.541534185409546


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.23659030182702, Training Loss Force: 4.292111953006262, time: 0.8650929927825928
Validation Loss Energy: 5.396039610361437, Validation Loss Force: 4.373832139481595, time: 0.07121849060058594
Test Loss Energy: 9.897952559295662, Test Loss Force: 10.535821320145237, time: 11.452280521392822


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.459192576821842, Training Loss Force: 4.313987792809923, time: 0.8221547603607178
Validation Loss Energy: 3.3391229094036383, Validation Loss Force: 4.464005572831388, time: 0.07391500473022461
Test Loss Energy: 9.461326753864475, Test Loss Force: 10.709885177020647, time: 11.570074081420898


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.272459128200657, Training Loss Force: 4.362281729368822, time: 0.7491395473480225
Validation Loss Energy: 6.3612230716531935, Validation Loss Force: 4.224587476416058, time: 0.0690314769744873
Test Loss Energy: 10.985528702406658, Test Loss Force: 10.594887060075598, time: 11.67722773551941


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.391735997378927, Training Loss Force: 4.293395340513254, time: 0.8674736022949219
Validation Loss Energy: 1.9506688932980523, Validation Loss Force: 4.423252888412829, time: 0.06874966621398926
Test Loss Energy: 8.643054785192362, Test Loss Force: 10.447337595870922, time: 11.375335454940796


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.284624170504744, Training Loss Force: 4.28843839132118, time: 0.859182596206665
Validation Loss Energy: 5.462163662605299, Validation Loss Force: 4.382996978858837, time: 0.07311868667602539
Test Loss Energy: 9.821362930120227, Test Loss Force: 10.471635327686212, time: 11.529786109924316


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.346447397238812, Training Loss Force: 4.293321927463968, time: 0.8299379348754883
Validation Loss Energy: 3.0415018816071084, Validation Loss Force: 4.305512124120593, time: 0.06989192962646484
Test Loss Energy: 8.919587159176633, Test Loss Force: 10.512375424886084, time: 11.47330093383789


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.368538175696528, Training Loss Force: 4.292837941553393, time: 0.7918322086334229
Validation Loss Energy: 6.33916858342563, Validation Loss Force: 4.260815301120217, time: 0.07656240463256836
Test Loss Energy: 10.772834061673954, Test Loss Force: 10.599790090108852, time: 11.638998985290527


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.407539976315905, Training Loss Force: 4.270746257897192, time: 0.9213235378265381
Validation Loss Energy: 2.3264229657166213, Validation Loss Force: 4.389023741962519, time: 0.0688173770904541
Test Loss Energy: 8.710152320128659, Test Loss Force: 10.391809805196958, time: 11.52839183807373


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.30267791136077, Training Loss Force: 4.274507314034722, time: 0.8677651882171631
Validation Loss Energy: 5.359020642181797, Validation Loss Force: 4.479161548248962, time: 0.06951451301574707
Test Loss Energy: 9.907895932779368, Test Loss Force: 10.469491609046063, time: 10.993858575820923


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.453280452023562, Training Loss Force: 4.262101380019493, time: 0.836855411529541
Validation Loss Energy: 2.8278541761265847, Validation Loss Force: 4.454339282537517, time: 0.06952691078186035
Test Loss Energy: 8.911141138937307, Test Loss Force: 10.410981590681972, time: 11.866689205169678


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.346590462165071, Training Loss Force: 4.27245326377304, time: 0.8250937461853027
Validation Loss Energy: 5.8780078673987175, Validation Loss Force: 4.334395652384616, time: 0.07039761543273926
Test Loss Energy: 10.843861098484595, Test Loss Force: 10.484243003951946, time: 9.687954664230347


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.41756548276881, Training Loss Force: 4.266913018231312, time: 0.7553539276123047
Validation Loss Energy: 2.7343217787104717, Validation Loss Force: 4.515087210922098, time: 0.07930994033813477
Test Loss Energy: 8.835327293729511, Test Loss Force: 10.390406439316688, time: 11.390116453170776


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.409261685616336, Training Loss Force: 4.283095721080759, time: 0.8140180110931396
Validation Loss Energy: 4.851601079095824, Validation Loss Force: 4.328707791721037, time: 0.06797313690185547
Test Loss Energy: 9.66584105245735, Test Loss Force: 10.334240471875654, time: 8.225198745727539


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.498930734625534, Training Loss Force: 4.261313048952137, time: 0.7967433929443359
Validation Loss Energy: 2.9723000964282327, Validation Loss Force: 4.315134548592717, time: 0.056501150131225586
Test Loss Energy: 9.236250323639412, Test Loss Force: 10.514027378134546, time: 7.947537422180176


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.42835609008839, Training Loss Force: 4.294721064201769, time: 0.7729747295379639
Validation Loss Energy: 5.578323030623157, Validation Loss Force: 4.548265581672776, time: 0.055559396743774414
Test Loss Energy: 10.475799441233873, Test Loss Force: 10.489089091305809, time: 8.00180721282959

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–…â–‚â–‡â–â–…â–„â–ˆâ–â–…â–‚â–‡â–â–…â–‚â–ˆâ–‚â–„â–ƒâ–†
wandb:   test_error_force â–ˆâ–…â–…â–†â–„â–ƒâ–†â–„â–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–‚â–â–ƒâ–ƒ
wandb:          test_loss â–…â–ˆâ–‚â–„â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–â–ƒ
wandb: train_error_energy â–ˆâ–â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„
wandb:  train_error_force â–ˆâ–…â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–ˆâ–‚â–ˆâ–â–†â–ƒâ–ˆâ–â–‡â–ƒâ–ˆâ–‚â–†â–‚â–‡â–‚â–†â–ƒâ–‡
wandb:  valid_error_force â–ˆâ–…â–â–â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–â–ƒâ–„â–ƒâ–‚â–„â–‚â–‚â–„
wandb:         valid_loss â–ƒâ–ˆâ–â–…â–â–„â–‚â–…â–â–„â–‚â–…â–â–„â–‚â–„â–‚â–ƒâ–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1470
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.4758
wandb:   test_error_force 10.48909
wandb:          test_loss 7.06572
wandb: train_error_energy 4.42836
wandb:  train_error_force 4.29472
wandb:         train_loss 1.80933
wandb: valid_error_energy 5.57832
wandb:  valid_error_force 4.54827
wandb:         valid_loss 2.14462
wandb: 
wandb: ğŸš€ View run al_72_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/x6j622rz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_175801-x6j622rz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.122795581817627, Uncertainty Bias: -0.11181452870368958
0.00012207031 0.07230377
2.575714 6.114039
(48745, 22, 3)
Found uncertainty sample 0 after 3344 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3383 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 665 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1514 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1119 steps.
Found uncertainty sample 20 after 1599 steps.
Found uncertainty sample 21 after 3521 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3411 steps.
Found uncertainty sample 24 after 1042 steps.
Found uncertainty sample 25 after 3631 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3610 steps.
Found uncertainty sample 31 after 1879 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3247 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3391 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3951 steps.
Found uncertainty sample 42 after 3437 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1832 steps.
Found uncertainty sample 45 after 2591 steps.
Found uncertainty sample 46 after 2663 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1167 steps.
Found uncertainty sample 54 after 878 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1199 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2989 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1794 steps.
Found uncertainty sample 63 after 2149 steps.
Found uncertainty sample 64 after 2105 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1060 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 602 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2383 steps.
Found uncertainty sample 71 after 2760 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 415 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3025 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 838 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 733 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2942 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 562 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1057 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3456 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_183453-i4nbdbvq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/i4nbdbvq
Training model 15. Added 38 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.115048362420605, Training Loss Force: 4.711169168111402, time: 0.809718132019043
Validation Loss Energy: 1.993386076256558, Validation Loss Force: 4.267792416138718, time: 0.06797432899475098
Test Loss Energy: 8.740925175111352, Test Loss Force: 10.34072235905554, time: 10.557379961013794


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0176344519880707, Training Loss Force: 4.373709709352466, time: 0.7938559055328369
Validation Loss Energy: 2.5050961397808402, Validation Loss Force: 4.363400089994878, time: 0.0655829906463623
Test Loss Energy: 9.01522879415787, Test Loss Force: 10.442774958179172, time: 9.96775221824646


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.915359739374395, Training Loss Force: 4.30438103118626, time: 0.7516968250274658
Validation Loss Energy: 3.915684359668232, Validation Loss Force: 4.40084435624324, time: 0.06273603439331055
Test Loss Energy: 9.681881400939934, Test Loss Force: 10.4265032949256, time: 9.546828985214233


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0313821611298657, Training Loss Force: 4.302151814564114, time: 0.7409284114837646
Validation Loss Energy: 3.3145675126635865, Validation Loss Force: 4.251607486597811, time: 0.062418460845947266
Test Loss Energy: 9.236584122176263, Test Loss Force: 10.337136616373453, time: 9.232288837432861


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0341020197397803, Training Loss Force: 4.302902688087673, time: 0.7281620502471924
Validation Loss Energy: 2.0958381543202464, Validation Loss Force: 4.358509607542866, time: 0.06307053565979004
Test Loss Energy: 8.686855403352014, Test Loss Force: 10.327332608127344, time: 9.293431043624878


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9178726388572733, Training Loss Force: 4.313025644373995, time: 0.7121260166168213
Validation Loss Energy: 2.8194736888158736, Validation Loss Force: 4.296027977188092, time: 0.06151914596557617
Test Loss Energy: 8.828582614988376, Test Loss Force: 10.344488624627203, time: 9.376154899597168


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9491985657624613, Training Loss Force: 4.317700137754455, time: 0.7587265968322754
Validation Loss Energy: 2.7391805308091888, Validation Loss Force: 4.383848688342011, time: 0.06484794616699219
Test Loss Energy: 8.72849692121334, Test Loss Force: 10.271496307602987, time: 9.223954200744629


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9764246704516943, Training Loss Force: 4.322610835722333, time: 0.7235414981842041
Validation Loss Energy: 2.5825777658164677, Validation Loss Force: 4.430417045513911, time: 0.0620269775390625
Test Loss Energy: 9.149420142774371, Test Loss Force: 10.300992503610093, time: 9.215150117874146


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9457670447180577, Training Loss Force: 4.296456847438431, time: 0.711883544921875
Validation Loss Energy: 4.2999039790112565, Validation Loss Force: 4.388520287023576, time: 0.06524872779846191
Test Loss Energy: 9.906312594270451, Test Loss Force: 10.263268801573275, time: 9.435483932495117


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0073071114828154, Training Loss Force: 4.330122195611253, time: 0.7973432540893555
Validation Loss Energy: 3.1701612274699142, Validation Loss Force: 4.498973535507888, time: 0.06391143798828125
Test Loss Energy: 9.49422174373565, Test Loss Force: 10.285414752026883, time: 9.702527523040771


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.99905955054576, Training Loss Force: 4.314152108632677, time: 0.7035658359527588
Validation Loss Energy: 1.9702978465190246, Validation Loss Force: 4.430656860184075, time: 0.06198549270629883
Test Loss Energy: 8.763793739404814, Test Loss Force: 10.286526190496193, time: 9.233043670654297


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9388679018017623, Training Loss Force: 4.290782498528132, time: 0.7926154136657715
Validation Loss Energy: 3.4604382928300264, Validation Loss Force: 4.448227905158383, time: 0.06128835678100586
Test Loss Energy: 9.115899412965696, Test Loss Force: 10.17753566845536, time: 9.456177711486816


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9760680776585953, Training Loss Force: 4.301456973125426, time: 0.754457950592041
Validation Loss Energy: 2.4719394792718896, Validation Loss Force: 4.4959554779039825, time: 0.061736106872558594
Test Loss Energy: 8.780710958984063, Test Loss Force: 10.248101689200983, time: 9.270647525787354


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.986008715290815, Training Loss Force: 4.30332847413346, time: 0.738987922668457
Validation Loss Energy: 2.6666300243447054, Validation Loss Force: 4.393763254733591, time: 0.0605618953704834
Test Loss Energy: 9.035867295478077, Test Loss Force: 10.256731860321413, time: 9.31669569015503


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.057708668256627, Training Loss Force: 4.292010798388766, time: 0.7211112976074219
Validation Loss Energy: 4.278149871461549, Validation Loss Force: 4.415533394461805, time: 0.06267023086547852
Test Loss Energy: 9.686935468270937, Test Loss Force: 10.273958599339958, time: 9.450785160064697


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0247606203115627, Training Loss Force: 4.3047175458550955, time: 0.7283785343170166
Validation Loss Energy: 3.1588880452844545, Validation Loss Force: 4.352959133742324, time: 0.06503152847290039
Test Loss Energy: 9.450647014680992, Test Loss Force: 10.229786781221781, time: 9.20503854751587


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9955115024734162, Training Loss Force: 4.282366836598826, time: 0.77339768409729
Validation Loss Energy: 2.0162855938929174, Validation Loss Force: 4.311688075552047, time: 0.06439375877380371
Test Loss Energy: 8.835269740167229, Test Loss Force: 10.201044428693697, time: 9.23717188835144


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.998084994021015, Training Loss Force: 4.299477614973219, time: 0.7468400001525879
Validation Loss Energy: 3.422894827477153, Validation Loss Force: 4.518663054736552, time: 0.06201505661010742
Test Loss Energy: 9.261552724651443, Test Loss Force: 10.173195713899224, time: 9.429599523544312


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0124318537204475, Training Loss Force: 4.298958179969825, time: 0.759742021560669
Validation Loss Energy: 2.3876336005864403, Validation Loss Force: 4.367727219507693, time: 0.06215500831604004
Test Loss Energy: 8.95561145029173, Test Loss Force: 10.17083351835529, time: 9.535301685333252


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.050219648715741, Training Loss Force: 4.293525891371714, time: 0.7299447059631348
Validation Loss Energy: 2.636033391006487, Validation Loss Force: 4.324219449746571, time: 0.062250375747680664
Test Loss Energy: 9.170593343828177, Test Loss Force: 10.128044132886052, time: 9.372763395309448

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–‡â–„â–â–‚â–â–„â–ˆâ–†â–â–ƒâ–‚â–ƒâ–‡â–…â–‚â–„â–ƒâ–„
wandb:   test_error_force â–†â–ˆâ–ˆâ–†â–…â–†â–„â–…â–„â–…â–…â–‚â–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:          test_loss â–â–„â–†â–…â–…â–†â–†â–†â–‡â–†â–…â–‡â–‡â–…â–†â–†â–†â–ˆâ–†â–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ƒâ–‡â–…â–â–„â–ƒâ–ƒâ–ˆâ–…â–â–…â–ƒâ–ƒâ–ˆâ–…â–â–…â–‚â–ƒ
wandb:  valid_error_force â–â–„â–…â–â–„â–‚â–„â–†â–…â–‡â–†â–†â–‡â–…â–…â–„â–ƒâ–ˆâ–„â–ƒ
wandb:         valid_loss â–‚â–‚â–†â–„â–â–„â–ƒâ–ƒâ–ˆâ–…â–‚â–†â–ƒâ–ƒâ–ˆâ–„â–â–†â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1504
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.17059
wandb:   test_error_force 10.12804
wandb:          test_loss 7.9233
wandb: train_error_energy 3.05022
wandb:  train_error_force 4.29353
wandb:         train_loss 1.42606
wandb: valid_error_energy 2.63603
wandb:  valid_error_force 4.32422
wandb:         valid_loss 1.27868
wandb: 
wandb: ğŸš€ View run al_72_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/i4nbdbvq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_183453-i4nbdbvq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.107886791229248, Uncertainty Bias: -0.01829540729522705
0.000333786 0.023982048
2.8636868 6.4927087
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3154 steps.
Found uncertainty sample 2 after 3650 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2899 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 330 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3977 steps.
Found uncertainty sample 11 after 973 steps.
Found uncertainty sample 12 after 1948 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1468 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 513 steps.
Found uncertainty sample 17 after 1060 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 652 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2215 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3224 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3074 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3434 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 655 steps.
Found uncertainty sample 33 after 2961 steps.
Found uncertainty sample 34 after 1178 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 459 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2734 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1091 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2474 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2237 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3474 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1436 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1982 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 31 steps.
Found uncertainty sample 60 after 2393 steps.
Found uncertainty sample 61 after 1912 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1269 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1963 steps.
Found uncertainty sample 67 after 2118 steps.
Found uncertainty sample 68 after 152 steps.
Found uncertainty sample 69 after 1652 steps.
Found uncertainty sample 70 after 3332 steps.
Found uncertainty sample 71 after 2212 steps.
Found uncertainty sample 72 after 413 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2025 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 899 steps.
Found uncertainty sample 85 after 3326 steps.
Found uncertainty sample 86 after 1363 steps.
Found uncertainty sample 87 after 691 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3409 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 58 steps.
Found uncertainty sample 93 after 1405 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3323 steps.
Found uncertainty sample 99 after 2521 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_190837-xirnvzbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/xirnvzbd
Training model 16. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.4707112721985665, Training Loss Force: 4.732270743390565, time: 0.8175044059753418
Validation Loss Energy: 3.213483625167051, Validation Loss Force: 4.6002414590535325, time: 0.06876397132873535
Test Loss Energy: 9.482470930986045, Test Loss Force: 10.199729113888052, time: 10.430397987365723


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.258179080203163, Training Loss Force: 4.405413372612558, time: 0.7580976486206055
Validation Loss Energy: 3.3883039549992815, Validation Loss Force: 4.391370897429743, time: 0.074432373046875
Test Loss Energy: 9.353499049741114, Test Loss Force: 10.142134687735872, time: 10.362079858779907


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.369622102129661, Training Loss Force: 4.403175161433179, time: 0.8455119132995605
Validation Loss Energy: 6.0415191653129945, Validation Loss Force: 4.501564068351612, time: 0.07532119750976562
Test Loss Energy: 10.232932352468845, Test Loss Force: 10.058546121965636, time: 10.910749197006226


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.4694698100527, Training Loss Force: 4.369689048290024, time: 0.8632769584655762
Validation Loss Energy: 4.538399557155008, Validation Loss Force: 4.504224073968865, time: 0.07490062713623047
Test Loss Energy: 9.952160315977057, Test Loss Force: 10.083370826545423, time: 10.404875755310059


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.445164170841818, Training Loss Force: 4.3615350586712704, time: 0.7794632911682129
Validation Loss Energy: 2.268042567026117, Validation Loss Force: 4.401657766633315, time: 0.06665968894958496
Test Loss Energy: 8.999048329657953, Test Loss Force: 10.071929945930808, time: 10.304907083511353


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.458498055998938, Training Loss Force: 4.399340444287376, time: 0.7616353034973145
Validation Loss Energy: 4.14304447649328, Validation Loss Force: 4.512023283474132, time: 0.06456661224365234
Test Loss Energy: 9.753061298370547, Test Loss Force: 10.075868424519417, time: 10.520527839660645


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.457465157450734, Training Loss Force: 4.40124585143469, time: 0.7878518104553223
Validation Loss Energy: 6.317699715051856, Validation Loss Force: 4.498276358411988, time: 0.07201170921325684
Test Loss Energy: 11.224934617304159, Test Loss Force: 10.068105576535936, time: 10.280983924865723


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.430125676120062, Training Loss Force: 4.369877553626991, time: 0.7955656051635742
Validation Loss Energy: 5.205144460880961, Validation Loss Force: 4.585860372263786, time: 0.06823587417602539
Test Loss Energy: 10.3738008842617, Test Loss Force: 10.081220117726225, time: 10.501479148864746


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.525671493396337, Training Loss Force: 4.37720348667899, time: 0.7857663631439209
Validation Loss Energy: 2.856739819747494, Validation Loss Force: 4.437455839885834, time: 0.06968474388122559
Test Loss Energy: 9.528308039185296, Test Loss Force: 10.08943013198701, time: 10.467846155166626


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.399942973363452, Training Loss Force: 4.369628268701722, time: 0.89571213722229
Validation Loss Energy: 3.619885990165694, Validation Loss Force: 4.514438353030864, time: 0.06542134284973145
Test Loss Energy: 9.435457094459636, Test Loss Force: 10.020125169387073, time: 10.416495323181152


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.364135956990951, Training Loss Force: 4.355149998190449, time: 0.8016347885131836
Validation Loss Energy: 5.370480532446116, Validation Loss Force: 4.459105738275246, time: 0.0669858455657959
Test Loss Energy: 10.158194645092983, Test Loss Force: 10.022102825808254, time: 10.535446643829346


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.419951113962866, Training Loss Force: 4.389304273276509, time: 0.8709235191345215
Validation Loss Energy: 4.897468696465489, Validation Loss Force: 4.567397314690892, time: 0.07000899314880371
Test Loss Energy: 10.00646981963426, Test Loss Force: 10.030167086208827, time: 10.307795763015747


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.497257865194246, Training Loss Force: 4.3427339847905895, time: 0.8214640617370605
Validation Loss Energy: 2.193613623646587, Validation Loss Force: 4.647708731567542, time: 0.07738137245178223
Test Loss Energy: 8.979929872850487, Test Loss Force: 10.028495449474187, time: 10.429832220077515


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.317577276838362, Training Loss Force: 4.360188773749381, time: 0.773787260055542
Validation Loss Energy: 4.3555875203408565, Validation Loss Force: 4.5501729655767935, time: 0.06429195404052734
Test Loss Energy: 10.02448040534198, Test Loss Force: 9.997004473672, time: 10.57651662826538


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.480759340243312, Training Loss Force: 4.495142144766469, time: 0.7875616550445557
Validation Loss Energy: 6.082399216483022, Validation Loss Force: 4.466211556060095, time: 0.06654834747314453
Test Loss Energy: 10.882497310339495, Test Loss Force: 10.068753667326135, time: 10.528605937957764


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.538463524547511, Training Loss Force: 4.3560112006500695, time: 0.8064138889312744
Validation Loss Energy: 6.084517468068233, Validation Loss Force: 4.3846384958026166, time: 0.06554341316223145
Test Loss Energy: 10.819513782563991, Test Loss Force: 10.06985210005203, time: 11.028481245040894


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.398638377558803, Training Loss Force: 4.38139115714243, time: 0.7482495307922363
Validation Loss Energy: 2.9681840572657574, Validation Loss Force: 4.503825941535946, time: 0.06799960136413574
Test Loss Energy: 9.443232491190168, Test Loss Force: 9.96491182018976, time: 10.477554321289062


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.4394184002953585, Training Loss Force: 4.341083638333533, time: 0.8131895065307617
Validation Loss Energy: 3.423535891948279, Validation Loss Force: 4.318587256369473, time: 0.06911635398864746
Test Loss Energy: 9.358035829832566, Test Loss Force: 10.003388987984113, time: 10.306344032287598


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.327180554036069, Training Loss Force: 4.378866016319316, time: 0.7842562198638916
Validation Loss Energy: 5.118473390527466, Validation Loss Force: 4.744055221649891, time: 0.06864666938781738
Test Loss Energy: 10.270951497990675, Test Loss Force: 10.184767444696766, time: 10.616161823272705


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.165515671989886, Training Loss Force: 5.508845840064914, time: 0.8441402912139893
Validation Loss Energy: 6.685246759424392, Validation Loss Force: 5.536005650116163, time: 0.06965255737304688
Test Loss Energy: 12.001068271100042, Test Loss Force: 10.812964385829643, time: 10.294485330581665

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–„â–ƒâ–â–ƒâ–†â–„â–‚â–‚â–„â–ƒâ–â–ƒâ–…â–…â–‚â–‚â–„â–ˆ
wandb:   test_error_force â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–ƒâ–ˆ
wandb:          test_loss â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–ƒâ–â–‚â–…â–ˆ
wandb: train_error_energy â–ˆâ–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–
wandb:  train_error_force â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–ˆ
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–ƒâ–ƒâ–‡â–…â–â–„â–‡â–†â–‚â–ƒâ–†â–…â–â–„â–‡â–‡â–‚â–ƒâ–†â–ˆ
wandb:  valid_error_force â–ƒâ–â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–ƒâ–ˆ
wandb:         valid_loss â–‚â–‚â–…â–ƒâ–â–‚â–…â–„â–â–‚â–„â–ƒâ–â–ƒâ–„â–„â–â–‚â–„â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1546
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.00107
wandb:   test_error_force 10.81296
wandb:          test_loss 9.47859
wandb: train_error_energy 3.16552
wandb:  train_error_force 5.50885
wandb:         train_loss 1.95311
wandb: valid_error_energy 6.68525
wandb:  valid_error_force 5.53601
wandb:         valid_loss 3.32796
wandb: 
wandb: ğŸš€ View run al_72_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/xirnvzbd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_190837-xirnvzbd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9243054389953613, Uncertainty Bias: 0.04295650124549866
0.00024414062 0.07826519
3.8222156 7.379259
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 19 steps.
Found uncertainty sample 2 after 856 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 57 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 99 steps.
Found uncertainty sample 7 after 216 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 141 steps.
Found uncertainty sample 10 after 369 steps.
Found uncertainty sample 11 after 1204 steps.
Found uncertainty sample 12 after 608 steps.
Found uncertainty sample 13 after 3033 steps.
Found uncertainty sample 14 after 1303 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1872 steps.
Found uncertainty sample 18 after 1759 steps.
Found uncertainty sample 19 after 1148 steps.
Found uncertainty sample 20 after 1895 steps.
Found uncertainty sample 21 after 1953 steps.
Found uncertainty sample 22 after 2278 steps.
Found uncertainty sample 23 after 150 steps.
Found uncertainty sample 24 after 3784 steps.
Found uncertainty sample 25 after 226 steps.
Found uncertainty sample 26 after 2080 steps.
Found uncertainty sample 27 after 791 steps.
Found uncertainty sample 28 after 461 steps.
Found uncertainty sample 29 after 159 steps.
Found uncertainty sample 30 after 2397 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 618 steps.
Found uncertainty sample 33 after 1706 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 927 steps.
Found uncertainty sample 36 after 75 steps.
Found uncertainty sample 37 after 89 steps.
Found uncertainty sample 38 after 1278 steps.
Found uncertainty sample 39 after 3463 steps.
Found uncertainty sample 40 after 20 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 460 steps.
Found uncertainty sample 43 after 472 steps.
Found uncertainty sample 44 after 56 steps.
Found uncertainty sample 45 after 1419 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2419 steps.
Found uncertainty sample 48 after 765 steps.
Found uncertainty sample 49 after 722 steps.
Found uncertainty sample 50 after 1249 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1854 steps.
Found uncertainty sample 53 after 96 steps.
Found uncertainty sample 54 after 1249 steps.
Found uncertainty sample 55 after 375 steps.
Found uncertainty sample 56 after 394 steps.
Found uncertainty sample 57 after 1595 steps.
Found uncertainty sample 58 after 554 steps.
Found uncertainty sample 59 after 17 steps.
Found uncertainty sample 60 after 863 steps.
Found uncertainty sample 61 after 1220 steps.
Found uncertainty sample 62 after 15 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 151 steps.
Found uncertainty sample 65 after 3067 steps.
Found uncertainty sample 66 after 129 steps.
Found uncertainty sample 67 after 352 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3459 steps.
Found uncertainty sample 70 after 1174 steps.
Found uncertainty sample 71 after 3526 steps.
Found uncertainty sample 72 after 3817 steps.
Found uncertainty sample 73 after 1138 steps.
Found uncertainty sample 74 after 445 steps.
Found uncertainty sample 75 after 87 steps.
Found uncertainty sample 76 after 96 steps.
Found uncertainty sample 77 after 1237 steps.
Found uncertainty sample 78 after 371 steps.
Found uncertainty sample 79 after 2467 steps.
Found uncertainty sample 80 after 935 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 527 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 188 steps.
Found uncertainty sample 85 after 2789 steps.
Found uncertainty sample 86 after 1875 steps.
Found uncertainty sample 87 after 2237 steps.
Found uncertainty sample 88 after 2707 steps.
Found uncertainty sample 89 after 2866 steps.
Found uncertainty sample 90 after 32 steps.
Found uncertainty sample 91 after 694 steps.
Found uncertainty sample 92 after 62 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 242 steps.
Found uncertainty sample 95 after 139 steps.
Found uncertainty sample 96 after 557 steps.
Found uncertainty sample 97 after 1372 steps.
Found uncertainty sample 98 after 879 steps.
Found uncertainty sample 99 after 249 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_192858-9fqav6wy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9fqav6wy
Training model 17. Added 86 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.585975466232762, Training Loss Force: 4.825132541799423, time: 0.8309001922607422
Validation Loss Energy: 2.3413957957616702, Validation Loss Force: 5.021741460153517, time: 0.07236337661743164
Test Loss Energy: 9.120267053107579, Test Loss Force: 10.535751390375344, time: 10.070980548858643


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.096901211968301, Training Loss Force: 4.521807444335308, time: 0.8569915294647217
Validation Loss Energy: 2.708434597808626, Validation Loss Force: 4.487837851520039, time: 0.06580710411071777
Test Loss Energy: 9.39723870318706, Test Loss Force: 10.094470731915006, time: 10.086961269378662


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0483574694816427, Training Loss Force: 4.3579131292936655, time: 0.8252239227294922
Validation Loss Energy: 2.612802987019278, Validation Loss Force: 4.376221824755692, time: 0.07594132423400879
Test Loss Energy: 8.978396514821275, Test Loss Force: 10.089274370839105, time: 10.433721542358398


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.102479202872612, Training Loss Force: 4.328170360090064, time: 0.8001234531402588
Validation Loss Energy: 3.143432468531034, Validation Loss Force: 4.359389596007573, time: 0.07010293006896973
Test Loss Energy: 9.45122902752778, Test Loss Force: 10.026900396936062, time: 10.344721555709839


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9890326850996107, Training Loss Force: 4.338711884207466, time: 0.844367265701294
Validation Loss Energy: 2.821055864432264, Validation Loss Force: 4.441405322527155, time: 0.07422089576721191
Test Loss Energy: 9.087713495477796, Test Loss Force: 10.051829306012918, time: 10.18945860862732


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.072842452561872, Training Loss Force: 4.336911543037776, time: 0.8085405826568604
Validation Loss Energy: 3.2408982050753887, Validation Loss Force: 4.374945485211234, time: 0.07004308700561523
Test Loss Energy: 9.455641126887196, Test Loss Force: 10.03437201232958, time: 10.46909236907959


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0343901521747405, Training Loss Force: 4.332249610816781, time: 0.8704733848571777
Validation Loss Energy: 2.615859455050856, Validation Loss Force: 4.41455164619741, time: 0.07442188262939453
Test Loss Energy: 9.005284338805225, Test Loss Force: 9.99296991392983, time: 10.14051866531372


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0958751809232665, Training Loss Force: 4.354669844031687, time: 0.8679683208465576
Validation Loss Energy: 3.020223395353103, Validation Loss Force: 4.274161421719691, time: 0.06343841552734375
Test Loss Energy: 9.638512334238005, Test Loss Force: 10.12771715665204, time: 10.169650554656982


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1273153570262777, Training Loss Force: 4.337706602870589, time: 0.8926589488983154
Validation Loss Energy: 2.394245649540193, Validation Loss Force: 4.441098707113213, time: 0.06944680213928223
Test Loss Energy: 8.976417524716831, Test Loss Force: 10.096409893387506, time: 10.64244818687439


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0493255781693347, Training Loss Force: 4.3432942274900075, time: 0.8169765472412109
Validation Loss Energy: 3.088658976000841, Validation Loss Force: 4.451450150369103, time: 0.06658458709716797
Test Loss Energy: 9.415461619663818, Test Loss Force: 10.110651625431919, time: 9.175709009170532


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1352510146913195, Training Loss Force: 4.3316235437675426, time: 0.8447847366333008
Validation Loss Energy: 2.1206034723976215, Validation Loss Force: 4.442794332659453, time: 0.06590032577514648
Test Loss Energy: 8.877777704478607, Test Loss Force: 10.071687276199187, time: 8.870151996612549


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.085297556024822, Training Loss Force: 4.324942308017301, time: 0.816408634185791
Validation Loss Energy: 3.085149153588154, Validation Loss Force: 4.474984497740504, time: 0.061988115310668945
Test Loss Energy: 9.332283557870879, Test Loss Force: 10.038883023422072, time: 8.800168752670288


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.053598319651741, Training Loss Force: 4.334051213778298, time: 0.8241682052612305
Validation Loss Energy: 2.427867911233278, Validation Loss Force: 4.348763156356461, time: 0.06456375122070312
Test Loss Energy: 8.994979583789943, Test Loss Force: 10.017932267679239, time: 8.618308544158936


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0249071906279843, Training Loss Force: 4.356297861112736, time: 0.8459932804107666
Validation Loss Energy: 3.1921783072809617, Validation Loss Force: 4.38647885629371, time: 0.0650644302368164
Test Loss Energy: 9.6540114498043, Test Loss Force: 10.075116702809218, time: 8.882189989089966


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.117279084482201, Training Loss Force: 4.336250102156767, time: 0.8234283924102783
Validation Loss Energy: 2.6354424270931944, Validation Loss Force: 4.4124897299061185, time: 0.06301641464233398
Test Loss Energy: 8.937816322047548, Test Loss Force: 10.020619429605839, time: 8.824317693710327


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.064745800738262, Training Loss Force: 4.350852286310235, time: 0.8785686492919922
Validation Loss Energy: 3.108779694030595, Validation Loss Force: 4.371353609218273, time: 0.06145596504211426
Test Loss Energy: 9.573942674679898, Test Loss Force: 10.120173004744071, time: 8.739970445632935


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.094926905070779, Training Loss Force: 4.333807587536282, time: 0.8032832145690918
Validation Loss Energy: 2.377839052864515, Validation Loss Force: 4.34462395960281, time: 0.06207156181335449
Test Loss Energy: 8.933172283044565, Test Loss Force: 10.025888439113666, time: 8.64454174041748


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.04975852994419, Training Loss Force: 4.324322785694528, time: 0.7943539619445801
Validation Loss Energy: 2.9957606289777576, Validation Loss Force: 4.277133386810389, time: 0.060897111892700195
Test Loss Energy: 9.523421628897298, Test Loss Force: 10.083167015494285, time: 8.87998342514038


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.037050622777562, Training Loss Force: 4.344946973944441, time: 0.8165078163146973
Validation Loss Energy: 2.413134895858393, Validation Loss Force: 4.455131539358728, time: 0.06208944320678711
Test Loss Energy: 8.798821104613575, Test Loss Force: 10.032114035272397, time: 8.712098360061646


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0454566755624692, Training Loss Force: 4.351282015931566, time: 0.834526777267456
Validation Loss Energy: 2.9668863414832902, Validation Loss Force: 4.413944650105611, time: 0.0634152889251709
Test Loss Energy: 9.460923468564406, Test Loss Force: 10.08039212891903, time: 8.733583211898804

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–†â–‚â–†â–ƒâ–†â–ƒâ–ˆâ–‚â–†â–‚â–…â–ƒâ–ˆâ–‚â–‡â–‚â–‡â–â–†
wandb:   test_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–ƒâ–â–‚â–‚â–‚
wandb:          test_loss â–â–‡â–‡â–†â–ˆâ–†â–‡â–…â–„â–ƒâ–„â–„â–†â–‡â–ƒâ–…â–„â–„â–„â–„
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–…â–„â–‡â–…â–ˆâ–„â–‡â–ƒâ–‡â–â–‡â–ƒâ–ˆâ–„â–‡â–ƒâ–†â–ƒâ–†
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚
wandb:         valid_loss â–ˆâ–…â–„â–‡â–‡â–ˆâ–…â–…â–ƒâ–‡â–â–ˆâ–‚â–ˆâ–„â–‡â–â–…â–ƒâ–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1623
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.46092
wandb:   test_error_force 10.08039
wandb:          test_loss 7.98599
wandb: train_error_energy 3.04546
wandb:  train_error_force 4.35128
wandb:         train_loss 1.45805
wandb: valid_error_energy 2.96689
wandb:  valid_error_force 4.41394
wandb:         valid_loss 1.44659
wandb: 
wandb: ğŸš€ View run al_72_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9fqav6wy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_192858-9fqav6wy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0858068466186523, Uncertainty Bias: -0.019744545221328735
7.343292e-05 0.034446716
2.8960176 7.0101514
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1381 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1840 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1244 steps.
Found uncertainty sample 12 after 1707 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1970 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 795 steps.
Found uncertainty sample 20 after 743 steps.
Found uncertainty sample 21 after 1347 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1700 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3642 steps.
Found uncertainty sample 28 after 677 steps.
Found uncertainty sample 29 after 3530 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1986 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3521 steps.
Found uncertainty sample 34 after 633 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3344 steps.
Found uncertainty sample 38 after 982 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 928 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1826 steps.
Found uncertainty sample 47 after 975 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1659 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3504 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2429 steps.
Found uncertainty sample 65 after 1641 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1487 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1690 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 428 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 15 steps.
Found uncertainty sample 80 after 3819 steps.
Found uncertainty sample 81 after 303 steps.
Found uncertainty sample 82 after 3868 steps.
Found uncertainty sample 83 after 171 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1549 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3448 steps.
Found uncertainty sample 88 after 340 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2044 steps.
Found uncertainty sample 92 after 3364 steps.
Found uncertainty sample 93 after 1859 steps.
Found uncertainty sample 94 after 146 steps.
Found uncertainty sample 95 after 767 steps.
Found uncertainty sample 96 after 3221 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_200335-luxi9kft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/luxi9kft
Training model 18. Added 41 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.322288405104749, Training Loss Force: 4.736781151632702, time: 0.8283934593200684
Validation Loss Energy: 2.785330603990463, Validation Loss Force: 5.1269969427644355, time: 0.06567716598510742
Test Loss Energy: 9.344711863064402, Test Loss Force: 10.445062686632188, time: 9.68608021736145


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2238641456311035, Training Loss Force: 4.551747964395326, time: 0.7877066135406494
Validation Loss Energy: 2.214003548673767, Validation Loss Force: 4.457727193592808, time: 0.06484127044677734
Test Loss Energy: 9.03412275383396, Test Loss Force: 10.020228679063141, time: 9.649577617645264


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.223155805103214, Training Loss Force: 4.37710683184038, time: 0.829686164855957
Validation Loss Energy: 2.1178179370493515, Validation Loss Force: 4.5168783615319406, time: 0.06543779373168945
Test Loss Energy: 8.882955594507658, Test Loss Force: 10.06314791678447, time: 9.98172378540039


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2220047490690833, Training Loss Force: 4.372399777379425, time: 0.8302903175354004
Validation Loss Energy: 2.255610057932385, Validation Loss Force: 4.358923549485146, time: 0.06485772132873535
Test Loss Energy: 8.928913907002334, Test Loss Force: 10.070733865206675, time: 10.289935111999512


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.226952746533278, Training Loss Force: 4.370442729691669, time: 0.8422703742980957
Validation Loss Energy: 2.099433927023261, Validation Loss Force: 4.489394308850074, time: 0.0748136043548584
Test Loss Energy: 9.01449231187739, Test Loss Force: 10.099847359402931, time: 10.958153247833252


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.177599102374848, Training Loss Force: 4.381307862103016, time: 0.9299490451812744
Validation Loss Energy: 2.49013566787339, Validation Loss Force: 4.442034808202693, time: 0.07077264785766602
Test Loss Energy: 9.11846647811357, Test Loss Force: 10.058864657756631, time: 10.796974897384644


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.201849371730346, Training Loss Force: 4.375331721973241, time: 0.825800895690918
Validation Loss Energy: 2.1245922004759126, Validation Loss Force: 4.436201099248531, time: 0.06609797477722168
Test Loss Energy: 9.019640333929907, Test Loss Force: 10.101957987775863, time: 10.59338641166687


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.2175677926669652, Training Loss Force: 5.077143265064133, time: 0.9053194522857666
Validation Loss Energy: 3.838783788768903, Validation Loss Force: 6.649365407911296, time: 0.0715034008026123
Test Loss Energy: 9.24580777768482, Test Loss Force: 11.704855623902795, time: 10.765762090682983


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.455045499144321, Training Loss Force: 4.900558016760289, time: 0.8688113689422607
Validation Loss Energy: 4.195337434737838, Validation Loss Force: 4.514190299602301, time: 0.07477355003356934
Test Loss Energy: 10.287475800957733, Test Loss Force: 10.242008976392665, time: 10.539654970169067


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.574032928035222, Training Loss Force: 4.414354780979815, time: 0.8331964015960693
Validation Loss Energy: 2.8653790486057735, Validation Loss Force: 4.3751701583794755, time: 0.08054828643798828
Test Loss Energy: 9.015474364417425, Test Loss Force: 10.020104982272255, time: 10.529049396514893


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.47025944561762, Training Loss Force: 4.405985324356026, time: 0.8097751140594482
Validation Loss Energy: 3.939602588647211, Validation Loss Force: 4.27090087741587, time: 0.0660252571105957
Test Loss Energy: 10.103484169096898, Test Loss Force: 10.113285272151847, time: 10.768460273742676


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.45982662107099, Training Loss Force: 4.387532903516949, time: 0.8454256057739258
Validation Loss Energy: 3.3138500726754074, Validation Loss Force: 4.406811221346668, time: 0.07430219650268555
Test Loss Energy: 9.41666636932915, Test Loss Force: 10.069626679601472, time: 10.426564693450928


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.390756626051812, Training Loss Force: 4.385248712032834, time: 0.8401572704315186
Validation Loss Energy: 4.099277965184591, Validation Loss Force: 4.376078425825715, time: 0.07540559768676758
Test Loss Energy: 10.20533091933867, Test Loss Force: 10.099257922696872, time: 10.531318426132202


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.494742851709953, Training Loss Force: 4.382704580013442, time: 0.8628156185150146
Validation Loss Energy: 3.2840520422290584, Validation Loss Force: 4.4160266066200355, time: 0.06519222259521484
Test Loss Energy: 9.308542587521744, Test Loss Force: 9.989610221234102, time: 10.732132911682129


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.489383138994937, Training Loss Force: 4.370715662115189, time: 0.7845325469970703
Validation Loss Energy: 4.082645247991222, Validation Loss Force: 4.543579509496726, time: 0.07297611236572266
Test Loss Energy: 10.267097605698153, Test Loss Force: 9.939199973753226, time: 10.734689235687256


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.41881302836279, Training Loss Force: 4.3621814817086015, time: 0.885033369064331
Validation Loss Energy: 3.34750718208983, Validation Loss Force: 4.429233336334159, time: 0.07266998291015625
Test Loss Energy: 9.360177174889564, Test Loss Force: 10.000204735259238, time: 10.755966663360596


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.425851664297053, Training Loss Force: 4.36432560573573, time: 0.8702430725097656
Validation Loss Energy: 4.113433488129511, Validation Loss Force: 4.482065153911861, time: 0.07272934913635254
Test Loss Energy: 10.145406459927361, Test Loss Force: 10.039218635954688, time: 11.146909236907959


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.522326985608716, Training Loss Force: 4.367830666454372, time: 0.8521363735198975
Validation Loss Energy: 3.2262002600909874, Validation Loss Force: 4.341276797001223, time: 0.07968902587890625
Test Loss Energy: 9.403923501415047, Test Loss Force: 9.984846257991839, time: 10.604188919067383


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.367094573643122, Training Loss Force: 4.369521530306569, time: 0.8646962642669678
Validation Loss Energy: 3.7771625519939924, Validation Loss Force: 4.378577664319608, time: 0.07375121116638184
Test Loss Energy: 9.926772060270872, Test Loss Force: 10.010346575734584, time: 10.63895297050476


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.413523004667303, Training Loss Force: 4.362760781184326, time: 0.8730411529541016
Validation Loss Energy: 3.3297443076463056, Validation Loss Force: 4.554111314760818, time: 0.07182955741882324
Test Loss Energy: 9.222085511543941, Test Loss Force: 9.914231035525615, time: 10.513023614883423

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–â–â–‚â–‚â–‚â–ƒâ–ˆâ–‚â–‡â–„â–ˆâ–ƒâ–ˆâ–ƒâ–‡â–„â–†â–ƒ
wandb:   test_error_force â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:          test_loss â–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–â–
wandb: train_error_energy â–‡â–â–â–â–â–â–â–„â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:  train_error_force â–…â–ƒâ–â–â–â–â–â–ˆâ–†â–‚â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb: valid_error_energy â–ƒâ–â–â–‚â–â–‚â–â–‡â–ˆâ–„â–‡â–…â–ˆâ–…â–ˆâ–…â–ˆâ–…â–‡â–…
wandb:  valid_error_force â–„â–‚â–‚â–â–‚â–‚â–â–ˆâ–‚â–â–â–â–â–â–‚â–â–‚â–â–â–‚
wandb:         valid_loss â–ƒâ–â–â–â–â–‚â–â–ˆâ–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1659
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.22209
wandb:   test_error_force 9.91423
wandb:          test_loss 6.82322
wandb: train_error_energy 4.41352
wandb:  train_error_force 4.36276
wandb:         train_loss 1.82847
wandb: valid_error_energy 3.32974
wandb:  valid_error_force 4.55411
wandb:         valid_loss 1.60172
wandb: 
wandb: ğŸš€ View run al_72_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/luxi9kft
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_200335-luxi9kft/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1271555423736572, Uncertainty Bias: -0.0875149667263031
0.00013589859 0.00015449524
2.5105007 6.7188835
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2071 steps.
Found uncertainty sample 2 after 3043 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1548 steps.
Found uncertainty sample 6 after 3012 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 610 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2796 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1258 steps.
Found uncertainty sample 13 after 3316 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2302 steps.
Found uncertainty sample 19 after 1649 steps.
Found uncertainty sample 20 after 3638 steps.
Found uncertainty sample 21 after 1276 steps.
Found uncertainty sample 22 after 23 steps.
Found uncertainty sample 23 after 2680 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3404 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2401 steps.
Found uncertainty sample 32 after 1962 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1317 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3978 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 748 steps.
Found uncertainty sample 40 after 1059 steps.
Found uncertainty sample 41 after 513 steps.
Found uncertainty sample 42 after 1340 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 593 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3145 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1169 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1428 steps.
Found uncertainty sample 55 after 801 steps.
Found uncertainty sample 56 after 1956 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2804 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2957 steps.
Found uncertainty sample 63 after 3400 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3432 steps.
Found uncertainty sample 67 after 1470 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3834 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 29 steps.
Found uncertainty sample 72 after 3218 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 588 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 648 steps.
Found uncertainty sample 83 after 518 steps.
Found uncertainty sample 84 after 1966 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1363 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 524 steps.
Found uncertainty sample 89 after 1360 steps.
Found uncertainty sample 90 after 884 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1465 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1984 steps.
Found uncertainty sample 97 after 2228 steps.
Found uncertainty sample 98 after 53 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_203712-1gjdxjib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1gjdxjib
Training model 19. Added 49 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5354778816012478, Training Loss Force: 4.586016034490801, time: 0.8739068508148193
Validation Loss Energy: 1.8315658948383162, Validation Loss Force: 4.537574345300199, time: 0.07263064384460449
Test Loss Energy: 8.93590839720906, Test Loss Force: 10.09964420120374, time: 9.62051010131836


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.297894501961542, Training Loss Force: 4.454294154923941, time: 0.844447135925293
Validation Loss Energy: 2.326711990268035, Validation Loss Force: 4.431009568111225, time: 0.06542205810546875
Test Loss Energy: 9.078927059580822, Test Loss Force: 10.026491557731228, time: 9.581559181213379


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.324028610575714, Training Loss Force: 4.458929128654504, time: 0.8611836433410645
Validation Loss Energy: 2.261184802669833, Validation Loss Force: 4.8752478743859164, time: 0.06684017181396484
Test Loss Energy: 8.745881139779373, Test Loss Force: 10.176048364467723, time: 9.787977457046509


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.933340661482393, Training Loss Force: 4.6988976302105465, time: 0.812760591506958
Validation Loss Energy: 2.2947123186413263, Validation Loss Force: 4.615637026472125, time: 0.06534266471862793
Test Loss Energy: 9.407177987019647, Test Loss Force: 10.141790769993856, time: 9.634400129318237


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.7684610252568866, Training Loss Force: 5.093413776000472, time: 0.8856396675109863
Validation Loss Energy: 2.4701946438444, Validation Loss Force: 5.2127439361623304, time: 0.07031440734863281
Test Loss Energy: 9.041740402881384, Test Loss Force: 10.479255154461194, time: 9.672386407852173


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9416804312656697, Training Loss Force: 4.9925106504919015, time: 0.8371381759643555
Validation Loss Energy: 4.734603584412694, Validation Loss Force: 4.654812322660931, time: 0.06647396087646484
Test Loss Energy: 10.095699441246765, Test Loss Force: 10.116665245226956, time: 9.797025680541992


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1326774601274137, Training Loss Force: 4.5287917298824505, time: 0.8409805297851562
Validation Loss Energy: 3.6122360803227718, Validation Loss Force: 4.410513763905155, time: 0.07025361061096191
Test Loss Energy: 9.456698607143155, Test Loss Force: 10.0002669007542, time: 9.64171814918518


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.950576721344167, Training Loss Force: 4.384994609742998, time: 0.8502583503723145
Validation Loss Energy: 3.850620101224413, Validation Loss Force: 4.456870362719278, time: 0.06596803665161133
Test Loss Energy: 9.787133632115001, Test Loss Force: 10.103522878554076, time: 9.670090675354004


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9362921987407042, Training Loss Force: 4.358977567370547, time: 0.842383861541748
Validation Loss Energy: 4.259689485918406, Validation Loss Force: 4.316204696508046, time: 0.06722855567932129
Test Loss Energy: 10.032299916211157, Test Loss Force: 10.034159033371825, time: 9.796702861785889


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0042364578562006, Training Loss Force: 4.352175181655555, time: 0.8282723426818848
Validation Loss Energy: 4.426015767175502, Validation Loss Force: 4.345861332046731, time: 0.06626296043395996
Test Loss Energy: 10.29193473778106, Test Loss Force: 10.104326049660859, time: 9.670804977416992


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9763009352339616, Training Loss Force: 4.360942787523468, time: 0.8379180431365967
Validation Loss Energy: 4.234531435134901, Validation Loss Force: 4.443306026356795, time: 0.07252025604248047
Test Loss Energy: 10.08226798706889, Test Loss Force: 10.017553818732498, time: 9.677656173706055


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0100637403314017, Training Loss Force: 4.362488622710542, time: 0.8892760276794434
Validation Loss Energy: 3.8264472500770657, Validation Loss Force: 4.41074645316265, time: 0.0655965805053711
Test Loss Energy: 9.70990225880293, Test Loss Force: 10.087892096739926, time: 9.776594877243042


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.969391756984232, Training Loss Force: 4.367799859131298, time: 0.8303496837615967
Validation Loss Energy: 4.032965757512419, Validation Loss Force: 4.442238773140363, time: 0.0733487606048584
Test Loss Energy: 10.015590856143334, Test Loss Force: 10.084537207169232, time: 10.211738586425781


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9987345609792446, Training Loss Force: 4.354307576855037, time: 0.8591508865356445
Validation Loss Energy: 3.8788510975562946, Validation Loss Force: 4.316549165676797, time: 0.0670158863067627
Test Loss Energy: 9.560687509180404, Test Loss Force: 10.04723652055094, time: 9.81179141998291


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.003676762463901, Training Loss Force: 4.363130660328306, time: 0.9044415950775146
Validation Loss Energy: 4.0362220711024674, Validation Loss Force: 4.426883063498891, time: 0.06743168830871582
Test Loss Energy: 9.856674199655853, Test Loss Force: 10.055719473557504, time: 9.68263840675354


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9786727657413565, Training Loss Force: 4.360157944760116, time: 0.8284544944763184
Validation Loss Energy: 4.300674191587021, Validation Loss Force: 4.424105488572588, time: 0.06688809394836426
Test Loss Energy: 10.03746288857324, Test Loss Force: 10.032422451858226, time: 9.719181776046753


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0348925871531605, Training Loss Force: 4.38126067908194, time: 0.8682839870452881
Validation Loss Energy: 3.965242940800796, Validation Loss Force: 4.380556525019468, time: 0.0682528018951416
Test Loss Energy: 9.727120450124207, Test Loss Force: 10.041291436220567, time: 9.807660102844238


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0095271901597695, Training Loss Force: 4.338592908056319, time: 0.8319821357727051
Validation Loss Energy: 4.2073724794060885, Validation Loss Force: 4.392592905702595, time: 0.06684303283691406
Test Loss Energy: 9.782930944343775, Test Loss Force: 10.099826538089077, time: 9.633529901504517


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.112215850067504, Training Loss Force: 4.388626776480865, time: 0.8373963832855225
Validation Loss Energy: 3.7318754330877617, Validation Loss Force: 4.38837132136495, time: 0.0657961368560791
Test Loss Energy: 9.595049140275123, Test Loss Force: 10.12990948011958, time: 9.681270360946655


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.047671249866497, Training Loss Force: 4.367061422267359, time: 0.8398692607879639
Validation Loss Energy: 3.937509053337198, Validation Loss Force: 4.427038041224456, time: 0.06939578056335449
Test Loss Energy: 9.699211379167307, Test Loss Force: 10.059151101211244, time: 9.830737113952637

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–â–„â–‚â–‡â–„â–†â–‡â–ˆâ–‡â–…â–‡â–…â–†â–‡â–…â–†â–…â–…
wandb:   test_error_force â–‚â–â–„â–ƒâ–ˆâ–ƒâ–â–ƒâ–â–ƒâ–â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚
wandb:          test_loss â–ƒâ–„â–„â–†â–ˆâ–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–â–
wandb: train_error_energy â–‡â–â–â–„â–ˆâ–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–…â–…
wandb:  train_error_force â–ƒâ–‚â–‚â–„â–ˆâ–‡â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–„â–â–â–„â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–â–‚â–‚â–‚â–ƒâ–ˆâ–…â–†â–‡â–‡â–‡â–†â–†â–†â–†â–‡â–†â–‡â–†â–†
wandb:  valid_error_force â–ƒâ–‚â–…â–ƒâ–ˆâ–„â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         valid_loss â–â–â–‚â–‚â–„â–ˆâ–„â–…â–…â–†â–…â–„â–…â–„â–…â–†â–…â–…â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1703
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.69921
wandb:   test_error_force 10.05915
wandb:          test_loss 8.20179
wandb: train_error_energy 3.04767
wandb:  train_error_force 4.36706
wandb:         train_loss 1.46601
wandb: valid_error_energy 3.93751
wandb:  valid_error_force 4.42704
wandb:         valid_loss 1.79268
wandb: 
wandb: ğŸš€ View run al_72_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1gjdxjib
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_203712-1gjdxjib/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9511557817459106, Uncertainty Bias: -0.0038193464279174805
0.00051116943 0.033813477
2.8124654 7.064076
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3794 steps.
Found uncertainty sample 3 after 894 steps.
Found uncertainty sample 4 after 2227 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 276 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1204 steps.
Found uncertainty sample 10 after 2611 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2050 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1038 steps.
Found uncertainty sample 17 after 1571 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3034 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3652 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3855 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2329 steps.
Found uncertainty sample 44 after 327 steps.
Found uncertainty sample 45 after 1771 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1057 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3178 steps.
Found uncertainty sample 50 after 2365 steps.
Found uncertainty sample 51 after 3281 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 930 steps.
Found uncertainty sample 61 after 2870 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 755 steps.
Found uncertainty sample 69 after 422 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1946 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 930 steps.
Found uncertainty sample 74 after 2741 steps.
Found uncertainty sample 75 after 1507 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1405 steps.
Found uncertainty sample 78 after 3508 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1843 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1867 steps.
Found uncertainty sample 91 after 3023 steps.
Found uncertainty sample 92 after 2561 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2707 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 855 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_211407-xlnitnpj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/xlnitnpj
Training model 20. Added 35 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.172239144403438, Training Loss Force: 4.780693065270832, time: 1.0274426937103271
Validation Loss Energy: 2.2025932022944166, Validation Loss Force: 4.609261563485921, time: 0.07826709747314453
Test Loss Energy: 8.683761258185395, Test Loss Force: 10.204702320842294, time: 10.9547119140625


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.6208573925720304, Training Loss Force: 4.7814823585681365, time: 0.9224441051483154
Validation Loss Energy: 2.3167525560435505, Validation Loss Force: 4.535621091552121, time: 0.0789337158203125
Test Loss Energy: 8.950870943087248, Test Loss Force: 10.149630430672032, time: 10.622655630111694


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.069320618160895, Training Loss Force: 4.477406393118691, time: 1.0117230415344238
Validation Loss Energy: 2.870308164154604, Validation Loss Force: 4.479080942018137, time: 0.08101058006286621
Test Loss Energy: 9.276964866348822, Test Loss Force: 10.071628374963957, time: 11.398284196853638


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9790843779420957, Training Loss Force: 4.388534092510623, time: 0.9689459800720215
Validation Loss Energy: 2.6843470289441687, Validation Loss Force: 4.473162396119376, time: 0.0766599178314209
Test Loss Energy: 8.779110014457123, Test Loss Force: 10.046902017866634, time: 10.320167064666748


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.00336863856021, Training Loss Force: 4.380126785713418, time: 0.8557014465332031
Validation Loss Energy: 3.2399243615656736, Validation Loss Force: 4.295018617949601, time: 0.06726288795471191
Test Loss Energy: 9.132640593349272, Test Loss Force: 10.040553890724059, time: 9.93252444267273


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0286068866730194, Training Loss Force: 4.393400457869866, time: 0.8464558124542236
Validation Loss Energy: 2.248928536205103, Validation Loss Force: 4.450100998013927, time: 0.06873941421508789
Test Loss Energy: 8.794653169550411, Test Loss Force: 10.011913495017057, time: 9.739436626434326


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0031135710535497, Training Loss Force: 4.377110096512627, time: 0.840979814529419
Validation Loss Energy: 2.9165751386374907, Validation Loss Force: 4.486987923390032, time: 0.06621360778808594
Test Loss Energy: 9.38943682398366, Test Loss Force: 10.11458281539487, time: 9.753607749938965


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.041528875180389, Training Loss Force: 4.39867909312853, time: 0.8173260688781738
Validation Loss Energy: 3.732269112137762, Validation Loss Force: 4.494285236640378, time: 0.07484269142150879
Test Loss Energy: 9.841881022225417, Test Loss Force: 10.153764275205532, time: 10.316507339477539


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1498100914079536, Training Loss Force: 4.38516103551163, time: 0.8504834175109863
Validation Loss Energy: 2.925540355125408, Validation Loss Force: 4.335614097951133, time: 0.06794142723083496
Test Loss Energy: 9.361723785813284, Test Loss Force: 10.057620769617127, time: 9.785298347473145


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9535383018806316, Training Loss Force: 4.403638841879045, time: 0.8532500267028809
Validation Loss Energy: 2.5418420042530006, Validation Loss Force: 4.429319509293633, time: 0.07138490676879883
Test Loss Energy: 8.803753044329973, Test Loss Force: 10.045977542205023, time: 9.763057470321655


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0376975994915822, Training Loss Force: 4.414542447937419, time: 0.8364534378051758
Validation Loss Energy: 3.428244119704349, Validation Loss Force: 4.419916413930248, time: 0.06736254692077637
Test Loss Energy: 9.211559201894266, Test Loss Force: 10.042504943428433, time: 10.08884882926941


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0013208759295407, Training Loss Force: 4.384026159699846, time: 0.8551533222198486
Validation Loss Energy: 2.330975659074261, Validation Loss Force: 4.605060464709702, time: 0.07036638259887695
Test Loss Energy: 8.616091843597163, Test Loss Force: 10.029740405492948, time: 9.791070699691772


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9940754263718117, Training Loss Force: 4.415006984358182, time: 0.8502769470214844
Validation Loss Energy: 3.546651778088639, Validation Loss Force: 4.543327893361828, time: 0.07454347610473633
Test Loss Energy: 9.314590635930484, Test Loss Force: 10.074533528818614, time: 9.792997360229492


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.918012180528829, Training Loss Force: 4.413994592770777, time: 0.8416008949279785
Validation Loss Energy: 4.20255837247113, Validation Loss Force: 4.296149109203476, time: 0.0698854923248291
Test Loss Energy: 9.628687406750249, Test Loss Force: 10.088886301652614, time: 10.071430444717407


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.011983651136738, Training Loss Force: 4.3934894283635195, time: 0.8654241561889648
Validation Loss Energy: 2.2937273416743142, Validation Loss Force: 4.49802741430684, time: 0.06682395935058594
Test Loss Energy: 8.956723611561408, Test Loss Force: 9.98984462306215, time: 9.779762029647827


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.056065360742814, Training Loss Force: 4.390895883413531, time: 0.8856334686279297
Validation Loss Energy: 2.516034316236251, Validation Loss Force: 4.418470400496593, time: 0.06872940063476562
Test Loss Energy: 8.912437448756474, Test Loss Force: 10.00613066771145, time: 9.85700273513794


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0881116511916207, Training Loss Force: 4.374539652474395, time: 0.8492677211761475
Validation Loss Energy: 3.619047084158411, Validation Loss Force: 4.359000147671345, time: 0.06790804862976074
Test Loss Energy: 9.287897436438143, Test Loss Force: 10.026354248977261, time: 9.96572756767273


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.941123571906069, Training Loss Force: 4.389558022408318, time: 0.8313846588134766
Validation Loss Energy: 2.231101421712978, Validation Loss Force: 4.396675989831473, time: 0.07763552665710449
Test Loss Energy: 8.665299006185169, Test Loss Force: 10.012040609954205, time: 9.810869693756104


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.983818771347077, Training Loss Force: 4.401729781883639, time: 0.8480958938598633
Validation Loss Energy: 2.408445594979727, Validation Loss Force: 4.623877566224621, time: 0.06715512275695801
Test Loss Energy: 8.927166847214998, Test Loss Force: 10.121897279998487, time: 9.68910551071167


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1373676836585522, Training Loss Force: 4.679530326581193, time: 1.0899405479431152
Validation Loss Energy: 4.689397739744727, Validation Loss Force: 4.4945963054372395, time: 0.06667375564575195
Test Loss Energy: 9.925771895752561, Test Loss Force: 10.039534163963504, time: 9.815248250961304

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–…â–‚â–„â–‚â–…â–ˆâ–…â–‚â–„â–â–…â–†â–ƒâ–ƒâ–…â–â–ƒâ–ˆ
wandb:   test_error_force â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–…â–†â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–â–‚â–‚â–‚â–…â–ƒ
wandb:          test_loss â–†â–ˆâ–…â–„â–†â–ƒâ–ƒâ–„â–ƒâ–„â–…â–ƒâ–„â–ƒâ–â–„â–„â–‚â–‚â–ƒ
wandb: train_error_energy â–ˆâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–ˆâ–ƒâ–â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–†
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–â–â–ƒâ–‚â–„â–â–ƒâ–…â–ƒâ–‚â–„â–â–…â–‡â–â–‚â–…â–â–‚â–ˆ
wandb:  valid_error_force â–ˆâ–†â–…â–…â–â–„â–…â–…â–‚â–„â–„â–ˆâ–†â–â–…â–„â–‚â–ƒâ–ˆâ–…
wandb:         valid_loss â–‚â–â–‚â–‚â–ƒâ–â–ƒâ–…â–‚â–â–„â–‚â–…â–†â–â–‚â–„â–â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1734
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.92577
wandb:   test_error_force 10.03953
wandb:          test_loss 8.43042
wandb: train_error_energy 3.13737
wandb:  train_error_force 4.67953
wandb:         train_loss 1.64145
wandb: valid_error_energy 4.6894
wandb:  valid_error_force 4.4946
wandb:         valid_loss 2.20905
wandb: 
wandb: ğŸš€ View run al_72_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/xlnitnpj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_211407-xlnitnpj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.065364122390747, Uncertainty Bias: -0.008654981851577759
7.6293945e-06 0.016296387
2.958554 7.4811935
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3066 steps.
Found uncertainty sample 4 after 927 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1547 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 144 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3887 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1964 steps.
Found uncertainty sample 16 after 1595 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3939 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1527 steps.
Found uncertainty sample 22 after 3975 steps.
Found uncertainty sample 23 after 3915 steps.
Found uncertainty sample 24 after 1285 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 562 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1172 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2011 steps.
Found uncertainty sample 37 after 911 steps.
Found uncertainty sample 38 after 3272 steps.
Found uncertainty sample 39 after 1459 steps.
Found uncertainty sample 40 after 3069 steps.
Found uncertainty sample 41 after 349 steps.
Found uncertainty sample 42 after 1256 steps.
Found uncertainty sample 43 after 930 steps.
Found uncertainty sample 44 after 1939 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1226 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2382 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 592 steps.
Found uncertainty sample 56 after 2091 steps.
Found uncertainty sample 57 after 3005 steps.
Found uncertainty sample 58 after 2205 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1379 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3582 steps.
Found uncertainty sample 63 after 293 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1573 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1735 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2536 steps.
Found uncertainty sample 72 after 2603 steps.
Found uncertainty sample 73 after 732 steps.
Found uncertainty sample 74 after 180 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 990 steps.
Found uncertainty sample 77 after 3770 steps.
Found uncertainty sample 78 after 1466 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3012 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2283 steps.
Found uncertainty sample 84 after 2076 steps.
Found uncertainty sample 85 after 1979 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1991 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 883 steps.
Found uncertainty sample 94 after 2271 steps.
Found uncertainty sample 95 after 440 steps.
Found uncertainty sample 96 after 2317 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1481 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_214735-m66q4c0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/m66q4c0k
Training model 21. Added 51 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.1887702337358155, Training Loss Force: 4.833820995508306, time: 0.8902981281280518
Validation Loss Energy: 8.107988372631095, Validation Loss Force: 5.3441093801555954, time: 0.07800507545471191
Test Loss Energy: 12.297922615801642, Test Loss Force: 10.59927972309993, time: 9.724653244018555


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.395898900362705, Training Loss Force: 4.937451486407062, time: 0.9050188064575195
Validation Loss Energy: 8.221902344981416, Validation Loss Force: 4.8153035589489885, time: 0.06780624389648438
Test Loss Energy: 11.469471803938522, Test Loss Force: 10.146417219300115, time: 9.662545204162598


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.284950686200639, Training Loss Force: 4.553820667905627, time: 0.8743855953216553
Validation Loss Energy: 7.156551836401483, Validation Loss Force: 4.471475009331535, time: 0.06789374351501465
Test Loss Energy: 11.450223257054326, Test Loss Force: 10.111399513968545, time: 9.939387083053589


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.184182992867556, Training Loss Force: 4.56529173138959, time: 0.8908238410949707
Validation Loss Energy: 1.7285065423463961, Validation Loss Force: 4.562322684855197, time: 0.07304978370666504
Test Loss Energy: 8.837887853674065, Test Loss Force: 10.037869466112406, time: 9.729758977890015


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.297840315169787, Training Loss Force: 4.518912635039259, time: 0.8846480846405029
Validation Loss Energy: 4.383440981135817, Validation Loss Force: 4.4939552409661125, time: 0.07552647590637207
Test Loss Energy: 9.823775278683312, Test Loss Force: 9.938442292437408, time: 10.238009929656982


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.850531388447491, Training Loss Force: 4.7861055343737515, time: 0.8442015647888184
Validation Loss Energy: 4.010981410065822, Validation Loss Force: 5.559110691374215, time: 0.06731939315795898
Test Loss Energy: 9.63717665045164, Test Loss Force: 10.30318107784217, time: 9.932798385620117


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.7503907175075244, Training Loss Force: 4.892996601386206, time: 0.8776721954345703
Validation Loss Energy: 2.1145002781096003, Validation Loss Force: 4.829018419654119, time: 0.0688478946685791
Test Loss Energy: 8.976321504185234, Test Loss Force: 10.09321686913041, time: 9.725531101226807


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.261933159871301, Training Loss Force: 4.61212986813672, time: 0.8420250415802002
Validation Loss Energy: 2.4532847035643517, Validation Loss Force: 4.414745145685221, time: 0.07075047492980957
Test Loss Energy: 8.910043561913781, Test Loss Force: 9.92353430166578, time: 9.740638971328735


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.508191642508946, Training Loss Force: 4.454020690704511, time: 0.8705601692199707
Validation Loss Energy: 5.555343574763409, Validation Loss Force: 4.651986651199107, time: 0.0697636604309082
Test Loss Energy: 10.590324744146592, Test Loss Force: 10.141591127868717, time: 9.95062255859375


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.425288527756785, Training Loss Force: 4.504114870657726, time: 0.888390064239502
Validation Loss Energy: 6.355139082579009, Validation Loss Force: 4.368565346172965, time: 0.06931710243225098
Test Loss Energy: 10.726402018822608, Test Loss Force: 9.955873761163044, time: 9.852816820144653


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.401810668764342, Training Loss Force: 4.434997417441636, time: 0.8854711055755615
Validation Loss Energy: 6.220171297142922, Validation Loss Force: 4.521180997438703, time: 0.06925725936889648
Test Loss Energy: 10.927967002789893, Test Loss Force: 9.995255604552128, time: 11.147230386734009


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.345056552074178, Training Loss Force: 4.412321272744754, time: 0.9381864070892334
Validation Loss Energy: 6.2641580282369365, Validation Loss Force: 4.478004559366722, time: 0.07552838325500488
Test Loss Energy: 10.679892086070854, Test Loss Force: 9.96713789143969, time: 11.077749729156494


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.383308180859562, Training Loss Force: 4.405481592304108, time: 0.8904271125793457
Validation Loss Energy: 6.20349671815012, Validation Loss Force: 4.537911243717987, time: 0.07208395004272461
Test Loss Energy: 10.5620276692884, Test Loss Force: 9.958814257624129, time: 11.314048528671265


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.45843730935658, Training Loss Force: 4.413226661397036, time: 0.9613888263702393
Validation Loss Energy: 6.456319051812011, Validation Loss Force: 4.461854588881725, time: 0.08008980751037598
Test Loss Energy: 10.719790843641237, Test Loss Force: 9.963285104332245, time: 11.67642092704773


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.353522375346949, Training Loss Force: 4.4294768329977, time: 0.9675447940826416
Validation Loss Energy: 6.290397583062212, Validation Loss Force: 4.3991803497157225, time: 0.07882452011108398
Test Loss Energy: 10.683983989530041, Test Loss Force: 9.885035599083658, time: 11.445427417755127


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.490446488160574, Training Loss Force: 4.417480946289254, time: 0.9993972778320312
Validation Loss Energy: 6.15411181895138, Validation Loss Force: 4.55250965559416, time: 0.08646130561828613
Test Loss Energy: 10.549084422459103, Test Loss Force: 9.899921602734382, time: 11.553652286529541


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.462875499082161, Training Loss Force: 4.411719501425416, time: 1.0196375846862793
Validation Loss Energy: 6.368494777951757, Validation Loss Force: 4.525441771546032, time: 0.07877111434936523
Test Loss Energy: 10.726795739841663, Test Loss Force: 9.939844147431746, time: 11.804637432098389


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.461173439988097, Training Loss Force: 4.420194233452141, time: 0.9910323619842529
Validation Loss Energy: 6.122297074050364, Validation Loss Force: 4.500491025737386, time: 0.08003497123718262
Test Loss Energy: 10.620310537144277, Test Loss Force: 9.912403912773538, time: 11.40805721282959


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.451956317100145, Training Loss Force: 4.406810672626273, time: 1.032120704650879
Validation Loss Energy: 6.314064195906293, Validation Loss Force: 4.481912848216046, time: 0.07295012474060059
Test Loss Energy: 10.86909299148644, Test Loss Force: 9.914286714470169, time: 11.4683997631073


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.5322325761091475, Training Loss Force: 4.4323089300548775, time: 1.0002186298370361
Validation Loss Energy: 6.095851327595959, Validation Loss Force: 4.468955953283654, time: 0.07835173606872559
Test Loss Energy: 10.616560051936798, Test Loss Force: 9.898297008645695, time: 11.277044296264648

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–†â–â–ƒâ–ƒâ–â–â–…â–…â–…â–…â–„â–…â–…â–„â–…â–…â–…â–…
wandb:   test_error_force â–ˆâ–„â–ƒâ–‚â–‚â–…â–ƒâ–â–„â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–
wandb:          test_loss â–ˆâ–ƒâ–‚â–â–â–ƒâ–„â–„â–†â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: train_error_energy â–„â–ˆâ–ˆâ–ˆâ–ˆâ–…â–‚â–â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:  train_error_force â–‡â–ˆâ–ƒâ–ƒâ–‚â–†â–‡â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–†â–ˆâ–…â–…â–…â–„â–‚â–â–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb: valid_error_energy â–ˆâ–ˆâ–‡â–â–„â–ƒâ–â–‚â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:  valid_error_force â–‡â–„â–‚â–‚â–‚â–ˆâ–„â–â–ƒâ–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:         valid_loss â–ˆâ–„â–ƒâ–â–‚â–‚â–â–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1779
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.61656
wandb:   test_error_force 9.8983
wandb:          test_loss 6.97766
wandb: train_error_energy 4.53223
wandb:  train_error_force 4.43231
wandb:         train_loss 1.86838
wandb: valid_error_energy 6.09585
wandb:  valid_error_force 4.46896
wandb:         valid_loss 2.28846
wandb: 
wandb: ğŸš€ View run al_72_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/m66q4c0k
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_214735-m66q4c0k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.11047625541687, Uncertainty Bias: -0.12663760781288147
0.00019073486 0.4357314
2.4252229 6.821085
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1873 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 516 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1364 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1413 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3320 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 539 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1768 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1056 steps.
Found uncertainty sample 23 after 2470 steps.
Found uncertainty sample 24 after 2938 steps.
Found uncertainty sample 25 after 3208 steps.
Found uncertainty sample 26 after 2301 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 378 steps.
Found uncertainty sample 29 after 2600 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3224 steps.
Found uncertainty sample 37 after 694 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 812 steps.
Found uncertainty sample 41 after 1186 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2953 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1392 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1384 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2981 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1280 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3118 steps.
Found uncertainty sample 63 after 59 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 755 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1267 steps.
Found uncertainty sample 68 after 717 steps.
Found uncertainty sample 69 after 1340 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3748 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1084 steps.
Found uncertainty sample 75 after 3265 steps.
Found uncertainty sample 76 after 614 steps.
Found uncertainty sample 77 after 2424 steps.
Found uncertainty sample 78 after 2562 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1656 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1934 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1595 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1466 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2436 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_222249-x2gyuy0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/x2gyuy0h
Training model 22. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.838327540007804, Training Loss Force: 4.640519131586681, time: 0.8853867053985596
Validation Loss Energy: 5.0919775435152275, Validation Loss Force: 4.535613520801159, time: 0.06816363334655762
Test Loss Energy: 10.274907757468359, Test Loss Force: 9.783333632750633, time: 9.73928451538086


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.651679066979056, Training Loss Force: 4.456025305965148, time: 0.9201345443725586
Validation Loss Energy: 5.1324962026614145, Validation Loss Force: 4.569555201384079, time: 0.07513117790222168
Test Loss Energy: 10.152075263282665, Test Loss Force: 9.87812019023214, time: 10.214729070663452


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.471800489119262, Training Loss Force: 4.4786186457129045, time: 0.9933757781982422
Validation Loss Energy: 2.3749041621866134, Validation Loss Force: 4.547383366516611, time: 0.07018494606018066
Test Loss Energy: 9.15183963540304, Test Loss Force: 9.853438949867526, time: 9.86346435546875


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.466737336510774, Training Loss Force: 4.457140761191959, time: 0.8893122673034668
Validation Loss Energy: 4.108111918210984, Validation Loss Force: 4.4357940600497745, time: 0.0682229995727539
Test Loss Energy: 9.460791513196403, Test Loss Force: 9.78665774501529, time: 9.769970893859863


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.520859627263987, Training Loss Force: 4.463833094092248, time: 0.895810604095459
Validation Loss Energy: 5.718354089768494, Validation Loss Force: 4.554563333127051, time: 0.06869220733642578
Test Loss Energy: 10.21566108894757, Test Loss Force: 9.88667737250499, time: 9.768664598464966


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.442876806185923, Training Loss Force: 4.471668852589256, time: 0.926948070526123
Validation Loss Energy: 5.5283275726262815, Validation Loss Force: 4.420938910648349, time: 0.06993603706359863
Test Loss Energy: 10.226181191840528, Test Loss Force: 9.872190228750778, time: 9.925170421600342


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.556157214499508, Training Loss Force: 4.455691106922444, time: 0.88555908203125
Validation Loss Energy: 2.961102510417816, Validation Loss Force: 4.416010574441529, time: 0.06919360160827637
Test Loss Energy: 9.223247000441383, Test Loss Force: 9.826279893879306, time: 9.741946697235107


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.558397469244306, Training Loss Force: 4.468409636487358, time: 0.9005742073059082
Validation Loss Energy: 3.201526514699875, Validation Loss Force: 4.5999357343161735, time: 0.06779193878173828
Test Loss Energy: 9.238389752109626, Test Loss Force: 9.818669901852568, time: 9.827902793884277


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.5197475921571275, Training Loss Force: 4.4547883515141855, time: 0.9060120582580566
Validation Loss Energy: 5.716460956689815, Validation Loss Force: 4.493281221461389, time: 0.08238792419433594
Test Loss Energy: 10.318991920886303, Test Loss Force: 9.79957531611019, time: 9.933010816574097


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.502539601412302, Training Loss Force: 4.47343404075798, time: 0.9030482769012451
Validation Loss Energy: 5.028109575057906, Validation Loss Force: 4.425100374316592, time: 0.07009363174438477
Test Loss Energy: 10.111239919647073, Test Loss Force: 9.77894606663471, time: 9.736482858657837


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.463900162429648, Training Loss Force: 4.46875187896465, time: 0.8862411975860596
Validation Loss Energy: 2.0885464634658355, Validation Loss Force: 4.416605323730302, time: 0.06770873069763184
Test Loss Energy: 8.968612567782825, Test Loss Force: 9.788945114399738, time: 9.889436721801758


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.460393871471486, Training Loss Force: 4.472157334004755, time: 0.9430739879608154
Validation Loss Energy: 4.202876121342369, Validation Loss Force: 4.473018329181961, time: 0.06771278381347656
Test Loss Energy: 9.59492995282589, Test Loss Force: 9.797366792587928, time: 9.724349021911621


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.538757663832327, Training Loss Force: 4.424209182078018, time: 0.9024226665496826
Validation Loss Energy: 6.146158522397132, Validation Loss Force: 4.553507881375354, time: 0.07013225555419922
Test Loss Energy: 10.688527708505035, Test Loss Force: 9.916483034324264, time: 9.839203119277954


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.463323103618548, Training Loss Force: 4.454505577324763, time: 0.9730918407440186
Validation Loss Energy: 6.386339037968119, Validation Loss Force: 4.469970433912501, time: 0.06834578514099121
Test Loss Energy: 10.711080637535431, Test Loss Force: 9.936960612302965, time: 10.400419235229492


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.489147275011811, Training Loss Force: 4.47169925278739, time: 0.8940296173095703
Validation Loss Energy: 2.695283201377266, Validation Loss Force: 4.504101828607751, time: 0.06992983818054199
Test Loss Energy: 9.072218390287745, Test Loss Force: 9.743658868682987, time: 9.772793054580688


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.4615696231591295, Training Loss Force: 4.4341891350689755, time: 0.9101011753082275
Validation Loss Energy: 3.2852044663938083, Validation Loss Force: 4.571147285777462, time: 0.06807732582092285
Test Loss Energy: 9.34565236624129, Test Loss Force: 9.842407957684086, time: 9.708189249038696


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.457370626067129, Training Loss Force: 4.4625079939113075, time: 0.8743438720703125
Validation Loss Energy: 5.102982075376124, Validation Loss Force: 4.483962963042604, time: 0.06776642799377441
Test Loss Energy: 10.063505819547819, Test Loss Force: 9.801553970462203, time: 9.966286182403564


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.488074089811201, Training Loss Force: 4.542205406477777, time: 0.8722712993621826
Validation Loss Energy: 5.22190120478861, Validation Loss Force: 4.618207964431008, time: 0.06851005554199219
Test Loss Energy: 10.259451688161462, Test Loss Force: 9.918882251236775, time: 9.788358926773071


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.501995128472793, Training Loss Force: 4.492127412450811, time: 0.8931822776794434
Validation Loss Energy: 2.264407715887992, Validation Loss Force: 4.503279288782693, time: 0.06866598129272461
Test Loss Energy: 8.855174883569838, Test Loss Force: 9.78683362799282, time: 9.708815336227417


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.425907366366197, Training Loss Force: 4.443068618075998, time: 0.9013614654541016
Validation Loss Energy: 4.127683422792305, Validation Loss Force: 4.413813720647806, time: 0.07711362838745117
Test Loss Energy: 9.418037787433112, Test Loss Force: 9.872124817649, time: 9.80876898765564

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–†â–‚â–ƒâ–†â–†â–‚â–‚â–‡â–†â–â–„â–ˆâ–ˆâ–‚â–ƒâ–†â–†â–â–ƒ
wandb:   test_error_force â–‚â–†â–…â–ƒâ–†â–†â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–‡â–ˆâ–â–…â–ƒâ–‡â–ƒâ–†
wandb:          test_loss â–…â–…â–ƒâ–â–ƒâ–„â–â–‚â–†â–‡â–‚â–„â–„â–…â–â–ƒâ–‡â–ˆâ–‚â–‚
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–ƒâ–â–‚â–…â–ƒâ–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–
wandb: valid_error_energy â–†â–†â–â–„â–‡â–‡â–‚â–ƒâ–‡â–†â–â–„â–ˆâ–ˆâ–‚â–ƒâ–†â–†â–â–„
wandb:  valid_error_force â–…â–†â–†â–‚â–†â–â–â–‡â–„â–â–â–ƒâ–†â–ƒâ–„â–†â–ƒâ–ˆâ–„â–
wandb:         valid_loss â–†â–†â–‚â–„â–‡â–†â–‚â–ƒâ–‡â–…â–â–„â–‡â–ˆâ–‚â–ƒâ–†â–†â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1815
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.41804
wandb:   test_error_force 9.87212
wandb:          test_loss 6.58277
wandb: train_error_energy 4.42591
wandb:  train_error_force 4.44307
wandb:         train_loss 1.85323
wandb: valid_error_energy 4.12768
wandb:  valid_error_force 4.41381
wandb:         valid_loss 1.72134
wandb: 
wandb: ğŸš€ View run al_72_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/x2gyuy0h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_222249-x2gyuy0h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.2661027908325195, Uncertainty Bias: -0.15694621205329895
0.000154078 0.011012077
2.5195057 6.7341833
(48745, 22, 3)
Found uncertainty sample 0 after 409 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2736 steps.
Found uncertainty sample 6 after 760 steps.
Found uncertainty sample 7 after 3051 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 455 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3172 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1693 steps.
Found uncertainty sample 20 after 3723 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2328 steps.
Found uncertainty sample 25 after 574 steps.
Found uncertainty sample 26 after 2941 steps.
Found uncertainty sample 27 after 39 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3336 steps.
Found uncertainty sample 36 after 3063 steps.
Found uncertainty sample 37 after 2054 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1878 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 317 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1195 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 94 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3587 steps.
Found uncertainty sample 53 after 3600 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 94 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 40 steps.
Found uncertainty sample 62 after 836 steps.
Found uncertainty sample 63 after 583 steps.
Found uncertainty sample 64 after 2686 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3548 steps.
Found uncertainty sample 72 after 820 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2514 steps.
Found uncertainty sample 76 after 947 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2023 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1803 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1311 steps.
Found uncertainty sample 88 after 1575 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1400 steps.
Found uncertainty sample 92 after 1636 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1312 steps.
Found uncertainty sample 97 after 2215 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_225750-55kw03tu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/55kw03tu
Training model 23. Added 38 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.685500439736796, Training Loss Force: 4.789607854317025, time: 0.9744336605072021
Validation Loss Energy: 4.67515337181058, Validation Loss Force: 4.536797007311765, time: 0.07998824119567871
Test Loss Energy: 10.01776757644936, Test Loss Force: 9.788800339817447, time: 9.86778974533081


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.398940064752966, Training Loss Force: 4.460053671542447, time: 0.9435698986053467
Validation Loss Energy: 3.55679736371912, Validation Loss Force: 4.492067006608646, time: 0.07223939895629883
Test Loss Energy: 9.332927344501462, Test Loss Force: 9.864038402251312, time: 9.930525541305542


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.584789437328199, Training Loss Force: 4.456001891624188, time: 0.8874866962432861
Validation Loss Energy: 5.877174862123802, Validation Loss Force: 4.440273272589258, time: 0.0766439437866211
Test Loss Energy: 10.55596632135287, Test Loss Force: 9.83647906874521, time: 10.08876347541809


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.506287618048396, Training Loss Force: 4.464243721322081, time: 0.8964471817016602
Validation Loss Energy: 3.301994054000482, Validation Loss Force: 4.455490259352818, time: 0.07109928131103516
Test Loss Energy: 9.308721184498076, Test Loss Force: 9.78819789736797, time: 9.922497987747192


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.602247235846187, Training Loss Force: 4.449583921865851, time: 0.9163801670074463
Validation Loss Energy: 5.080805341787446, Validation Loss Force: 4.51586410357224, time: 0.07409048080444336
Test Loss Energy: 10.226280737772637, Test Loss Force: 9.771214294403867, time: 9.922674894332886


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.476417066564692, Training Loss Force: 4.477873821865076, time: 0.8958799839019775
Validation Loss Energy: 3.999214459049269, Validation Loss Force: 4.593352075678526, time: 0.06833004951477051
Test Loss Energy: 9.641987465147498, Test Loss Force: 9.905745494427403, time: 10.03825831413269


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.492082044454243, Training Loss Force: 4.4596538575735645, time: 0.9370343685150146
Validation Loss Energy: 5.364098166716388, Validation Loss Force: 4.682686714355609, time: 0.07038712501525879
Test Loss Energy: 10.38398005387868, Test Loss Force: 9.98328300866995, time: 9.897707223892212


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.5461541522095015, Training Loss Force: 4.487390931509423, time: 0.8922162055969238
Validation Loss Energy: 3.3514277177421805, Validation Loss Force: 4.463154531355652, time: 0.06931924819946289
Test Loss Energy: 9.360876943574532, Test Loss Force: 9.779722288945798, time: 9.893837451934814


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.47822191132701, Training Loss Force: 4.449306668066185, time: 1.1313045024871826
Validation Loss Energy: 5.167528516721088, Validation Loss Force: 4.509433418637846, time: 0.06964612007141113
Test Loss Energy: 10.248975153809454, Test Loss Force: 9.778438809998987, time: 9.977860927581787


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.459391430467719, Training Loss Force: 4.448150339513136, time: 0.9122376441955566
Validation Loss Energy: 4.234916207419064, Validation Loss Force: 4.4363816839258785, time: 0.07008743286132812
Test Loss Energy: 9.641912340541406, Test Loss Force: 9.790434064506925, time: 10.041869163513184


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.531154801501347, Training Loss Force: 4.436070039260536, time: 0.9697432518005371
Validation Loss Energy: 6.016557508716197, Validation Loss Force: 4.43284324852794, time: 0.07563352584838867
Test Loss Energy: 10.697366531107463, Test Loss Force: 9.754148655929498, time: 10.701687574386597


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.422279659162828, Training Loss Force: 4.463204954399835, time: 0.962183952331543
Validation Loss Energy: 3.983821118322135, Validation Loss Force: 4.489380726032173, time: 0.08171653747558594
Test Loss Energy: 9.60931099414916, Test Loss Force: 9.770010752514636, time: 11.042771100997925


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.489772009469293, Training Loss Force: 4.438249563252111, time: 0.9428606033325195
Validation Loss Energy: 4.994291698520123, Validation Loss Force: 4.548627641704055, time: 0.07186436653137207
Test Loss Energy: 10.208763633524574, Test Loss Force: 9.777105243318218, time: 10.576327323913574


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.392729797318739, Training Loss Force: 4.494359408500712, time: 0.9098036289215088
Validation Loss Energy: 3.965998679882075, Validation Loss Force: 4.479282234926056, time: 0.07286977767944336
Test Loss Energy: 9.498465351334215, Test Loss Force: 9.720992170874508, time: 10.778464794158936


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.5335297215075965, Training Loss Force: 4.465862433874019, time: 0.9594621658325195
Validation Loss Energy: 5.296081872070431, Validation Loss Force: 4.473700142106792, time: 0.0762321949005127
Test Loss Energy: 10.194506358940615, Test Loss Force: 9.79655494321349, time: 10.48755693435669


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.408072933831712, Training Loss Force: 4.4262143650189305, time: 1.0269455909729004
Validation Loss Energy: 3.333709154458696, Validation Loss Force: 4.444789002868674, time: 0.07683420181274414
Test Loss Energy: 9.548562985323894, Test Loss Force: 9.791980866623, time: 10.71519684791565


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.5434500043536294, Training Loss Force: 4.441876905065245, time: 0.9950306415557861
Validation Loss Energy: 4.953451950465507, Validation Loss Force: 4.39482137851504, time: 0.08480334281921387
Test Loss Energy: 10.26567024284563, Test Loss Force: 9.746436795683017, time: 10.620800256729126


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.4473957598470655, Training Loss Force: 4.4643828588253, time: 0.8984217643737793
Validation Loss Energy: 4.1478939878224415, Validation Loss Force: 4.692293106649226, time: 0.07129168510437012
Test Loss Energy: 9.626164315844179, Test Loss Force: 10.038586306875764, time: 10.533293724060059


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.482204721396879, Training Loss Force: 4.489223529293393, time: 0.9522218704223633
Validation Loss Energy: 5.84092365715932, Validation Loss Force: 4.475170203808208, time: 0.07146048545837402
Test Loss Energy: 10.468737136031239, Test Loss Force: 9.744610787442475, time: 10.756245613098145


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.4921426296575495, Training Loss Force: 4.432096899942022, time: 0.9520828723907471
Validation Loss Energy: 3.6311970261059607, Validation Loss Force: 4.401626592952885, time: 0.07458305358886719
Test Loss Energy: 9.654216855679477, Test Loss Force: 9.756388022042989, time: 10.543832778930664

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–‡â–â–†â–ƒâ–†â–â–†â–ƒâ–ˆâ–ƒâ–†â–‚â–…â–‚â–†â–ƒâ–‡â–ƒ
wandb:   test_error_force â–‚â–„â–„â–‚â–‚â–…â–‡â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–ƒâ–‚â–ˆâ–‚â–‚
wandb:          test_loss â–…â–â–…â–ƒâ–‡â–â–…â–ƒâ–‡â–‚â–†â–„â–ˆâ–‚â–ƒâ–†â–ˆâ–ƒâ–†â–ƒ
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‚â–ˆâ–â–†â–ƒâ–†â–â–†â–ƒâ–ˆâ–ƒâ–…â–ƒâ–†â–â–…â–ƒâ–ˆâ–‚
wandb:  valid_error_force â–„â–ƒâ–‚â–‚â–„â–†â–ˆâ–ƒâ–„â–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–‚â–â–ˆâ–ƒâ–
wandb:         valid_loss â–…â–‚â–‡â–â–†â–ƒâ–‡â–â–†â–ƒâ–ˆâ–ƒâ–†â–ƒâ–†â–â–…â–„â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1849
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.65422
wandb:   test_error_force 9.75639
wandb:          test_loss 6.89424
wandb: train_error_energy 4.49214
wandb:  train_error_force 4.4321
wandb:         train_loss 1.85379
wandb: valid_error_energy 3.6312
wandb:  valid_error_force 4.40163
wandb:         valid_loss 1.62705
wandb: 
wandb: ğŸš€ View run al_72_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/55kw03tu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_225750-55kw03tu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.2899746894836426, Uncertainty Bias: -0.15175431966781616
0.00024414062 0.042037964
2.3106341 6.7718434
(48745, 22, 3)
Found uncertainty sample 0 after 1693 steps.
Found uncertainty sample 1 after 1809 steps.
Found uncertainty sample 2 after 2879 steps.
Found uncertainty sample 3 after 1319 steps.
Found uncertainty sample 4 after 1647 steps.
Found uncertainty sample 5 after 2065 steps.
Found uncertainty sample 6 after 1942 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1427 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2760 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1813 steps.
Found uncertainty sample 18 after 1978 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2658 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 791 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3612 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1082 steps.
Found uncertainty sample 28 after 1698 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1977 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1170 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1941 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2568 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3498 steps.
Found uncertainty sample 47 after 2763 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3978 steps.
Found uncertainty sample 51 after 2049 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1246 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2256 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 644 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2531 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2681 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3500 steps.
Found uncertainty sample 73 after 719 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2482 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1361 steps.
Found uncertainty sample 81 after 1692 steps.
Found uncertainty sample 82 after 931 steps.
Found uncertainty sample 83 after 1438 steps.
Found uncertainty sample 84 after 2274 steps.
Found uncertainty sample 85 after 855 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2824 steps.
Found uncertainty sample 88 after 2831 steps.
Found uncertainty sample 89 after 573 steps.
Found uncertainty sample 90 after 2963 steps.
Found uncertainty sample 91 after 2691 steps.
Found uncertainty sample 92 after 2432 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 686 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3283 steps.
Found uncertainty sample 98 after 986 steps.
Found uncertainty sample 99 after 2967 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_233248-n4t2so34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/n4t2so34
Training model 24. Added 48 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.728726480953143, Training Loss Force: 4.8141625354445114, time: 0.945181131362915
Validation Loss Energy: 2.333923464562626, Validation Loss Force: 4.761803288595211, time: 0.07384824752807617
Test Loss Energy: 8.856969023308947, Test Loss Force: 10.021564983058854, time: 9.604300498962402


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.268007402001247, Training Loss Force: 4.587447364956032, time: 0.924633264541626
Validation Loss Energy: 2.3528644814572544, Validation Loss Force: 4.459112863687917, time: 0.06922173500061035
Test Loss Energy: 8.924171853937706, Test Loss Force: 9.79785550356515, time: 9.582480907440186


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.248701788502652, Training Loss Force: 4.504849573866691, time: 0.9269747734069824
Validation Loss Energy: 2.403676689881392, Validation Loss Force: 4.553950324968312, time: 0.07475781440734863
Test Loss Energy: 8.75926916531314, Test Loss Force: 9.812146390697883, time: 9.818320035934448


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.190137422419359, Training Loss Force: 4.474705693702886, time: 0.9298808574676514
Validation Loss Energy: 2.2798205401653946, Validation Loss Force: 4.38312857632408, time: 0.06890463829040527
Test Loss Energy: 8.932536822607915, Test Loss Force: 9.81826968029342, time: 9.893370866775513


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.227515934468929, Training Loss Force: 4.465190729360589, time: 0.9277925491333008
Validation Loss Energy: 2.6343546883153373, Validation Loss Force: 4.531161251228333, time: 0.06920361518859863
Test Loss Energy: 9.018891200311353, Test Loss Force: 9.802063120368567, time: 9.718658685684204


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2430208918166117, Training Loss Force: 4.510231680103692, time: 0.9197797775268555
Validation Loss Energy: 2.2192249174766276, Validation Loss Force: 4.553115093001937, time: 0.06907868385314941
Test Loss Energy: 8.81208949735982, Test Loss Force: 9.916861693116273, time: 9.835064888000488


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2038342524903975, Training Loss Force: 4.468858773046067, time: 0.9636054039001465
Validation Loss Energy: 2.2865951375956746, Validation Loss Force: 4.519752797536723, time: 0.06866908073425293
Test Loss Energy: 8.902182681215743, Test Loss Force: 9.874793965525113, time: 9.698407649993896


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.211267315985558, Training Loss Force: 4.452241731760571, time: 0.946202278137207
Validation Loss Energy: 2.42173872032247, Validation Loss Force: 4.568321168977346, time: 0.07094526290893555
Test Loss Energy: 8.81306610791256, Test Loss Force: 9.885826449941572, time: 9.661029815673828


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2311668047965276, Training Loss Force: 4.4833635228571564, time: 0.9569442272186279
Validation Loss Energy: 2.2612886778264087, Validation Loss Force: 4.595140776927764, time: 0.0799870491027832
Test Loss Energy: 8.810133830391155, Test Loss Force: 9.873491987552084, time: 9.841747283935547


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.21577284801809, Training Loss Force: 4.517073041166226, time: 0.9521548748016357
Validation Loss Energy: 2.712813275228723, Validation Loss Force: 4.563379027283479, time: 0.07419872283935547
Test Loss Energy: 8.899180469261216, Test Loss Force: 9.807811043411197, time: 10.238638877868652


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2790183931229513, Training Loss Force: 4.488225221610905, time: 0.9683747291564941
Validation Loss Energy: 2.348547594725152, Validation Loss Force: 4.609114156511317, time: 0.07201266288757324
Test Loss Energy: 8.730940107704427, Test Loss Force: 9.925132166130501, time: 9.88503122329712


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9605864858055857, Training Loss Force: 4.701575604403176, time: 0.9346561431884766
Validation Loss Energy: 4.279364086314294, Validation Loss Force: 4.527436219086107, time: 0.07076668739318848
Test Loss Energy: 9.759900318881131, Test Loss Force: 9.956108867138546, time: 9.672126054763794


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.110590951664315, Training Loss Force: 4.465550161895946, time: 0.9306159019470215
Validation Loss Energy: 3.850361025673126, Validation Loss Force: 4.46851328702155, time: 0.0778970718383789
Test Loss Energy: 9.606866082263647, Test Loss Force: 9.818963820461963, time: 9.634944915771484


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9990355317303385, Training Loss Force: 4.445881855614583, time: 0.9472451210021973
Validation Loss Energy: 4.552019783473119, Validation Loss Force: 4.4504897783427175, time: 0.07018375396728516
Test Loss Energy: 9.768045285771935, Test Loss Force: 9.824713301022808, time: 9.942338943481445


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0210188307763723, Training Loss Force: 4.461574626964551, time: 0.9651737213134766
Validation Loss Energy: 4.197904587321239, Validation Loss Force: 4.481147089023201, time: 0.06910061836242676
Test Loss Energy: 9.954668381961907, Test Loss Force: 9.951400582840835, time: 9.637884140014648


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9736449828136884, Training Loss Force: 4.452288076632144, time: 0.9036967754364014
Validation Loss Energy: 4.242883532129506, Validation Loss Force: 4.561486339543093, time: 0.0700688362121582
Test Loss Energy: 9.560781034884922, Test Loss Force: 9.879575350587883, time: 9.670214891433716


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.072181347867612, Training Loss Force: 4.436735334485745, time: 0.9362382888793945
Validation Loss Energy: 3.8727163399168383, Validation Loss Force: 4.449752966138842, time: 0.0692296028137207
Test Loss Energy: 9.513442143374514, Test Loss Force: 9.900303376562823, time: 9.80691409111023


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0743733029401255, Training Loss Force: 4.421745956412002, time: 0.9089622497558594
Validation Loss Energy: 3.9701652649406753, Validation Loss Force: 4.4407025787026075, time: 0.07575440406799316
Test Loss Energy: 9.635394970858243, Test Loss Force: 9.848651334731898, time: 9.706389904022217


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0251650861419503, Training Loss Force: 4.436516599161396, time: 0.9161562919616699
Validation Loss Energy: 4.143930699694073, Validation Loss Force: 4.470187536329782, time: 0.07296133041381836
Test Loss Energy: 9.6473787631513, Test Loss Force: 9.868947681010338, time: 9.701841831207275


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.048095189241079, Training Loss Force: 4.4286446733353735, time: 0.9158601760864258
Validation Loss Energy: 4.042496664965567, Validation Loss Force: 4.43733960659166, time: 0.07336187362670898
Test Loss Energy: 9.771090961344777, Test Loss Force: 9.850045756540505, time: 9.87671184539795

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–â–‚â–ƒâ–â–‚â–â–â–‚â–â–‡â–†â–‡â–ˆâ–†â–…â–†â–†â–‡
wandb:   test_error_force â–ˆâ–â–â–‚â–â–…â–ƒâ–„â–ƒâ–â–…â–†â–‚â–‚â–†â–„â–„â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–â–„â–…â–†â–†â–†â–‡â–†â–†â–ˆâ–‡â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–†â–‚â–â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb: valid_error_energy â–â–â–‚â–â–‚â–â–â–‚â–â–‚â–â–‡â–†â–ˆâ–‡â–‡â–†â–†â–‡â–†
wandb:  valid_error_force â–ˆâ–‚â–„â–â–„â–„â–„â–„â–…â–„â–…â–„â–ƒâ–‚â–ƒâ–„â–‚â–‚â–ƒâ–‚
wandb:         valid_loss â–‚â–â–‚â–â–‚â–â–â–‚â–‚â–ƒâ–‚â–‡â–…â–ˆâ–†â–‡â–…â–…â–†â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1892
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.77109
wandb:   test_error_force 9.85005
wandb:          test_loss 8.07688
wandb: train_error_energy 3.0481
wandb:  train_error_force 4.42864
wandb:         train_loss 1.47793
wandb: valid_error_energy 4.0425
wandb:  valid_error_force 4.43734
wandb:         valid_loss 1.85735
wandb: 
wandb: ğŸš€ View run al_72_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/n4t2so34
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_233248-n4t2so34/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.088503122329712, Uncertainty Bias: -0.01810288429260254
3.0517578e-05 0.103405
2.6230242 7.062104
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1568 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1455 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1346 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1320 steps.
Found uncertainty sample 15 after 1848 steps.
Found uncertainty sample 16 after 389 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 838 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 390 steps.
Found uncertainty sample 22 after 982 steps.
Found uncertainty sample 23 after 1078 steps.
Found uncertainty sample 24 after 1036 steps.
Found uncertainty sample 25 after 1324 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1096 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1208 steps.
Found uncertainty sample 34 after 774 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 37 steps.
Found uncertainty sample 37 after 1862 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 94 steps.
Found uncertainty sample 42 after 1851 steps.
Found uncertainty sample 43 after 1268 steps.
Found uncertainty sample 44 after 455 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 206 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 479 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 564 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 999 steps.
Found uncertainty sample 55 after 21 steps.
Found uncertainty sample 56 after 2225 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1818 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3293 steps.
Found uncertainty sample 64 after 1361 steps.
Found uncertainty sample 65 after 3710 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1068 steps.
Found uncertainty sample 68 after 2428 steps.
Found uncertainty sample 69 after 777 steps.
Found uncertainty sample 70 after 3907 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 43 steps.
Found uncertainty sample 75 after 735 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2028 steps.
Found uncertainty sample 78 after 3901 steps.
Found uncertainty sample 79 after 2713 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1349 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 647 steps.
Found uncertainty sample 85 after 2546 steps.
Found uncertainty sample 86 after 1235 steps.
Found uncertainty sample 87 after 558 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3316 steps.
Found uncertainty sample 91 after 2941 steps.
Found uncertainty sample 92 after 2468 steps.
Found uncertainty sample 93 after 1139 steps.
Found uncertainty sample 94 after 1850 steps.
Found uncertainty sample 95 after 3131 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3704 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_000412-2rvoeise
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2rvoeise
Training model 25. Added 52 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.500645179963654, Training Loss Force: 4.898991559957, time: 0.9707591533660889
Validation Loss Energy: 3.704581873860236, Validation Loss Force: 5.002911221158987, time: 0.07238221168518066
Test Loss Energy: 9.30169396542432, Test Loss Force: 9.734628695175134, time: 9.96129584312439


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.243099988441232, Training Loss Force: 4.740745591575493, time: 0.9574804306030273
Validation Loss Energy: 4.312289059576906, Validation Loss Force: 4.625251880193288, time: 0.07164764404296875
Test Loss Energy: 9.701825957947179, Test Loss Force: 9.770335961385166, time: 9.8800208568573


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.422264242880381, Training Loss Force: 4.496476487202315, time: 0.9740033149719238
Validation Loss Energy: 2.8490580682167046, Validation Loss Force: 4.594755781974455, time: 0.07066750526428223
Test Loss Energy: 9.128207630706948, Test Loss Force: 9.762421908227724, time: 10.130159378051758


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.388472705182311, Training Loss Force: 4.480511291954985, time: 0.9620246887207031
Validation Loss Energy: 4.208563982005948, Validation Loss Force: 4.508679906248026, time: 0.07042670249938965
Test Loss Energy: 9.615425833975225, Test Loss Force: 9.719461344978203, time: 9.986718893051147


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.398021243651439, Training Loss Force: 4.484260689942278, time: 0.9393599033355713
Validation Loss Energy: 5.781825929815209, Validation Loss Force: 4.563700116191907, time: 0.07022690773010254
Test Loss Energy: 10.485108293921405, Test Loss Force: 9.772247633127504, time: 9.88885760307312


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.571483501586558, Training Loss Force: 4.487971942149654, time: 0.9668128490447998
Validation Loss Energy: 4.839161667258567, Validation Loss Force: 4.5401695541959874, time: 0.07056093215942383
Test Loss Energy: 9.849022317850311, Test Loss Force: 9.812855168739706, time: 10.127625226974487


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.448839705063232, Training Loss Force: 4.477323888990132, time: 0.961707592010498
Validation Loss Energy: 2.272928596095211, Validation Loss Force: 4.476315168556567, time: 0.07032084465026855
Test Loss Energy: 9.003608957498354, Test Loss Force: 9.776834827378883, time: 10.13661789894104


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.423223114627769, Training Loss Force: 4.4927208617795635, time: 0.9391183853149414
Validation Loss Energy: 3.4530063760809675, Validation Loss Force: 4.583180994430837, time: 0.0716392993927002
Test Loss Energy: 9.539653468182154, Test Loss Force: 9.713635098354949, time: 10.195519924163818


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.48064912780663, Training Loss Force: 4.490808834676307, time: 0.9288289546966553
Validation Loss Energy: 6.021419266848385, Validation Loss Force: 4.537810597264029, time: 0.07216405868530273
Test Loss Energy: 10.561649691327704, Test Loss Force: 9.764992666652324, time: 10.573171854019165


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.4927202010727525, Training Loss Force: 4.484179324446167, time: 0.9557833671569824
Validation Loss Energy: 5.002812356058195, Validation Loss Force: 4.495203969536476, time: 0.07761573791503906
Test Loss Energy: 10.092411739467789, Test Loss Force: 9.717855860798625, time: 9.947888135910034


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.4100283816701715, Training Loss Force: 4.474100238408572, time: 0.9334118366241455
Validation Loss Energy: 2.4920244589037224, Validation Loss Force: 4.48596230930389, time: 0.07116889953613281
Test Loss Energy: 8.978659367004491, Test Loss Force: 9.655430913148269, time: 10.192362546920776


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.510245518565242, Training Loss Force: 4.478022529861892, time: 0.9243192672729492
Validation Loss Energy: 3.893074979929016, Validation Loss Force: 4.508766079207501, time: 0.07078838348388672
Test Loss Energy: 9.40262267992261, Test Loss Force: 9.69921655068737, time: 9.948325395584106


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.5579633559237545, Training Loss Force: 4.46556819919186, time: 0.9689016342163086
Validation Loss Energy: 5.539712423388423, Validation Loss Force: 4.453482674333133, time: 0.0729362964630127
Test Loss Energy: 10.52617553056828, Test Loss Force: 9.645113045135323, time: 9.96692180633545


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.587570869188723, Training Loss Force: 4.466310892051375, time: 0.9470219612121582
Validation Loss Energy: 5.76305692483581, Validation Loss Force: 4.440704805394066, time: 0.07256793975830078
Test Loss Energy: 10.202221003134323, Test Loss Force: 9.730385912967959, time: 10.189012289047241


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.482035590019847, Training Loss Force: 4.511395984336601, time: 0.9519176483154297
Validation Loss Energy: 2.839687927886917, Validation Loss Force: 4.550012421122579, time: 0.07581901550292969
Test Loss Energy: 9.243440340672402, Test Loss Force: 9.721537213648231, time: 9.97506594657898


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.473208797084105, Training Loss Force: 4.503747306474608, time: 0.9936010837554932
Validation Loss Energy: 3.466615914280074, Validation Loss Force: 4.474337198533291, time: 0.07254934310913086
Test Loss Energy: 9.560009923471926, Test Loss Force: 9.753728060726404, time: 9.978312969207764


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.482508075695936, Training Loss Force: 4.468751718222758, time: 0.9569599628448486
Validation Loss Energy: 6.220781855941057, Validation Loss Force: 4.466473414975706, time: 0.08413243293762207
Test Loss Energy: 10.628696676870454, Test Loss Force: 9.742646663709492, time: 10.158172369003296


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.542595381227688, Training Loss Force: 4.484495091196978, time: 0.9881923198699951
Validation Loss Energy: 4.779967301505124, Validation Loss Force: 4.484527874665822, time: 0.07235574722290039
Test Loss Energy: 10.01282908722897, Test Loss Force: 9.740972984480909, time: 9.95030403137207


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.467139175645304, Training Loss Force: 4.464803881872992, time: 0.930567741394043
Validation Loss Energy: 3.1508502457893264, Validation Loss Force: 4.439722834460525, time: 0.07506132125854492
Test Loss Energy: 9.226091695542596, Test Loss Force: 9.660982546926823, time: 10.173879861831665


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.422432637334568, Training Loss Force: 4.44867605784223, time: 0.9588251113891602
Validation Loss Energy: 4.155908741060966, Validation Loss Force: 4.488906886089638, time: 0.07317924499511719
Test Loss Energy: 9.765591150021066, Test Loss Force: 9.686908897196728, time: 9.945062160491943

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.051 MB of 0.058 MB uploadedwandb: | 0.051 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–‚â–„â–‡â–…â–â–ƒâ–ˆâ–†â–â–ƒâ–ˆâ–†â–‚â–ƒâ–ˆâ–…â–‚â–„
wandb:   test_error_force â–…â–†â–†â–„â–†â–ˆâ–†â–„â–†â–„â–â–ƒâ–â–…â–„â–†â–…â–…â–‚â–ƒ
wandb:          test_loss â–…â–ˆâ–‚â–‚â–†â–‚â–ƒâ–„â–ƒâ–„â–â–â–…â–ƒâ–ƒâ–„â–„â–„â–â–‚
wandb: train_error_energy â–ˆâ–â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–†â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–…â–‚â–„â–‡â–†â–â–ƒâ–ˆâ–†â–â–„â–‡â–‡â–‚â–ƒâ–ˆâ–…â–ƒâ–„
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚
wandb:         valid_loss â–…â–…â–‚â–„â–ˆâ–…â–â–ƒâ–ˆâ–†â–â–„â–‡â–‡â–‚â–ƒâ–ˆâ–…â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1938
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.76559
wandb:   test_error_force 9.68691
wandb:          test_loss 6.59873
wandb: train_error_energy 4.42243
wandb:  train_error_force 4.44868
wandb:         train_loss 1.85108
wandb: valid_error_energy 4.15591
wandb:  valid_error_force 4.48891
wandb:         valid_loss 1.74838
wandb: 
wandb: ğŸš€ View run al_72_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2rvoeise
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_000412-2rvoeise/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3817813396453857, Uncertainty Bias: -0.17684835195541382
0.0003876686 0.051063538
2.3838031 6.670219
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 720 steps.
Found uncertainty sample 3 after 1478 steps.
Found uncertainty sample 4 after 1794 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1311 steps.
Found uncertainty sample 7 after 3558 steps.
Found uncertainty sample 8 after 654 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2506 steps.
Found uncertainty sample 11 after 1006 steps.
Found uncertainty sample 12 after 2355 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 882 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 805 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3932 steps.
Found uncertainty sample 21 after 617 steps.
Found uncertainty sample 22 after 1554 steps.
Found uncertainty sample 23 after 811 steps.
Found uncertainty sample 24 after 749 steps.
Found uncertainty sample 25 after 2784 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 776 steps.
Found uncertainty sample 29 after 2646 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 387 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 353 steps.
Found uncertainty sample 36 after 595 steps.
Found uncertainty sample 37 after 3330 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1306 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 521 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2914 steps.
Found uncertainty sample 47 after 1020 steps.
Found uncertainty sample 48 after 2481 steps.
Found uncertainty sample 49 after 1078 steps.
Found uncertainty sample 50 after 1110 steps.
Found uncertainty sample 51 after 572 steps.
Found uncertainty sample 52 after 92 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2993 steps.
Found uncertainty sample 61 after 1018 steps.
Found uncertainty sample 62 after 700 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3029 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2637 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1419 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2707 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 866 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1470 steps.
Found uncertainty sample 83 after 1665 steps.
Found uncertainty sample 84 after 3301 steps.
Found uncertainty sample 85 after 2937 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2509 steps.
Found uncertainty sample 88 after 3828 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1961 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1363 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3437 steps.
Found uncertainty sample 97 after 176 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2399 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_003654-oi92l50f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oi92l50f
Training model 26. Added 51 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.128013957182248, Training Loss Force: 4.906286768153763, time: 1.0543992519378662
Validation Loss Energy: 4.437815227887361, Validation Loss Force: 5.055309056571277, time: 0.07854890823364258
Test Loss Energy: 9.875290785856153, Test Loss Force: 10.121858966915703, time: 9.931426048278809


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1553352980067335, Training Loss Force: 4.977451812826533, time: 1.005202293395996
Validation Loss Energy: 4.989264942550802, Validation Loss Force: 4.724604626414807, time: 0.07545232772827148
Test Loss Energy: 9.956729720012902, Test Loss Force: 9.701879822895968, time: 9.934235572814941


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.212218081484733, Training Loss Force: 4.771917388090171, time: 1.0327889919281006
Validation Loss Energy: 6.199599117419801, Validation Loss Force: 5.364600062971309, time: 0.07381725311279297
Test Loss Energy: 10.914331984711975, Test Loss Force: 10.424303738791144, time: 10.43937873840332


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.854757299342908, Training Loss Force: 5.019919746407677, time: 0.9966297149658203
Validation Loss Energy: 4.208244229112396, Validation Loss Force: 4.743912268058206, time: 0.07604622840881348
Test Loss Energy: 9.636690149844577, Test Loss Force: 9.953942335986108, time: 10.094710350036621


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.8274659686025614, Training Loss Force: 4.634689446177038, time: 1.0311040878295898
Validation Loss Energy: 2.3947259468879594, Validation Loss Force: 4.61947695589365, time: 0.07932686805725098
Test Loss Energy: 8.883948810815975, Test Loss Force: 9.804184590747035, time: 11.424765348434448


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9623052560138263, Training Loss Force: 4.524784193643729, time: 1.2347238063812256
Validation Loss Energy: 2.6085097032166447, Validation Loss Force: 4.525314850132853, time: 0.0824432373046875
Test Loss Energy: 9.107512135411842, Test Loss Force: 9.811439025614204, time: 12.083554983139038


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.965363681379025, Training Loss Force: 4.460997528156175, time: 1.0655012130737305
Validation Loss Energy: 3.3340682084565043, Validation Loss Force: 4.514309872933664, time: 0.07576155662536621
Test Loss Energy: 9.263515505374707, Test Loss Force: 9.78362155911181, time: 10.772106647491455


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9699695944582607, Training Loss Force: 4.467738369662218, time: 0.9685375690460205
Validation Loss Energy: 3.1289998338340057, Validation Loss Force: 4.508335882417567, time: 0.07458138465881348
Test Loss Energy: 9.226223413085965, Test Loss Force: 9.75986264466061, time: 11.332319736480713


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9793705062274394, Training Loss Force: 4.461006032680975, time: 1.0238029956817627
Validation Loss Energy: 2.825596088317731, Validation Loss Force: 4.465189950018578, time: 0.08024024963378906
Test Loss Energy: 9.083274372711037, Test Loss Force: 9.666454737949984, time: 10.750368595123291


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.946669502211252, Training Loss Force: 4.459982365154138, time: 1.1252679824829102
Validation Loss Energy: 3.1706744798512774, Validation Loss Force: 4.462422395203841, time: 0.09190750122070312
Test Loss Energy: 9.185792739729207, Test Loss Force: 9.73197963182282, time: 10.878133296966553


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0392798015540134, Training Loss Force: 4.4644739035082806, time: 1.0667598247528076
Validation Loss Energy: 2.7724064414225227, Validation Loss Force: 4.441479026014457, time: 0.08834958076477051
Test Loss Energy: 9.165246369808294, Test Loss Force: 9.789819124605907, time: 10.471580266952515


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9927280889007726, Training Loss Force: 4.469388908297846, time: 0.9538476467132568
Validation Loss Energy: 2.7570479484167265, Validation Loss Force: 4.476372617196217, time: 0.0691385269165039
Test Loss Energy: 8.997564642003777, Test Loss Force: 9.815397136393479, time: 10.479151248931885


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.989704631570078, Training Loss Force: 4.454445283825293, time: 1.0567185878753662
Validation Loss Energy: 3.464148628808621, Validation Loss Force: 4.488474685277392, time: 0.08374667167663574
Test Loss Energy: 9.369772433725885, Test Loss Force: 9.777716392014717, time: 11.194928169250488


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0305199165458627, Training Loss Force: 4.463408094049858, time: 0.9700992107391357
Validation Loss Energy: 3.1609677751074203, Validation Loss Force: 4.54970892307668, time: 0.07458758354187012
Test Loss Energy: 9.298806308001819, Test Loss Force: 9.821221704254585, time: 9.278109550476074


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9699271508458964, Training Loss Force: 4.4640452582194925, time: 0.9849393367767334
Validation Loss Energy: 2.8234236167954867, Validation Loss Force: 4.509075143982047, time: 0.08829617500305176
Test Loss Energy: 9.041020199930504, Test Loss Force: 9.770114108304172, time: 9.318055629730225


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0879326867098307, Training Loss Force: 4.5617417195048455, time: 0.9678974151611328
Validation Loss Energy: 2.445778971993418, Validation Loss Force: 5.130563879813053, time: 0.06962156295776367
Test Loss Energy: 8.908075131689568, Test Loss Force: 10.002462143402585, time: 9.556479930877686


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.02342546922364, Training Loss Force: 5.415456244960329, time: 1.0074729919433594
Validation Loss Energy: 3.8337130556432624, Validation Loss Force: 4.744170341598336, time: 0.0801393985748291
Test Loss Energy: 10.098174552198017, Test Loss Force: 9.989882255313619, time: 9.284969568252563


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.43194423262557, Training Loss Force: 4.561990620512738, time: 1.0090737342834473
Validation Loss Energy: 6.521709631889188, Validation Loss Force: 4.536861804033231, time: 0.06946134567260742
Test Loss Energy: 11.066162548869842, Test Loss Force: 9.908316527982466, time: 9.217060327529907


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.4619065174814185, Training Loss Force: 4.486718687661103, time: 1.0439913272857666
Validation Loss Energy: 2.1938792679376786, Validation Loss Force: 4.5239612443947586, time: 0.06981158256530762
Test Loss Energy: 8.87108826400696, Test Loss Force: 9.67078553392596, time: 9.511555194854736


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.349151545218527, Training Loss Force: 4.480255076424614, time: 0.965801477432251
Validation Loss Energy: 5.552005318927659, Validation Loss Force: 4.512831795142995, time: 0.06993246078491211
Test Loss Energy: 10.462707138978807, Test Loss Force: 9.71868747293412, time: 9.232591152191162

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–ˆâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–â–…â–ˆâ–â–†
wandb:   test_error_force â–…â–â–ˆâ–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–„â–„â–ƒâ–â–
wandb:          test_loss â–†â–ˆâ–‡â–…â–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–†â–ƒâ–‚â–â–ƒ
wandb: train_error_energy â–†â–‚â–‚â–…â–…â–â–â–â–â–â–â–â–â–â–â–‚â–†â–ˆâ–ˆâ–‡
wandb:  train_error_force â–„â–…â–ƒâ–…â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–ˆâ–‚â–â–
wandb:         train_loss â–‡â–„â–ƒâ–‡â–…â–â–â–â–â–â–â–â–â–â–â–‚â–ˆâ–„â–„â–ƒ
wandb: valid_error_energy â–…â–†â–‡â–„â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–â–„â–ˆâ–â–†
wandb:  valid_error_force â–†â–ƒâ–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–†â–ƒâ–‚â–‚â–‚
wandb:         valid_loss â–„â–†â–ˆâ–„â–â–â–‚â–‚â–â–‚â–â–â–‚â–‚â–â–‚â–‚â–…â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1983
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.46271
wandb:   test_error_force 9.71869
wandb:          test_loss 7.52146
wandb: train_error_energy 4.34915
wandb:  train_error_force 4.48026
wandb:         train_loss 1.83878
wandb: valid_error_energy 5.55201
wandb:  valid_error_force 4.51283
wandb:         valid_loss 2.24425
wandb: 
wandb: ğŸš€ View run al_72_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oi92l50f
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_003654-oi92l50f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0592169761657715, Uncertainty Bias: -0.06836262345314026
2.0980835e-05 0.21395493
2.5267272 6.8833976
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1070 steps.
Found uncertainty sample 3 after 146 steps.
Found uncertainty sample 4 after 3450 steps.
Found uncertainty sample 5 after 782 steps.
Found uncertainty sample 6 after 1478 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2855 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3170 steps.
Found uncertainty sample 15 after 1865 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2486 steps.
Found uncertainty sample 18 after 1613 steps.
Found uncertainty sample 19 after 482 steps.
Found uncertainty sample 20 after 2635 steps.
Found uncertainty sample 21 after 1170 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2367 steps.
Found uncertainty sample 25 after 2324 steps.
Found uncertainty sample 26 after 712 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1673 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 972 steps.
Found uncertainty sample 35 after 985 steps.
Found uncertainty sample 36 after 2354 steps.
Found uncertainty sample 37 after 581 steps.
Found uncertainty sample 38 after 1945 steps.
Found uncertainty sample 39 after 1683 steps.
Found uncertainty sample 40 after 2854 steps.
Found uncertainty sample 41 after 1751 steps.
Found uncertainty sample 42 after 2352 steps.
Found uncertainty sample 43 after 1728 steps.
Found uncertainty sample 44 after 43 steps.
Found uncertainty sample 45 after 3926 steps.
Found uncertainty sample 46 after 2883 steps.
Found uncertainty sample 47 after 20 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3807 steps.
Found uncertainty sample 50 after 1420 steps.
Found uncertainty sample 51 after 2147 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 683 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 839 steps.
Found uncertainty sample 59 after 1773 steps.
Found uncertainty sample 60 after 1816 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 728 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 690 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1554 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3121 steps.
Found uncertainty sample 76 after 422 steps.
Found uncertainty sample 77 after 2183 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1265 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2279 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2583 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1758 steps.
Found uncertainty sample 88 after 1614 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2856 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_010948-9204g3ed
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9204g3ed
Training model 27. Added 50 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.29006593078415, Training Loss Force: 4.886584329400874, time: 1.028381109237671
Validation Loss Energy: 4.151037853493796, Validation Loss Force: 6.063348089695733, time: 0.0780479907989502
Test Loss Energy: 9.696517264367483, Test Loss Force: 10.845781439168128, time: 9.739235162734985


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.2942251135822396, Training Loss Force: 4.928405902262403, time: 1.0240180492401123
Validation Loss Energy: 1.8185956954244549, Validation Loss Force: 5.50127082203545, time: 0.07332491874694824
Test Loss Energy: 8.717012651592059, Test Loss Force: 10.314740814816815, time: 9.833798885345459


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.359198712882226, Training Loss Force: 4.824655892705513, time: 0.9927825927734375
Validation Loss Energy: 5.253232980312109, Validation Loss Force: 4.582144246887397, time: 0.07711362838745117
Test Loss Energy: 10.213896835837911, Test Loss Force: 9.715843020320774, time: 9.982038259506226


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.445067301029824, Training Loss Force: 4.53234980346201, time: 1.0818591117858887
Validation Loss Energy: 4.903841932760233, Validation Loss Force: 4.5285342006446765, time: 0.07897591590881348
Test Loss Energy: 9.972076329364569, Test Loss Force: 9.73255423946325, time: 9.786999940872192


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.418951482405179, Training Loss Force: 4.499174863207861, time: 0.9712588787078857
Validation Loss Energy: 4.747259207990647, Validation Loss Force: 4.551808693122779, time: 0.07567882537841797
Test Loss Energy: 10.134277334769957, Test Loss Force: 9.724034297730702, time: 9.811482906341553


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.429077377472668, Training Loss Force: 4.495029636991241, time: 0.9831721782684326
Validation Loss Energy: 4.926809141816955, Validation Loss Force: 4.501482348775056, time: 0.07262992858886719
Test Loss Energy: 10.154623125256867, Test Loss Force: 9.716734410378397, time: 9.940330743789673


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.457421848088838, Training Loss Force: 4.505840812011749, time: 1.015965461730957
Validation Loss Energy: 4.904530203090296, Validation Loss Force: 4.488423248704683, time: 0.07207775115966797
Test Loss Energy: 10.195126423729405, Test Loss Force: 9.699210693672766, time: 9.744016408920288


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.416013270825718, Training Loss Force: 4.503521511062997, time: 0.9859194755554199
Validation Loss Energy: 4.891767252984008, Validation Loss Force: 4.500288174145446, time: 0.07337737083435059
Test Loss Energy: 10.236521485317821, Test Loss Force: 9.706155881899486, time: 9.836622953414917


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.378550197732538, Training Loss Force: 4.499153626138067, time: 1.2186477184295654
Validation Loss Energy: 4.991256940730273, Validation Loss Force: 4.481420304065255, time: 0.0737457275390625
Test Loss Energy: 10.274368459791765, Test Loss Force: 9.675136745514939, time: 9.854316711425781


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.485308670984429, Training Loss Force: 4.517195929484499, time: 0.993431806564331
Validation Loss Energy: 5.330199906616924, Validation Loss Force: 4.5454154166049, time: 0.07445597648620605
Test Loss Energy: 10.358820660085458, Test Loss Force: 9.745468401738341, time: 9.82710337638855


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.4397794620076985, Training Loss Force: 4.514717656682377, time: 1.001283884048462
Validation Loss Energy: 5.084870389715504, Validation Loss Force: 4.54147083268479, time: 0.07959961891174316
Test Loss Energy: 10.284445700567034, Test Loss Force: 9.65767297460765, time: 9.973720788955688


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.509834292684624, Training Loss Force: 4.501764268789033, time: 1.006401777267456
Validation Loss Energy: 4.782103589291156, Validation Loss Force: 4.542062019267227, time: 0.08633923530578613
Test Loss Energy: 10.071829798442264, Test Loss Force: 9.649733077839599, time: 9.838795185089111


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.423852214596314, Training Loss Force: 4.521889523702635, time: 1.0088977813720703
Validation Loss Energy: 4.932427529707006, Validation Loss Force: 4.55236803801735, time: 0.07225394248962402
Test Loss Energy: 10.120064948420525, Test Loss Force: 9.616734447721965, time: 10.480117797851562


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.489525339204837, Training Loss Force: 4.508102198107327, time: 0.9802241325378418
Validation Loss Energy: 4.971706144379521, Validation Loss Force: 4.655125618149251, time: 0.07199573516845703
Test Loss Energy: 10.207562497861087, Test Loss Force: 9.677471861692792, time: 10.008803844451904


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.47099952720405, Training Loss Force: 4.497335887440518, time: 1.0097150802612305
Validation Loss Energy: 5.35266989547079, Validation Loss Force: 4.696477059901209, time: 0.07470440864562988
Test Loss Energy: 10.337915907088691, Test Loss Force: 9.6918212770025, time: 9.849052429199219


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.472284505615529, Training Loss Force: 4.493526742028418, time: 1.0060172080993652
Validation Loss Energy: 5.121037203073679, Validation Loss Force: 4.551662176824759, time: 0.07371377944946289
Test Loss Energy: 10.170958805306986, Test Loss Force: 9.578829635228823, time: 9.789855241775513


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.539134904613408, Training Loss Force: 4.497964600732456, time: 0.9635429382324219
Validation Loss Energy: 5.240399889424854, Validation Loss Force: 4.524158083919758, time: 0.07535457611083984
Test Loss Energy: 10.349077670180172, Test Loss Force: 9.607382147737415, time: 10.129210948944092


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.515214988219807, Training Loss Force: 4.493175551034826, time: 0.954531192779541
Validation Loss Energy: 5.080319255041886, Validation Loss Force: 4.613189892558379, time: 0.0747079849243164
Test Loss Energy: 10.179641684895616, Test Loss Force: 9.655081595388012, time: 9.79872179031372


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.508652380514463, Training Loss Force: 4.496673321479989, time: 1.0182414054870605
Validation Loss Energy: 5.246542885822709, Validation Loss Force: 4.589463604383189, time: 0.07548379898071289
Test Loss Energy: 10.394874856482916, Test Loss Force: 9.745347069204145, time: 9.916128873825073


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.564746066233643, Training Loss Force: 4.507653853782001, time: 1.0342180728912354
Validation Loss Energy: 5.126055942953745, Validation Loss Force: 4.457136675017807, time: 0.08647727966308594
Test Loss Energy: 10.237934886465153, Test Loss Force: 9.585276403637236, time: 10.011707067489624

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.040 MB of 0.058 MB uploadedwandb: | 0.040 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡
wandb:   test_error_force â–ˆâ–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–‚â–
wandb:          test_loss â–ˆâ–†â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–‚â–
wandb: train_error_energy â–†â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–‡â–ˆâ–†â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–…â–â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–†â–â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:  valid_error_force â–ˆâ–†â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–‚â–‚â–
wandb:         valid_loss â–ˆâ–â–†â–…â–„â–„â–„â–„â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2028
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.23793
wandb:   test_error_force 9.58528
wandb:          test_loss 7.19486
wandb: train_error_energy 4.56475
wandb:  train_error_force 4.50765
wandb:         train_loss 1.89903
wandb: valid_error_energy 5.12606
wandb:  valid_error_force 4.45714
wandb:         valid_loss 2.01499
wandb: 
wandb: ğŸš€ View run al_72_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9204g3ed
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_010948-9204g3ed/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.245025634765625, Uncertainty Bias: -0.12503013014793396
0.00051116943 0.11243057
2.284563 6.7090244
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3400 steps.
Found uncertainty sample 2 after 1593 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 377 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2466 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3362 steps.
Found uncertainty sample 13 after 1358 steps.
Found uncertainty sample 14 after 2932 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2386 steps.
Found uncertainty sample 17 after 3321 steps.
Found uncertainty sample 18 after 1485 steps.
Found uncertainty sample 19 after 1829 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 320 steps.
Found uncertainty sample 22 after 3850 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2890 steps.
Found uncertainty sample 29 after 1325 steps.
Found uncertainty sample 30 after 3585 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 386 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 330 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2451 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 860 steps.
Found uncertainty sample 41 after 1753 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 977 steps.
Found uncertainty sample 44 after 1288 steps.
Found uncertainty sample 45 after 2223 steps.
Found uncertainty sample 46 after 2004 steps.
Found uncertainty sample 47 after 2466 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1003 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2884 steps.
Found uncertainty sample 55 after 1632 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1833 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 942 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2108 steps.
Found uncertainty sample 64 after 788 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 170 steps.
Found uncertainty sample 70 after 3068 steps.
Found uncertainty sample 71 after 1518 steps.
Found uncertainty sample 72 after 514 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 741 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 215 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1000 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1870 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1400 steps.
Found uncertainty sample 88 after 1156 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3028 steps.
Found uncertainty sample 93 after 2316 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 382 steps.
Found uncertainty sample 96 after 1758 steps.
Found uncertainty sample 97 after 2675 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 976 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_014256-yrmga8wj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/yrmga8wj
Training model 28. Added 49 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.019273247651022, Training Loss Force: 4.746828165057959, time: 1.0234501361846924
Validation Loss Energy: 2.3734243030427775, Validation Loss Force: 4.636343475690243, time: 0.0781552791595459
Test Loss Energy: 8.756720200485477, Test Loss Force: 9.645046505532326, time: 9.94443941116333


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.6157434739289287, Training Loss Force: 4.949586866281851, time: 1.0806925296783447
Validation Loss Energy: 5.130700821337799, Validation Loss Force: 4.69235901671642, time: 0.07334709167480469
Test Loss Energy: 9.977151996768534, Test Loss Force: 9.720691481257786, time: 9.800427436828613


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.6003456472749233, Training Loss Force: 4.959957890719867, time: 1.0217046737670898
Validation Loss Energy: 1.9740002220756523, Validation Loss Force: 4.869168116025504, time: 0.07987236976623535
Test Loss Energy: 8.563619579565588, Test Loss Force: 9.89139244646294, time: 9.945198774337769


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9944082770382376, Training Loss Force: 4.587479896347306, time: 1.0398905277252197
Validation Loss Energy: 3.298356085494314, Validation Loss Force: 4.494989539148948, time: 0.07532358169555664
Test Loss Energy: 9.207268588955579, Test Loss Force: 9.618002188273646, time: 9.771103143692017


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.029824506962282, Training Loss Force: 4.510993997059919, time: 1.0282204151153564
Validation Loss Energy: 2.3353155920629662, Validation Loss Force: 4.507023247802323, time: 0.07897281646728516
Test Loss Energy: 8.800711861777492, Test Loss Force: 9.597269345183994, time: 9.838889598846436


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0425875392848707, Training Loss Force: 4.5088205612089896, time: 0.9942982196807861
Validation Loss Energy: 2.723894293941246, Validation Loss Force: 4.493338892770185, time: 0.07715463638305664
Test Loss Energy: 8.698905989394003, Test Loss Force: 9.602436985437489, time: 9.947830200195312


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0957605168252473, Training Loss Force: 4.5059666758535375, time: 1.0006468296051025
Validation Loss Energy: 4.145571993968707, Validation Loss Force: 4.5073049242719225, time: 0.07185053825378418
Test Loss Energy: 9.43506640920213, Test Loss Force: 9.587467104301364, time: 9.886560678482056


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0431260526244204, Training Loss Force: 4.499226110832952, time: 1.009770393371582
Validation Loss Energy: 3.3027702786431865, Validation Loss Force: 4.466624607325791, time: 0.07926702499389648
Test Loss Energy: 9.094578252344744, Test Loss Force: 9.607639730472778, time: 9.763247013092041


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0406740456820573, Training Loss Force: 4.507706304248693, time: 1.2523105144500732
Validation Loss Energy: 2.172608241100062, Validation Loss Force: 4.5415928553767575, time: 0.07770395278930664
Test Loss Energy: 8.599227316164813, Test Loss Force: 9.571147960058394, time: 9.841066360473633


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9921172187802303, Training Loss Force: 4.512287711649119, time: 1.0345468521118164
Validation Loss Energy: 3.5109799582418613, Validation Loss Force: 4.5205746693543425, time: 0.07375431060791016
Test Loss Energy: 9.225937683105263, Test Loss Force: 9.577494907404235, time: 10.341673135757446


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.092904610319086, Training Loss Force: 4.5039350014579425, time: 1.0239534378051758
Validation Loss Energy: 2.557592840293921, Validation Loss Force: 4.456751680064499, time: 0.07730507850646973
Test Loss Energy: 8.851940102435941, Test Loss Force: 9.59095617359991, time: 9.940035581588745


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0852449390033745, Training Loss Force: 4.520780463604688, time: 1.0490386486053467
Validation Loss Energy: 2.648666302331554, Validation Loss Force: 4.527111122133053, time: 0.07284879684448242
Test Loss Energy: 8.881013385615542, Test Loss Force: 9.610239233035921, time: 9.896097183227539


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0445019646724187, Training Loss Force: 4.529421663941328, time: 1.0018892288208008
Validation Loss Energy: 3.9325829438218376, Validation Loss Force: 4.489960779157315, time: 0.07242488861083984
Test Loss Energy: 9.271142163778988, Test Loss Force: 9.658666186252736, time: 9.825906038284302


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.089374560983751, Training Loss Force: 4.496483196928472, time: 0.9715821743011475
Validation Loss Energy: 3.0708246247614737, Validation Loss Force: 4.4720528357652185, time: 0.0718071460723877
Test Loss Energy: 8.686388996595209, Test Loss Force: 9.652118682789032, time: 9.952101707458496


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0802817019771895, Training Loss Force: 4.51108768253381, time: 1.0241508483886719
Validation Loss Energy: 2.3790835507211052, Validation Loss Force: 4.5662425525001105, time: 0.07159233093261719
Test Loss Energy: 8.78638640147098, Test Loss Force: 9.620295358713959, time: 9.766766548156738


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0317612712036843, Training Loss Force: 4.517946049809628, time: 1.0271332263946533
Validation Loss Energy: 3.4530158395196695, Validation Loss Force: 4.486000385727843, time: 0.0831904411315918
Test Loss Energy: 9.201935502029235, Test Loss Force: 9.613458138209452, time: 9.74790334701538


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.057847460085444, Training Loss Force: 4.511902788635073, time: 1.0121076107025146
Validation Loss Energy: 2.5182836086138405, Validation Loss Force: 4.535734207478252, time: 0.07497310638427734
Test Loss Energy: 8.791395422017699, Test Loss Force: 9.64288577543575, time: 9.994213342666626


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0853764097184886, Training Loss Force: 4.503657014444808, time: 1.0311102867126465
Validation Loss Energy: 2.773229760589591, Validation Loss Force: 4.473609961102691, time: 0.07471251487731934
Test Loss Energy: 8.773552505011054, Test Loss Force: 9.684710422931209, time: 9.755743503570557


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1282700305697086, Training Loss Force: 4.503117949570912, time: 1.0134470462799072
Validation Loss Energy: 4.301294547827576, Validation Loss Force: 4.497351168110658, time: 0.07926368713378906
Test Loss Energy: 9.314985350217142, Test Loss Force: 9.647936065551923, time: 9.773103475570679


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1587025002236717, Training Loss Force: 4.497983534782376, time: 1.0482513904571533
Validation Loss Energy: 2.792367505674646, Validation Loss Force: 4.5160689591864935, time: 0.07153582572937012
Test Loss Energy: 8.797151512704495, Test Loss Force: 9.612259385455568, time: 9.911974668502808

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–â–„â–‚â–‚â–…â–„â–â–„â–‚â–ƒâ–…â–‚â–‚â–„â–‚â–‚â–…â–‚
wandb:   test_error_force â–ƒâ–„â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚
wandb:          test_loss â–„â–ˆâ–…â–†â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–„â–‚â–ƒâ–â–ƒâ–…â–ƒâ–‚â–‚â–
wandb: train_error_energy â–ˆâ–…â–…â–â–â–â–‚â–â–â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚
wandb:  train_error_force â–…â–ˆâ–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–‡â–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–‚â–ˆâ–â–„â–‚â–ƒâ–†â–„â–â–„â–‚â–‚â–…â–ƒâ–‚â–„â–‚â–ƒâ–†â–ƒ
wandb:  valid_error_force â–„â–…â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–ƒâ–â–‚â–â–‚â–‚
wandb:         valid_loss â–â–ˆâ–â–ƒâ–â–‚â–„â–ƒâ–â–ƒâ–â–‚â–„â–‚â–â–ƒâ–â–‚â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2072
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.79715
wandb:   test_error_force 9.61226
wandb:          test_loss 7.17072
wandb: train_error_energy 3.1587
wandb:  train_error_force 4.49798
wandb:         train_loss 1.53796
wandb: valid_error_energy 2.79237
wandb:  valid_error_force 4.51607
wandb:         valid_loss 1.41217
wandb: 
wandb: ğŸš€ View run al_72_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/yrmga8wj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_014256-yrmga8wj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1052920818328857, Uncertainty Bias: -0.03774699568748474
0.00017929077 0.03486824
2.6819334 6.992324
(48745, 22, 3)
Found uncertainty sample 0 after 2498 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1192 steps.
Found uncertainty sample 6 after 267 steps.
Found uncertainty sample 7 after 104 steps.
Found uncertainty sample 8 after 3370 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2453 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 617 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 421 steps.
Found uncertainty sample 20 after 1699 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3090 steps.
Found uncertainty sample 29 after 2189 steps.
Found uncertainty sample 30 after 94 steps.
Found uncertainty sample 31 after 3836 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3646 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 126 steps.
Found uncertainty sample 37 after 246 steps.
Found uncertainty sample 38 after 1135 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3154 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 583 steps.
Found uncertainty sample 48 after 3076 steps.
Found uncertainty sample 49 after 1570 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1104 steps.
Found uncertainty sample 54 after 1261 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1825 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 666 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 34 steps.
Found uncertainty sample 69 after 1509 steps.
Found uncertainty sample 70 after 1419 steps.
Found uncertainty sample 71 after 1299 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3587 steps.
Found uncertainty sample 76 after 2724 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2220 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 858 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2080 steps.
Found uncertainty sample 84 after 1294 steps.
Found uncertainty sample 85 after 21 steps.
Found uncertainty sample 86 after 2995 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 778 steps.
Found uncertainty sample 89 after 3609 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1568 steps.
Found uncertainty sample 94 after 462 steps.
Found uncertainty sample 95 after 974 steps.
Found uncertainty sample 96 after 178 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 813 steps.
Found uncertainty sample 99 after 2376 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_021557-3498hjbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3498hjbo
Training model 29. Added 45 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.898324324073665, Training Loss Force: 4.8843146583683525, time: 1.061774492263794
Validation Loss Energy: 1.9176001314344568, Validation Loss Force: 4.714673582506428, time: 0.07586455345153809
Test Loss Energy: 8.590993405191185, Test Loss Force: 9.68018863045515, time: 10.066832542419434


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.391974267885783, Training Loss Force: 4.990153574626902, time: 1.0098233222961426
Validation Loss Energy: 1.8253837086707771, Validation Loss Force: 6.484029336346142, time: 0.07685375213623047
Test Loss Energy: 8.40284839220236, Test Loss Force: 11.095458184095852, time: 10.053796768188477


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.233138003155959, Training Loss Force: 5.0220089735159235, time: 1.0187714099884033
Validation Loss Energy: 2.5656178363131588, Validation Loss Force: 4.551344873291812, time: 0.07862329483032227
Test Loss Energy: 8.765716248489454, Test Loss Force: 9.646376654066831, time: 10.150414228439331


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.585309982025613, Training Loss Force: 4.6127809707932075, time: 1.017146110534668
Validation Loss Energy: 2.56202529231276, Validation Loss Force: 4.707479587739792, time: 0.07475519180297852
Test Loss Energy: 8.581969065381795, Test Loss Force: 9.692059460708606, time: 10.023252248764038


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.5723519169079054, Training Loss Force: 4.939497565234857, time: 1.0186266899108887
Validation Loss Energy: 1.7461178904361168, Validation Loss Force: 4.729155315750133, time: 0.07226014137268066
Test Loss Energy: 8.483970478656717, Test Loss Force: 9.80126050884917, time: 9.973482608795166


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.233075677210048, Training Loss Force: 4.564377698402964, time: 1.028698444366455
Validation Loss Energy: 2.2645609122603902, Validation Loss Force: 4.4825367671629355, time: 0.07241511344909668
Test Loss Energy: 8.59193241380344, Test Loss Force: 9.56993694301438, time: 10.245723247528076


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.189923108595754, Training Loss Force: 4.541107861734278, time: 1.0163764953613281
Validation Loss Energy: 1.9556628055683478, Validation Loss Force: 4.520205929248686, time: 0.07412934303283691
Test Loss Energy: 8.503170038328813, Test Loss Force: 9.656183726053861, time: 10.085697174072266


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.213524604209751, Training Loss Force: 4.543075433783193, time: 1.0937795639038086
Validation Loss Energy: 2.3554688197880256, Validation Loss Force: 4.535243667349773, time: 0.07541131973266602
Test Loss Energy: 8.367799025883015, Test Loss Force: 9.595741848832613, time: 10.35936951637268


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1683261076235993, Training Loss Force: 4.547852321233034, time: 1.0612461566925049
Validation Loss Energy: 2.031022839981575, Validation Loss Force: 4.497662682245811, time: 0.07868075370788574
Test Loss Energy: 8.371514247758942, Test Loss Force: 9.608354248948498, time: 10.64867115020752


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.698240569830694, Training Loss Force: 4.793077210626067, time: 1.141685962677002
Validation Loss Energy: 5.8292188308344794, Validation Loss Force: 4.933474074692866, time: 0.07927656173706055
Test Loss Energy: 10.361801801243422, Test Loss Force: 9.903837949642014, time: 10.582832336425781


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.677966006491454, Training Loss Force: 5.00791270080647, time: 1.102726697921753
Validation Loss Energy: 2.0190018234695177, Validation Loss Force: 4.483687075970799, time: 0.08419060707092285
Test Loss Energy: 8.52266555910425, Test Loss Force: 9.67982129398118, time: 10.978920936584473


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.007321062795901, Training Loss Force: 4.530366308882272, time: 1.0624184608459473
Validation Loss Energy: 2.065765572816969, Validation Loss Force: 4.5606446501714855, time: 0.08084988594055176
Test Loss Energy: 8.663323112464242, Test Loss Force: 9.694220102203843, time: 10.538524627685547


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9649472356604156, Training Loss Force: 4.542985158313395, time: 1.0841219425201416
Validation Loss Energy: 2.2244062058332217, Validation Loss Force: 4.5493553244729465, time: 0.07610702514648438
Test Loss Energy: 8.69083619140996, Test Loss Force: 9.627822205382122, time: 10.545846462249756


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0294975568465574, Training Loss Force: 4.523151039090876, time: 1.3546900749206543
Validation Loss Energy: 1.9586050443280645, Validation Loss Force: 4.4497583101983444, time: 0.08601999282836914
Test Loss Energy: 8.55025943080992, Test Loss Force: 9.609965590142679, time: 10.523892879486084


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9628049661714186, Training Loss Force: 4.517655200201684, time: 1.0744142532348633
Validation Loss Energy: 2.0729603469256146, Validation Loss Force: 4.453286280146424, time: 0.0962066650390625
Test Loss Energy: 8.599936154828601, Test Loss Force: 9.646117168734367, time: 10.661717414855957


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.047890308323513, Training Loss Force: 4.518040586512885, time: 1.0380096435546875
Validation Loss Energy: 2.0005682695584586, Validation Loss Force: 4.458884405144195, time: 0.07629108428955078
Test Loss Energy: 8.529281546737112, Test Loss Force: 9.670365843389133, time: 10.66370964050293


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0670210831895464, Training Loss Force: 4.5158614585326875, time: 1.084730625152588
Validation Loss Energy: 2.183905248884135, Validation Loss Force: 4.486946952267182, time: 0.09078693389892578
Test Loss Energy: 8.53740254929826, Test Loss Force: 9.588355225436029, time: 10.62589693069458


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.068350126159203, Training Loss Force: 4.514904790911185, time: 1.0900883674621582
Validation Loss Energy: 2.048878010786087, Validation Loss Force: 4.457117080132965, time: 0.0849003791809082
Test Loss Energy: 8.586316059080879, Test Loss Force: 9.587731868408136, time: 11.277185678482056


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9849537412871827, Training Loss Force: 4.511120191398647, time: 1.1076788902282715
Validation Loss Energy: 1.9374776390895712, Validation Loss Force: 4.511029956414148, time: 0.08115124702453613
Test Loss Energy: 8.534584052213003, Test Loss Force: 9.60743606864494, time: 10.810619592666626


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0121282585528983, Training Loss Force: 4.49638046558541, time: 1.1049575805664062
Validation Loss Energy: 2.333459867400804, Validation Loss Force: 4.518067637440342, time: 0.07927298545837402
Test Loss Energy: 8.65155257659102, Test Loss Force: 9.62089691048685, time: 10.587448358535767

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–‚â–â–‚â–â–â–â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:   test_error_force â–‚â–ˆâ–â–‚â–‚â–â–â–â–â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:          test_loss â–ƒâ–‡â–ƒâ–ƒâ–„â–„â–…â–„â–†â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–â–‚â–
wandb: train_error_energy â–ˆâ–†â–…â–ƒâ–‡â–â–â–â–â–ƒâ–‡â–„â–„â–„â–„â–…â–…â–…â–„â–„
wandb:  train_error_force â–†â–ˆâ–ˆâ–ƒâ–‡â–‚â–‚â–‚â–‚â–…â–ˆâ–â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–…â–…â–‚â–…â–â–â–â–â–ƒâ–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚
wandb: valid_error_energy â–â–â–‚â–‚â–â–‚â–â–‚â–â–ˆâ–â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚
wandb:  valid_error_force â–‚â–ˆâ–â–‚â–‚â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–ƒâ–‚â–‚â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2112
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.65155
wandb:   test_error_force 9.6209
wandb:          test_loss 7.6742
wandb: train_error_energy 3.01213
wandb:  train_error_force 4.49638
wandb:         train_loss 1.49092
wandb: valid_error_energy 2.33346
wandb:  valid_error_force 4.51807
wandb:         valid_loss 1.3
wandb: 
wandb: ğŸš€ View run al_72_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3498hjbo
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_021557-3498hjbo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.127473831176758, Uncertainty Bias: -0.014956951141357422
8.773804e-05 0.0023145676
2.7705634 7.1688976
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2192 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1902 steps.
Found uncertainty sample 5 after 21 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 436 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3488 steps.
Found uncertainty sample 11 after 3652 steps.
Found uncertainty sample 12 after 1152 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2746 steps.
Found uncertainty sample 15 after 504 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1118 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2278 steps.
Found uncertainty sample 21 after 3957 steps.
Found uncertainty sample 22 after 1576 steps.
Found uncertainty sample 23 after 578 steps.
Found uncertainty sample 24 after 3664 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3786 steps.
Found uncertainty sample 28 after 1490 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3002 steps.
Found uncertainty sample 31 after 137 steps.
Found uncertainty sample 32 after 1419 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3232 steps.
Found uncertainty sample 35 after 3796 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2508 steps.
Found uncertainty sample 41 after 3302 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1613 steps.
Found uncertainty sample 44 after 1909 steps.
Found uncertainty sample 45 after 1574 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2473 steps.
Found uncertainty sample 48 after 3826 steps.
Found uncertainty sample 49 after 2641 steps.
Found uncertainty sample 50 after 2261 steps.
Found uncertainty sample 51 after 1635 steps.
Found uncertainty sample 52 after 2359 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 894 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1025 steps.
Found uncertainty sample 59 after 2411 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 983 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2328 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 819 steps.
Found uncertainty sample 67 after 488 steps.
Found uncertainty sample 68 after 619 steps.
Found uncertainty sample 69 after 2993 steps.
Found uncertainty sample 70 after 1651 steps.
Found uncertainty sample 71 after 429 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3054 steps.
Found uncertainty sample 74 after 546 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2367 steps.
Found uncertainty sample 77 after 1160 steps.
Found uncertainty sample 78 after 26 steps.
Found uncertainty sample 79 after 1558 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1352 steps.
Found uncertainty sample 83 after 2852 steps.
Found uncertainty sample 84 after 478 steps.
Found uncertainty sample 85 after 2897 steps.
Found uncertainty sample 86 after 1996 steps.
Found uncertainty sample 87 after 2689 steps.
Found uncertainty sample 88 after 1499 steps.
Found uncertainty sample 89 after 1264 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 190 steps.
Found uncertainty sample 92 after 98 steps.
Found uncertainty sample 93 after 1119 steps.
Found uncertainty sample 94 after 3956 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_024727-2erfcl6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_30
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2erfcl6n
Training model 30. Added 62 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.07613448402795, Training Loss Force: 4.836772610697354, time: 1.0713911056518555
Validation Loss Energy: 3.580434472901365, Validation Loss Force: 4.507795909738692, time: 0.07527470588684082
Test Loss Energy: 8.84635637865262, Test Loss Force: 9.533415136747243, time: 9.08683729171753


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0966690761091256, Training Loss Force: 4.5721107751718915, time: 1.0874130725860596
Validation Loss Energy: 2.6711221516946524, Validation Loss Force: 4.496217114150448, time: 0.07509946823120117
Test Loss Energy: 8.665144317579752, Test Loss Force: 9.604682926702724, time: 9.138314962387085


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.128877824240222, Training Loss Force: 4.580797949936562, time: 1.1278400421142578
Validation Loss Energy: 2.119157180627534, Validation Loss Force: 4.501984467699123, time: 0.07314634323120117
Test Loss Energy: 8.570824222813787, Test Loss Force: 9.573080504410093, time: 9.339876174926758


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0656124492472485, Training Loss Force: 4.572124023986074, time: 1.09368896484375
Validation Loss Energy: 4.032687866418302, Validation Loss Force: 4.634478621593097, time: 0.07775640487670898
Test Loss Energy: 9.220662825909292, Test Loss Force: 9.574616250012136, time: 9.12014627456665


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0969082653409536, Training Loss Force: 4.573549538760118, time: 1.1183841228485107
Validation Loss Energy: 2.628108930106636, Validation Loss Force: 4.534619748402884, time: 0.07795047760009766
Test Loss Energy: 8.822300362938787, Test Loss Force: 9.535346282130488, time: 9.735661268234253


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1187708324120047, Training Loss Force: 4.5635145018114995, time: 1.0976617336273193
Validation Loss Energy: 2.3475906740705277, Validation Loss Force: 4.574545216944319, time: 0.07432174682617188
Test Loss Energy: 8.468950885176506, Test Loss Force: 9.55808037757595, time: 9.334635496139526


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.086922258173539, Training Loss Force: 4.582454123749419, time: 1.1113815307617188
Validation Loss Energy: 4.138773904943531, Validation Loss Force: 4.512655886517713, time: 0.0764169692993164
Test Loss Energy: 9.126491525428316, Test Loss Force: 9.49896372918347, time: 9.889580965042114


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0910806666901194, Training Loss Force: 4.574697666720168, time: 1.1422317028045654
Validation Loss Energy: 2.559484080684859, Validation Loss Force: 4.475805701550685, time: 0.09396052360534668
Test Loss Energy: 8.774022570070368, Test Loss Force: 9.47711992327378, time: 11.28500509262085


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1499245610315105, Training Loss Force: 4.562148976725004, time: 1.1627092361450195
Validation Loss Energy: 2.066279827209489, Validation Loss Force: 4.5578581684793456, time: 0.08638191223144531
Test Loss Energy: 8.454320750524785, Test Loss Force: 9.502863712823395, time: 11.096547603607178


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.147182174379356, Training Loss Force: 4.560972576332513, time: 1.1220815181732178
Validation Loss Energy: 4.163880073816035, Validation Loss Force: 4.554168763400468, time: 0.08476066589355469
Test Loss Energy: 9.238323371056383, Test Loss Force: 9.551994011421197, time: 10.03733229637146


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1225507983423495, Training Loss Force: 4.602141645504863, time: 1.0553956031799316
Validation Loss Energy: 2.429470572411094, Validation Loss Force: 4.57462114712308, time: 0.07529187202453613
Test Loss Energy: 8.611895425536234, Test Loss Force: 9.563662639437236, time: 10.038919687271118


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.104660203496358, Training Loss Force: 4.559869080438034, time: 1.0317585468292236
Validation Loss Energy: 2.194552730769537, Validation Loss Force: 4.484018184990793, time: 0.07796883583068848
Test Loss Energy: 8.470656055185037, Test Loss Force: 9.58608995508996, time: 9.810922622680664


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.071514935133859, Training Loss Force: 4.554207160729954, time: 1.0637927055358887
Validation Loss Energy: 4.322370850497078, Validation Loss Force: 4.538377067571269, time: 0.08263826370239258
Test Loss Energy: 9.421021665906022, Test Loss Force: 9.560983656812875, time: 9.784204244613647


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0308918736291472, Training Loss Force: 4.585125066351192, time: 1.0493385791778564
Validation Loss Energy: 2.5383484366879663, Validation Loss Force: 4.519178979147667, time: 0.07897067070007324
Test Loss Energy: 8.684894466935496, Test Loss Force: 9.532074901650166, time: 10.013277769088745


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.109874050666451, Training Loss Force: 4.5537269812658545, time: 1.0795948505401611
Validation Loss Energy: 2.4099840161089423, Validation Loss Force: 4.52197681696625, time: 0.08105802536010742
Test Loss Energy: 8.48173451436819, Test Loss Force: 9.567695082073808, time: 9.861899375915527


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0680684981131976, Training Loss Force: 4.550155073456009, time: 1.0781168937683105
Validation Loss Energy: 4.18371610934272, Validation Loss Force: 4.575086748307216, time: 0.07579851150512695
Test Loss Energy: 9.171634134390457, Test Loss Force: 9.536260680555985, time: 9.821667194366455


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0599042651122836, Training Loss Force: 4.584598322839222, time: 1.0497775077819824
Validation Loss Energy: 2.874896150571873, Validation Loss Force: 4.621613466348827, time: 0.0832056999206543
Test Loss Energy: 8.801179254807057, Test Loss Force: 9.543329150546283, time: 9.948186159133911


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0920913357471145, Training Loss Force: 4.5683086209160635, time: 1.0681688785552979
Validation Loss Energy: 1.9496750095652036, Validation Loss Force: 4.521688460422274, time: 0.08744573593139648
Test Loss Energy: 8.370561249462124, Test Loss Force: 9.543785997685303, time: 9.826865434646606


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0540983685168124, Training Loss Force: 4.560629934360577, time: 1.090496301651001
Validation Loss Energy: 3.8227906886972125, Validation Loss Force: 4.5146612448459384, time: 0.07624363899230957
Test Loss Energy: 8.939940522746117, Test Loss Force: 9.487833400913194, time: 9.83011531829834


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.147129752168222, Training Loss Force: 4.58117263006914, time: 1.3009614944458008
Validation Loss Energy: 2.545337575840348, Validation Loss Force: 4.570604863737982, time: 0.09022855758666992
Test Loss Energy: 8.572213363516473, Test Loss Force: 9.42605508912584, time: 9.783440351486206

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–‚â–‡â–„â–‚â–†â–„â–‚â–‡â–ƒâ–‚â–ˆâ–ƒâ–‚â–†â–„â–â–…â–‚
wandb:   test_error_force â–…â–ˆâ–‡â–‡â–…â–†â–„â–ƒâ–„â–†â–†â–‡â–†â–…â–‡â–…â–†â–†â–ƒâ–
wandb:          test_loss â–â–„â–„â–ƒâ–‡â–„â–â–†â–‚â–‚â–…â–‚â–ƒâ–†â–‚â–ƒâ–ˆâ–ƒâ–â–„
wandb: train_error_energy â–ˆâ–â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–†â–ƒâ–‚â–‡â–ƒâ–‚â–‡â–ƒâ–â–ˆâ–‚â–‚â–ˆâ–ƒâ–‚â–ˆâ–„â–â–‡â–ƒ
wandb:  valid_error_force â–‚â–‚â–‚â–ˆâ–„â–…â–ƒâ–â–…â–„â–…â–â–„â–ƒâ–ƒâ–…â–‡â–ƒâ–ƒâ–…
wandb:         valid_loss â–…â–ƒâ–â–ˆâ–ƒâ–‚â–‡â–‚â–‚â–‡â–‚â–‚â–ˆâ–‚â–‚â–ˆâ–„â–â–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2167
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.57221
wandb:   test_error_force 9.42606
wandb:          test_loss 7.52704
wandb: train_error_energy 3.14713
wandb:  train_error_force 4.58117
wandb:         train_loss 1.57044
wandb: valid_error_energy 2.54534
wandb:  valid_error_force 4.5706
wandb:         valid_loss 1.37544
wandb: 
wandb: ğŸš€ View run al_72_30 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2erfcl6n
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_024727-2erfcl6n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1734955310821533, Uncertainty Bias: -0.023865491151809692
0.00051164627 0.011108875
2.9112277 7.1103663
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1798 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2388 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1970 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 961 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2822 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3025 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3630 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 12 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1489 steps.
Found uncertainty sample 29 after 1362 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 652 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1048 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2244 steps.
Found uncertainty sample 37 after 2571 steps.
Found uncertainty sample 38 after 3798 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3488 steps.
Found uncertainty sample 42 after 807 steps.
Found uncertainty sample 43 after 1790 steps.
Found uncertainty sample 44 after 1638 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1824 steps.
Found uncertainty sample 49 after 3070 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 955 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1159 steps.
Found uncertainty sample 54 after 2894 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1935 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 496 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2771 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3024 steps.
Found uncertainty sample 66 after 1284 steps.
Found uncertainty sample 67 after 1711 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1805 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 37 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1712 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 484 steps.
Found uncertainty sample 80 after 252 steps.
Found uncertainty sample 81 after 2198 steps.
Found uncertainty sample 82 after 1358 steps.
Found uncertainty sample 83 after 1652 steps.
Found uncertainty sample 84 after 2732 steps.
Found uncertainty sample 85 after 1056 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3224 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 297 steps.
Found uncertainty sample 94 after 2389 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 938 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_032150-61d65jqa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_31
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/61d65jqa
Training model 31. Added 44 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.285983200979569, Training Loss Force: 4.9057577813188855, time: 1.0509936809539795
Validation Loss Energy: 3.2866903376045844, Validation Loss Force: 4.643150248812109, time: 0.07734370231628418
Test Loss Energy: 8.947094707533719, Test Loss Force: 9.527091272380927, time: 9.830874919891357


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.193052164276432, Training Loss Force: 4.876863193820616, time: 1.080732822418213
Validation Loss Energy: 3.9519754224098342, Validation Loss Force: 4.622541551349054, time: 0.0795443058013916
Test Loss Energy: 9.20295644589235, Test Loss Force: 9.562346573851853, time: 9.772648811340332


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.021747363963912, Training Loss Force: 4.573740671367925, time: 1.0668458938598633
Validation Loss Energy: 3.220860208633347, Validation Loss Force: 4.541372190253144, time: 0.07547211647033691
Test Loss Energy: 8.81074534048784, Test Loss Force: 9.553930365630325, time: 9.982365131378174


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.991552470944194, Training Loss Force: 4.576142897110153, time: 1.0800564289093018
Validation Loss Energy: 3.701704097818265, Validation Loss Force: 4.547412758843873, time: 0.08427882194519043
Test Loss Energy: 8.796725902199483, Test Loss Force: 9.47315436998232, time: 9.852898597717285


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.015306244237005, Training Loss Force: 4.573974990305401, time: 1.0412371158599854
Validation Loss Energy: 3.410257017430875, Validation Loss Force: 4.565649361895359, time: 0.07714557647705078
Test Loss Energy: 8.906041689069589, Test Loss Force: 9.491004064991133, time: 9.832631587982178


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.073929713730546, Training Loss Force: 4.565765114353263, time: 1.0726277828216553
Validation Loss Energy: 3.9668693162426525, Validation Loss Force: 4.553543731107848, time: 0.07869219779968262
Test Loss Energy: 9.023103223865409, Test Loss Force: 9.466091453896793, time: 10.05561113357544


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1105192886654343, Training Loss Force: 4.559273598789871, time: 1.1066358089447021
Validation Loss Energy: 3.5411211218420844, Validation Loss Force: 4.544838480847802, time: 0.08563733100891113
Test Loss Energy: 9.087153143325937, Test Loss Force: 9.54181866565133, time: 9.791303873062134


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1003653642367923, Training Loss Force: 4.583278358935211, time: 1.1162176132202148
Validation Loss Energy: 4.023079470102371, Validation Loss Force: 4.606001687189538, time: 0.08010458946228027
Test Loss Energy: 9.060620787900222, Test Loss Force: 9.566779433903157, time: 10.65951156616211


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0970102162032984, Training Loss Force: 4.586234869496346, time: 1.0914287567138672
Validation Loss Energy: 3.4162827785234002, Validation Loss Force: 4.515938697736126, time: 0.0756382942199707
Test Loss Energy: 8.9953205963408, Test Loss Force: 9.501603937065456, time: 9.747068405151367


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0680288296902734, Training Loss Force: 4.565561284953332, time: 1.0932085514068604
Validation Loss Energy: 4.064658925059759, Validation Loss Force: 4.543477081689599, time: 0.07965278625488281
Test Loss Energy: 8.950503984334757, Test Loss Force: 9.486851991898648, time: 9.837076425552368


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.112503932308909, Training Loss Force: 4.557263457915641, time: 1.0680737495422363
Validation Loss Energy: 3.472596473535975, Validation Loss Force: 4.54013281378691, time: 0.07664346694946289
Test Loss Energy: 9.035850186093858, Test Loss Force: 9.47308173554008, time: 9.972524642944336


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.12793300982042, Training Loss Force: 4.562750193479934, time: 1.1175971031188965
Validation Loss Energy: 4.143830943916697, Validation Loss Force: 4.616411915099954, time: 0.07634353637695312
Test Loss Energy: 9.035281538059055, Test Loss Force: 9.549824188029657, time: 9.772614240646362


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0697476079870563, Training Loss Force: 4.565692330586344, time: 1.1279122829437256
Validation Loss Energy: 3.465018819830907, Validation Loss Force: 4.48273561071025, time: 0.07934331893920898
Test Loss Energy: 9.04158992050779, Test Loss Force: 9.518943689419109, time: 9.90597939491272


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1304159014946222, Training Loss Force: 4.569685349886328, time: 1.0870518684387207
Validation Loss Energy: 4.214047877731858, Validation Loss Force: 4.5357041471435515, time: 0.07751154899597168
Test Loss Energy: 9.159782395393199, Test Loss Force: 9.512961406517489, time: 10.042340993881226


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0392307321552376, Training Loss Force: 4.579449521018825, time: 1.0875377655029297
Validation Loss Energy: 3.777911388331748, Validation Loss Force: 4.492149171523493, time: 0.07555270195007324
Test Loss Energy: 9.000985168842814, Test Loss Force: 9.49207330124535, time: 9.879941940307617


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.05049947547968, Training Loss Force: 4.553413017865009, time: 1.0875537395477295
Validation Loss Energy: 4.172191645026082, Validation Loss Force: 4.527926981883732, time: 0.07789921760559082
Test Loss Energy: 9.024515062831295, Test Loss Force: 9.45409075740156, time: 9.868707656860352


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.097587910326328, Training Loss Force: 4.585822415242129, time: 1.0574331283569336
Validation Loss Energy: 4.118998212755392, Validation Loss Force: 4.5490578384939875, time: 0.07537722587585449
Test Loss Energy: 9.240325313569965, Test Loss Force: 9.46505180582542, time: 10.000041961669922


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1274326367515406, Training Loss Force: 4.580674388492593, time: 1.0664889812469482
Validation Loss Energy: 3.884179792887493, Validation Loss Force: 4.51033099796508, time: 0.07586479187011719
Test Loss Energy: 8.976595991122776, Test Loss Force: 9.455961504653324, time: 9.880988121032715


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.037997274170362, Training Loss Force: 4.546012237684857, time: 1.097172737121582
Validation Loss Energy: 3.294580952794254, Validation Loss Force: 4.518246886102814, time: 0.08466267585754395
Test Loss Energy: 8.747369546620476, Test Loss Force: 9.441564738924606, time: 10.67684531211853


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.044985646889088, Training Loss Force: 4.558180093203843, time: 1.0968501567840576
Validation Loss Energy: 4.102945771356312, Validation Loss Force: 4.576864761437449, time: 0.07896041870117188
Test Loss Energy: 9.015241086427373, Test Loss Force: 9.511127974417677, time: 9.82162094116211

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‡â–‚â–‚â–ƒâ–…â–†â–…â–…â–„â–…â–…â–…â–‡â–…â–…â–ˆâ–„â–â–…
wandb:   test_error_force â–†â–ˆâ–‡â–ƒâ–„â–‚â–‡â–ˆâ–„â–„â–ƒâ–‡â–…â–…â–„â–‚â–‚â–‚â–â–…
wandb:          test_loss â–ˆâ–„â–…â–‚â–†â–‚â–…â–‚â–…â–‚â–…â–‚â–…â–â–…â–‚â–ˆâ–â–„â–‚
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‡â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–‚â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–†â–â–„â–‚â–†â–ƒâ–‡â–‚â–‡â–ƒâ–ˆâ–ƒâ–ˆâ–…â–ˆâ–‡â–†â–‚â–‡
wandb:  valid_error_force â–ˆâ–‡â–„â–„â–…â–„â–„â–†â–‚â–„â–„â–‡â–â–ƒâ–â–ƒâ–„â–‚â–ƒâ–…
wandb:         valid_loss â–ƒâ–‡â–â–„â–ƒâ–†â–ƒâ–†â–‚â–†â–‚â–ˆâ–‚â–‡â–…â–ˆâ–ˆâ–„â–â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2206
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.01524
wandb:   test_error_force 9.51113
wandb:          test_loss 7.19076
wandb: train_error_energy 3.04499
wandb:  train_error_force 4.55818
wandb:         train_loss 1.52347
wandb: valid_error_energy 4.10295
wandb:  valid_error_force 4.57686
wandb:         valid_loss 1.92236
wandb: 
wandb: ğŸš€ View run al_72_31 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/61d65jqa
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_032150-61d65jqa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1969971656799316, Uncertainty Bias: -0.04661571979522705
0.00015258789 0.08456612
2.81669 7.277923
(48745, 22, 3)
Found uncertainty sample 0 after 451 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 619 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 296 steps.
Found uncertainty sample 7 after 879 steps.
Found uncertainty sample 8 after 2808 steps.
Found uncertainty sample 9 after 2277 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 750 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3518 steps.
Found uncertainty sample 17 after 622 steps.
Found uncertainty sample 18 after 1726 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1541 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2929 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 49 steps.
Found uncertainty sample 26 after 1871 steps.
Found uncertainty sample 27 after 1453 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 630 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1644 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1283 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2585 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 80 steps.
Found uncertainty sample 41 after 1219 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 239 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2591 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3180 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2043 steps.
Found uncertainty sample 56 after 1866 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1706 steps.
Found uncertainty sample 60 after 43 steps.
Found uncertainty sample 61 after 2044 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 436 steps.
Found uncertainty sample 65 after 349 steps.
Found uncertainty sample 66 after 1080 steps.
Found uncertainty sample 67 after 501 steps.
Found uncertainty sample 68 after 256 steps.
Found uncertainty sample 69 after 2742 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 650 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3033 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2304 steps.
Found uncertainty sample 78 after 272 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2021 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3463 steps.
Found uncertainty sample 85 after 2966 steps.
Found uncertainty sample 86 after 639 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 507 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 228 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1879 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2544 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1912 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_035354-l0j1vm3n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_32
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/l0j1vm3n
Training model 32. Added 48 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.856010221418505, Training Loss Force: 4.924256588175445, time: 1.1304662227630615
Validation Loss Energy: 3.1035426270529465, Validation Loss Force: 4.612873702371162, time: 0.08749651908874512
Test Loss Energy: 8.772126116773224, Test Loss Force: 9.471726405573364, time: 9.953707218170166


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.113506727920941, Training Loss Force: 4.593549777654446, time: 1.1067380905151367
Validation Loss Energy: 2.8697087388137663, Validation Loss Force: 4.533959089046916, time: 0.08316516876220703
Test Loss Energy: 8.494401854306963, Test Loss Force: 9.427196050492803, time: 9.92467212677002


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0680909846529913, Training Loss Force: 4.59857349466035, time: 1.0888440608978271
Validation Loss Energy: 3.6763624563239423, Validation Loss Force: 4.543237712357727, time: 0.07769203186035156
Test Loss Energy: 8.980242588932706, Test Loss Force: 9.453916469248071, time: 10.166947841644287


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.1340199018884847, Training Loss Force: 4.584800128421173, time: 1.1422767639160156
Validation Loss Energy: 3.186462724308714, Validation Loss Force: 4.543677483920934, time: 0.08781933784484863
Test Loss Energy: 8.618731069869614, Test Loss Force: 9.4696506301679, time: 10.088432312011719


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.128710450189391, Training Loss Force: 4.589021013389529, time: 1.1152291297912598
Validation Loss Energy: 2.450642066140481, Validation Loss Force: 4.522542619266051, time: 0.07684922218322754
Test Loss Energy: 8.387111797077418, Test Loss Force: 9.427086324733564, time: 9.940259218215942


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.103297814871739, Training Loss Force: 4.57262681248567, time: 1.1376316547393799
Validation Loss Energy: 3.452088088523161, Validation Loss Force: 4.532911876053618, time: 0.1138160228729248
Test Loss Energy: 8.977386492238574, Test Loss Force: 9.450978682122562, time: 10.215025901794434


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1818483233719865, Training Loss Force: 4.608756443232661, time: 1.10176682472229
Validation Loss Energy: 2.8783947281926903, Validation Loss Force: 4.554637704621792, time: 0.08656024932861328
Test Loss Energy: 8.65472371398662, Test Loss Force: 9.440451962108806, time: 10.089947700500488


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.153840314508826, Training Loss Force: 4.593252354399188, time: 1.107452630996704
Validation Loss Energy: 2.5921545431136757, Validation Loss Force: 4.6324841740530225, time: 0.0828855037689209
Test Loss Energy: 8.286548791586464, Test Loss Force: 9.555202270444775, time: 10.16244649887085


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.080365121100729, Training Loss Force: 4.602378715920775, time: 1.134091854095459
Validation Loss Energy: 3.88257234432304, Validation Loss Force: 4.563776937047251, time: 0.08762574195861816
Test Loss Energy: 8.836246019630767, Test Loss Force: 9.508779474774927, time: 10.0581693649292


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.109954411767511, Training Loss Force: 4.577809885331617, time: 1.1125571727752686
Validation Loss Energy: 3.047666476912119, Validation Loss Force: 4.493942548824796, time: 0.08092713356018066
Test Loss Energy: 8.698923795930835, Test Loss Force: 9.423836311164795, time: 10.67824387550354


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.06586624390088, Training Loss Force: 4.58502912638874, time: 1.0880250930786133
Validation Loss Energy: 2.354079475652009, Validation Loss Force: 4.556533064391929, time: 0.0971231460571289
Test Loss Energy: 8.336139989668581, Test Loss Force: 9.487450750397857, time: 10.297117710113525


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.04857330955365, Training Loss Force: 4.57169702767309, time: 1.1405718326568604
Validation Loss Energy: 3.3665401613417267, Validation Loss Force: 4.512991671589772, time: 0.08301544189453125
Test Loss Energy: 8.91498590062904, Test Loss Force: 9.418449387269035, time: 10.112318992614746


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1315544589258093, Training Loss Force: 4.578943114475132, time: 1.117701768875122
Validation Loss Energy: 2.6885171767091043, Validation Loss Force: 4.597485260365238, time: 0.07922482490539551
Test Loss Energy: 8.50375061490132, Test Loss Force: 9.415194057620136, time: 10.045676231384277


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.114055375287951, Training Loss Force: 4.589475986042178, time: 1.1159403324127197
Validation Loss Energy: 2.700469722458789, Validation Loss Force: 4.562313332751068, time: 0.07693958282470703
Test Loss Energy: 8.324304819121071, Test Loss Force: 9.419969608984442, time: 10.884721517562866


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0389705207367763, Training Loss Force: 4.578833297815784, time: 1.182997465133667
Validation Loss Energy: 4.343738181740308, Validation Loss Force: 4.463014917801155, time: 0.09221124649047852
Test Loss Energy: 9.111431242950559, Test Loss Force: 9.459016021706809, time: 11.530832052230835


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0627212789966287, Training Loss Force: 4.608062788072691, time: 1.2289423942565918
Validation Loss Energy: 3.1128550960739383, Validation Loss Force: 4.479987428111208, time: 0.09034991264343262
Test Loss Energy: 8.497305916966223, Test Loss Force: 9.44280065760714, time: 11.757479190826416


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0893151615886874, Training Loss Force: 4.5702798106915195, time: 1.1929516792297363
Validation Loss Energy: 1.9610242332639969, Validation Loss Force: 4.49686552670339, time: 0.08834695816040039
Test Loss Energy: 8.3111842087393, Test Loss Force: 9.46681552266384, time: 11.482748985290527


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.076445617253295, Training Loss Force: 4.582996395436494, time: 1.1574649810791016
Validation Loss Energy: 3.2825973446987122, Validation Loss Force: 4.44822590113607, time: 0.09351491928100586
Test Loss Energy: 8.93344957957709, Test Loss Force: 9.42520042199019, time: 11.627601146697998


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.077297449047689, Training Loss Force: 4.569025531073434, time: 1.2144989967346191
Validation Loss Energy: 2.578988227849539, Validation Loss Force: 4.499898503140072, time: 0.09117746353149414
Test Loss Energy: 8.587676945283981, Test Loss Force: 9.350631383577852, time: 11.539600372314453


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.125916518489417, Training Loss Force: 4.5520181620653934, time: 1.2517437934875488
Validation Loss Energy: 2.853849240229633, Validation Loss Force: 4.55269936970649, time: 0.09623956680297852
Test Loss Energy: 8.364164470859878, Test Loss Force: 9.437753897554705, time: 11.420643091201782

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–‡â–„â–‚â–‡â–„â–â–†â–„â–â–†â–ƒâ–â–ˆâ–ƒâ–â–†â–„â–‚
wandb:   test_error_force â–…â–„â–…â–…â–„â–„â–„â–ˆâ–†â–„â–†â–ƒâ–ƒâ–ƒâ–…â–„â–…â–„â–â–„
wandb:          test_loss â–†â–‚â–ƒâ–‚â–„â–‡â–„â–‚â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–â–ƒâ–ƒâ–„â–‡â–…â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–„â–†â–…â–‚â–…â–„â–ƒâ–‡â–„â–‚â–…â–ƒâ–ƒâ–ˆâ–„â–â–…â–ƒâ–„
wandb:  valid_error_force â–‡â–„â–…â–…â–„â–„â–…â–ˆâ–…â–ƒâ–…â–ƒâ–‡â–…â–‚â–‚â–ƒâ–â–ƒâ–…
wandb:         valid_loss â–…â–ƒâ–†â–„â–‚â–…â–„â–ƒâ–‡â–„â–‚â–…â–ƒâ–ƒâ–ˆâ–„â–â–…â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2249
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.36416
wandb:   test_error_force 9.43775
wandb:          test_loss 6.94401
wandb: train_error_energy 3.12592
wandb:  train_error_force 4.55202
wandb:         train_loss 1.54621
wandb: valid_error_energy 2.85385
wandb:  valid_error_force 4.5527
wandb:         valid_loss 1.43894
wandb: 
wandb: ğŸš€ View run al_72_32 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/l0j1vm3n
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_035354-l0j1vm3n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.175278663635254, Uncertainty Bias: -0.041440725326538086
1.9073486e-05 0.027816772
2.8516924 7.2778306
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3063 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 687 steps.
Found uncertainty sample 5 after 417 steps.
Found uncertainty sample 6 after 995 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1356 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1836 steps.
Found uncertainty sample 11 after 658 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3478 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1008 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3786 steps.
Found uncertainty sample 31 after 486 steps.
Found uncertainty sample 32 after 2621 steps.
Found uncertainty sample 33 after 663 steps.
Found uncertainty sample 34 after 1541 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2641 steps.
Found uncertainty sample 37 after 131 steps.
Found uncertainty sample 38 after 2214 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3392 steps.
Found uncertainty sample 41 after 1937 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 26 steps.
Found uncertainty sample 47 after 2016 steps.
Found uncertainty sample 48 after 3425 steps.
Found uncertainty sample 49 after 1096 steps.
Found uncertainty sample 50 after 289 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2710 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 58 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 482 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3640 steps.
Found uncertainty sample 60 after 128 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1098 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3702 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2919 steps.
Found uncertainty sample 73 after 756 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1000 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3840 steps.
Found uncertainty sample 83 after 1802 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2954 steps.
Found uncertainty sample 90 after 1708 steps.
Found uncertainty sample 91 after 1033 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 646 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1796 steps.
Found uncertainty sample 97 after 1858 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2395 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_042826-etbop67j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_33
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/etbop67j
Training model 33. Added 43 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.51081818690332, Training Loss Force: 5.173433380837881, time: 1.1119797229766846
Validation Loss Energy: 4.487107942059687, Validation Loss Force: 4.555595849956719, time: 0.08100056648254395
Test Loss Energy: 8.94549820473163, Test Loss Force: 9.393218156445592, time: 10.787065267562866


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.125718613772197, Training Loss Force: 4.614044917337726, time: 1.1172730922698975
Validation Loss Energy: 3.9905746735181244, Validation Loss Force: 4.536452092804723, time: 0.08625078201293945
Test Loss Energy: 8.922616191688077, Test Loss Force: 9.35395752901, time: 10.243288516998291


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0586375821137977, Training Loss Force: 4.587117580817457, time: 1.1330289840698242
Validation Loss Energy: 4.215911841152419, Validation Loss Force: 4.512243057921163, time: 0.08270406723022461
Test Loss Energy: 8.958953935675444, Test Loss Force: 9.41471515341179, time: 10.354805707931519


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0634359181972335, Training Loss Force: 4.576459386072035, time: 1.1612739562988281
Validation Loss Energy: 4.200418521978763, Validation Loss Force: 4.475367488671499, time: 0.08026719093322754
Test Loss Energy: 9.029115309458371, Test Loss Force: 9.407121305481034, time: 10.095353364944458


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.116436253021625, Training Loss Force: 4.583187903359615, time: 1.0898957252502441
Validation Loss Energy: 4.103689486303711, Validation Loss Force: 4.516563062021307, time: 0.07749176025390625
Test Loss Energy: 8.830008998562977, Test Loss Force: 9.447100237933633, time: 10.348179578781128


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.132983922971756, Training Loss Force: 4.5899263974619835, time: 1.1043634414672852
Validation Loss Energy: 4.271687344839288, Validation Loss Force: 4.541087396415502, time: 0.08346843719482422
Test Loss Energy: 8.766563214303757, Test Loss Force: 9.417212895009435, time: 10.249186992645264


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1049796440345805, Training Loss Force: 4.594459588713594, time: 1.1229143142700195
Validation Loss Energy: 3.98624754400531, Validation Loss Force: 4.534134997672199, time: 0.07771158218383789
Test Loss Energy: 9.000493314849793, Test Loss Force: 9.432874146356559, time: 10.137073516845703


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0479827289518773, Training Loss Force: 4.608540913350889, time: 1.0998029708862305
Validation Loss Energy: 4.168075383194461, Validation Loss Force: 4.5534994199478085, time: 0.08017492294311523
Test Loss Energy: 8.73837736210105, Test Loss Force: 9.399851785070682, time: 10.295330286026001


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1054760694322914, Training Loss Force: 4.587129209095077, time: 1.1206891536712646
Validation Loss Energy: 4.287491287471512, Validation Loss Force: 4.523391211381183, time: 0.08197331428527832
Test Loss Energy: 8.75596502565481, Test Loss Force: 9.415237075900158, time: 10.181573629379272


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.043027720383265, Training Loss Force: 4.584612862188472, time: 1.1435794830322266
Validation Loss Energy: 3.7920350695888017, Validation Loss Force: 4.4930135731479846, time: 0.08170485496520996
Test Loss Energy: 8.727816472282754, Test Loss Force: 9.409809050311159, time: 10.124088764190674


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1186237964616845, Training Loss Force: 4.593984449867708, time: 1.086292028427124
Validation Loss Energy: 4.098511983322599, Validation Loss Force: 4.541491095577069, time: 0.08069849014282227
Test Loss Energy: 9.232350256061382, Test Loss Force: 9.425472609956236, time: 10.35946011543274


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0637646381628496, Training Loss Force: 4.60576441465879, time: 1.153075933456421
Validation Loss Energy: 4.340409946016127, Validation Loss Force: 4.501622184998698, time: 0.08217787742614746
Test Loss Energy: 8.978321865864459, Test Loss Force: 9.38998940253413, time: 10.917553186416626


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.026676843568728, Training Loss Force: 4.6000082997167295, time: 1.1643664836883545
Validation Loss Energy: 4.158466764209384, Validation Loss Force: 4.55562257025423, time: 0.09087491035461426
Test Loss Energy: 8.733912561268278, Test Loss Force: 9.352666719468479, time: 10.86363697052002


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.104486527747788, Training Loss Force: 4.58938488465485, time: 1.1763088703155518
Validation Loss Energy: 4.299784405679894, Validation Loss Force: 4.445871842925321, time: 0.08022117614746094
Test Loss Energy: 8.89271256010782, Test Loss Force: 9.414095550282587, time: 10.704710006713867


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.120939295798663, Training Loss Force: 4.58252827075582, time: 1.1782054901123047
Validation Loss Energy: 4.1301185325721725, Validation Loss Force: 4.488165175164553, time: 0.08259916305541992
Test Loss Energy: 8.760250173290064, Test Loss Force: 9.390542218909237, time: 10.823969841003418


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0671852166374247, Training Loss Force: 4.620856428364196, time: 1.1431264877319336
Validation Loss Energy: 4.252205130585481, Validation Loss Force: 4.486998388839892, time: 0.08018612861633301
Test Loss Energy: 9.000536431057611, Test Loss Force: 9.439270621848975, time: 10.8881676197052


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0646353348296547, Training Loss Force: 4.583579918576274, time: 1.2013506889343262
Validation Loss Energy: 4.051162280117638, Validation Loss Force: 4.498543116048809, time: 0.08653020858764648
Test Loss Energy: 8.786381080727619, Test Loss Force: 9.392822201740236, time: 10.823989391326904


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0364044312765834, Training Loss Force: 4.581931511259479, time: 1.2386553287506104
Validation Loss Energy: 4.30246445152028, Validation Loss Force: 4.567835304900932, time: 0.08831524848937988
Test Loss Energy: 8.85064094338435, Test Loss Force: 9.399652208230739, time: 11.035897016525269


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0852270692334667, Training Loss Force: 4.612400289211157, time: 1.268739938735962
Validation Loss Energy: 4.281260782099306, Validation Loss Force: 4.5084750506337725, time: 0.08784103393554688
Test Loss Energy: 9.084132551257511, Test Loss Force: 9.402955499181541, time: 10.911725521087646


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1542164419639493, Training Loss Force: 4.572646152207004, time: 1.1383452415466309
Validation Loss Energy: 4.273511227813581, Validation Loss Force: 4.5156095927384445, time: 0.08174419403076172
Test Loss Energy: 9.078576067721643, Test Loss Force: 9.385655640745025, time: 10.946263551712036

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–„â–…â–‚â–‚â–…â–â–â–â–ˆâ–„â–â–ƒâ–â–…â–‚â–ƒâ–†â–†
wandb:   test_error_force â–„â–â–†â–…â–ˆâ–†â–‡â–„â–†â–…â–†â–„â–â–†â–„â–‡â–„â–„â–…â–ƒ
wandb:          test_loss â–â–…â–†â–‡â–„â–„â–ˆâ–†â–„â–„â–ˆâ–†â–†â–†â–‚â–„â–„â–…â–…â–„
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–…â–…â–„â–†â–ƒâ–…â–†â–â–„â–‡â–…â–†â–„â–†â–„â–†â–†â–†
wandb:  valid_error_force â–‡â–†â–…â–ƒâ–…â–†â–†â–‡â–…â–„â–†â–„â–‡â–â–ƒâ–ƒâ–„â–ˆâ–…â–…
wandb:         valid_loss â–‡â–„â–†â–†â–…â–‡â–„â–†â–‡â–â–…â–ˆâ–‡â–†â–„â–…â–„â–ˆâ–‡â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2287
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.07858
wandb:   test_error_force 9.38566
wandb:          test_loss 6.91621
wandb: train_error_energy 3.15422
wandb:  train_error_force 4.57265
wandb:         train_loss 1.56131
wandb: valid_error_energy 4.27351
wandb:  valid_error_force 4.51561
wandb:         valid_loss 1.94951
wandb: 
wandb: ğŸš€ View run al_72_33 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/etbop67j
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_042826-etbop67j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0158674716949463, Uncertainty Bias: -0.038913339376449585
3.0517578e-05 0.022521973
2.7747667 7.0531588
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2043 steps.
Found uncertainty sample 3 after 930 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 747 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2499 steps.
Found uncertainty sample 12 after 727 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2610 steps.
Found uncertainty sample 15 after 2894 steps.
Found uncertainty sample 16 after 791 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3440 steps.
Found uncertainty sample 19 after 2862 steps.
Found uncertainty sample 20 after 1469 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1236 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 377 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3154 steps.
Found uncertainty sample 34 after 10 steps.
Found uncertainty sample 35 after 2357 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2819 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 38 steps.
Found uncertainty sample 46 after 2975 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 691 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1805 steps.
Found uncertainty sample 51 after 1806 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 913 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 753 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1809 steps.
Found uncertainty sample 61 after 2610 steps.
Found uncertainty sample 62 after 2605 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1383 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1022 steps.
Found uncertainty sample 71 after 120 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1991 steps.
Found uncertainty sample 74 after 1767 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1999 steps.
Found uncertainty sample 78 after 1550 steps.
Found uncertainty sample 79 after 2177 steps.
Found uncertainty sample 80 after 3978 steps.
Found uncertainty sample 81 after 2850 steps.
Found uncertainty sample 82 after 2070 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2566 steps.
Found uncertainty sample 87 after 2678 steps.
Found uncertainty sample 88 after 2182 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1701 steps.
Found uncertainty sample 96 after 3536 steps.
Found uncertainty sample 97 after 198 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2139 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_050305-lm8rrqgz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_34
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/lm8rrqgz
Training model 34. Added 45 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8312141374269086, Training Loss Force: 4.994169559918188, time: 1.2599105834960938
Validation Loss Energy: 1.7984086776565011, Validation Loss Force: 4.980611574201758, time: 0.08053159713745117
Test Loss Energy: 8.023699026255375, Test Loss Force: 9.629130987005079, time: 9.528404951095581


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 5.874306368029927, Training Loss Force: 4.908210551940485, time: 1.1525523662567139
Validation Loss Energy: 9.020125363288475, Validation Loss Force: 4.738068761661623, time: 0.09310317039489746
Test Loss Energy: 12.15404984588161, Test Loss Force: 9.646141552754559, time: 9.515498876571655


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.500471502130185, Training Loss Force: 4.751717047342383, time: 1.2079510688781738
Validation Loss Energy: 1.9840608037596752, Validation Loss Force: 4.78165223893236, time: 0.08327960968017578
Test Loss Energy: 8.062239066023762, Test Loss Force: 9.502956543706912, time: 10.329943656921387


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.6578325444259185, Training Loss Force: 4.868015836748213, time: 1.2313978672027588
Validation Loss Energy: 2.070336302375429, Validation Loss Force: 4.525433310118487, time: 0.07852935791015625
Test Loss Energy: 8.217633763464296, Test Loss Force: 9.317484705291742, time: 10.156407594680786


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.422156550945625, Training Loss Force: 4.639023759451086, time: 1.258882999420166
Validation Loss Energy: 3.874673935713263, Validation Loss Force: 4.533587231573216, time: 0.0876917839050293
Test Loss Energy: 8.696987143275102, Test Loss Force: 9.378436478535866, time: 11.516134262084961


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.462198088067073, Training Loss Force: 4.6528343404366055, time: 1.3788094520568848
Validation Loss Energy: 6.4473160929038595, Validation Loss Force: 4.479480633135077, time: 0.09992861747741699
Test Loss Energy: 9.663901760414463, Test Loss Force: 9.33667313850138, time: 10.734737873077393


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.516742623335662, Training Loss Force: 4.632053916257844, time: 1.1992933750152588
Validation Loss Energy: 5.501456528103154, Validation Loss Force: 4.54321566811228, time: 0.0874185562133789
Test Loss Energy: 9.400008441558397, Test Loss Force: 9.319123662123246, time: 10.559544563293457


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.526821548534429, Training Loss Force: 4.623786851424622, time: 1.1311073303222656
Validation Loss Energy: 2.8613286968413467, Validation Loss Force: 4.528274345751379, time: 0.0864410400390625
Test Loss Energy: 8.379116244680953, Test Loss Force: 9.28990262455854, time: 10.374138593673706


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.48640303864945, Training Loss Force: 4.631445858674774, time: 1.1060128211975098
Validation Loss Energy: 3.7595377324209434, Validation Loss Force: 4.577384471224045, time: 0.08128643035888672
Test Loss Energy: 9.080579698323826, Test Loss Force: 9.246937640568698, time: 10.193333625793457


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.508393343258266, Training Loss Force: 4.619249269066284, time: 1.157174825668335
Validation Loss Energy: 5.786571454653222, Validation Loss Force: 4.539191591307073, time: 0.08081579208374023
Test Loss Energy: 10.092492506579987, Test Loss Force: 9.276386472167106, time: 10.167477130889893


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.606413033358624, Training Loss Force: 4.608098705899067, time: 1.1339423656463623
Validation Loss Energy: 5.204631876507035, Validation Loss Force: 4.554141152426373, time: 0.08117103576660156
Test Loss Energy: 9.68552195986936, Test Loss Force: 9.293108864404319, time: 10.277030229568481


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.486799305846989, Training Loss Force: 4.609640747689601, time: 1.108940839767456
Validation Loss Energy: 2.4565912290468064, Validation Loss Force: 4.733572180928757, time: 0.0804131031036377
Test Loss Energy: 8.431650739492682, Test Loss Force: 9.418076762694298, time: 10.192949533462524


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.504172050220668, Training Loss Force: 4.677877933178579, time: 1.1735570430755615
Validation Loss Energy: 3.9321062091804064, Validation Loss Force: 4.562134306757742, time: 0.07948756217956543
Test Loss Energy: 8.886650650253294, Test Loss Force: 9.241319234025735, time: 10.352035999298096


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.543586091962711, Training Loss Force: 4.617403640772244, time: 1.197345495223999
Validation Loss Energy: 6.02606681726219, Validation Loss Force: 4.504642914632355, time: 0.08549785614013672
Test Loss Energy: 9.654545743837048, Test Loss Force: 9.256696713947997, time: 10.21464204788208


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.54263101519163, Training Loss Force: 4.611833373819813, time: 1.1299152374267578
Validation Loss Energy: 5.771863489557255, Validation Loss Force: 4.518256683545234, time: 0.08726739883422852
Test Loss Energy: 9.336602747071897, Test Loss Force: 9.288358060791998, time: 10.293651580810547


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.506148884021249, Training Loss Force: 4.654081458468489, time: 1.1282577514648438
Validation Loss Energy: 2.639911508186538, Validation Loss Force: 4.6407721423336, time: 0.08716988563537598
Test Loss Energy: 8.33184517282968, Test Loss Force: 9.29652049613559, time: 10.323499917984009


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.530181644248053, Training Loss Force: 4.6633442936217735, time: 1.1257150173187256
Validation Loss Energy: 3.3058896507084885, Validation Loss Force: 4.4378377174710995, time: 0.09365344047546387
Test Loss Energy: 8.73004889251786, Test Loss Force: 9.217212312181397, time: 10.259275674819946


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.473923023245948, Training Loss Force: 4.620903481201642, time: 1.1926171779632568
Validation Loss Energy: 5.389084539588382, Validation Loss Force: 4.537949542811088, time: 0.08586812019348145
Test Loss Energy: 9.846209216120066, Test Loss Force: 9.261009374629555, time: 10.163548469543457


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.579756431424074, Training Loss Force: 4.60402390323226, time: 1.1131391525268555
Validation Loss Energy: 5.242091061588175, Validation Loss Force: 4.517329489221591, time: 0.08186721801757812
Test Loss Energy: 9.875712602825034, Test Loss Force: 9.267488384597652, time: 10.340166568756104


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.5175576945935445, Training Loss Force: 4.623031399067997, time: 1.2052607536315918
Validation Loss Energy: 2.3390031044541035, Validation Loss Force: 4.602496206825197, time: 0.08254575729370117
Test Loss Energy: 8.231685196161244, Test Loss Force: 9.182178453427387, time: 10.203210830688477

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–â–â–‚â–„â–ƒâ–‚â–ƒâ–…â–„â–‚â–‚â–„â–ƒâ–‚â–‚â–„â–„â–
wandb:   test_error_force â–ˆâ–ˆâ–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–…â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–
wandb:          test_loss â–‡â–ˆâ–â–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–„â–‚
wandb: train_error_energy â–â–†â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–†â–„â–†â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–‚â–‚â–â–â–
wandb:         train_loss â–…â–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–â–â–ƒâ–†â–…â–‚â–ƒâ–…â–„â–‚â–ƒâ–…â–…â–‚â–‚â–„â–„â–‚
wandb:  valid_error_force â–ˆâ–…â–…â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–…â–ƒâ–‚â–‚â–„â–â–‚â–‚â–ƒ
wandb:         valid_loss â–â–ˆâ–‚â–â–‚â–„â–„â–‚â–‚â–„â–ƒâ–‚â–‚â–„â–„â–‚â–‚â–ƒâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2327
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.23169
wandb:   test_error_force 9.18218
wandb:          test_loss 5.8316
wandb: train_error_energy 4.51756
wandb:  train_error_force 4.62303
wandb:         train_loss 1.92418
wandb: valid_error_energy 2.339
wandb:  valid_error_force 4.6025
wandb:         valid_loss 1.44805
wandb: 
wandb: ğŸš€ View run al_72_34 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/lm8rrqgz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_050305-lm8rrqgz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0495400428771973, Uncertainty Bias: -0.11488491296768188
5.340576e-05 0.005763054
2.6053839 6.823669
(48745, 22, 3)
Found uncertainty sample 0 after 382 steps.
Found uncertainty sample 1 after 1385 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2876 steps.
Found uncertainty sample 8 after 1998 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 992 steps.
Found uncertainty sample 12 after 2738 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1100 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 93 steps.
Found uncertainty sample 20 after 2620 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1538 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3080 steps.
Found uncertainty sample 29 after 3405 steps.
Found uncertainty sample 30 after 1525 steps.
Found uncertainty sample 31 after 1495 steps.
Found uncertainty sample 32 after 3314 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2892 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1398 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2414 steps.
Found uncertainty sample 41 after 708 steps.
Found uncertainty sample 42 after 2001 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1549 steps.
Found uncertainty sample 45 after 1277 steps.
Found uncertainty sample 46 after 3805 steps.
Found uncertainty sample 47 after 193 steps.
Found uncertainty sample 48 after 1177 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3687 steps.
Found uncertainty sample 51 after 3136 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3019 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 278 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2462 steps.
Found uncertainty sample 61 after 2645 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2169 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 34 steps.
Found uncertainty sample 71 after 2642 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2841 steps.
Found uncertainty sample 76 after 3118 steps.
Found uncertainty sample 77 after 1836 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1472 steps.
Found uncertainty sample 80 after 714 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3253 steps.
Found uncertainty sample 84 after 934 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2082 steps.
Found uncertainty sample 87 after 428 steps.
Found uncertainty sample 88 after 1325 steps.
Found uncertainty sample 89 after 2350 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 585 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 660 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2552 steps.
Found uncertainty sample 98 after 1704 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_053645-5hg0ot8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_35
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/5hg0ot8o
Training model 35. Added 49 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.497208582707553, Training Loss Force: 4.893283766438186, time: 1.1900677680969238
Validation Loss Energy: 2.451788812242009, Validation Loss Force: 4.542630716265927, time: 0.091217041015625
Test Loss Energy: 8.033465677380478, Test Loss Force: 9.12913259134429, time: 10.18659496307373


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.480990138449002, Training Loss Force: 4.666721627546936, time: 1.2402112483978271
Validation Loss Energy: 5.5622195979896585, Validation Loss Force: 4.618664658849305, time: 0.08717799186706543
Test Loss Energy: 10.044377635246356, Test Loss Force: 9.224964924379007, time: 10.20049786567688


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.507434024873809, Training Loss Force: 4.609299298483851, time: 1.1800127029418945
Validation Loss Energy: 6.328780177091515, Validation Loss Force: 4.536801015356392, time: 0.0876455307006836
Test Loss Energy: 9.817068330121439, Test Loss Force: 9.158196296253195, time: 10.337773561477661


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.578055230852471, Training Loss Force: 4.627895800191438, time: 1.1994926929473877
Validation Loss Energy: 3.4987500780709233, Validation Loss Force: 4.515823132449389, time: 0.08803486824035645
Test Loss Energy: 8.81737936781894, Test Loss Force: 9.218680245119145, time: 10.087394952774048


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.605711051997969, Training Loss Force: 4.66937453744074, time: 1.1622023582458496
Validation Loss Energy: 2.3116328357058054, Validation Loss Force: 4.5745441035985905, time: 0.08184099197387695
Test Loss Energy: 8.339131909878498, Test Loss Force: 9.153324295340292, time: 10.342488288879395


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.457191680234696, Training Loss Force: 4.628505290177673, time: 1.3015992641448975
Validation Loss Energy: 5.909908339920916, Validation Loss Force: 4.532805217532718, time: 0.07905364036560059
Test Loss Energy: 9.643343056254995, Test Loss Force: 9.187943900881542, time: 10.201395988464355


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.58759518757971, Training Loss Force: 4.64686193861911, time: 1.210883378982544
Validation Loss Energy: 5.93820402163969, Validation Loss Force: 4.5838316336752385, time: 0.07913422584533691
Test Loss Energy: 10.11158829077201, Test Loss Force: 9.25963444045154, time: 10.206065654754639


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.5566752089523845, Training Loss Force: 4.659728795055655, time: 1.1867938041687012
Validation Loss Energy: 3.82925867071355, Validation Loss Force: 4.51479017028143, time: 0.08087468147277832
Test Loss Energy: 8.737463998912208, Test Loss Force: 9.184095744359688, time: 10.303426742553711


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.534818685471238, Training Loss Force: 4.681413795009233, time: 1.159613847732544
Validation Loss Energy: 3.024898111402711, Validation Loss Force: 4.590680491265685, time: 0.09320926666259766
Test Loss Energy: 8.37905638981556, Test Loss Force: 9.143939226851272, time: 10.829897165298462


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.482852636706584, Training Loss Force: 4.640754201138282, time: 1.213883638381958
Validation Loss Energy: 5.453709360472713, Validation Loss Force: 4.5711279135617655, time: 0.08124065399169922
Test Loss Energy: 9.840230892299175, Test Loss Force: 9.216910675929352, time: 10.26662540435791


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.5094733892339995, Training Loss Force: 4.613852965647889, time: 1.197021722793579
Validation Loss Energy: 6.3033137295409, Validation Loss Force: 4.515196318803603, time: 0.08563041687011719
Test Loss Energy: 9.625234440164329, Test Loss Force: 9.265445522256732, time: 10.28001880645752


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.5415547299655925, Training Loss Force: 4.640484593336393, time: 1.17366361618042
Validation Loss Energy: 3.5285832902423286, Validation Loss Force: 4.560948816224823, time: 0.08078312873840332
Test Loss Energy: 8.855488369084705, Test Loss Force: 9.214422601203738, time: 10.144068717956543


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.619162846920716, Training Loss Force: 4.636132480345405, time: 1.185347557067871
Validation Loss Energy: 2.277152295789742, Validation Loss Force: 4.590689843369814, time: 0.08194184303283691
Test Loss Energy: 8.194574638682589, Test Loss Force: 9.274133065073546, time: 10.326895475387573


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.6066167943338336, Training Loss Force: 4.893585581105342, time: 1.1807689666748047
Validation Loss Energy: 2.8870684707685887, Validation Loss Force: 4.729772999960937, time: 0.08184051513671875
Test Loss Energy: 8.025962456957926, Test Loss Force: 9.400657129241802, time: 10.178258895874023


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1203946941375067, Training Loss Force: 4.716195647844644, time: 1.1578447818756104
Validation Loss Energy: 2.576592530508502, Validation Loss Force: 4.531522643252174, time: 0.08804178237915039
Test Loss Energy: 8.236446972349487, Test Loss Force: 9.1780286793064, time: 10.118994951248169


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.108084771830913, Training Loss Force: 4.605296621668028, time: 1.1817936897277832
Validation Loss Energy: 3.0727197618624653, Validation Loss Force: 4.526145183378018, time: 0.08614492416381836
Test Loss Energy: 8.64404200458923, Test Loss Force: 9.187258802712453, time: 10.384825229644775


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.066679249681253, Training Loss Force: 4.596775115018279, time: 1.1757848262786865
Validation Loss Energy: 2.7548971871362102, Validation Loss Force: 4.522261610803891, time: 0.08515572547912598
Test Loss Energy: 8.611526834653882, Test Loss Force: 9.252673770307238, time: 10.197503089904785


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1281316735543303, Training Loss Force: 4.592854707029572, time: 1.1606814861297607
Validation Loss Energy: 3.1997521756105494, Validation Loss Force: 4.460128680331639, time: 0.08328127861022949
Test Loss Energy: 8.523020018073582, Test Loss Force: 9.20746007509462, time: 10.192169427871704


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1346303319566715, Training Loss Force: 4.614152411115333, time: 1.1428751945495605
Validation Loss Energy: 2.440061162329711, Validation Loss Force: 4.737445288053024, time: 0.08478188514709473
Test Loss Energy: 8.255203308503711, Test Loss Force: 9.256702790134325, time: 10.304141283035278


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0351550895001327, Training Loss Force: 5.174160622227045, time: 1.2262282371520996
Validation Loss Energy: 3.4411606001867554, Validation Loss Force: 5.0797069148905845, time: 0.08359861373901367
Test Loss Energy: 8.781818279822884, Test Loss Force: 9.601767560378336, time: 10.160727262496948

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–‡â–„â–‚â–†â–ˆâ–ƒâ–‚â–‡â–†â–„â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–„
wandb:   test_error_force â–â–‚â–â–‚â–â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–ƒâ–…â–‚â–‚â–ƒâ–‚â–ƒâ–ˆ
wandb:          test_loss â–â–…â–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–‚â–„â–‚â–ƒâ–‚â–†â–†â–…â–‡â–…â–„â–ˆ
wandb: train_error_energy â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–ƒâ–â–â–â–â–â–
wandb:  train_error_force â–…â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–…â–‚â–â–â–â–â–ˆ
wandb:         train_loss â–ˆâ–„â–„â–„â–…â–„â–„â–„â–…â–„â–„â–„â–„â–ƒâ–‚â–â–â–â–â–„
wandb: valid_error_energy â–â–‡â–ˆâ–ƒâ–â–‡â–‡â–„â–‚â–†â–ˆâ–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–â–ƒ
wandb:  valid_error_force â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–â–„â–ˆ
wandb:         valid_loss â–â–‡â–ˆâ–ƒâ–â–‡â–ˆâ–ƒâ–‚â–†â–ˆâ–ƒâ–â–‚â–â–‚â–â–‚â–â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2371
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.78182
wandb:   test_error_force 9.60177
wandb:          test_loss 7.94777
wandb: train_error_energy 3.03516
wandb:  train_error_force 5.17416
wandb:         train_loss 1.84786
wandb: valid_error_energy 3.44116
wandb:  valid_error_force 5.07971
wandb:         valid_loss 1.91172
wandb: 
wandb: ğŸš€ View run al_72_35 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/5hg0ot8o
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_053645-5hg0ot8o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.338461399078369, Uncertainty Bias: 0.008370190858840942
0.0003080368 0.057663918
3.4950888 7.672172
(48745, 22, 3)
Found uncertainty sample 0 after 1710 steps.
Found uncertainty sample 1 after 1917 steps.
Found uncertainty sample 2 after 2642 steps.
Found uncertainty sample 3 after 1167 steps.
Found uncertainty sample 4 after 2749 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1870 steps.
Found uncertainty sample 7 after 823 steps.
Found uncertainty sample 8 after 349 steps.
Found uncertainty sample 9 after 3125 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2963 steps.
Found uncertainty sample 12 after 1741 steps.
Found uncertainty sample 13 after 382 steps.
Found uncertainty sample 14 after 1611 steps.
Found uncertainty sample 15 after 3602 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 434 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 361 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 794 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1481 steps.
Found uncertainty sample 26 after 2218 steps.
Found uncertainty sample 27 after 2725 steps.
Found uncertainty sample 28 after 104 steps.
Found uncertainty sample 29 after 1559 steps.
Found uncertainty sample 30 after 2651 steps.
Found uncertainty sample 31 after 3704 steps.
Found uncertainty sample 32 after 3647 steps.
Found uncertainty sample 33 after 2013 steps.
Found uncertainty sample 34 after 413 steps.
Found uncertainty sample 35 after 3929 steps.
Found uncertainty sample 36 after 3817 steps.
Found uncertainty sample 37 after 35 steps.
Found uncertainty sample 38 after 820 steps.
Found uncertainty sample 39 after 713 steps.
Found uncertainty sample 40 after 919 steps.
Found uncertainty sample 41 after 38 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1476 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1913 steps.
Found uncertainty sample 47 after 1349 steps.
Found uncertainty sample 48 after 3153 steps.
Found uncertainty sample 49 after 191 steps.
Found uncertainty sample 50 after 916 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1973 steps.
Found uncertainty sample 53 after 2028 steps.
Found uncertainty sample 54 after 3466 steps.
Found uncertainty sample 55 after 384 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2407 steps.
Found uncertainty sample 59 after 1092 steps.
Found uncertainty sample 60 after 1481 steps.
Found uncertainty sample 61 after 1221 steps.
Found uncertainty sample 62 after 578 steps.
Found uncertainty sample 63 after 494 steps.
Found uncertainty sample 64 after 57 steps.
Found uncertainty sample 65 after 607 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1863 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1492 steps.
Found uncertainty sample 71 after 1232 steps.
Found uncertainty sample 72 after 2368 steps.
Found uncertainty sample 73 after 2585 steps.
Found uncertainty sample 74 after 2338 steps.
Found uncertainty sample 75 after 3492 steps.
Found uncertainty sample 76 after 2490 steps.
Found uncertainty sample 77 after 1118 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3833 steps.
Found uncertainty sample 82 after 2490 steps.
Found uncertainty sample 83 after 3487 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 220 steps.
Found uncertainty sample 86 after 76 steps.
Found uncertainty sample 87 after 379 steps.
Found uncertainty sample 88 after 990 steps.
Found uncertainty sample 89 after 178 steps.
Found uncertainty sample 90 after 841 steps.
Found uncertainty sample 91 after 1770 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 631 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 935 steps.
Found uncertainty sample 97 after 1912 steps.
Found uncertainty sample 98 after 769 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_060323-b0tizba6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_36
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/b0tizba6
Training model 36. Added 76 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.622871311341042, Training Loss Force: 4.949995049568471, time: 1.2403395175933838
Validation Loss Energy: 1.8399339683441418, Validation Loss Force: 4.663557208028953, time: 0.08564424514770508
Test Loss Energy: 7.843846272882867, Test Loss Force: 9.367938871055681, time: 9.934019565582275


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.5950827077218905, Training Loss Force: 4.940812966345551, time: 1.2870802879333496
Validation Loss Energy: 3.546585422683153, Validation Loss Force: 5.143140010505909, time: 0.08602571487426758
Test Loss Energy: 8.070014388142642, Test Loss Force: 9.40390194331114, time: 9.870077848434448


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.72075617429058, Training Loss Force: 5.093565966880834, time: 1.198984146118164
Validation Loss Energy: 5.590437568176503, Validation Loss Force: 5.554027154772683, time: 0.08467578887939453
Test Loss Energy: 9.403757732979457, Test Loss Force: 9.751639503412479, time: 10.087332010269165


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.586093381065964, Training Loss Force: 5.267743382931305, time: 1.189117193222046
Validation Loss Energy: 4.314441824879736, Validation Loss Force: 4.644375597122149, time: 0.08882999420166016
Test Loss Energy: 9.163068091984053, Test Loss Force: 9.341132756156023, time: 10.247426748275757


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.407474199931921, Training Loss Force: 4.632032554756167, time: 1.3370769023895264
Validation Loss Energy: 3.0304531499207448, Validation Loss Force: 4.588912720916165, time: 0.09773564338684082
Test Loss Energy: 8.412410975798773, Test Loss Force: 9.289444639591842, time: 11.377261877059937


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.874140486951183, Training Loss Force: 4.845205098738316, time: 1.239224910736084
Validation Loss Energy: 2.7272513653198267, Validation Loss Force: 4.874663145208711, time: 0.0877678394317627
Test Loss Energy: 8.529136599615375, Test Loss Force: 9.435899443622224, time: 11.191439867019653


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.048394834917967, Training Loss Force: 4.639126435161347, time: 1.2646198272705078
Validation Loss Energy: 2.738060950343464, Validation Loss Force: 4.539482842549946, time: 0.10144352912902832
Test Loss Energy: 8.30848052266362, Test Loss Force: 9.189313122605029, time: 11.36545205116272


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0933566891463316, Training Loss Force: 4.5917269292546825, time: 1.3110597133636475
Validation Loss Energy: 3.773907351749674, Validation Loss Force: 4.57111566675874, time: 0.10271024703979492
Test Loss Energy: 8.675246182531462, Test Loss Force: 9.251860727146385, time: 11.465571165084839


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0753089774880595, Training Loss Force: 4.584833670858178, time: 1.2129297256469727
Validation Loss Energy: 3.0329722059686257, Validation Loss Force: 4.57530741343083, time: 0.09449100494384766
Test Loss Energy: 8.378513916480568, Test Loss Force: 9.260764970177046, time: 11.312224626541138


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0884828172342456, Training Loss Force: 4.60312525872967, time: 1.2622363567352295
Validation Loss Energy: 2.0531771953210876, Validation Loss Force: 4.524213083198802, time: 0.09114336967468262
Test Loss Energy: 8.071514781811796, Test Loss Force: 9.19806152521291, time: 11.481322526931763


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0708286559405575, Training Loss Force: 4.5814422462572715, time: 1.3131065368652344
Validation Loss Energy: 3.322853699590997, Validation Loss Force: 4.564634658597365, time: 0.0999000072479248
Test Loss Energy: 8.660591031992134, Test Loss Force: 9.239099626010072, time: 11.937894582748413


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.051396944205771, Training Loss Force: 4.5967843586218065, time: 1.2882075309753418
Validation Loss Energy: 2.681114540952735, Validation Loss Force: 4.495310182719084, time: 0.09583806991577148
Test Loss Energy: 8.403028180633493, Test Loss Force: 9.245030016508428, time: 11.304456233978271


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1083598687067915, Training Loss Force: 4.603573905248838, time: 1.5394854545593262
Validation Loss Energy: 2.819845546289573, Validation Loss Force: 4.581695123220062, time: 0.13266539573669434
Test Loss Energy: 8.438434435464059, Test Loss Force: 9.279256903624683, time: 11.379770517349243


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0082452556647685, Training Loss Force: 4.61155778555487, time: 1.3712775707244873
Validation Loss Energy: 4.363234201481163, Validation Loss Force: 4.542353493179247, time: 0.09609770774841309
Test Loss Energy: 8.83598870269941, Test Loss Force: 9.228226535396276, time: 11.203752756118774


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.098202798264452, Training Loss Force: 4.611663851255315, time: 1.2952566146850586
Validation Loss Energy: 3.1319157976345027, Validation Loss Force: 4.586622123412004, time: 0.08998537063598633
Test Loss Energy: 8.408555665884881, Test Loss Force: 9.26360963729889, time: 11.53444504737854


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1446451203620462, Training Loss Force: 4.605482150911369, time: 1.2589106559753418
Validation Loss Energy: 2.2738117019279604, Validation Loss Force: 4.559736382725246, time: 0.09364914894104004
Test Loss Energy: 8.06669533781218, Test Loss Force: 9.28833562133796, time: 11.294705629348755


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0432266016244807, Training Loss Force: 4.593798509965269, time: 1.315164566040039
Validation Loss Energy: 3.5257530540630135, Validation Loss Force: 4.579958303881824, time: 0.08601880073547363
Test Loss Energy: 8.68729255301517, Test Loss Force: 9.278346058579062, time: 11.46795654296875


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0913538047590716, Training Loss Force: 4.597841337247647, time: 1.263381004333496
Validation Loss Energy: 2.366758145486564, Validation Loss Force: 4.534886728708852, time: 0.09891772270202637
Test Loss Energy: 8.234808204378723, Test Loss Force: 9.278912748058028, time: 11.225475549697876


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1072727097362547, Training Loss Force: 4.591995954068263, time: 1.3248624801635742
Validation Loss Energy: 2.628095013285015, Validation Loss Force: 4.5078037031588, time: 0.09075927734375
Test Loss Energy: 8.171105798009146, Test Loss Force: 9.25820164493818, time: 11.284699201583862


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0520141556061153, Training Loss Force: 4.590801793897688, time: 1.3711276054382324
Validation Loss Energy: 4.053998862367612, Validation Loss Force: 4.536353005034785, time: 0.10185742378234863
Test Loss Energy: 8.864667336877545, Test Loss Force: 9.243117621965723, time: 11.406836032867432

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–ˆâ–‡â–„â–„â–ƒâ–…â–ƒâ–‚â–…â–„â–„â–…â–„â–‚â–…â–ƒâ–‚â–†
wandb:   test_error_force â–ƒâ–„â–ˆâ–ƒâ–‚â–„â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚
wandb:          test_loss â–ƒâ–…â–ˆâ–„â–â–…â–ƒâ–ƒâ–ƒâ–„â–…â–„â–ƒâ–„â–ƒâ–„â–…â–„â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–„â–â–ˆâ–‡â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚
wandb:  train_error_force â–…â–…â–†â–ˆâ–‚â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–…â–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–„â–ˆâ–†â–ƒâ–ƒâ–ƒâ–…â–ƒâ–â–„â–ƒâ–ƒâ–†â–ƒâ–‚â–„â–‚â–‚â–…
wandb:  valid_error_force â–‚â–…â–ˆâ–‚â–‚â–„â–â–‚â–‚â–â–â–â–‚â–â–‚â–â–‚â–â–â–
wandb:         valid_loss â–â–ƒâ–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2439
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.86467
wandb:   test_error_force 9.24312
wandb:          test_loss 6.97408
wandb: train_error_energy 3.05201
wandb:  train_error_force 4.5908
wandb:         train_loss 1.53494
wandb: valid_error_energy 4.054
wandb:  valid_error_force 4.53635
wandb:         valid_loss 1.89135
wandb: 
wandb: ğŸš€ View run al_72_36 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/b0tizba6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_060323-b0tizba6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.2817654609680176, Uncertainty Bias: -0.06755766272544861
3.0517578e-05 0.004776001
2.6507378 7.275992
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3510 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 461 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2400 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 998 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3203 steps.
Found uncertainty sample 19 after 3431 steps.
Found uncertainty sample 20 after 385 steps.
Found uncertainty sample 21 after 3440 steps.
Found uncertainty sample 22 after 1858 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1154 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2512 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3172 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3514 steps.
Found uncertainty sample 40 after 740 steps.
Found uncertainty sample 41 after 2839 steps.
Found uncertainty sample 42 after 408 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3017 steps.
Found uncertainty sample 46 after 3445 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 655 steps.
Found uncertainty sample 50 after 58 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2577 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 263 steps.
Found uncertainty sample 61 after 1618 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3765 steps.
Found uncertainty sample 64 after 674 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2379 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3603 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3717 steps.
Found uncertainty sample 76 after 3674 steps.
Found uncertainty sample 77 after 3074 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2010 steps.
Found uncertainty sample 84 after 417 steps.
Found uncertainty sample 85 after 3032 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 85 steps.
Found uncertainty sample 90 after 709 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1237 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_064041-9eiay0h4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_37
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9eiay0h4
Training model 37. Added 36 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.731787974071232, Training Loss Force: 4.978461349610977, time: 1.206040620803833
Validation Loss Energy: 2.65025471268403, Validation Loss Force: 4.7911753529654, time: 0.08383870124816895
Test Loss Energy: 8.171396944329384, Test Loss Force: 9.455957335727327, time: 10.209506511688232


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0949248129715667, Training Loss Force: 4.664392913880946, time: 1.1936817169189453
Validation Loss Energy: 2.0289918747015676, Validation Loss Force: 4.570144606613349, time: 0.08430123329162598
Test Loss Energy: 7.994428064169702, Test Loss Force: 9.350995315895249, time: 10.05306887626648


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.070825672448353, Training Loss Force: 4.626603704578214, time: 1.2206897735595703
Validation Loss Energy: 2.345127841981993, Validation Loss Force: 4.5829572119391795, time: 0.09501147270202637
Test Loss Energy: 8.185183514991767, Test Loss Force: 9.262861879332654, time: 10.979763269424438


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.1083772309682614, Training Loss Force: 4.626032923624688, time: 1.2397515773773193
Validation Loss Energy: 2.2307555051947796, Validation Loss Force: 4.576664804544406, time: 0.08848023414611816
Test Loss Energy: 8.131791300961536, Test Loss Force: 9.27372890774981, time: 10.213198184967041


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0755349179166087, Training Loss Force: 4.607298963343179, time: 1.228576898574829
Validation Loss Energy: 2.0823434020658658, Validation Loss Force: 4.5352777357291, time: 0.08615589141845703
Test Loss Energy: 8.083987921612723, Test Loss Force: 9.198206313784887, time: 10.348810911178589


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1695059307292106, Training Loss Force: 4.613791219151155, time: 1.1768295764923096
Validation Loss Energy: 2.450985421963501, Validation Loss Force: 4.579660595233719, time: 0.08232617378234863
Test Loss Energy: 8.127756661944487, Test Loss Force: 9.273946461334415, time: 10.184776306152344


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.091182345549741, Training Loss Force: 4.62631100313116, time: 1.2271614074707031
Validation Loss Energy: 2.1482857562866506, Validation Loss Force: 4.573674803252888, time: 0.09451031684875488
Test Loss Energy: 8.059427190722529, Test Loss Force: 9.29959778373231, time: 10.166629791259766


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1003409773108572, Training Loss Force: 4.612555793634895, time: 1.208611011505127
Validation Loss Energy: 2.0976977756924624, Validation Loss Force: 4.559408168404149, time: 0.08274960517883301
Test Loss Energy: 8.324963290257216, Test Loss Force: 9.266092680401291, time: 10.341177463531494


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0769942615243266, Training Loss Force: 4.616251684666332, time: 1.2074344158172607
Validation Loss Energy: 2.207460415820679, Validation Loss Force: 4.555187697412233, time: 0.08399391174316406
Test Loss Energy: 8.210650726145998, Test Loss Force: 9.252134752424336, time: 10.224430084228516


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.024634670965217, Training Loss Force: 4.62030504531896, time: 1.1637094020843506
Validation Loss Energy: 2.146536133472523, Validation Loss Force: 4.581682431078743, time: 0.08429098129272461
Test Loss Energy: 8.099823656968919, Test Loss Force: 9.217228624153595, time: 10.12852144241333


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.120208324972505, Training Loss Force: 4.642516224111674, time: 1.1853673458099365
Validation Loss Energy: 1.9768290665728054, Validation Loss Force: 4.553605633130417, time: 0.09512805938720703
Test Loss Energy: 8.189254641437767, Test Loss Force: 9.238714350097265, time: 10.358832836151123


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0938046858245416, Training Loss Force: 4.630446220387511, time: 1.2379124164581299
Validation Loss Energy: 2.1766433400279923, Validation Loss Force: 4.547448831245513, time: 0.08329463005065918
Test Loss Energy: 8.061792580577771, Test Loss Force: 9.238328771074626, time: 10.175965309143066


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.076148829598229, Training Loss Force: 4.602941722110476, time: 1.2043559551239014
Validation Loss Energy: 2.0117095202749558, Validation Loss Force: 4.54165676142164, time: 0.08491778373718262
Test Loss Energy: 8.07381791990236, Test Loss Force: 9.203585291539818, time: 10.29980993270874


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1450190076062645, Training Loss Force: 4.635335463885557, time: 1.2475934028625488
Validation Loss Energy: 2.1688137361843065, Validation Loss Force: 4.58338807673655, time: 0.08167028427124023
Test Loss Energy: 8.063520136413215, Test Loss Force: 9.237415226019886, time: 10.149539947509766


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.070149431961635, Training Loss Force: 4.623275017806274, time: 1.1860218048095703
Validation Loss Energy: 2.1868413642423388, Validation Loss Force: 4.501710807318778, time: 0.0873403549194336
Test Loss Energy: 8.196534877946492, Test Loss Force: 9.23366866725054, time: 10.240516185760498


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0972604610115186, Training Loss Force: 4.6180380564537336, time: 1.2262656688690186
Validation Loss Energy: 2.061200910992736, Validation Loss Force: 4.523931406729204, time: 0.08606195449829102
Test Loss Energy: 8.107268815537319, Test Loss Force: 9.268939632504946, time: 10.409898042678833


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.111517080030791, Training Loss Force: 4.637862279096756, time: 1.2456557750701904
Validation Loss Energy: 2.166829197421225, Validation Loss Force: 4.6272979869752175, time: 0.08325314521789551
Test Loss Energy: 8.069266173180042, Test Loss Force: 9.294501001231113, time: 10.18872332572937


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.185142952861869, Training Loss Force: 4.62759626656985, time: 1.1839056015014648
Validation Loss Energy: 2.1171786539313926, Validation Loss Force: 4.522457559652308, time: 0.0957183837890625
Test Loss Energy: 8.134683446741168, Test Loss Force: 9.258547451287615, time: 10.842936754226685


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0478682365688243, Training Loss Force: 4.621387599902342, time: 1.2205286026000977
Validation Loss Energy: 2.2067251623008257, Validation Loss Force: 4.548440599621475, time: 0.12456560134887695
Test Loss Energy: 8.06292957586916, Test Loss Force: 9.224645884959367, time: 10.287717580795288


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0970559636662123, Training Loss Force: 4.61487097609655, time: 1.2329127788543701
Validation Loss Energy: 2.132521226093255, Validation Loss Force: 4.576401164275628, time: 0.08481097221374512
Test Loss Energy: 8.06469117327037, Test Loss Force: 9.27107139929125, time: 10.22374415397644

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–…â–„â–ƒâ–„â–‚â–ˆâ–†â–ƒâ–…â–‚â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–‚â–‚
wandb:   test_error_force â–ˆâ–…â–ƒâ–ƒâ–â–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–„â–ƒâ–‚â–ƒ
wandb:          test_loss â–ˆâ–ƒâ–†â–ƒâ–ƒâ–‚â–„â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–„â–‚
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–…â–„â–‚â–†â–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒ
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–„â–‚â–‚â–ƒ
wandb:         valid_loss â–ˆâ–â–„â–ƒâ–‚â–…â–‚â–‚â–ƒâ–ƒâ–â–‚â–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2471
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.06469
wandb:   test_error_force 9.27107
wandb:          test_loss 6.94341
wandb: train_error_energy 3.09706
wandb:  train_error_force 4.61487
wandb:         train_loss 1.55764
wandb: valid_error_energy 2.13252
wandb:  valid_error_force 4.5764
wandb:         valid_loss 1.25339
wandb: 
wandb: ğŸš€ View run al_72_37 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9eiay0h4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_064041-9eiay0h4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.413311243057251, Uncertainty Bias: -0.06606045365333557
0.0001373291 0.0054473877
2.767041 7.494502
(48745, 22, 3)
Found uncertainty sample 0 after 279 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1835 steps.
Found uncertainty sample 5 after 1076 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 468 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2037 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1904 steps.
Found uncertainty sample 21 after 1822 steps.
Found uncertainty sample 22 after 2135 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 952 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2645 steps.
Found uncertainty sample 27 after 3061 steps.
Found uncertainty sample 28 after 1291 steps.
Found uncertainty sample 29 after 3218 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 20 steps.
Found uncertainty sample 32 after 3007 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2514 steps.
Found uncertainty sample 35 after 925 steps.
Found uncertainty sample 36 after 146 steps.
Found uncertainty sample 37 after 1560 steps.
Found uncertainty sample 38 after 2773 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 307 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1875 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 89 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2910 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2071 steps.
Found uncertainty sample 49 after 783 steps.
Found uncertainty sample 50 after 1434 steps.
Found uncertainty sample 51 after 3346 steps.
Found uncertainty sample 52 after 204 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2557 steps.
Found uncertainty sample 55 after 2763 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 762 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2563 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1132 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2908 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2020 steps.
Found uncertainty sample 70 after 1194 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1337 steps.
Found uncertainty sample 73 after 1397 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2587 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3555 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3778 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3297 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 308 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3508 steps.
Found uncertainty sample 88 after 20 steps.
Found uncertainty sample 89 after 2128 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3718 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 95 steps.
Found uncertainty sample 98 after 150 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_071358-nc8y2owb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_38
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/nc8y2owb
Training model 38. Added 50 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.256434454789895, Training Loss Force: 4.925807575998573, time: 1.303361177444458
Validation Loss Energy: 3.2473905693632052, Validation Loss Force: 4.607788607085609, time: 0.08715677261352539
Test Loss Energy: 8.395144531723831, Test Loss Force: 9.195075543624089, time: 10.158578634262085


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0862501158128235, Training Loss Force: 4.6293589308506204, time: 1.2340803146362305
Validation Loss Energy: 2.5429728295105942, Validation Loss Force: 4.501210469747878, time: 0.08764910697937012
Test Loss Energy: 8.307413007140601, Test Loss Force: 9.177387555379113, time: 10.218064308166504


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1073010919809247, Training Loss Force: 4.6157757408942475, time: 1.2625412940979004
Validation Loss Energy: 3.435525289441615, Validation Loss Force: 4.537444306518978, time: 0.08594489097595215
Test Loss Energy: 8.786248752301358, Test Loss Force: 9.19161048528748, time: 10.323832750320435


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.123810539253247, Training Loss Force: 4.611314888694214, time: 1.276669979095459
Validation Loss Energy: 2.1091772608416237, Validation Loss Force: 4.5475902261531775, time: 0.0912477970123291
Test Loss Energy: 7.998849186875661, Test Loss Force: 9.260383317592542, time: 10.175722122192383


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0609489437311237, Training Loss Force: 4.621271542372972, time: 1.226696252822876
Validation Loss Energy: 3.5545181223414026, Validation Loss Force: 4.54984452858655, time: 0.08727264404296875
Test Loss Energy: 8.662129416981328, Test Loss Force: 9.199351971022635, time: 10.308907270431519


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.091487630947361, Training Loss Force: 4.606704611404282, time: 1.2958083152770996
Validation Loss Energy: 4.332404990220022, Validation Loss Force: 4.529410403733904, time: 0.08725976943969727
Test Loss Energy: 8.953632366922724, Test Loss Force: 9.157662892897026, time: 10.885050058364868


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1453774144650923, Training Loss Force: 4.633988002543909, time: 1.2305161952972412
Validation Loss Energy: 3.025271193556713, Validation Loss Force: 4.5546755583766, time: 0.0918431282043457
Test Loss Energy: 8.185880672268945, Test Loss Force: 9.202604595999185, time: 10.155120134353638


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1249018646955116, Training Loss Force: 4.649165757258831, time: 1.2534139156341553
Validation Loss Energy: 2.3962547932439, Validation Loss Force: 4.546180507790309, time: 0.08737897872924805
Test Loss Energy: 8.1260947946729, Test Loss Force: 9.22960095195596, time: 10.363215446472168


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1319247706373647, Training Loss Force: 4.623417588141071, time: 1.2351913452148438
Validation Loss Energy: 3.3583723230653764, Validation Loss Force: 4.58681050150946, time: 0.08745598793029785
Test Loss Energy: 8.611047520081454, Test Loss Force: 9.173661580098988, time: 10.195636749267578


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.09375621239204, Training Loss Force: 4.63956635508524, time: 1.2703490257263184
Validation Loss Energy: 2.0429553455081266, Validation Loss Force: 4.510864958577015, time: 0.08775091171264648
Test Loss Energy: 8.1031495599132, Test Loss Force: 9.128593685378863, time: 10.182636976242065


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1555435716241997, Training Loss Force: 4.6171249242539885, time: 1.2381901741027832
Validation Loss Energy: 3.0300648149302463, Validation Loss Force: 4.541809067117454, time: 0.08572649955749512
Test Loss Energy: 8.287868839568718, Test Loss Force: 9.199726815293987, time: 10.373033046722412


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0972696383807157, Training Loss Force: 4.616124942486997, time: 1.2067172527313232
Validation Loss Energy: 4.45374252922643, Validation Loss Force: 4.533969331827628, time: 0.08635425567626953
Test Loss Energy: 8.746835273572252, Test Loss Force: 9.221075316421798, time: 10.229314804077148


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.135396188259572, Training Loss Force: 4.615303800685947, time: 1.25168776512146
Validation Loss Energy: 2.7664248801554647, Validation Loss Force: 4.579640109672293, time: 0.08849072456359863
Test Loss Energy: 8.252453102063637, Test Loss Force: 9.143557882039827, time: 10.373811483383179


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.159518583705891, Training Loss Force: 4.630160009879764, time: 1.2744622230529785
Validation Loss Energy: 2.449003109891879, Validation Loss Force: 4.536835306404865, time: 0.08452486991882324
Test Loss Energy: 8.142786901574649, Test Loss Force: 9.230363371111618, time: 10.20696759223938


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0379782847119383, Training Loss Force: 4.623173384915713, time: 1.219881296157837
Validation Loss Energy: 3.6903028808738974, Validation Loss Force: 4.531437806307576, time: 0.08491134643554688
Test Loss Energy: 8.839428437375352, Test Loss Force: 9.160679712413847, time: 10.21938443183899


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.192734416426424, Training Loss Force: 4.634011577287408, time: 1.2654204368591309
Validation Loss Energy: 2.0776519858303133, Validation Loss Force: 4.5353507712089645, time: 0.08911609649658203
Test Loss Energy: 8.061397367325698, Test Loss Force: 9.247334457971267, time: 10.360190391540527


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0846293451506717, Training Loss Force: 4.612705511063873, time: 1.2186157703399658
Validation Loss Energy: 3.5562069564786922, Validation Loss Force: 4.578820019207841, time: 0.09187602996826172
Test Loss Energy: 8.370208299047112, Test Loss Force: 9.217817627179436, time: 10.216079711914062


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1651929489280692, Training Loss Force: 4.613934362889715, time: 1.2638170719146729
Validation Loss Energy: 4.215139847223488, Validation Loss Force: 4.592749532969646, time: 0.08781862258911133
Test Loss Energy: 8.817019338623538, Test Loss Force: 9.273435180332768, time: 10.154900789260864


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0867159142987335, Training Loss Force: 4.621776195215548, time: 1.4284610748291016
Validation Loss Energy: 2.6207421440827607, Validation Loss Force: 4.529833029772874, time: 0.08652114868164062
Test Loss Energy: 7.952468108445168, Test Loss Force: 9.20175897552622, time: 10.211991310119629


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1608743879494785, Training Loss Force: 4.662874820110378, time: 1.2621028423309326
Validation Loss Energy: 2.6892789278573233, Validation Loss Force: 4.567598384929664, time: 0.09019160270690918
Test Loss Energy: 8.2083326097665, Test Loss Force: 9.204971044407227, time: 10.1952223777771

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–‡â–â–†â–ˆâ–ƒâ–‚â–†â–‚â–ƒâ–‡â–ƒâ–‚â–‡â–‚â–„â–‡â–â–ƒ
wandb:   test_error_force â–„â–ƒâ–„â–‡â–„â–‚â–…â–†â–ƒâ–â–„â–…â–‚â–†â–ƒâ–‡â–…â–ˆâ–…â–…
wandb:          test_loss â–ƒâ–„â–‡â–ƒâ–ƒâ–ƒâ–‚â–„â–…â–ƒâ–â–‚â–â–‚â–ˆâ–ƒâ–‚â–‚â–â–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–‚â–â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–‚â–…â–â–…â–ˆâ–„â–‚â–…â–â–„â–ˆâ–ƒâ–‚â–†â–â–…â–‡â–ƒâ–ƒ
wandb:  valid_error_force â–ˆâ–â–ƒâ–„â–„â–ƒâ–…â–„â–‡â–‚â–„â–ƒâ–†â–ƒâ–ƒâ–ƒâ–†â–‡â–ƒâ–…
wandb:         valid_loss â–„â–‚â–…â–â–…â–‡â–„â–‚â–…â–â–ƒâ–ˆâ–ƒâ–‚â–†â–â–…â–‡â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2516
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.20833
wandb:   test_error_force 9.20497
wandb:          test_loss 7.40287
wandb: train_error_energy 3.16087
wandb:  train_error_force 4.66287
wandb:         train_loss 1.59702
wandb: valid_error_energy 2.68928
wandb:  valid_error_force 4.5676
wandb:         valid_loss 1.4249
wandb: 
wandb: ğŸš€ View run al_72_38 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/nc8y2owb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_071358-nc8y2owb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5353710651397705, Uncertainty Bias: -0.06452071666717529
3.8146973e-05 0.03192711
2.8464906 7.5221243
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2666 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3117 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 772 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1716 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 525 steps.
Found uncertainty sample 12 after 326 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 558 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2805 steps.
Found uncertainty sample 19 after 2983 steps.
Found uncertainty sample 20 after 2535 steps.
Found uncertainty sample 21 after 814 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2093 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 175 steps.
Found uncertainty sample 26 after 2630 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1128 steps.
Found uncertainty sample 29 after 3634 steps.
Found uncertainty sample 30 after 3539 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1433 steps.
Found uncertainty sample 34 after 3348 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2083 steps.
Found uncertainty sample 38 after 939 steps.
Found uncertainty sample 39 after 317 steps.
Found uncertainty sample 40 after 31 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1639 steps.
Found uncertainty sample 48 after 136 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2704 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 788 steps.
Found uncertainty sample 58 after 1583 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 57 steps.
Found uncertainty sample 62 after 3383 steps.
Found uncertainty sample 63 after 3941 steps.
Found uncertainty sample 64 after 3219 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 673 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1242 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3248 steps.
Found uncertainty sample 77 after 3553 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 437 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 338 steps.
Found uncertainty sample 85 after 493 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2500 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1049 steps.
Found uncertainty sample 92 after 1263 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3950 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 351 steps.
Found uncertainty sample 98 after 3195 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_074804-yotf4woz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_39
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/yotf4woz
Training model 39. Added 45 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.924274872692429, Training Loss Force: 4.7986066017070215, time: 1.2747397422790527
Validation Loss Energy: 4.352588612283501, Validation Loss Force: 4.601659861513093, time: 0.0947422981262207
Test Loss Energy: 8.645044162637593, Test Loss Force: 9.161743721189271, time: 10.264720678329468


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1540326610565694, Training Loss Force: 4.626696485244595, time: 1.2309153079986572
Validation Loss Energy: 2.5919789684921115, Validation Loss Force: 4.575318546888127, time: 0.09168553352355957
Test Loss Energy: 8.261035412141569, Test Loss Force: 9.172947434681523, time: 10.081135272979736


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.2637616210847824, Training Loss Force: 4.65759353822777, time: 1.2920753955841064
Validation Loss Energy: 2.3946281951328974, Validation Loss Force: 4.570647393544854, time: 0.08617782592773438
Test Loss Energy: 8.206065231641292, Test Loss Force: 9.110751386249953, time: 10.332078456878662


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.103455240546627, Training Loss Force: 4.633946659436747, time: 1.221987247467041
Validation Loss Energy: 4.178043390181064, Validation Loss Force: 4.558146302354176, time: 0.08713221549987793
Test Loss Energy: 8.568576777657462, Test Loss Force: 9.126759385918605, time: 10.191407442092896


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0878600363218878, Training Loss Force: 4.635483054276734, time: 1.2357597351074219
Validation Loss Energy: 2.202825446213619, Validation Loss Force: 4.61746692151336, time: 0.0848994255065918
Test Loss Energy: 8.078538372894023, Test Loss Force: 9.198469730218712, time: 10.249552011489868


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0855909931910546, Training Loss Force: 4.646240740689184, time: 1.375502109527588
Validation Loss Energy: 2.078756313459542, Validation Loss Force: 4.58378175578655, time: 0.09129166603088379
Test Loss Energy: 7.896222922083696, Test Loss Force: 9.10329148954887, time: 10.181501388549805


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0959940205379644, Training Loss Force: 4.6253584440798, time: 1.2624359130859375
Validation Loss Energy: 4.278520170251227, Validation Loss Force: 4.606737608716829, time: 0.09078311920166016
Test Loss Energy: 8.719235761692092, Test Loss Force: 9.197772279158157, time: 10.208098649978638


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.175884005438939, Training Loss Force: 4.622298663844677, time: 1.2851507663726807
Validation Loss Energy: 2.5028560881728064, Validation Loss Force: 4.565442056920499, time: 0.08687400817871094
Test Loss Energy: 8.183179662886245, Test Loss Force: 9.150592520309628, time: 10.310840606689453


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1767216130067646, Training Loss Force: 4.627651863915384, time: 1.2527575492858887
Validation Loss Energy: 2.13497882545686, Validation Loss Force: 4.511072486221019, time: 0.08800220489501953
Test Loss Energy: 8.0166098305474, Test Loss Force: 9.190977927710374, time: 10.132225513458252


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1279949098865654, Training Loss Force: 4.628125069250852, time: 1.228172779083252
Validation Loss Energy: 4.202126616997176, Validation Loss Force: 4.572016586123164, time: 0.09137225151062012
Test Loss Energy: 8.558727748274823, Test Loss Force: 9.150100838856051, time: 10.243290901184082


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.100515559698724, Training Loss Force: 4.629055392075996, time: 1.287593126296997
Validation Loss Energy: 2.4253838142413082, Validation Loss Force: 4.522633245608445, time: 0.09060144424438477
Test Loss Energy: 8.238030718890872, Test Loss Force: 9.162175498813557, time: 10.340002059936523


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.194029489492547, Training Loss Force: 4.6265754589970545, time: 1.3194503784179688
Validation Loss Energy: 2.2304987676695247, Validation Loss Force: 4.55511844730785, time: 0.08735108375549316
Test Loss Energy: 8.092815766975997, Test Loss Force: 9.205887774446818, time: 10.868499517440796


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1636021904730773, Training Loss Force: 4.614710244086402, time: 1.2417852878570557
Validation Loss Energy: 4.307921181610387, Validation Loss Force: 4.534753572559586, time: 0.08721137046813965
Test Loss Energy: 8.796192097805694, Test Loss Force: 9.201803481376032, time: 10.384509563446045


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0715914026656623, Training Loss Force: 4.6098424850207325, time: 1.3422646522521973
Validation Loss Energy: 2.4857586604718875, Validation Loss Force: 4.53236388728549, time: 0.08562874794006348
Test Loss Energy: 8.279895652014636, Test Loss Force: 9.18436845927052, time: 10.243975400924683


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1502504460859875, Training Loss Force: 4.610873487700206, time: 1.1996312141418457
Validation Loss Energy: 2.4224764232029288, Validation Loss Force: 4.583481152439548, time: 0.09312319755554199
Test Loss Energy: 8.144468039636719, Test Loss Force: 9.173808579041127, time: 10.126468420028687


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.097915894636653, Training Loss Force: 4.6187109239311015, time: 1.2387173175811768
Validation Loss Energy: 4.014751198706381, Validation Loss Force: 4.603280670226301, time: 0.09077572822570801
Test Loss Energy: 8.619394740505184, Test Loss Force: 9.236962603765605, time: 10.334165811538696


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.11133112338893, Training Loss Force: 4.613182338507603, time: 1.2239415645599365
Validation Loss Energy: 2.7470735953594643, Validation Loss Force: 4.533033453407294, time: 0.08520054817199707
Test Loss Energy: 8.187133471837518, Test Loss Force: 9.102366430983736, time: 10.184804916381836


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1605491877300835, Training Loss Force: 4.627070597243396, time: 1.221921443939209
Validation Loss Energy: 1.9494049118911931, Validation Loss Force: 4.63710366815444, time: 0.09436821937561035
Test Loss Energy: 7.790847299559189, Test Loss Force: 9.218370989152243, time: 10.158430099487305


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.2567323499938943, Training Loss Force: 4.62217432539359, time: 1.5010943412780762
Validation Loss Energy: 4.402362291811031, Validation Loss Force: 4.5497661490471835, time: 0.08583998680114746
Test Loss Energy: 8.833486645284077, Test Loss Force: 9.151059281471776, time: 10.152057886123657


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1383488261616583, Training Loss Force: 4.60818034891404, time: 1.223996877670288
Validation Loss Energy: 2.7593353172182695, Validation Loss Force: 4.549780399872523, time: 0.09125876426696777
Test Loss Energy: 8.39777030225135, Test Loss Force: 9.231704389631028, time: 10.335004568099976

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–„â–„â–†â–ƒâ–‚â–‡â–„â–ƒâ–†â–„â–ƒâ–ˆâ–„â–ƒâ–‡â–„â–â–ˆâ–…
wandb:   test_error_force â–„â–…â–â–‚â–†â–â–†â–„â–†â–ƒâ–„â–†â–†â–…â–…â–ˆâ–â–‡â–„â–ˆ
wandb:          test_loss â–‚â–†â–ƒâ–‚â–…â–ƒâ–‚â–…â–ƒâ–‚â–…â–„â–â–…â–ƒâ–‚â–„â–â–‚â–ˆ
wandb: train_error_energy â–ˆâ–‚â–ƒâ–â–â–â–â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–â–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–
wandb: valid_error_energy â–ˆâ–ƒâ–‚â–‡â–‚â–â–ˆâ–ƒâ–‚â–‡â–‚â–‚â–ˆâ–ƒâ–‚â–‡â–ƒâ–â–ˆâ–ƒ
wandb:  valid_error_force â–†â–…â–„â–„â–‡â–…â–†â–„â–â–„â–‚â–ƒâ–‚â–‚â–…â–†â–‚â–ˆâ–ƒâ–ƒ
wandb:         valid_loss â–ˆâ–‚â–‚â–ˆâ–‚â–â–‡â–‚â–â–ˆâ–‚â–â–‡â–‚â–‚â–‡â–ƒâ–â–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2556
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.39777
wandb:   test_error_force 9.2317
wandb:          test_loss 7.30287
wandb: train_error_energy 3.13835
wandb:  train_error_force 4.60818
wandb:         train_loss 1.56472
wandb: valid_error_energy 2.75934
wandb:  valid_error_force 4.54978
wandb:         valid_loss 1.43896
wandb: 
wandb: ğŸš€ View run al_72_39 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/yotf4woz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_074804-yotf4woz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4072115421295166, Uncertainty Bias: -0.06016796827316284
0.0002193451 0.008636475
2.7628114 7.3560586
(48745, 22, 3)
Found uncertainty sample 0 after 17 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 95 steps.
Found uncertainty sample 3 after 2172 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 747 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 179 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1123 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1540 steps.
Found uncertainty sample 15 after 3184 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1294 steps.
Found uncertainty sample 21 after 1131 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1682 steps.
Found uncertainty sample 24 after 2298 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 91 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3972 steps.
Found uncertainty sample 38 after 1910 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2092 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2756 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 671 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2770 steps.
Found uncertainty sample 51 after 1993 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 198 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1428 steps.
Found uncertainty sample 57 after 365 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1754 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2492 steps.
Found uncertainty sample 65 after 2589 steps.
Found uncertainty sample 66 after 2111 steps.
Found uncertainty sample 67 after 1568 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1182 steps.
Found uncertainty sample 73 after 2397 steps.
Found uncertainty sample 74 after 440 steps.
Found uncertainty sample 75 after 508 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1334 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1405 steps.
Found uncertainty sample 83 after 946 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2109 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 878 steps.
Found uncertainty sample 92 after 599 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1661 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 394 steps.
Found uncertainty sample 99 after 2478 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_082159-fhzgjc2q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_40
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/fhzgjc2q
Training model 40. Added 41 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.186049455871876, Training Loss Force: 4.798589743453473, time: 1.2837822437286377
Validation Loss Energy: 1.8799707714585416, Validation Loss Force: 4.570441869923162, time: 0.09475445747375488
Test Loss Energy: 7.787498840580167, Test Loss Force: 9.08661009175065, time: 10.756781339645386


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.218992856366045, Training Loss Force: 4.6407228829703175, time: 1.3740179538726807
Validation Loss Energy: 2.551423568936846, Validation Loss Force: 4.535546052049943, time: 0.09636116027832031
Test Loss Energy: 7.8343442203199345, Test Loss Force: 9.123563652325934, time: 10.502471685409546


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2974100405632973, Training Loss Force: 4.654533988977523, time: 1.3395683765411377
Validation Loss Energy: 2.353981055889509, Validation Loss Force: 4.586321742734149, time: 0.09052801132202148
Test Loss Energy: 7.85351784078524, Test Loss Force: 9.2048781622282, time: 11.499672174453735


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.329987094659898, Training Loss Force: 4.872104099431622, time: 1.3921642303466797
Validation Loss Energy: 1.8744211883345834, Validation Loss Force: 5.250260347213974, time: 0.10220861434936523
Test Loss Energy: 7.592883549518025, Test Loss Force: 9.527506971194427, time: 10.690210342407227


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.23788813744522, Training Loss Force: 5.054190364033134, time: 1.3375647068023682
Validation Loss Energy: 2.130078990900719, Validation Loss Force: 4.628033240495071, time: 0.08967328071594238
Test Loss Energy: 7.82555949349609, Test Loss Force: 9.161350102761235, time: 11.149481058120728


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.141801220483485, Training Loss Force: 4.6250843340314844, time: 1.364492654800415
Validation Loss Energy: 2.943088465177685, Validation Loss Force: 4.538974488889794, time: 0.09000062942504883
Test Loss Energy: 8.198005974884564, Test Loss Force: 9.111638742615195, time: 10.759222984313965


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1602746995222084, Training Loss Force: 4.629339343482035, time: 1.3683991432189941
Validation Loss Energy: 2.315708905756587, Validation Loss Force: 4.525553551457287, time: 0.09452056884765625
Test Loss Energy: 8.025359044556987, Test Loss Force: 9.132363392412927, time: 10.66945505142212


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.14959472168651, Training Loss Force: 4.630053677098179, time: 1.274933099746704
Validation Loss Energy: 2.772473242166301, Validation Loss Force: 4.501196664260831, time: 0.09118795394897461
Test Loss Energy: 7.968596088311845, Test Loss Force: 9.130004871492803, time: 11.020603895187378


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0888557811633186, Training Loss Force: 4.613937159216105, time: 1.2883949279785156
Validation Loss Energy: 2.142283598123594, Validation Loss Force: 4.509189150584763, time: 0.09495377540588379
Test Loss Energy: 7.892150555218999, Test Loss Force: 9.123502438129524, time: 10.788110494613647


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.124498548184556, Training Loss Force: 4.610214939302723, time: 1.3207006454467773
Validation Loss Energy: 2.735501813849316, Validation Loss Force: 4.489659507802874, time: 0.09578418731689453
Test Loss Energy: 7.919728394746163, Test Loss Force: 9.122944911893944, time: 10.86432671546936


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0972022413297298, Training Loss Force: 4.6205770211955866, time: 1.3489012718200684
Validation Loss Energy: 2.2009038114842623, Validation Loss Force: 4.568636245818833, time: 0.09394598007202148
Test Loss Energy: 7.749515557614709, Test Loss Force: 9.119932881512472, time: 10.864879131317139


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.069178456506646, Training Loss Force: 4.614942936505249, time: 1.295952558517456
Validation Loss Energy: 2.87244389526777, Validation Loss Force: 4.6075296428688945, time: 0.09937143325805664
Test Loss Energy: 7.845704137966769, Test Loss Force: 9.148989521630673, time: 10.910440683364868


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.102798521747292, Training Loss Force: 4.625185332357675, time: 1.4324333667755127
Validation Loss Energy: 2.174318006137068, Validation Loss Force: 4.5537229797703205, time: 0.1317746639251709
Test Loss Energy: 7.8571745508054915, Test Loss Force: 9.091819174113045, time: 10.799172163009644


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.145492672194203, Training Loss Force: 4.626013232736245, time: 1.3406648635864258
Validation Loss Energy: 2.8048076968539126, Validation Loss Force: 4.497274569924459, time: 0.09186410903930664
Test Loss Energy: 7.7380475626597995, Test Loss Force: 9.100443404280764, time: 10.732947826385498


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1089900009154214, Training Loss Force: 4.632413145344473, time: 1.3834295272827148
Validation Loss Energy: 2.529181481953838, Validation Loss Force: 4.619704969099081, time: 0.09373879432678223
Test Loss Energy: 7.964522266519952, Test Loss Force: 9.155493671061924, time: 11.820487260818481


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1328735278701583, Training Loss Force: 4.642155409801135, time: 1.3064546585083008
Validation Loss Energy: 2.9818287771899206, Validation Loss Force: 4.502438267418524, time: 0.09014296531677246
Test Loss Energy: 7.874237645488885, Test Loss Force: 9.031081517654354, time: 10.734455585479736


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1433469017264573, Training Loss Force: 4.623822844594758, time: 1.304616928100586
Validation Loss Energy: 2.079204101112003, Validation Loss Force: 4.690633998842918, time: 0.09300827980041504
Test Loss Energy: 7.82311953395891, Test Loss Force: 9.178499362243453, time: 10.179754495620728


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.101162894539872, Training Loss Force: 4.625775488064438, time: 1.6295711994171143
Validation Loss Energy: 2.763848932140799, Validation Loss Force: 4.572175571893355, time: 0.10565304756164551
Test Loss Energy: 7.904152046794639, Test Loss Force: 9.1694853188419, time: 11.550179958343506


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1671723106596064, Training Loss Force: 4.60494704364437, time: 1.3006436824798584
Validation Loss Energy: 1.9570498116783317, Validation Loss Force: 4.516743646698655, time: 0.0899953842163086
Test Loss Energy: 7.610318954008251, Test Loss Force: 9.08203130996292, time: 9.498939275741577


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1285128536628597, Training Loss Force: 4.672681953214918, time: 1.293870449066162
Validation Loss Energy: 5.66877146036817, Validation Loss Force: 4.98853080237668, time: 0.08646726608276367
Test Loss Energy: 9.479497218350584, Test Loss Force: 9.27091653348316, time: 9.622411012649536

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ˆ
wandb:   test_error_force â–‚â–‚â–ƒâ–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–„
wandb:          test_loss â–†â–†â–†â–‡â–„â–‚â–ƒâ–‚â–ƒâ–â–„â–â–ƒâ–â–ƒâ–â–‚â–â–‚â–ˆ
wandb: train_error_energy â–ˆâ–â–‚â–‚â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡
wandb:  train_error_force â–„â–‚â–‚â–…â–ˆâ–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–â–â–‚â–ˆâ–…â–…â–…â–„â–…â–…â–„â–…â–…â–…â–…â–…â–„â–…â–…
wandb: valid_error_energy â–â–‚â–‚â–â–â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–ƒâ–â–ˆ
wandb:  valid_error_force â–‚â–â–‚â–ˆâ–‚â–â–â–â–â–â–‚â–‚â–‚â–â–‚â–â–ƒâ–‚â–â–†
wandb:         valid_loss â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2592
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.4795
wandb:   test_error_force 9.27092
wandb:          test_loss 8.06644
wandb: train_error_energy 3.12851
wandb:  train_error_force 4.67268
wandb:         train_loss 1.6001
wandb: valid_error_energy 5.66877
wandb:  valid_error_force 4.98853
wandb:         valid_loss 3.25233
wandb: 
wandb: ğŸš€ View run al_72_40 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/fhzgjc2q
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_082159-fhzgjc2q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.380676031112671, Uncertainty Bias: -0.007088690996170044
0.00031614304 0.12262535
3.3391957 7.744005
(48745, 22, 3)
Found uncertainty sample 0 after 2641 steps.
Found uncertainty sample 1 after 491 steps.
Found uncertainty sample 2 after 14 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1888 steps.
Found uncertainty sample 5 after 1511 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1456 steps.
Found uncertainty sample 8 after 2054 steps.
Found uncertainty sample 9 after 1683 steps.
Found uncertainty sample 10 after 1410 steps.
Found uncertainty sample 11 after 585 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 735 steps.
Found uncertainty sample 14 after 46 steps.
Found uncertainty sample 15 after 2147 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 325 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2553 steps.
Found uncertainty sample 20 after 259 steps.
Found uncertainty sample 21 after 840 steps.
Found uncertainty sample 22 after 3137 steps.
Found uncertainty sample 23 after 591 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 39 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2617 steps.
Found uncertainty sample 31 after 3053 steps.
Found uncertainty sample 32 after 560 steps.
Found uncertainty sample 33 after 94 steps.
Found uncertainty sample 34 after 563 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2416 steps.
Found uncertainty sample 37 after 3406 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 950 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 152 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3565 steps.
Found uncertainty sample 45 after 3859 steps.
Found uncertainty sample 46 after 1173 steps.
Found uncertainty sample 47 after 1064 steps.
Found uncertainty sample 48 after 1933 steps.
Found uncertainty sample 49 after 3805 steps.
Found uncertainty sample 50 after 3992 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2154 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1848 steps.
Found uncertainty sample 57 after 3321 steps.
Found uncertainty sample 58 after 412 steps.
Found uncertainty sample 59 after 1902 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3220 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 54 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2186 steps.
Found uncertainty sample 66 after 231 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 385 steps.
Found uncertainty sample 69 after 93 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 480 steps.
Found uncertainty sample 73 after 3597 steps.
Found uncertainty sample 74 after 3362 steps.
Found uncertainty sample 75 after 413 steps.
Found uncertainty sample 76 after 3675 steps.
Found uncertainty sample 77 after 852 steps.
Found uncertainty sample 78 after 3234 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1539 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1813 steps.
Found uncertainty sample 83 after 3714 steps.
Found uncertainty sample 84 after 1853 steps.
Found uncertainty sample 85 after 1092 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1812 steps.
Found uncertainty sample 88 after 1730 steps.
Found uncertainty sample 89 after 2159 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3190 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1113 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 755 steps.
Found uncertainty sample 98 after 2862 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_085127-3sqsju3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_41
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3sqsju3k
Training model 41. Added 66 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.835096137774947, Training Loss Force: 5.055073142635306, time: 1.4224426746368408
Validation Loss Energy: 2.4872794907385742, Validation Loss Force: 4.539699276959788, time: 0.10273599624633789
Test Loss Energy: 8.01334254671304, Test Loss Force: 9.0527418441878, time: 10.920322179794312


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1476578610476267, Training Loss Force: 4.62389813226887, time: 1.2904484272003174
Validation Loss Energy: 2.7123864184759796, Validation Loss Force: 4.568154612456192, time: 0.09393429756164551
Test Loss Energy: 8.02657868390992, Test Loss Force: 9.07658997552067, time: 11.125919342041016


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0853385886933626, Training Loss Force: 4.613011392386168, time: 1.4185733795166016
Validation Loss Energy: 4.021327509262211, Validation Loss Force: 4.517131981689153, time: 0.09485983848571777
Test Loss Energy: 8.399938006205678, Test Loss Force: 9.118759417445046, time: 11.005470991134644


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.108340990206184, Training Loss Force: 4.622851313641408, time: 1.4332756996154785
Validation Loss Energy: 3.526269757816139, Validation Loss Force: 4.531883812606869, time: 0.09156298637390137
Test Loss Energy: 8.183735130306578, Test Loss Force: 9.09623969059934, time: 11.483319520950317


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.151797272422142, Training Loss Force: 4.622469030959262, time: 1.4596185684204102
Validation Loss Energy: 1.9909538611755888, Validation Loss Force: 4.570354806287105, time: 0.09610104560852051
Test Loss Energy: 7.680973834898591, Test Loss Force: 9.104280308433005, time: 11.641623735427856


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.180627008649478, Training Loss Force: 4.622211319591839, time: 1.3773815631866455
Validation Loss Energy: 3.599883843456147, Validation Loss Force: 4.552165409094556, time: 0.10899972915649414
Test Loss Energy: 8.341522017174746, Test Loss Force: 9.065392086400424, time: 11.279111623764038


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.2143910582746833, Training Loss Force: 4.630183331085389, time: 1.4937796592712402
Validation Loss Energy: 2.476981042739414, Validation Loss Force: 4.529597445816482, time: 0.10347986221313477
Test Loss Energy: 7.9843520754712, Test Loss Force: 9.08383576009955, time: 12.487033605575562


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1761650717481293, Training Loss Force: 4.618692546147762, time: 1.5173125267028809
Validation Loss Energy: 2.7559934986761854, Validation Loss Force: 4.531459850553023, time: 0.10814142227172852
Test Loss Energy: 7.870138003402521, Test Loss Force: 9.026455553323826, time: 11.383259296417236


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.135858416432332, Training Loss Force: 4.62479228571057, time: 1.5071699619293213
Validation Loss Energy: 4.270311917524891, Validation Loss Force: 4.533228734248272, time: 0.10680747032165527
Test Loss Energy: 8.531225261851931, Test Loss Force: 9.05177531087117, time: 11.465060472488403


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0764499167364283, Training Loss Force: 4.609720294119662, time: 1.510406494140625
Validation Loss Energy: 3.0992480072354374, Validation Loss Force: 4.536284645606986, time: 0.1106109619140625
Test Loss Energy: 8.06273808973012, Test Loss Force: 9.169630116740334, time: 11.368019819259644


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1275020243376943, Training Loss Force: 4.626373156163834, time: 1.5094122886657715
Validation Loss Energy: 2.443080221944773, Validation Loss Force: 4.622736164182595, time: 0.09873604774475098
Test Loss Energy: 7.87163270793329, Test Loss Force: 9.126107853666005, time: 11.26762580871582


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1173195024565983, Training Loss Force: 4.623926199312302, time: 1.5793957710266113
Validation Loss Energy: 3.283597017829355, Validation Loss Force: 4.558932324439301, time: 0.10120034217834473
Test Loss Energy: 8.38161170829163, Test Loss Force: 9.086276181296322, time: 11.765515089035034


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1218709067476755, Training Loss Force: 4.610704218103062, time: 1.4723451137542725
Validation Loss Energy: 2.649452547085825, Validation Loss Force: 4.518861898283866, time: 0.10068631172180176
Test Loss Energy: 7.890727377613776, Test Loss Force: 9.069342642750033, time: 11.378181219100952


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1860314731937898, Training Loss Force: 4.632688933087887, time: 1.4801719188690186
Validation Loss Energy: 2.778074484532114, Validation Loss Force: 4.553772634989862, time: 0.08964109420776367
Test Loss Energy: 7.847922057893825, Test Loss Force: 9.093398082555186, time: 11.771946430206299


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1240266740598344, Training Loss Force: 4.620995175834084, time: 1.555718183517456
Validation Loss Energy: 4.451513165737401, Validation Loss Force: 4.567844211666769, time: 0.10575413703918457
Test Loss Energy: 8.759464036955846, Test Loss Force: 9.160191444443305, time: 11.569007158279419


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1567257534980446, Training Loss Force: 4.631520156154716, time: 1.4707434177398682
Validation Loss Energy: 3.3333525498214924, Validation Loss Force: 4.5037738369558, time: 0.10547685623168945
Test Loss Energy: 8.407831184422138, Test Loss Force: 9.128826161293667, time: 10.556397676467896


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.2002530886336396, Training Loss Force: 4.609279017527649, time: 1.3985021114349365
Validation Loss Energy: 2.1247726738186867, Validation Loss Force: 4.550483811704509, time: 0.0918114185333252
Test Loss Energy: 7.795332739839916, Test Loss Force: 9.113981068143827, time: 10.815023183822632


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0771136599259292, Training Loss Force: 4.608610913510478, time: 1.355539083480835
Validation Loss Energy: 3.5530453886102364, Validation Loss Force: 4.588211090437346, time: 0.09205508232116699
Test Loss Energy: 8.487934313548593, Test Loss Force: 9.159543017900676, time: 10.5790536403656


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.106308931701153, Training Loss Force: 4.637340647146445, time: 1.391669511795044
Validation Loss Energy: 2.590107768324308, Validation Loss Force: 4.499827694351667, time: 0.11376762390136719
Test Loss Energy: 8.052593418675267, Test Loss Force: 9.090363286293705, time: 10.976754903793335


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.096519964121679, Training Loss Force: 4.6117321661910955, time: 1.4608721733093262
Validation Loss Energy: 2.8518172729384688, Validation Loss Force: 4.561349175349201, time: 0.10557842254638672
Test Loss Energy: 8.139853612132727, Test Loss Force: 9.147573462443276, time: 11.509592294692993

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–†â–„â–â–…â–ƒâ–‚â–‡â–ƒâ–‚â–†â–‚â–‚â–ˆâ–†â–‚â–†â–ƒâ–„
wandb:   test_error_force â–‚â–ƒâ–†â–„â–…â–ƒâ–„â–â–‚â–ˆâ–†â–„â–ƒâ–„â–ˆâ–†â–…â–ˆâ–„â–‡
wandb:          test_loss â–„â–‚â–ƒâ–‚â–‚â–…â–ƒâ–â–ƒâ–‚â–ƒâ–…â–ƒâ–â–„â–ƒâ–ƒâ–ˆâ–„â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–‡â–…â–â–†â–‚â–ƒâ–‡â–„â–‚â–…â–ƒâ–ƒâ–ˆâ–…â–â–…â–ƒâ–ƒ
wandb:  valid_error_force â–ƒâ–…â–‚â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–„â–‚â–„â–…â–â–„â–†â–â–…
wandb:         valid_loss â–‚â–ƒâ–†â–…â–â–…â–‚â–‚â–‡â–ƒâ–‚â–„â–‚â–ƒâ–ˆâ–„â–â–…â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2651
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.13985
wandb:   test_error_force 9.14757
wandb:          test_loss 6.30697
wandb: train_error_energy 3.09652
wandb:  train_error_force 4.61173
wandb:         train_loss 1.55517
wandb: valid_error_energy 2.85182
wandb:  valid_error_force 4.56135
wandb:         valid_loss 1.453
wandb: 
wandb: ğŸš€ View run al_72_41 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3sqsju3k
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_085127-3sqsju3k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.123692274093628, Uncertainty Bias: -0.051485657691955566
2.0980835e-05 0.0031795502
2.7455616 7.168302
(48745, 22, 3)
Found uncertainty sample 0 after 2054 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3821 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 398 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3561 steps.
Found uncertainty sample 10 after 3585 steps.
Found uncertainty sample 11 after 880 steps.
Found uncertainty sample 12 after 3657 steps.
Found uncertainty sample 13 after 1016 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 585 steps.
Found uncertainty sample 16 after 3359 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 195 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3031 steps.
Found uncertainty sample 25 after 3524 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1383 steps.
Found uncertainty sample 28 after 640 steps.
Found uncertainty sample 29 after 3458 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 782 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1251 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 764 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1241 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1963 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1872 steps.
Found uncertainty sample 54 after 1761 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1573 steps.
Found uncertainty sample 57 after 218 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3315 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3610 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 823 steps.
Found uncertainty sample 67 after 2939 steps.
Found uncertainty sample 68 after 412 steps.
Found uncertainty sample 69 after 1577 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3878 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 530 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 55 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1683 steps.
Found uncertainty sample 83 after 84 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1017 steps.
Found uncertainty sample 86 after 2670 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1401 steps.
Found uncertainty sample 92 after 691 steps.
Found uncertainty sample 93 after 2808 steps.
Found uncertainty sample 94 after 2898 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 33 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2312 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_092628-w3cclzs6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_42
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/w3cclzs6
Training model 42. Added 44 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8210878578393737, Training Loss Force: 5.256939177264227, time: 1.3914785385131836
Validation Loss Energy: 1.8529059491111703, Validation Loss Force: 4.882196710422885, time: 0.09275054931640625
Test Loss Energy: 7.418486264832399, Test Loss Force: 9.217151615603315, time: 10.07206392288208


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.5974135506414058, Training Loss Force: 5.097873026129743, time: 1.3701448440551758
Validation Loss Energy: 2.376112142303272, Validation Loss Force: 4.614821834728884, time: 0.0972144603729248
Test Loss Energy: 7.738129290397003, Test Loss Force: 9.139518752334032, time: 9.9988534450531


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.525044870342509, Training Loss Force: 4.664370018522152, time: 1.2747893333435059
Validation Loss Energy: 3.002064949171838, Validation Loss Force: 4.506436514602804, time: 0.0957038402557373
Test Loss Energy: 8.11240634998964, Test Loss Force: 9.045287916418795, time: 10.229172229766846


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.486289067106808, Training Loss Force: 4.665201438916677, time: 1.317577600479126
Validation Loss Energy: 6.08893366523942, Validation Loss Force: 4.5701557400706445, time: 0.09195828437805176
Test Loss Energy: 9.567859316307327, Test Loss Force: 9.078366007944734, time: 10.02042031288147


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.460416062370648, Training Loss Force: 4.6390496445509015, time: 1.285301923751831
Validation Loss Energy: 5.290521155489177, Validation Loss Force: 4.621104444681237, time: 0.09312748908996582
Test Loss Energy: 9.361906015444374, Test Loss Force: 9.05249018841546, time: 10.081469535827637


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.626197773485914, Training Loss Force: 4.654680515624726, time: 1.4980268478393555
Validation Loss Energy: 3.1178320854891433, Validation Loss Force: 4.538174661317621, time: 0.09927892684936523
Test Loss Energy: 8.018753078201502, Test Loss Force: 9.059639546761892, time: 10.092166900634766


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.527197659222072, Training Loss Force: 4.645150119000797, time: 1.3258154392242432
Validation Loss Energy: 4.308242047849669, Validation Loss Force: 4.570955790311963, time: 0.09007883071899414
Test Loss Energy: 8.585507250131219, Test Loss Force: 8.949275340288196, time: 10.01175594329834


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.62669716798749, Training Loss Force: 4.648919137468074, time: 1.3317599296569824
Validation Loss Energy: 5.998522421241777, Validation Loss Force: 4.54240092170733, time: 0.0994107723236084
Test Loss Energy: 9.854217130734453, Test Loss Force: 9.030406599312398, time: 10.2925705909729


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.50768199744291, Training Loss Force: 4.680887851534405, time: 1.3177509307861328
Validation Loss Energy: 5.392396520464912, Validation Loss Force: 4.519370474613165, time: 0.0923452377319336
Test Loss Energy: 9.130211937477217, Test Loss Force: 8.986615920823628, time: 10.079792737960815


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.603688255619374, Training Loss Force: 4.652980779868015, time: 1.325751781463623
Validation Loss Energy: 2.5109994328431045, Validation Loss Force: 4.601789900294314, time: 0.09342813491821289
Test Loss Energy: 7.786169260959497, Test Loss Force: 9.005975806944019, time: 10.030605792999268


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.630542086507702, Training Loss Force: 4.651154719975365, time: 1.3655431270599365
Validation Loss Energy: 3.0725481952855276, Validation Loss Force: 4.526315970612945, time: 0.09086871147155762
Test Loss Energy: 8.137311115202557, Test Loss Force: 8.906433605419332, time: 10.19241213798523


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.56037297023672, Training Loss Force: 4.639853962180911, time: 1.3703629970550537
Validation Loss Energy: 6.314479919201741, Validation Loss Force: 4.521492956912148, time: 0.09514927864074707
Test Loss Energy: 9.593098246120507, Test Loss Force: 8.896736725514362, time: 10.770143032073975


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.6132501350409, Training Loss Force: 4.749729271587149, time: 1.2986643314361572
Validation Loss Energy: 5.410943301636676, Validation Loss Force: 4.59093010337827, time: 0.09306621551513672
Test Loss Energy: 9.588874261386152, Test Loss Force: 9.001673027642989, time: 10.162203311920166


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.623391861946065, Training Loss Force: 4.630641076041252, time: 1.3624074459075928
Validation Loss Energy: 3.2460910722275704, Validation Loss Force: 4.510243266321584, time: 0.08985209465026855
Test Loss Energy: 8.173064866802774, Test Loss Force: 8.935092425540903, time: 10.046356439590454


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.522924815137215, Training Loss Force: 4.637911910000692, time: 1.3383913040161133
Validation Loss Energy: 4.218180394411132, Validation Loss Force: 4.64045172143261, time: 0.09176921844482422
Test Loss Energy: 8.362567182303836, Test Loss Force: 9.007056104375497, time: 10.075193881988525


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.621995477535581, Training Loss Force: 4.702070985620851, time: 1.332892656326294
Validation Loss Energy: 6.439127880400656, Validation Loss Force: 4.504100269923729, time: 0.0929403305053711
Test Loss Energy: 10.143776820225774, Test Loss Force: 8.959094340812927, time: 10.221036911010742


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.691661912970357, Training Loss Force: 4.595875857551575, time: 1.330702304840088
Validation Loss Energy: 5.839729037191418, Validation Loss Force: 4.528694967768037, time: 0.0886542797088623
Test Loss Energy: 9.341118164915027, Test Loss Force: 8.973030678043374, time: 10.129112005233765


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.6636860208200535, Training Loss Force: 4.66041738969678, time: 1.344834327697754
Validation Loss Energy: 2.1454463906723524, Validation Loss Force: 4.620022272632028, time: 0.09100079536437988
Test Loss Energy: 7.690944469614278, Test Loss Force: 8.974264409671887, time: 10.086321115493774


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.591067141829584, Training Loss Force: 4.641277939228031, time: 1.3656690120697021
Validation Loss Energy: 3.386495770199775, Validation Loss Force: 4.535541153328733, time: 0.0957639217376709
Test Loss Energy: 8.225332396464028, Test Loss Force: 8.96645776464928, time: 10.158009052276611


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.559557639652717, Training Loss Force: 4.623136968645265, time: 1.310650110244751
Validation Loss Energy: 6.416036644629653, Validation Loss Force: 4.622627278970237, time: 0.10105228424072266
Test Loss Energy: 9.616052912259212, Test Loss Force: 9.03477971408417, time: 10.130436182022095

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–ƒâ–‡â–†â–ƒâ–„â–‡â–…â–‚â–ƒâ–‡â–‡â–ƒâ–ƒâ–ˆâ–†â–‚â–ƒâ–‡
wandb:   test_error_force â–ˆâ–†â–„â–…â–„â–…â–‚â–„â–ƒâ–ƒâ–â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„
wandb:          test_loss â–†â–…â–„â–„â–‡â–â–‚â–‡â–ƒâ–â–‚â–ƒâ–†â–â–â–ˆâ–ƒâ–â–‚â–„
wandb: train_error_energy â–‚â–â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:  train_error_force â–ˆâ–†â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–â–â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–â–‚â–ƒâ–‡â–†â–ƒâ–…â–‡â–†â–‚â–ƒâ–ˆâ–†â–ƒâ–…â–ˆâ–‡â–â–ƒâ–ˆ
wandb:  valid_error_force â–ˆâ–ƒâ–â–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–â–â–ƒâ–â–„â–â–â–ƒâ–‚â–ƒ
wandb:         valid_loss â–â–â–‚â–‡â–†â–ƒâ–„â–‡â–†â–‚â–ƒâ–‡â–†â–ƒâ–„â–ˆâ–†â–‚â–ƒâ–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 2690
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.61605
wandb:   test_error_force 9.03478
wandb:          test_loss 5.8784
wandb: train_error_energy 4.55956
wandb:  train_error_force 4.62314
wandb:         train_loss 1.93116
wandb: valid_error_energy 6.41604
wandb:  valid_error_force 4.62263
wandb:         valid_loss 2.40024
wandb: 
wandb: ğŸš€ View run al_72_42 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/w3cclzs6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_092628-w3cclzs6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0816285610198975, Uncertainty Bias: -0.14991730451583862
0.00018310547 0.09402847
2.7209687 6.7970843
(48745, 22, 3)
Found uncertainty sample 0 after 2233 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2866 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3887 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1411 steps.
Found uncertainty sample 11 after 2641 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 750 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3785 steps.
Found uncertainty sample 19 after 3319 steps.
Found uncertainty sample 20 after 2682 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1067 steps.
Found uncertainty sample 23 after 2925 steps.
Found uncertainty sample 24 after 1084 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1867 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2638 steps.
Found uncertainty sample 29 after 225 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 486 steps.
Found uncertainty sample 32 after 2395 steps.
Found uncertainty sample 33 after 3097 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1283 steps.
Found uncertainty sample 36 after 1664 steps.
Found uncertainty sample 37 after 3597 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3863 steps.
Found uncertainty sample 41 after 2152 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2007 steps.
Found uncertainty sample 44 after 1837 steps.
Found uncertainty sample 45 after 3020 steps.
Found uncertainty sample 46 after 327 steps.
Found uncertainty sample 47 after 77 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2887 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1533 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2525 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3523 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2950 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 536 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1203 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2382 steps.
Found uncertainty sample 70 after 1042 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2179 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1972 steps.
Found uncertainty sample 81 after 515 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1466 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1447 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1098 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_100151-r8plkre5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_43
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/r8plkre5
Training model 43. Added 43 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.608492851224625, Training Loss Force: 4.824077008107916, time: 1.308295726776123
Validation Loss Energy: 5.369336458374338, Validation Loss Force: 4.516783949814068, time: 0.09395456314086914
Test Loss Energy: 9.041577973317175, Test Loss Force: 8.90915642238865, time: 10.008769035339355


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.490991646681796, Training Loss Force: 4.663398993833243, time: 1.3572041988372803
Validation Loss Energy: 4.149450667821623, Validation Loss Force: 4.526573821483929, time: 0.09506106376647949
Test Loss Energy: 8.654036974361208, Test Loss Force: 8.875650251178376, time: 9.941808938980103


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.62730727693912, Training Loss Force: 4.639995249683457, time: 1.3227488994598389
Validation Loss Energy: 5.406312451408816, Validation Loss Force: 4.574868755213353, time: 0.09144043922424316
Test Loss Energy: 9.298732988065035, Test Loss Force: 8.869458295547785, time: 10.253508567810059


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.572889203203468, Training Loss Force: 4.654953717568595, time: 1.35142183303833
Validation Loss Energy: 3.669352831610136, Validation Loss Force: 4.555091727010338, time: 0.094146728515625
Test Loss Energy: 8.60904571746472, Test Loss Force: 8.91269077163289, time: 10.68792462348938


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.677915142405874, Training Loss Force: 4.670441651255931, time: 1.356426477432251
Validation Loss Energy: 6.344853994728604, Validation Loss Force: 4.541059117433969, time: 0.09434747695922852
Test Loss Energy: 9.476141414787167, Test Loss Force: 8.906607198751821, time: 10.130894899368286


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.593150205384333, Training Loss Force: 4.670992177416652, time: 1.3197131156921387
Validation Loss Energy: 4.680967485879901, Validation Loss Force: 4.503205807964537, time: 0.0902245044708252
Test Loss Energy: 8.794174249020768, Test Loss Force: 8.920814763323309, time: 10.000192880630493


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.658400283819605, Training Loss Force: 4.630961205126863, time: 1.3310270309448242
Validation Loss Energy: 5.426070998072718, Validation Loss Force: 4.5721715638487295, time: 0.095062255859375
Test Loss Energy: 9.303099872763953, Test Loss Force: 8.862211368477999, time: 10.006918668746948


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.6330432444949246, Training Loss Force: 4.674428537135415, time: 1.3624796867370605
Validation Loss Energy: 2.3898326810716233, Validation Loss Force: 4.780887370416098, time: 0.09208297729492188
Test Loss Energy: 7.7084886415703515, Test Loss Force: 9.169395337190803, time: 10.19417929649353


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.5490864788917698, Training Loss Force: 5.3320315519412125, time: 1.3438997268676758
Validation Loss Energy: 3.9179306460123513, Validation Loss Force: 4.995992222787573, time: 0.09478020668029785
Test Loss Energy: 8.434116605594058, Test Loss Force: 9.18663909699223, time: 10.0020592212677


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.412918955868099, Training Loss Force: 5.236730959550696, time: 1.3439733982086182
Validation Loss Energy: 2.071815493511827, Validation Loss Force: 4.616201938095344, time: 0.09350943565368652
Test Loss Energy: 7.667594646182237, Test Loss Force: 8.989333724822645, time: 10.054689407348633


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.442570363860206, Training Loss Force: 4.924755971762583, time: 1.3271183967590332
Validation Loss Energy: 4.847214942259338, Validation Loss Force: 4.7324278841878336, time: 0.09560084342956543
Test Loss Energy: 8.81973968641353, Test Loss Force: 9.180254382161303, time: 10.171919822692871


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.569963774669683, Training Loss Force: 4.750418443011423, time: 1.3566820621490479
Validation Loss Energy: 6.2122282433693865, Validation Loss Force: 4.5251469575968235, time: 0.09704208374023438
Test Loss Energy: 9.732193291611893, Test Loss Force: 8.956794618537012, time: 9.932140588760376


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.528373797300562, Training Loss Force: 4.647529348267913, time: 1.3365278244018555
Validation Loss Energy: 4.195784999721152, Validation Loss Force: 4.513915748545372, time: 0.09032511711120605
Test Loss Energy: 8.66546823240446, Test Loss Force: 8.927723741583156, time: 10.12890362739563


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.606591706053547, Training Loss Force: 4.634850644774068, time: 1.3629744052886963
Validation Loss Energy: 5.071002555307121, Validation Loss Force: 4.5128286777749524, time: 0.0893852710723877
Test Loss Energy: 9.291030766711216, Test Loss Force: 8.894463844779892, time: 10.038193941116333


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.561012774053226, Training Loss Force: 4.6282765298395825, time: 1.3389105796813965
Validation Loss Energy: 3.592902275054727, Validation Loss Force: 4.486286960918652, time: 0.09703636169433594
Test Loss Energy: 8.52377712814395, Test Loss Force: 8.90443504374619, time: 10.044313669204712


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.597996679609911, Training Loss Force: 4.619279914412915, time: 1.3433151245117188
Validation Loss Energy: 6.006013901987371, Validation Loss Force: 4.479723119834993, time: 0.09156250953674316
Test Loss Energy: 9.390289527900242, Test Loss Force: 8.917678788999854, time: 10.206332683563232


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.537753208175428, Training Loss Force: 4.6165058038042535, time: 1.3096303939819336
Validation Loss Energy: 4.0506102833048825, Validation Loss Force: 4.569702831027827, time: 0.09191703796386719
Test Loss Energy: 8.354442146050307, Test Loss Force: 8.990188853617886, time: 10.06707215309143


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.517043211786036, Training Loss Force: 4.614795026399385, time: 1.3530640602111816
Validation Loss Energy: 5.385975187634647, Validation Loss Force: 4.473150817323788, time: 0.09497427940368652
Test Loss Energy: 9.517404362457821, Test Loss Force: 8.879383086067167, time: 10.099034309387207


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.5956140912675485, Training Loss Force: 4.598356409382688, time: 1.3522841930389404
Validation Loss Energy: 3.7066893259918694, Validation Loss Force: 4.478446334952243, time: 0.09339737892150879
Test Loss Energy: 8.490257307664772, Test Loss Force: 8.91662769736651, time: 11.019634246826172


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.556481051727535, Training Loss Force: 4.689747651361672, time: 1.3372275829315186
Validation Loss Energy: 5.547339286974742, Validation Loss Force: 4.5219725862524776, time: 0.09455251693725586
Test Loss Energy: 9.222406364959346, Test Loss Force: 8.913940143728743, time: 10.071907043457031

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–„â–‡â–„â–‡â–…â–‡â–â–„â–â–…â–ˆâ–„â–‡â–„â–‡â–ƒâ–‡â–„â–†
wandb:   test_error_force â–‚â–â–â–‚â–‚â–‚â–â–ˆâ–ˆâ–„â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–„â–â–‚â–‚
wandb:          test_loss â–â–â–ƒâ–‚â–‚â–â–ƒâ–â–‡â–ˆâ–ˆâ–ƒâ–â–ƒâ–‚â–‚â–â–„â–‚â–‚
wandb: train_error_energy â–ˆâ–…â–†â–†â–†â–†â–†â–†â–â–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:  train_error_force â–ƒâ–‚â–â–‚â–‚â–‚â–â–‚â–ˆâ–‡â–„â–‚â–â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–„â–„â–„â–„â–„â–„â–„â–â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„
wandb: valid_error_energy â–†â–„â–†â–„â–ˆâ–…â–†â–‚â–„â–â–†â–ˆâ–„â–†â–ƒâ–‡â–„â–†â–„â–‡
wandb:  valid_error_force â–‚â–‚â–‚â–‚â–‚â–â–‚â–…â–ˆâ–ƒâ–„â–‚â–‚â–‚â–â–â–‚â–â–â–‚
wandb:         valid_loss â–†â–„â–†â–„â–‡â–…â–†â–‚â–†â–â–ˆâ–ˆâ–„â–…â–ƒâ–‡â–„â–†â–ƒâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2728
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.22241
wandb:   test_error_force 8.91394
wandb:          test_loss 5.74585
wandb: train_error_energy 4.55648
wandb:  train_error_force 4.68975
wandb:         train_loss 1.96468
wandb: valid_error_energy 5.54734
wandb:  valid_error_force 4.52197
wandb:         valid_loss 2.14837
wandb: 
wandb: ğŸš€ View run al_72_43 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/r8plkre5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_100151-r8plkre5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1821272373199463, Uncertainty Bias: -0.15802770853042603
0.0009498596 0.2158513
2.5786393 6.62638
(48745, 22, 3)
Found uncertainty sample 0 after 3050 steps.
Found uncertainty sample 1 after 1615 steps.
Found uncertainty sample 2 after 1432 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1822 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1576 steps.
Found uncertainty sample 9 after 10 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3271 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2358 steps.
Found uncertainty sample 16 after 2412 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1298 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1787 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2125 steps.
Found uncertainty sample 29 after 294 steps.
Found uncertainty sample 30 after 1507 steps.
Found uncertainty sample 31 after 3645 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3005 steps.
Found uncertainty sample 34 after 3664 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2463 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1571 steps.
Found uncertainty sample 41 after 3285 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 525 steps.
Found uncertainty sample 47 after 3354 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3936 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 734 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1087 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1048 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1878 steps.
Found uncertainty sample 71 after 3030 steps.
Found uncertainty sample 72 after 2748 steps.
Found uncertainty sample 73 after 2575 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 578 steps.
Found uncertainty sample 77 after 432 steps.
Found uncertainty sample 78 after 3706 steps.
Found uncertainty sample 79 after 368 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 606 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1689 steps.
Found uncertainty sample 90 after 3303 steps.
Found uncertainty sample 91 after 1008 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 438 steps.
Found uncertainty sample 99 after 2161 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_103725-4vfqviui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_44
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/4vfqviui
Training model 44. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.039296503671231, Training Loss Force: 4.9255039474224835, time: 1.3904359340667725
Validation Loss Energy: 1.9090050467343578, Validation Loss Force: 4.641035559933233, time: 0.09589982032775879
Test Loss Energy: 7.419633192799827, Test Loss Force: 8.959378364052109, time: 10.103363275527954


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.8141349209050923, Training Loss Force: 5.279070179668941, time: 1.3888003826141357
Validation Loss Energy: 3.1940169977534607, Validation Loss Force: 7.793262012378966, time: 0.09178733825683594
Test Loss Energy: 8.015626878004324, Test Loss Force: 11.397301642023038, time: 10.094459295272827


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.506805625823704, Training Loss Force: 5.027271793913721, time: 1.3239455223083496
Validation Loss Energy: 5.029899166983727, Validation Loss Force: 4.558008915491138, time: 0.09908795356750488
Test Loss Energy: 9.118472689533515, Test Loss Force: 8.970681348346009, time: 10.210095167160034


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.490698297759859, Training Loss Force: 4.6456027856519135, time: 1.392937421798706
Validation Loss Energy: 5.212993548274915, Validation Loss Force: 4.488675310177873, time: 0.09373283386230469
Test Loss Energy: 9.300006422418335, Test Loss Force: 8.890926636976774, time: 10.028260946273804


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.58287443788345, Training Loss Force: 4.628281798128483, time: 1.358431339263916
Validation Loss Energy: 3.3677466941089365, Validation Loss Force: 4.546764568960077, time: 0.0908510684967041
Test Loss Energy: 8.300071132081701, Test Loss Force: 8.91482895502118, time: 10.227577924728394


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.579002523446792, Training Loss Force: 4.631792788914331, time: 1.3481547832489014
Validation Loss Energy: 2.8592224693900157, Validation Loss Force: 4.469040567559107, time: 0.09656476974487305
Test Loss Energy: 7.984058257121209, Test Loss Force: 8.89392443984905, time: 10.102284669876099


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.5357032551872605, Training Loss Force: 4.646603435199558, time: 1.3637235164642334
Validation Loss Energy: 6.41665633286277, Validation Loss Force: 4.509563457419068, time: 0.09458470344543457
Test Loss Energy: 9.595757111578468, Test Loss Force: 8.852017085338467, time: 10.11630916595459


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.538751333454925, Training Loss Force: 4.6627625555948615, time: 1.3764050006866455
Validation Loss Energy: 6.199826685286938, Validation Loss Force: 4.493697835433421, time: 0.09469413757324219
Test Loss Energy: 9.361795930616564, Test Loss Force: 8.886013627635197, time: 10.268424272537231


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.502330847471521, Training Loss Force: 4.643103393593092, time: 1.3853816986083984
Validation Loss Energy: 4.066289308546242, Validation Loss Force: 4.500345845454241, time: 0.10660982131958008
Test Loss Energy: 8.388744125130053, Test Loss Force: 8.82514946712225, time: 10.106321096420288


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.581420119146593, Training Loss Force: 4.6335341281802895, time: 1.3685121536254883
Validation Loss Energy: 2.1349370749919987, Validation Loss Force: 4.497197526399967, time: 0.09472942352294922
Test Loss Energy: 7.657154314802259, Test Loss Force: 8.85645496768653, time: 10.030567646026611


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.625430872914212, Training Loss Force: 4.626900394578962, time: 1.4346463680267334
Validation Loss Energy: 5.309570946261591, Validation Loss Force: 4.570627798660012, time: 0.09607100486755371
Test Loss Energy: 9.386909149124278, Test Loss Force: 8.860129922587062, time: 10.29683542251587


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.574158156542727, Training Loss Force: 4.631134650582602, time: 1.3356506824493408
Validation Loss Energy: 5.502391070508613, Validation Loss Force: 4.520297446267662, time: 0.09553241729736328
Test Loss Energy: 9.384643668932943, Test Loss Force: 8.873614080569906, time: 10.893348217010498


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.633039126990645, Training Loss Force: 4.633543674799993, time: 1.3841357231140137
Validation Loss Energy: 2.887742490273312, Validation Loss Force: 4.485844962663986, time: 0.0967106819152832
Test Loss Energy: 8.092625838355174, Test Loss Force: 8.801419837744065, time: 10.353930950164795


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.618025191453433, Training Loss Force: 4.65320374283484, time: 1.3625688552856445
Validation Loss Energy: 2.6352420248618595, Validation Loss Force: 4.486450177402617, time: 0.09331369400024414
Test Loss Energy: 7.819575725356293, Test Loss Force: 8.886181168097501, time: 10.161196231842041


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.660472114215046, Training Loss Force: 4.602269747184957, time: 1.383523941040039
Validation Loss Energy: 5.722330515376472, Validation Loss Force: 4.529134516662099, time: 0.09686517715454102
Test Loss Energy: 9.134144843508139, Test Loss Force: 8.85624377474517, time: 10.077044248580933


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.614414949095055, Training Loss Force: 4.642097947700855, time: 1.3176946640014648
Validation Loss Energy: 6.442857588594947, Validation Loss Force: 4.63221363104072, time: 0.09406304359436035
Test Loss Energy: 9.494805178867036, Test Loss Force: 8.956572690844364, time: 10.344045162200928


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.563061946419678, Training Loss Force: 4.638238871292196, time: 1.3510537147521973
Validation Loss Energy: 4.540011236433233, Validation Loss Force: 4.549042474322918, time: 0.09444594383239746
Test Loss Energy: 8.427592150135663, Test Loss Force: 8.818610837781781, time: 10.05922269821167


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.729547361893064, Training Loss Force: 4.637542444105029, time: 1.411829948425293
Validation Loss Energy: 2.021668620495722, Validation Loss Force: 4.559201086098436, time: 0.09952068328857422
Test Loss Energy: 7.577781360940166, Test Loss Force: 8.884348346880579, time: 10.201716661453247


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.606646963178821, Training Loss Force: 4.6598116570529, time: 1.549156665802002
Validation Loss Energy: 5.194949108696365, Validation Loss Force: 4.53256451218597, time: 0.09426498413085938
Test Loss Energy: 9.4537527060006, Test Loss Force: 8.882221667676227, time: 10.220092058181763


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.617372540508472, Training Loss Force: 4.629744074088038, time: 1.3703134059906006
Validation Loss Energy: 5.816587255524288, Validation Loss Force: 4.507768966772035, time: 0.10032439231872559
Test Loss Energy: 9.718529221622367, Test Loss Force: 8.876291603603843, time: 10.176872968673706

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–†â–‡â–„â–ƒâ–ˆâ–‡â–„â–‚â–‡â–‡â–ƒâ–‚â–†â–‡â–„â–â–‡â–ˆ
wandb:   test_error_force â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_loss â–…â–ˆâ–„â–ƒâ–‚â–â–ƒâ–‚â–â–â–ƒâ–ƒâ–‚â–â–‚â–‚â–â–â–ƒâ–ƒ
wandb: train_error_energy â–…â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–„â–ˆâ–…â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–‚â–
wandb:         train_loss â–†â–â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb: valid_error_energy â–â–ƒâ–†â–†â–ƒâ–‚â–ˆâ–ˆâ–„â–â–†â–‡â–ƒâ–‚â–‡â–ˆâ–…â–â–†â–‡
wandb:  valid_error_force â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–ˆâ–…â–…â–ƒâ–‚â–†â–†â–ƒâ–‚â–…â–…â–‚â–‚â–…â–†â–„â–‚â–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2764
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.71853
wandb:   test_error_force 8.87629
wandb:          test_loss 6.01238
wandb: train_error_energy 4.61737
wandb:  train_error_force 4.62974
wandb:         train_loss 1.94649
wandb: valid_error_energy 5.81659
wandb:  valid_error_force 4.50777
wandb:         valid_loss 2.21467
wandb: 
wandb: ğŸš€ View run al_72_44 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/4vfqviui
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_103725-4vfqviui/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.127528190612793, Uncertainty Bias: -0.13898533582687378
1.5258789e-05 0.102472305
2.6244583 6.459198
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1962 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3477 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3216 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2065 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2348 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2372 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 591 steps.
Found uncertainty sample 41 after 3555 steps.
Found uncertainty sample 42 after 1954 steps.
Found uncertainty sample 43 after 1256 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2926 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2161 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2593 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2054 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2520 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2647 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2835 steps.
Found uncertainty sample 75 after 3268 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1870 steps.
Found uncertainty sample 83 after 3594 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2629 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3743 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3115 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_111748-lwl8h7pb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_45
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/lwl8h7pb
Training model 45. Added 23 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.45783363071534, Training Loss Force: 4.77732600521496, time: 1.3635778427124023
Validation Loss Energy: 2.449061449208112, Validation Loss Force: 4.52791941113277, time: 0.0952906608581543
Test Loss Energy: 8.002544021117954, Test Loss Force: 8.774779136874653, time: 10.013641595840454


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.546132892424896, Training Loss Force: 4.633482832375431, time: 1.3707096576690674
Validation Loss Energy: 5.302227317828892, Validation Loss Force: 4.533698343477035, time: 0.1024787425994873
Test Loss Energy: 9.651619274366348, Test Loss Force: 8.869748623471478, time: 9.968318223953247


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.574815931437459, Training Loss Force: 4.631977573592466, time: 1.3551335334777832
Validation Loss Energy: 5.805883327010394, Validation Loss Force: 4.577900172966014, time: 0.09501051902770996
Test Loss Energy: 9.667136665123905, Test Loss Force: 8.861997904544513, time: 10.08127474784851


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.6447253553229695, Training Loss Force: 4.624007840472066, time: 1.3655574321746826
Validation Loss Energy: 3.887107669487297, Validation Loss Force: 4.499387032111875, time: 0.09191417694091797
Test Loss Energy: 8.472607557890932, Test Loss Force: 8.851314999029093, time: 9.919414758682251


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.6959612685796985, Training Loss Force: 4.632427508594507, time: 1.375089406967163
Validation Loss Energy: 2.966616466478426, Validation Loss Force: 4.548237302691243, time: 0.09393167495727539
Test Loss Energy: 7.736968144246832, Test Loss Force: 8.844037886883253, time: 10.856248140335083


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.552197781861133, Training Loss Force: 4.625418835983254, time: 1.416152000427246
Validation Loss Energy: 6.293538999372961, Validation Loss Force: 4.515977219498371, time: 0.09186887741088867
Test Loss Energy: 9.391814216988253, Test Loss Force: 8.800758834475017, time: 9.904672145843506


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.586627897453306, Training Loss Force: 4.622424028109484, time: 1.3450839519500732
Validation Loss Energy: 6.430767544647653, Validation Loss Force: 4.594676066420213, time: 0.09373283386230469
Test Loss Energy: 9.500839414793887, Test Loss Force: 8.920470710347674, time: 9.883592128753662


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.694924577343399, Training Loss Force: 4.6652802116424805, time: 1.3453435897827148
Validation Loss Energy: 4.206202130375091, Validation Loss Force: 4.5986184236488645, time: 0.09384369850158691
Test Loss Energy: 8.620854648027223, Test Loss Force: 8.827956147587281, time: 10.13378620147705


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.645309159271484, Training Loss Force: 4.619180301724718, time: 1.3335328102111816
Validation Loss Energy: 2.3700593269095167, Validation Loss Force: 4.5030601823431, time: 0.09511089324951172
Test Loss Energy: 7.799002394981614, Test Loss Force: 8.784529490017245, time: 9.934512615203857


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.644286351584403, Training Loss Force: 4.6276135705809684, time: 1.4441730976104736
Validation Loss Energy: 4.8463062294748065, Validation Loss Force: 4.638357518115159, time: 0.09627938270568848
Test Loss Energy: 9.047409759855515, Test Loss Force: 8.862169175589365, time: 9.938458442687988


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.607954777135027, Training Loss Force: 4.674750023288932, time: 1.3583157062530518
Validation Loss Energy: 5.931056119386262, Validation Loss Force: 4.595651134610231, time: 0.0985875129699707
Test Loss Energy: 9.81261516171138, Test Loss Force: 8.860515627516863, time: 10.15467381477356


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.61267848551557, Training Loss Force: 4.68382264948619, time: 1.360327959060669
Validation Loss Energy: 3.583372592281882, Validation Loss Force: 4.502403085693468, time: 0.10249567031860352
Test Loss Energy: 8.345874305969435, Test Loss Force: 8.816730908633716, time: 10.020858764648438


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.5692482711620315, Training Loss Force: 4.6208379532236235, time: 1.3875515460968018
Validation Loss Energy: 2.892392267378576, Validation Loss Force: 4.561277921222504, time: 0.09578227996826172
Test Loss Energy: 8.036931421211634, Test Loss Force: 8.843493837377137, time: 10.241860628128052


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.531798386996712, Training Loss Force: 4.620818557973188, time: 1.3501384258270264
Validation Loss Energy: 5.837952137406914, Validation Loss Force: 4.613745229408323, time: 0.09686446189880371
Test Loss Energy: 9.144616476807322, Test Loss Force: 8.934315890793524, time: 9.943233728408813


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.613774214788526, Training Loss Force: 4.664482620999428, time: 1.3740875720977783
Validation Loss Energy: 6.408691012174641, Validation Loss Force: 4.5605230728178086, time: 0.09549617767333984
Test Loss Energy: 9.305080140592919, Test Loss Force: 8.775854015634977, time: 9.96027159690857


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.698581022269849, Training Loss Force: 4.624570517725579, time: 1.3805372714996338
Validation Loss Energy: 4.160828393171094, Validation Loss Force: 4.5115492208624515, time: 0.09270572662353516
Test Loss Energy: 8.225118428901895, Test Loss Force: 8.7607518573681, time: 10.114309072494507


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.661933079753879, Training Loss Force: 4.619646140934493, time: 1.3285882472991943
Validation Loss Energy: 2.1470430397832274, Validation Loss Force: 4.526143179355705, time: 0.09482979774475098
Test Loss Energy: 7.821604772883708, Test Loss Force: 8.741184849304558, time: 10.050600290298462


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.618781506403193, Training Loss Force: 4.614494314009378, time: 1.363955020904541
Validation Loss Energy: 4.918409616294268, Validation Loss Force: 4.604747614559672, time: 0.09615540504455566
Test Loss Energy: 9.070158726335666, Test Loss Force: 8.808202423867131, time: 10.034235000610352


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.565647324600644, Training Loss Force: 4.657311512525931, time: 1.4024245738983154
Validation Loss Energy: 5.549652151393494, Validation Loss Force: 4.545650109884708, time: 0.09637165069580078
Test Loss Energy: 9.324515552357026, Test Loss Force: 8.826962189825686, time: 10.529971599578857


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.577455996648781, Training Loss Force: 4.61248371399827, time: 1.3774919509887695
Validation Loss Energy: 3.254069975733601, Validation Loss Force: 4.520128663055049, time: 0.09995818138122559
Test Loss Energy: 8.148987281326962, Test Loss Force: 8.761336136543788, time: 11.020591259002686

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‡â–ˆâ–ƒâ–â–‡â–‡â–„â–â–…â–ˆâ–ƒâ–‚â–†â–†â–ƒâ–â–…â–†â–‚
wandb:   test_error_force â–‚â–†â–…â–…â–…â–ƒâ–‡â–„â–ƒâ–…â–…â–„â–…â–ˆâ–‚â–‚â–â–ƒâ–„â–‚
wandb:          test_loss â–ƒâ–ˆâ–ˆâ–„â–â–„â–„â–ƒâ–‚â–…â–ˆâ–„â–‚â–„â–„â–â–‚â–…â–†â–ƒ
wandb: train_error_energy â–ˆâ–â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–â–ƒâ–â–‚â–„â–„â–â–â–ƒâ–‚â–â–â–ƒâ–
wandb:         train_loss â–ˆâ–â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–‚â–
wandb: valid_error_energy â–â–†â–‡â–„â–‚â–ˆâ–ˆâ–„â–â–…â–‡â–ƒâ–‚â–‡â–ˆâ–„â–â–†â–‡â–ƒ
wandb:  valid_error_force â–‚â–ƒâ–…â–â–ƒâ–‚â–†â–†â–â–ˆâ–†â–â–„â–‡â–„â–‚â–‚â–†â–ƒâ–‚
wandb:         valid_loss â–â–†â–‡â–ƒâ–‚â–ˆâ–ˆâ–„â–â–…â–‡â–ƒâ–‚â–‡â–ˆâ–„â–â–…â–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2784
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.14899
wandb:   test_error_force 8.76134
wandb:          test_loss 5.40835
wandb: train_error_energy 4.57746
wandb:  train_error_force 4.61248
wandb:         train_loss 1.94191
wandb: valid_error_energy 3.25407
wandb:  valid_error_force 4.52013
wandb:         valid_loss 1.58485
wandb: 
wandb: ğŸš€ View run al_72_45 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/lwl8h7pb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_111748-lwl8h7pb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.2925562858581543, Uncertainty Bias: -0.16752752661705017
9.918213e-05 0.0022830963
2.5445747 6.5945697
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3529 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 855 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2969 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2438 steps.
Found uncertainty sample 24 after 847 steps.
Found uncertainty sample 25 after 3324 steps.
Found uncertainty sample 26 after 3367 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1905 steps.
Found uncertainty sample 29 after 1773 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3278 steps.
Found uncertainty sample 37 after 519 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1951 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3132 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 547 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3450 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2652 steps.
Found uncertainty sample 62 after 288 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2553 steps.
Found uncertainty sample 67 after 2902 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3358 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 395 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2773 steps.
Found uncertainty sample 79 after 255 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1959 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 890 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2496 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2116 steps.
Found uncertainty sample 95 after 1657 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 636 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_115549-98r7cw7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_46
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/98r7cw7x
Training model 46. Added 29 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.757233021994495, Training Loss Force: 4.971764508999066, time: 1.5723776817321777
Validation Loss Energy: 1.8820468272405995, Validation Loss Force: 5.031386374209379, time: 0.11513924598693848
Test Loss Energy: 7.208582612801876, Test Loss Force: 9.114636769322424, time: 11.105284929275513


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.5406024988327416, Training Loss Force: 4.916818716095887, time: 1.5396440029144287
Validation Loss Energy: 4.150939879069588, Validation Loss Force: 4.555492754142154, time: 0.11489152908325195
Test Loss Energy: 8.358051696843903, Test Loss Force: 8.848818171424172, time: 11.196104526519775


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0380088454116274, Training Loss Force: 4.668991332140084, time: 1.6743414402008057
Validation Loss Energy: 3.9529518266147283, Validation Loss Force: 4.849306473547038, time: 0.09934711456298828
Test Loss Energy: 8.278320527782169, Test Loss Force: 8.989497310867444, time: 11.418753147125244


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0947272200891107, Training Loss Force: 4.960812127264278, time: 1.41522216796875
Validation Loss Energy: 2.556208172209969, Validation Loss Force: 4.837736807393776, time: 0.10039806365966797
Test Loss Energy: 7.220719298357497, Test Loss Force: 9.18067459031646, time: 11.217310905456543


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.106221988438742, Training Loss Force: 4.651052169521597, time: 1.495988130569458
Validation Loss Energy: 3.14986170611598, Validation Loss Force: 4.5225190163365845, time: 0.1031184196472168
Test Loss Energy: 7.800492723072732, Test Loss Force: 8.867892164350877, time: 11.219213247299194


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.134018917839116, Training Loss Force: 4.594424283283455, time: 1.5126347541809082
Validation Loss Energy: 3.542396125371667, Validation Loss Force: 4.492782887912803, time: 0.10632658004760742
Test Loss Energy: 8.20406694509861, Test Loss Force: 8.827656073516678, time: 10.93949294090271


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1363961488230276, Training Loss Force: 4.612010808824067, time: 1.5484824180603027
Validation Loss Energy: 2.941797429469596, Validation Loss Force: 4.540249047081084, time: 0.10464262962341309
Test Loss Energy: 7.705255308368812, Test Loss Force: 8.857405893178417, time: 11.533323287963867


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1668308612068574, Training Loss Force: 4.600414796862312, time: 1.4582762718200684
Validation Loss Energy: 3.4962777825436873, Validation Loss Force: 4.53076334146456, time: 0.10876774787902832
Test Loss Energy: 7.987531490096832, Test Loss Force: 8.868258833983218, time: 11.445185899734497


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1323076421943807, Training Loss Force: 4.590865777298409, time: 1.5335948467254639
Validation Loss Energy: 3.406501702284803, Validation Loss Force: 4.523804485316026, time: 0.11191415786743164
Test Loss Energy: 7.94048243920277, Test Loss Force: 8.89599814011797, time: 11.091433763504028


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.130982815178231, Training Loss Force: 4.608890181714488, time: 1.6201508045196533
Validation Loss Energy: 2.948453344245096, Validation Loss Force: 4.525666222045127, time: 0.11814594268798828
Test Loss Energy: 7.881709337825666, Test Loss Force: 8.905544164591092, time: 11.229957580566406


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.106573480541748, Training Loss Force: 4.605685917037301, time: 1.5208427906036377
Validation Loss Energy: 3.103305707081679, Validation Loss Force: 4.530951719562015, time: 0.09991192817687988
Test Loss Energy: 7.987859056229211, Test Loss Force: 8.898480945395734, time: 11.246486186981201


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1784962295469072, Training Loss Force: 4.625188222120864, time: 1.4292500019073486
Validation Loss Energy: 3.7323153159855416, Validation Loss Force: 4.54642099046791, time: 0.10682106018066406
Test Loss Energy: 8.190016752820362, Test Loss Force: 8.93356637945349, time: 11.452760934829712


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.189195153065681, Training Loss Force: 4.601713433685338, time: 1.4969828128814697
Validation Loss Energy: 2.8458253575561248, Validation Loss Force: 4.539513348222938, time: 0.09840607643127441
Test Loss Energy: 7.677374871964594, Test Loss Force: 8.837405130281834, time: 11.21319055557251


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1506328890737607, Training Loss Force: 4.606700503940058, time: 1.4791409969329834
Validation Loss Energy: 3.092816654293605, Validation Loss Force: 4.508089833011317, time: 0.10860919952392578
Test Loss Energy: 7.982127246971584, Test Loss Force: 8.884271184443767, time: 11.974492311477661


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1581661721560064, Training Loss Force: 4.615822666751217, time: 1.5928122997283936
Validation Loss Energy: 3.5307437376306927, Validation Loss Force: 4.529096217568998, time: 0.10906195640563965
Test Loss Energy: 8.05271892946192, Test Loss Force: 8.866759312337733, time: 11.077940464019775


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.181343666917745, Training Loss Force: 4.619696006665956, time: 1.4757120609283447
Validation Loss Energy: 2.9448844031741657, Validation Loss Force: 4.554860151098573, time: 0.10555768013000488
Test Loss Energy: 7.86601369283905, Test Loss Force: 8.937537038979814, time: 11.38831877708435


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.125254378123469, Training Loss Force: 4.615074609755474, time: 1.3879318237304688
Validation Loss Energy: 3.1420159587592145, Validation Loss Force: 4.531937921209329, time: 0.08981013298034668
Test Loss Energy: 7.801302229175004, Test Loss Force: 8.815371913369644, time: 10.674753427505493


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.190441622050279, Training Loss Force: 4.605742313059168, time: 1.5517158508300781
Validation Loss Energy: 3.5873091601127394, Validation Loss Force: 4.57356747672455, time: 0.12050819396972656
Test Loss Energy: 8.204704667200934, Test Loss Force: 8.9270018878495, time: 11.478615522384644


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.203101203066233, Training Loss Force: 4.615978251756272, time: 1.4044725894927979
Validation Loss Energy: 2.687162123621561, Validation Loss Force: 4.53734299205758, time: 0.09314727783203125
Test Loss Energy: 7.509206370754166, Test Loss Force: 8.897577384312541, time: 9.68628454208374


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.148654649570211, Training Loss Force: 4.603770107130374, time: 1.4954187870025635
Validation Loss Energy: 3.295277573217289, Validation Loss Force: 4.505618650829811, time: 0.09084177017211914
Test Loss Energy: 7.896968042994394, Test Loss Force: 8.91914068772033, time: 9.453227281570435

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–ˆâ–â–…â–‡â–„â–†â–…â–…â–†â–‡â–„â–†â–†â–…â–…â–‡â–ƒâ–…
wandb:   test_error_force â–‡â–‚â–„â–ˆâ–‚â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–ƒâ–„â–ˆâ–„â–‚â–…â–‚â–‚â–ƒâ–‚â–‚â–„â–â–‚â–ƒâ–ƒâ–‚â–„â–â–‚
wandb: train_error_energy â–ˆâ–†â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‡â–‚â–ˆâ–‚â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–†â–â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–‡â–ƒâ–…â–†â–„â–†â–†â–„â–…â–‡â–„â–…â–†â–„â–…â–†â–ƒâ–…
wandb:  valid_error_force â–ˆâ–‚â–†â–…â–â–â–‚â–â–â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–
wandb:         valid_loss â–â–†â–ˆâ–‚â–ƒâ–„â–‚â–„â–„â–‚â–‚â–…â–‚â–‚â–„â–‚â–ƒâ–„â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2810
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.89697
wandb:   test_error_force 8.91914
wandb:          test_loss 6.00157
wandb: train_error_energy 3.14865
wandb:  train_error_force 4.60377
wandb:         train_loss 1.55505
wandb: valid_error_energy 3.29528
wandb:  valid_error_force 4.50562
wandb:         valid_loss 1.56688
wandb: 
wandb: ğŸš€ View run al_72_46 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/98r7cw7x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_115549-98r7cw7x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.252347707748413, Uncertainty Bias: -0.07356956601142883
6.866455e-05 0.033273697
2.6434972 7.028747
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 253 steps.
Found uncertainty sample 2 after 268 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2289 steps.
Found uncertainty sample 8 after 1906 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2207 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1427 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1105 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 213 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2714 steps.
Found uncertainty sample 33 after 2215 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2893 steps.
Found uncertainty sample 37 after 710 steps.
Found uncertainty sample 38 after 3977 steps.
Found uncertainty sample 39 after 1170 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 693 steps.
Found uncertainty sample 42 after 558 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1851 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3487 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1975 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3377 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1195 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 711 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3616 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2596 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2060 steps.
Found uncertainty sample 79 after 303 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 147 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3612 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3565 steps.
Found uncertainty sample 91 after 2875 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1140 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2306 steps.
Found uncertainty sample 96 after 1758 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_123303-8tr6qim8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_47
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/8tr6qim8
Training model 47. Added 33 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.118367220935744, Training Loss Force: 5.098294972417061, time: 1.515146017074585
Validation Loss Energy: 2.8978089170224153, Validation Loss Force: 4.627933707386841, time: 0.10597729682922363
Test Loss Energy: 7.61077552601681, Test Loss Force: 8.892820733012073, time: 10.870818614959717


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.480428963514281, Training Loss Force: 4.659003048557611, time: 1.4720563888549805
Validation Loss Energy: 3.16128930935414, Validation Loss Force: 4.571968044249351, time: 0.1048429012298584
Test Loss Energy: 7.953871994275385, Test Loss Force: 8.827594201805093, time: 10.955172777175903


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.45745041584442, Training Loss Force: 4.623057022916175, time: 1.5115876197814941
Validation Loss Energy: 6.039604655996307, Validation Loss Force: 4.551883287286665, time: 0.13487672805786133
Test Loss Energy: 9.454889181342047, Test Loss Force: 8.849762013472441, time: 11.140164136886597


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.656057120745583, Training Loss Force: 4.62960988566037, time: 1.3962724208831787
Validation Loss Energy: 5.4358003037348865, Validation Loss Force: 4.54460289689141, time: 0.10200977325439453
Test Loss Energy: 9.308559053380472, Test Loss Force: 8.802904679547218, time: 10.994302034378052


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.590112182061565, Training Loss Force: 4.628297103432995, time: 1.466402292251587
Validation Loss Energy: 2.5197575670253096, Validation Loss Force: 4.532212694935405, time: 0.10677075386047363
Test Loss Energy: 7.634118897872654, Test Loss Force: 8.781453839213615, time: 11.065637588500977


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.569086662968736, Training Loss Force: 4.6327689453735585, time: 1.5203840732574463
Validation Loss Energy: 4.135211866616125, Validation Loss Force: 4.511210095753203, time: 0.1002655029296875
Test Loss Energy: 8.34379335204907, Test Loss Force: 8.762723064544701, time: 10.301575422286987


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.593929975918274, Training Loss Force: 4.631226383598989, time: 1.4582509994506836
Validation Loss Energy: 6.118366740955592, Validation Loss Force: 4.560065265053781, time: 0.1088552474975586
Test Loss Energy: 9.476868370092463, Test Loss Force: 8.812530072164083, time: 11.547746181488037


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.625891244623013, Training Loss Force: 4.635325212187815, time: 1.5318107604980469
Validation Loss Energy: 4.480547441013218, Validation Loss Force: 4.983712019389656, time: 0.10523843765258789
Test Loss Energy: 8.682138494413769, Test Loss Force: 9.15580765087898, time: 10.964156866073608


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.643165859420378, Training Loss Force: 4.726000471739314, time: 1.5162827968597412
Validation Loss Energy: 3.1997714364916723, Validation Loss Force: 4.56098511129561, time: 0.09597659111022949
Test Loss Energy: 7.963363860016342, Test Loss Force: 8.745207415223831, time: 9.551693677902222


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.6242231637505045, Training Loss Force: 4.6942404008702745, time: 1.43324875831604
Validation Loss Energy: 3.192821153105255, Validation Loss Force: 4.627919456561502, time: 0.09607505798339844
Test Loss Energy: 7.843042178456905, Test Loss Force: 8.795882576034783, time: 9.77668046951294


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.5781351414548785, Training Loss Force: 4.642156921752124, time: 1.4742729663848877
Validation Loss Energy: 5.890969883721466, Validation Loss Force: 4.6146214324975485, time: 0.09599971771240234
Test Loss Energy: 9.610565654345779, Test Loss Force: 8.806143939711786, time: 9.66567063331604


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.660742367294463, Training Loss Force: 4.621241103491223, time: 1.408827543258667
Validation Loss Energy: 5.263437684600834, Validation Loss Force: 4.582371146747097, time: 0.09161686897277832
Test Loss Energy: 9.129133957670149, Test Loss Force: 8.748343995766952, time: 9.566593647003174


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.728839688490531, Training Loss Force: 4.627310689124137, time: 1.433300495147705
Validation Loss Energy: 2.20504022487359, Validation Loss Force: 4.623780259807851, time: 0.09272980690002441
Test Loss Energy: 7.504179802479779, Test Loss Force: 8.765377033613065, time: 9.640732765197754


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.598696629306145, Training Loss Force: 4.649581221465063, time: 1.5091166496276855
Validation Loss Energy: 4.356078283138481, Validation Loss Force: 4.586229780376881, time: 0.09501528739929199
Test Loss Energy: 8.605220336149333, Test Loss Force: 8.796081779816475, time: 9.49631929397583


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.6152260217610515, Training Loss Force: 4.6548754381052495, time: 1.4558055400848389
Validation Loss Energy: 6.415485761162628, Validation Loss Force: 4.613044044267797, time: 0.09507584571838379
Test Loss Energy: 9.3947347548327, Test Loss Force: 8.840371465690302, time: 9.67546534538269


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.0302335845747805, Training Loss Force: 4.8081517011908455, time: 1.5736651420593262
Validation Loss Energy: 3.4519761972773324, Validation Loss Force: 4.569246359278676, time: 0.1017909049987793
Test Loss Energy: 7.871763709671132, Test Loss Force: 8.803732873536452, time: 9.53125


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1749490707042054, Training Loss Force: 4.611519303530603, time: 1.4053592681884766
Validation Loss Energy: 2.320611635011625, Validation Loss Force: 4.527617471770892, time: 0.09401321411132812
Test Loss Energy: 7.547790186577156, Test Loss Force: 8.729319255856359, time: 9.491655588150024


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.113556904187693, Training Loss Force: 4.599579408640878, time: 1.4589252471923828
Validation Loss Energy: 4.01431922056328, Validation Loss Force: 4.491509443067242, time: 0.10761117935180664
Test Loss Energy: 8.283200847894156, Test Loss Force: 8.73309444218354, time: 10.22597622871399


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1820576781081282, Training Loss Force: 4.589595384487171, time: 1.449629306793213
Validation Loss Energy: 2.5495435733377776, Validation Loss Force: 4.4919534453442225, time: 0.10475873947143555
Test Loss Energy: 7.615619808701365, Test Loss Force: 8.785294930944767, time: 11.624631643295288


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1810758998209265, Training Loss Force: 4.609804966270404, time: 1.5045394897460938
Validation Loss Energy: 3.068378938197176, Validation Loss Force: 4.561044341288426, time: 0.10094428062438965
Test Loss Energy: 7.745723182628427, Test Loss Force: 8.807201513232307, time: 10.712164402008057

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–‡â–‡â–â–„â–ˆâ–…â–ƒâ–‚â–ˆâ–†â–â–…â–‡â–‚â–â–„â–â–‚
wandb:   test_error_force â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ˆâ–â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–â–â–‚â–‚
wandb:          test_loss â–„â–ƒâ–†â–…â–â–‚â–„â–„â–â–‚â–…â–„â–â–‚â–ƒâ–…â–…â–ˆâ–†â–…
wandb: train_error_energy â–…â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–…â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–„â–â–â–â–
wandb:         train_loss â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–‡â–†â–‚â–„â–ˆâ–…â–ƒâ–ƒâ–‡â–†â–â–…â–ˆâ–ƒâ–â–„â–‚â–‚
wandb:  valid_error_force â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–â–‚
wandb:         valid_loss â–‚â–ƒâ–ˆâ–†â–‚â–„â–‡â–…â–ƒâ–ƒâ–‡â–†â–‚â–„â–ˆâ–ƒâ–â–…â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2839
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.74572
wandb:   test_error_force 8.8072
wandb:          test_loss 5.97996
wandb: train_error_energy 3.18108
wandb:  train_error_force 4.6098
wandb:         train_loss 1.57332
wandb: valid_error_energy 3.06838
wandb:  valid_error_force 4.56104
wandb:         valid_loss 1.5052
wandb: 
wandb: ğŸš€ View run al_72_47 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/8tr6qim8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_123303-8tr6qim8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.480583429336548, Uncertainty Bias: -0.1037987470626831
6.1035156e-05 0.02818966
2.6670525 7.0992417
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2523 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2749 steps.
Found uncertainty sample 4 after 2961 steps.
Found uncertainty sample 5 after 582 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3067 steps.
Found uncertainty sample 12 after 765 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1610 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3175 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2761 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1929 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2086 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2248 steps.
Found uncertainty sample 39 after 3599 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 69 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2244 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3933 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1595 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 37 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 529 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 598 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1244 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3591 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1923 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3393 steps.
Found uncertainty sample 72 after 3096 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2681 steps.
Found uncertainty sample 75 after 1509 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2219 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 687 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3745 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 255 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2922 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2975 steps.
Found uncertainty sample 95 after 1537 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2238 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_131020-n3f39w00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_48
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/n3f39w00
Training model 48. Added 35 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.055046058042199, Training Loss Force: 5.015288364806635, time: 1.4557344913482666
Validation Loss Energy: 4.294540101955002, Validation Loss Force: 4.725880297951827, time: 0.09875917434692383
Test Loss Energy: 8.461271506645959, Test Loss Force: 8.831827172580164, time: 10.235734462738037


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.987213827897521, Training Loss Force: 4.812044222006759, time: 1.3901793956756592
Validation Loss Energy: 2.8697281110294623, Validation Loss Force: 4.560846611086842, time: 0.09729242324829102
Test Loss Energy: 7.713691076500966, Test Loss Force: 8.77923923017857, time: 10.20088791847229


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.5011764681692945, Training Loss Force: 4.621403261726868, time: 1.3743505477905273
Validation Loss Energy: 6.615779775292716, Validation Loss Force: 4.584078573758072, time: 0.1063692569732666
Test Loss Energy: 9.672347603451119, Test Loss Force: 8.801863721108726, time: 11.14785099029541


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.569139695809573, Training Loss Force: 4.620988854653484, time: 1.4053199291229248
Validation Loss Energy: 3.3749004970947314, Validation Loss Force: 4.529551353303275, time: 0.10083174705505371
Test Loss Energy: 8.018217618361703, Test Loss Force: 8.758270754168628, time: 10.250983238220215


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.553300435376703, Training Loss Force: 4.613323687025862, time: 1.4277770519256592
Validation Loss Energy: 6.280534898581633, Validation Loss Force: 4.538711516628452, time: 0.09565544128417969
Test Loss Energy: 9.747052761494233, Test Loss Force: 8.724921010947885, time: 10.376760005950928


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.649091259553592, Training Loss Force: 4.614036307464084, time: 1.454833984375
Validation Loss Energy: 2.182973712512146, Validation Loss Force: 4.551027347089718, time: 0.10085439682006836
Test Loss Energy: 7.629042351450177, Test Loss Force: 8.757005900155193, time: 10.205092668533325


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.565337011513857, Training Loss Force: 4.627266758864552, time: 1.3935365676879883
Validation Loss Energy: 6.658746013690942, Validation Loss Force: 4.601758058606446, time: 0.09903216361999512
Test Loss Energy: 9.521562931427168, Test Loss Force: 8.793974746792472, time: 10.234344005584717


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.620166891294104, Training Loss Force: 4.614763005540529, time: 1.4390614032745361
Validation Loss Energy: 2.7868661304207816, Validation Loss Force: 4.5636079311654925, time: 0.09645795822143555
Test Loss Energy: 7.7929402589605195, Test Loss Force: 8.741107155259735, time: 10.430644512176514


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.6115762760585834, Training Loss Force: 4.632758319357285, time: 1.356926679611206
Validation Loss Energy: 5.767056508034965, Validation Loss Force: 4.539400232296807, time: 0.09892010688781738
Test Loss Energy: 9.424705546225303, Test Loss Force: 8.708767896281284, time: 10.179360389709473


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.647302767365941, Training Loss Force: 4.614906750844734, time: 1.4806694984436035
Validation Loss Energy: 2.2842666863367076, Validation Loss Force: 4.558124703447021, time: 0.10296249389648438
Test Loss Energy: 7.463274319229026, Test Loss Force: 8.732751783513134, time: 10.316815376281738


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.564075509156823, Training Loss Force: 4.63521687867232, time: 1.4163422584533691
Validation Loss Energy: 6.017415007597165, Validation Loss Force: 4.611848088285019, time: 0.10170364379882812
Test Loss Energy: 9.165800449918242, Test Loss Force: 8.756281257811082, time: 10.257685661315918


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.660198016345283, Training Loss Force: 4.634384922416491, time: 1.4022037982940674
Validation Loss Energy: 2.9940360564425466, Validation Loss Force: 4.499903401861282, time: 0.1177670955657959
Test Loss Energy: 7.813821383380067, Test Loss Force: 8.6605253970554, time: 10.271243572235107


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.654298300833964, Training Loss Force: 4.622592745459805, time: 1.4308075904846191
Validation Loss Energy: 5.3818083799069, Validation Loss Force: 4.665078928972223, time: 0.0983893871307373
Test Loss Energy: 9.14857514251075, Test Loss Force: 8.753797216777848, time: 10.350836277008057


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.6731310906272645, Training Loss Force: 4.649270963450762, time: 1.4096450805664062
Validation Loss Energy: 2.1321283263852653, Validation Loss Force: 4.542853830750147, time: 0.10169100761413574
Test Loss Energy: 7.491628434694402, Test Loss Force: 8.729293412245745, time: 10.240089178085327


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.634625093357288, Training Loss Force: 4.675198479631342, time: 1.3756239414215088
Validation Loss Energy: 6.561881149836873, Validation Loss Force: 4.548046475233184, time: 0.10196852684020996
Test Loss Energy: 9.521306146103823, Test Loss Force: 8.7086379134588, time: 10.152514696121216


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.682457612545466, Training Loss Force: 4.635920874392288, time: 1.4124629497528076
Validation Loss Energy: 3.1029577865411673, Validation Loss Force: 4.587308612388901, time: 0.133026123046875
Test Loss Energy: 7.601433599383361, Test Loss Force: 8.690266491817201, time: 10.267531156539917


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.588432982715364, Training Loss Force: 4.608372302088338, time: 1.57187819480896
Validation Loss Energy: 5.975873629063731, Validation Loss Force: 4.558384335671173, time: 0.11918497085571289
Test Loss Energy: 9.385785119938864, Test Loss Force: 8.70151867490323, time: 10.256359338760376


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.672949280032563, Training Loss Force: 4.614237268842385, time: 1.4242219924926758
Validation Loss Energy: 2.2429387361796453, Validation Loss Force: 4.497897375525619, time: 0.09742593765258789
Test Loss Energy: 7.4508574949033015, Test Loss Force: 8.611348550113837, time: 10.483809471130371


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.578158900906023, Training Loss Force: 4.637393959445884, time: 1.4279348850250244
Validation Loss Energy: 6.851159766746646, Validation Loss Force: 4.603482185803365, time: 0.10121655464172363
Test Loss Energy: 9.497652914393026, Test Loss Force: 8.782627517789537, time: 10.279500484466553


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.607255252628572, Training Loss Force: 4.635805556515713, time: 1.4072973728179932
Validation Loss Energy: 3.253634880222458, Validation Loss Force: 4.49464818734824, time: 0.09847903251647949
Test Loss Energy: 7.885902913649015, Test Loss Force: 8.669364891162687, time: 11.030750036239624

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–ˆâ–ƒâ–ˆâ–‚â–‡â–‚â–‡â–â–†â–‚â–†â–â–‡â–â–‡â–â–‡â–‚
wandb:   test_error_force â–ˆâ–†â–‡â–†â–…â–†â–‡â–…â–„â–…â–†â–ƒâ–†â–…â–„â–„â–„â–â–†â–ƒ
wandb:          test_loss â–ˆâ–ƒâ–„â–‚â–…â–‚â–ƒâ–‚â–„â–â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–
wandb: train_error_energy â–‚â–â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡
wandb:  train_error_force â–ˆâ–…â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb: valid_error_energy â–„â–‚â–ˆâ–ƒâ–‡â–â–ˆâ–‚â–†â–â–‡â–‚â–†â–â–ˆâ–‚â–‡â–â–ˆâ–ƒ
wandb:  valid_error_force â–ˆâ–ƒâ–„â–‚â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–…â–â–†â–‚â–ƒâ–„â–ƒâ–â–„â–
wandb:         valid_loss â–†â–â–ˆâ–‚â–‡â–â–ˆâ–‚â–†â–â–†â–‚â–…â–â–‡â–‚â–†â–â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2870
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.8859
wandb:   test_error_force 8.66936
wandb:          test_loss 4.97756
wandb: train_error_energy 4.60726
wandb:  train_error_force 4.63581
wandb:         train_loss 1.94799
wandb: valid_error_energy 3.25363
wandb:  valid_error_force 4.49465
wandb:         valid_loss 1.57951
wandb: 
wandb: ğŸš€ View run al_72_48 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/n3f39w00
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_131020-n3f39w00/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.418722629547119, Uncertainty Bias: -0.22728776931762695
1.6450882e-05 0.025024414
2.3886132 6.7567973
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2286 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1230 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3969 steps.
Found uncertainty sample 8 after 3380 steps.
Found uncertainty sample 9 after 9 steps.
Found uncertainty sample 10 after 2648 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 482 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3945 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3092 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2502 steps.
Found uncertainty sample 35 after 1798 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3495 steps.
Found uncertainty sample 38 after 1324 steps.
Found uncertainty sample 39 after 1456 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1122 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1826 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1649 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3577 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3905 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2938 steps.
Found uncertainty sample 73 after 2204 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3503 steps.
Found uncertainty sample 78 after 1977 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3241 steps.
Found uncertainty sample 83 after 1743 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3241 steps.
Found uncertainty sample 87 after 1759 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 931 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 328 steps.
Found uncertainty sample 94 after 2577 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_134851-mk1ri2uv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_49
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/mk1ri2uv
Training model 49. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8549762511336088, Training Loss Force: 4.878866228431934, time: 1.4612057209014893
Validation Loss Energy: 4.654761776764805, Validation Loss Force: 4.858083423272074, time: 0.09823822975158691
Test Loss Energy: 8.778101885145066, Test Loss Force: 9.0293866673698, time: 10.318618297576904


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.447259484848037, Training Loss Force: 4.785477702200142, time: 1.4802308082580566
Validation Loss Energy: 2.3460367774356703, Validation Loss Force: 4.565973122833538, time: 0.1023404598236084
Test Loss Energy: 7.551265445725424, Test Loss Force: 8.829951286450935, time: 10.269462823867798


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.028239447902797, Training Loss Force: 4.606425898828582, time: 1.4737887382507324
Validation Loss Energy: 3.4450123310730136, Validation Loss Force: 4.5492542326806955, time: 0.10391449928283691
Test Loss Energy: 7.954415006213229, Test Loss Force: 8.745216587793676, time: 10.414039373397827


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.1888701448132473, Training Loss Force: 4.600905847505966, time: 1.4559857845306396
Validation Loss Energy: 2.25041518675789, Validation Loss Force: 4.563932137441963, time: 0.09868621826171875
Test Loss Energy: 7.471063472482705, Test Loss Force: 8.773511153835106, time: 10.237403631210327


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1257065082274593, Training Loss Force: 4.584126596886182, time: 1.4507720470428467
Validation Loss Energy: 3.291156189995312, Validation Loss Force: 4.513009039783154, time: 0.09977269172668457
Test Loss Energy: 7.9899764929152965, Test Loss Force: 8.76998631291314, time: 10.43381118774414


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1515603584944563, Training Loss Force: 4.62239612637454, time: 1.4383933544158936
Validation Loss Energy: 4.3671718826577495, Validation Loss Force: 4.533637777469342, time: 0.09811019897460938
Test Loss Energy: 8.409388320251876, Test Loss Force: 8.70755126937376, time: 10.155030727386475


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1193312520054626, Training Loss Force: 4.612691656886341, time: 1.4195477962493896
Validation Loss Energy: 2.752974550395696, Validation Loss Force: 4.514577743916215, time: 0.09775209426879883
Test Loss Energy: 7.759945081963358, Test Loss Force: 8.700764481682095, time: 10.27700161933899


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.2178271269793757, Training Loss Force: 4.601906635205796, time: 1.4281840324401855
Validation Loss Energy: 2.7308812064021684, Validation Loss Force: 4.496153208105566, time: 0.09865164756774902
Test Loss Energy: 7.619597549339694, Test Loss Force: 8.694393416120072, time: 10.35246729850769


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1907251121556226, Training Loss Force: 4.598935896018856, time: 1.4497904777526855
Validation Loss Energy: 3.3315613992116493, Validation Loss Force: 4.62009864814908, time: 0.10319662094116211
Test Loss Energy: 7.855102347432819, Test Loss Force: 8.788007614719234, time: 10.295958042144775


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1269412502391623, Training Loss Force: 4.600699146918789, time: 1.440643072128296
Validation Loss Energy: 2.2194271010611306, Validation Loss Force: 4.540094737362956, time: 0.10127067565917969
Test Loss Energy: 7.401576543724077, Test Loss Force: 8.736512248028932, time: 10.358587980270386


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.180414073562062, Training Loss Force: 4.591123737446335, time: 1.5106821060180664
Validation Loss Energy: 3.3253173110215424, Validation Loss Force: 4.51947468377346, time: 0.1014094352722168
Test Loss Energy: 7.915289304621999, Test Loss Force: 8.761669645960492, time: 10.321911573410034


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1679413690171203, Training Loss Force: 4.58974438772929, time: 1.4159502983093262
Validation Loss Energy: 4.358991018236362, Validation Loss Force: 4.551793551620856, time: 0.09773945808410645
Test Loss Energy: 8.208886319149807, Test Loss Force: 8.76750231384896, time: 10.291138172149658


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1865526569510743, Training Loss Force: 4.600078159374502, time: 1.3978769779205322
Validation Loss Energy: 2.80857748549447, Validation Loss Force: 4.544405166689826, time: 0.09943151473999023
Test Loss Energy: 7.74916096574337, Test Loss Force: 8.735737373390789, time: 10.44928789138794


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.168775476626653, Training Loss Force: 4.612513712428866, time: 1.4217026233673096
Validation Loss Energy: 2.909422003659133, Validation Loss Force: 4.531004937487891, time: 0.09855866432189941
Test Loss Energy: 7.727807862009338, Test Loss Force: 8.754556413642828, time: 10.302931547164917


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1683835042989537, Training Loss Force: 4.607976517822548, time: 1.4057414531707764
Validation Loss Energy: 3.354234796330319, Validation Loss Force: 4.584641258689832, time: 0.10136795043945312
Test Loss Energy: 7.835893724776743, Test Loss Force: 8.756388568018119, time: 11.055402278900146


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.2273201084937604, Training Loss Force: 4.602371211133094, time: 1.6488192081451416
Validation Loss Energy: 2.1029847205587986, Validation Loss Force: 4.582160724404196, time: 0.10269308090209961
Test Loss Energy: 7.265642688962566, Test Loss Force: 8.835304569818556, time: 10.304800271987915


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.199461698815859, Training Loss Force: 4.610664393786748, time: 1.4318110942840576
Validation Loss Energy: 3.143943828224657, Validation Loss Force: 4.493493647826605, time: 0.1019582748413086
Test Loss Energy: 7.652599931024403, Test Loss Force: 8.710219862325719, time: 10.345801830291748


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.179128942256711, Training Loss Force: 4.591398726500814, time: 1.415194034576416
Validation Loss Energy: 4.33704697390518, Validation Loss Force: 4.5561010862488285, time: 0.09879755973815918
Test Loss Energy: 8.109896141251438, Test Loss Force: 8.772050626103718, time: 10.447136878967285


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.2354476448781555, Training Loss Force: 4.599178546661989, time: 1.3989009857177734
Validation Loss Energy: 2.7688761334484107, Validation Loss Force: 4.525043639113113, time: 0.0976858139038086
Test Loss Energy: 7.611458665630059, Test Loss Force: 8.72990190290218, time: 10.28415060043335


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.219028129721643, Training Loss Force: 4.614931713388201, time: 1.4121677875518799
Validation Loss Energy: 2.516561485439235, Validation Loss Force: 4.565768712557576, time: 0.09822869300842285
Test Loss Energy: 7.622481501827398, Test Loss Force: 8.815626618893216, time: 10.299243927001953

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–„â–‚â–„â–†â–ƒâ–ƒâ–„â–‚â–„â–…â–ƒâ–ƒâ–„â–â–ƒâ–…â–ƒâ–ƒ
wandb:   test_error_force â–ˆâ–„â–‚â–ƒâ–ƒâ–â–â–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–„â–â–ƒâ–‚â–„
wandb:          test_loss â–ˆâ–…â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚
wandb: train_error_energy â–ˆâ–…â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–†â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–…â–â–„â–‡â–ƒâ–ƒâ–„â–â–„â–‡â–ƒâ–ƒâ–„â–â–„â–‡â–ƒâ–‚
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–â–‚â–‚â–‚
wandb:         valid_loss â–ˆâ–â–ƒâ–â–‚â–…â–‚â–‚â–ƒâ–â–ƒâ–…â–‚â–‚â–ƒâ–â–‚â–…â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2897
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.62248
wandb:   test_error_force 8.81563
wandb:          test_loss 5.97678
wandb: train_error_energy 3.21903
wandb:  train_error_force 4.61493
wandb:         train_loss 1.58048
wandb: valid_error_energy 2.51656
wandb:  valid_error_force 4.56577
wandb:         valid_loss 1.36096
wandb: 
wandb: ğŸš€ View run al_72_49 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/mk1ri2uv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_134851-mk1ri2uv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3265540599823, Uncertainty Bias: -0.07292339205741882
3.8146973e-05 0.005958557
2.6375465 6.9008884
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2678 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 342 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3214 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 930 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1931 steps.
Found uncertainty sample 17 after 1 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3619 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3920 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 792 steps.
Found uncertainty sample 28 after 2452 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2187 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2874 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3699 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 434 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2497 steps.
Found uncertainty sample 44 after 1340 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 45 after 1 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1920 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3802 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1617 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 494 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2169 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3219 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3498 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1062 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 404 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2447 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 450 steps.
Found uncertainty sample 97 after 3189 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_142720-0e25cmxl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_50
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0e25cmxl
Training model 50. Added 29 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.673752232992863, Training Loss Force: 4.970024198463855, time: 1.5623812675476074
Validation Loss Energy: 1.993336532371589, Validation Loss Force: 4.556257177320124, time: 0.1154031753540039
Test Loss Energy: 7.1618567912379785, Test Loss Force: 8.775623111228072, time: 10.296148300170898


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.145321228097248, Training Loss Force: 4.585091043103655, time: 1.5491907596588135
Validation Loss Energy: 4.364279855790439, Validation Loss Force: 4.5108128539968675, time: 0.11971807479858398
Test Loss Energy: 8.316481596322257, Test Loss Force: 8.729386345720284, time: 11.324203968048096


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.2049758098299383, Training Loss Force: 4.576900916129861, time: 1.4712190628051758
Validation Loss Energy: 2.4076653622923962, Validation Loss Force: 4.502174181811453, time: 0.09534287452697754
Test Loss Energy: 7.387562339909362, Test Loss Force: 8.72459529844871, time: 9.77517557144165


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.1335027630578476, Training Loss Force: 4.587320922120163, time: 1.4500081539154053
Validation Loss Energy: 2.2454527821717427, Validation Loss Force: 4.5016132782328615, time: 0.09726357460021973
Test Loss Energy: 7.42540528069092, Test Loss Force: 8.692395022323145, time: 9.587586164474487


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.136692113742891, Training Loss Force: 4.586313508816383, time: 1.4361417293548584
Validation Loss Energy: 3.9680058195634675, Validation Loss Force: 4.526319978657571, time: 0.09253263473510742
Test Loss Energy: 7.949134054178017, Test Loss Force: 8.720172170554632, time: 9.816141843795776


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1744446363799885, Training Loss Force: 4.5999017821120525, time: 1.415961503982544
Validation Loss Energy: 2.464683916486406, Validation Loss Force: 4.49684415046538, time: 0.09654545783996582
Test Loss Energy: 7.4643672236979075, Test Loss Force: 8.67963104397504, time: 9.593010902404785


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.204574407549018, Training Loss Force: 4.6093535016400216, time: 1.476680040359497
Validation Loss Energy: 2.1212365764467807, Validation Loss Force: 4.6265255477079945, time: 0.09654474258422852
Test Loss Energy: 7.2413577926828605, Test Loss Force: 8.744636249045808, time: 9.589048862457275


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1859507377530383, Training Loss Force: 4.606216708134366, time: 1.4277515411376953
Validation Loss Energy: 4.2022323848414915, Validation Loss Force: 4.5432561938968385, time: 0.09359574317932129
Test Loss Energy: 8.163276533998213, Test Loss Force: 8.773056316547436, time: 9.788356065750122


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.2363675293397107, Training Loss Force: 4.584495894462609, time: 1.434753656387329
Validation Loss Energy: 2.662353663397162, Validation Loss Force: 4.49247961253605, time: 0.0962984561920166
Test Loss Energy: 7.4410431179693175, Test Loss Force: 8.731440399808852, time: 9.611730337142944


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.2000279961236417, Training Loss Force: 4.592078277466711, time: 1.473527431488037
Validation Loss Energy: 1.9766750908583963, Validation Loss Force: 4.5120382023069086, time: 0.10296511650085449
Test Loss Energy: 7.172163887193813, Test Loss Force: 8.787647445626986, time: 10.406109809875488


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.170498939114148, Training Loss Force: 4.610027366244469, time: 1.4485576152801514
Validation Loss Energy: 4.12227478923772, Validation Loss Force: 4.528935673114785, time: 0.0966958999633789
Test Loss Energy: 8.218574140734024, Test Loss Force: 8.727775139759718, time: 9.746412992477417


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1608597587887943, Training Loss Force: 4.583492494044089, time: 1.4179344177246094
Validation Loss Energy: 2.5105365036887206, Validation Loss Force: 4.537982497844685, time: 0.10020971298217773
Test Loss Energy: 7.397738259256294, Test Loss Force: 8.760028632645357, time: 9.591779947280884


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1955711061660375, Training Loss Force: 4.600475600501109, time: 1.4697003364562988
Validation Loss Energy: 2.0650577076020644, Validation Loss Force: 4.597055508913598, time: 0.09361529350280762
Test Loss Energy: 7.332904551396943, Test Loss Force: 8.778343424043852, time: 10.3707275390625


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1578050285446815, Training Loss Force: 4.598650488005878, time: 1.5839416980743408
Validation Loss Energy: 4.431289685896802, Validation Loss Force: 4.518527894564974, time: 0.10729217529296875
Test Loss Energy: 8.016375207216015, Test Loss Force: 8.766764707730488, time: 11.668007612228394


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.222087737648828, Training Loss Force: 4.597813450483168, time: 1.5734407901763916
Validation Loss Energy: 2.318868803606448, Validation Loss Force: 4.52580115954756, time: 0.11248159408569336
Test Loss Energy: 7.412620567298681, Test Loss Force: 8.758651758564415, time: 10.797516345977783


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.151683215969648, Training Loss Force: 4.626482819435145, time: 1.492011308670044
Validation Loss Energy: 2.370679571815499, Validation Loss Force: 4.5073902065548115, time: 0.10217094421386719
Test Loss Energy: 7.348687673881121, Test Loss Force: 8.712964936883173, time: 10.3707914352417


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.249110787748486, Training Loss Force: 4.588131040879384, time: 1.4193973541259766
Validation Loss Energy: 4.3503619208242235, Validation Loss Force: 4.598683220370329, time: 0.1092977523803711
Test Loss Energy: 8.555082624045001, Test Loss Force: 8.82621638108883, time: 10.192424297332764


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.2110532192728933, Training Loss Force: 4.606722007354714, time: 1.478308916091919
Validation Loss Energy: 2.372151414870081, Validation Loss Force: 4.465068818003193, time: 0.09840917587280273
Test Loss Energy: 7.44514309114488, Test Loss Force: 8.726392110217573, time: 10.353850841522217


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1910170259668704, Training Loss Force: 4.591480684305695, time: 1.4175283908843994
Validation Loss Energy: 2.2185556853585418, Validation Loss Force: 4.495970619405906, time: 0.10096526145935059
Test Loss Energy: 7.45440527424472, Test Loss Force: 8.711184852113817, time: 10.176632642745972


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1861503981572743, Training Loss Force: 4.574066255611428, time: 1.4780371189117432
Validation Loss Energy: 4.418432101403493, Validation Loss Force: 4.5473263632152525, time: 0.09820413589477539
Test Loss Energy: 8.111430191770035, Test Loss Force: 8.77040743972425, time: 10.207930326461792

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‡â–‚â–‚â–…â–ƒâ–â–†â–‚â–â–†â–‚â–‚â–…â–‚â–‚â–ˆâ–‚â–‚â–†
wandb:   test_error_force â–†â–ƒâ–ƒâ–‚â–ƒâ–â–„â–…â–ƒâ–†â–ƒâ–…â–†â–…â–…â–ƒâ–ˆâ–ƒâ–ƒâ–…
wandb:          test_loss â–ˆâ–‡â–„â–…â–„â–„â–„â–„â–ƒâ–â–†â–„â–„â–ƒâ–â–‚â–†â–„â–â–…
wandb: train_error_energy â–ˆâ–â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–â–â–â–â–â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–
wandb: valid_error_energy â–â–ˆâ–‚â–‚â–‡â–‚â–â–‡â–ƒâ–â–‡â–ƒâ–â–ˆâ–‚â–‚â–ˆâ–‚â–‚â–ˆ
wandb:  valid_error_force â–…â–ƒâ–ƒâ–ƒâ–„â–‚â–ˆâ–„â–‚â–ƒâ–„â–„â–‡â–ƒâ–„â–ƒâ–‡â–â–‚â–…
wandb:         valid_loss â–â–ˆâ–‚â–‚â–‡â–‚â–‚â–‡â–ƒâ–â–‡â–‚â–‚â–ˆâ–‚â–‚â–‡â–‚â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2923
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.11143
wandb:   test_error_force 8.77041
wandb:          test_loss 5.93313
wandb: train_error_energy 3.18615
wandb:  train_error_force 4.57407
wandb:         train_loss 1.56445
wandb: valid_error_energy 4.41843
wandb:  valid_error_force 4.54733
wandb:         valid_loss 2.02056
wandb: 
wandb: ğŸš€ View run al_72_50 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0e25cmxl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_142720-0e25cmxl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.2637038230895996, Uncertainty Bias: -0.07319852709770203
1.5258789e-05 0.022690773
2.5983934 7.043977
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3303 steps.
Found uncertainty sample 2 after 3057 steps.
Found uncertainty sample 3 after 2128 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3606 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1785 steps.
Found uncertainty sample 8 after 1792 steps.
Found uncertainty sample 9 after 3875 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 639 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 627 steps.
Found uncertainty sample 16 after 2696 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3121 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1703 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 871 steps.
Found uncertainty sample 28 after 373 steps.
Found uncertainty sample 29 after 2535 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1454 steps.
Found uncertainty sample 34 after 2696 steps.
Found uncertainty sample 35 after 1151 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2865 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 32 steps.
Found uncertainty sample 40 after 1299 steps.
Found uncertainty sample 41 after 1588 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3445 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3280 steps.
Found uncertainty sample 46 after 3664 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3578 steps.
Found uncertainty sample 50 after 1136 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 774 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1365 steps.
Found uncertainty sample 61 after 2235 steps.
Found uncertainty sample 62 after 2695 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2228 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2758 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1711 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1594 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1190 steps.
Found uncertainty sample 78 after 2997 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1857 steps.
Found uncertainty sample 85 after 181 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1859 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3661 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1270 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_150309-6puirqhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_51
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6puirqhf
Training model 51. Added 42 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.561508445411986, Training Loss Force: 4.788407946596761, time: 1.4393212795257568
Validation Loss Energy: 6.200383358151758, Validation Loss Force: 4.564490814329096, time: 0.10338807106018066
Test Loss Energy: 9.361901300920678, Test Loss Force: 8.722886127390394, time: 10.402201890945435


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.73784002298575, Training Loss Force: 4.623396074125202, time: 1.4858803749084473
Validation Loss Energy: 5.1259532924774724, Validation Loss Force: 4.545041555108888, time: 0.1014096736907959
Test Loss Energy: 8.858691050887376, Test Loss Force: 8.63954542152475, time: 10.392882108688354


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.667964019575923, Training Loss Force: 4.63974278596923, time: 1.483290433883667
Validation Loss Energy: 3.0783752241653124, Validation Loss Force: 4.618777106767999, time: 0.10690999031066895
Test Loss Energy: 7.756899693179051, Test Loss Force: 8.668240824671447, time: 10.50023889541626


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.641030873106855, Training Loss Force: 4.6480373074267165, time: 1.4715065956115723
Validation Loss Energy: 4.462462475650108, Validation Loss Force: 4.555360934007766, time: 0.10247421264648438
Test Loss Energy: 8.267923391884889, Test Loss Force: 8.661849077692414, time: 10.38398814201355


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.682975707781229, Training Loss Force: 4.647285935533847, time: 1.4175748825073242
Validation Loss Energy: 5.4868046756319595, Validation Loss Force: 4.5340201003929, time: 0.10120630264282227
Test Loss Energy: 9.242357585719668, Test Loss Force: 8.663283738497046, time: 10.54066276550293


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.703432937550631, Training Loss Force: 4.656451222643673, time: 1.4265196323394775
Validation Loss Energy: 5.8610219969399076, Validation Loss Force: 4.651314190378406, time: 0.10877776145935059
Test Loss Energy: 9.056588965472995, Test Loss Force: 8.764184548237862, time: 11.282718896865845


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.6980876761138335, Training Loss Force: 4.617449189387609, time: 1.4404237270355225
Validation Loss Energy: 2.664648046276802, Validation Loss Force: 4.549002171207505, time: 0.10167455673217773
Test Loss Energy: 7.7549346554533445, Test Loss Force: 8.653434772067985, time: 10.420191764831543


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.57101967720251, Training Loss Force: 4.630152435431287, time: 1.4889123439788818
Validation Loss Energy: 3.647742679663271, Validation Loss Force: 4.599214286283368, time: 0.1014862060546875
Test Loss Energy: 8.024207164241227, Test Loss Force: 8.578452739514498, time: 10.5952627658844


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.430881135899862, Training Loss Force: 5.544472613264273, time: 1.4346330165863037
Validation Loss Energy: 2.599734868848495, Validation Loss Force: 6.052929623026918, time: 0.10076498985290527
Test Loss Energy: 7.26158126436281, Test Loss Force: 9.741025487767066, time: 10.444692134857178


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.618044615063843, Training Loss Force: 4.754468710585863, time: 1.4993481636047363
Validation Loss Energy: 3.411667181132036, Validation Loss Force: 4.52001376577575, time: 0.10351753234863281
Test Loss Energy: 7.947266018593441, Test Loss Force: 8.561480426225836, time: 10.66694712638855


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.62500007730362, Training Loss Force: 4.604026611865159, time: 1.484257698059082
Validation Loss Energy: 6.707909134420339, Validation Loss Force: 4.542760309708857, time: 0.11188459396362305
Test Loss Energy: 9.194162068517773, Test Loss Force: 8.594575100191205, time: 10.4465651512146


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.655940898481293, Training Loss Force: 4.597903473724252, time: 1.4403421878814697
Validation Loss Energy: 5.151678704244802, Validation Loss Force: 4.582185886017686, time: 0.10955524444580078
Test Loss Energy: 8.861556026367975, Test Loss Force: 8.64625453848773, time: 10.489996194839478


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.639048640046864, Training Loss Force: 4.607046685462837, time: 1.4981968402862549
Validation Loss Energy: 2.9292023718993363, Validation Loss Force: 4.532377247434245, time: 0.10360002517700195
Test Loss Energy: 7.553273380487225, Test Loss Force: 8.624770029646617, time: 10.600662469863892


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.673256206744356, Training Loss Force: 4.653996690367981, time: 1.5039684772491455
Validation Loss Energy: 4.136909050846386, Validation Loss Force: 4.547354642196785, time: 0.10257840156555176
Test Loss Energy: 7.977826573118081, Test Loss Force: 8.625764183263799, time: 10.42942214012146


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.58577722329497, Training Loss Force: 4.5773243960461905, time: 1.673738718032837
Validation Loss Energy: 5.857766351357298, Validation Loss Force: 4.564456745949769, time: 0.11766695976257324
Test Loss Energy: 9.371888504086112, Test Loss Force: 8.61598822899846, time: 11.891674757003784


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.747666680556234, Training Loss Force: 4.605560194130461, time: 1.6014878749847412
Validation Loss Energy: 5.9782121004342645, Validation Loss Force: 4.54740964147583, time: 0.11636471748352051
Test Loss Energy: 8.913817202380821, Test Loss Force: 8.599855226835032, time: 11.693483591079712


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.695425419862203, Training Loss Force: 4.624678332359216, time: 1.5404958724975586
Validation Loss Energy: 1.8302073903790108, Validation Loss Force: 4.554277425943681, time: 0.11707782745361328
Test Loss Energy: 7.260316240141549, Test Loss Force: 8.608440453762194, time: 11.769400596618652


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.696321365085222, Training Loss Force: 4.631830039142459, time: 1.5464458465576172
Validation Loss Energy: 3.0769112858654104, Validation Loss Force: 4.5623113287287556, time: 0.11254096031188965
Test Loss Energy: 7.830559486033039, Test Loss Force: 8.612508239005198, time: 11.708389520645142


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.674576716185632, Training Loss Force: 4.617031979236899, time: 1.623020887374878
Validation Loss Energy: 6.412111210256093, Validation Loss Force: 4.524621903750726, time: 0.11261796951293945
Test Loss Energy: 9.330937442443059, Test Loss Force: 8.606700248920292, time: 11.689867496490479


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.734409778455522, Training Loss Force: 4.588309708926073, time: 1.5556604862213135
Validation Loss Energy: 5.276495448656331, Validation Loss Force: 4.585161636483864, time: 0.12104463577270508
Test Loss Energy: 9.069990020066319, Test Loss Force: 8.55985255388773, time: 11.78316044807434

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–ƒâ–„â–ˆâ–‡â–ƒâ–„â–â–ƒâ–‡â–†â–‚â–ƒâ–ˆâ–†â–â–ƒâ–ˆâ–‡
wandb:   test_error_force â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–ˆâ–â–â–‚â–â–â–â–â–â–â–â–
wandb:          test_loss â–†â–†â–‚â–ƒâ–ˆâ–†â–ƒâ–ƒâ–ˆâ–„â–†â–†â–â–ƒâ–ˆâ–„â–â–ƒâ–†â–†
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ƒâ–â–â–‚â–‚â–‚â–â–â–ˆâ–‚â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–â–â–„â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‡â–†â–ƒâ–…â–†â–‡â–‚â–„â–‚â–ƒâ–ˆâ–†â–ƒâ–„â–‡â–‡â–â–ƒâ–ˆâ–†
wandb:  valid_error_force â–â–â–â–â–â–‚â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–‡â–…â–‚â–„â–†â–†â–‚â–ƒâ–„â–‚â–ˆâ–…â–‚â–ƒâ–†â–†â–â–‚â–‡â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2960
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.06999
wandb:   test_error_force 8.55985
wandb:          test_loss 5.4792
wandb: train_error_energy 4.73441
wandb:  train_error_force 4.58831
wandb:         train_loss 1.94602
wandb: valid_error_energy 5.2765
wandb:  valid_error_force 4.58516
wandb:         valid_loss 2.07456
wandb: 
wandb: ğŸš€ View run al_72_51 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6puirqhf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_150309-6puirqhf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.316197395324707, Uncertainty Bias: -0.18195992708206177
0.00026512146 0.27485275
2.5572112 6.583661
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1538 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1506 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1371 steps.
Found uncertainty sample 9 after 1927 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2306 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1000 steps.
Found uncertainty sample 17 after 2085 steps.
Found uncertainty sample 18 after 3569 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1178 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2841 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2997 steps.
Found uncertainty sample 29 after 3281 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3968 steps.
Found uncertainty sample 32 after 1126 steps.
Found uncertainty sample 33 after 2273 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 633 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 847 steps.
Found uncertainty sample 39 after 684 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1648 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3150 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 524 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2536 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1060 steps.
Found uncertainty sample 56 after 3164 steps.
Found uncertainty sample 57 after 2940 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1003 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2976 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2192 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1966 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2803 steps.
Found uncertainty sample 71 after 2678 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2947 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 334 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 343 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3615 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3395 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 553 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 905 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_153930-17126whg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_52
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/17126whg
Training model 52. Added 38 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.255962746514608, Training Loss Force: 4.934124424941141, time: 1.5316178798675537
Validation Loss Energy: 7.780644242555821, Validation Loss Force: 4.540547201067481, time: 0.1075594425201416
Test Loss Energy: 9.885143347634145, Test Loss Force: 8.563246885042426, time: 10.252736806869507


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.64165389793855, Training Loss Force: 4.623533035466533, time: 1.497664451599121
Validation Loss Energy: 2.321353791275002, Validation Loss Force: 4.521252696903693, time: 0.1017303466796875
Test Loss Energy: 7.403118435460869, Test Loss Force: 8.530421531157767, time: 10.288803815841675


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.601158405858822, Training Loss Force: 4.589611655677024, time: 1.4921238422393799
Validation Loss Energy: 6.000370797822123, Validation Loss Force: 4.55545690440966, time: 0.10084247589111328
Test Loss Energy: 9.527000353420966, Test Loss Force: 8.591229667647278, time: 10.452752590179443


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.698092612201282, Training Loss Force: 4.604255245701611, time: 1.4556396007537842
Validation Loss Energy: 2.56536733352399, Validation Loss Force: 4.518370690147949, time: 0.10188794136047363
Test Loss Energy: 7.371503870122041, Test Loss Force: 8.532414510946769, time: 10.289552927017212


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.688368594931328, Training Loss Force: 4.609680020400457, time: 1.5021939277648926
Validation Loss Energy: 6.706520124288041, Validation Loss Force: 4.575052902597035, time: 0.10212182998657227
Test Loss Energy: 9.699790207029245, Test Loss Force: 8.657445619294826, time: 10.421962976455688


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.6860468865204865, Training Loss Force: 4.630780172356781, time: 1.5068552494049072
Validation Loss Energy: 2.0706848909233786, Validation Loss Force: 4.503636672761907, time: 0.10282659530639648
Test Loss Energy: 7.367097410937117, Test Loss Force: 8.548768177068009, time: 10.37809133529663


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.597342694075736, Training Loss Force: 4.606438384023475, time: 1.5001862049102783
Validation Loss Energy: 6.0690466384783175, Validation Loss Force: 4.580855437870767, time: 0.1031181812286377
Test Loss Energy: 9.450480910492972, Test Loss Force: 8.591772173624864, time: 10.399911642074585


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.722326638143241, Training Loss Force: 4.642971293883404, time: 1.4908199310302734
Validation Loss Energy: 3.3283322512574047, Validation Loss Force: 4.608504933728058, time: 0.1048581600189209
Test Loss Energy: 7.703155466042674, Test Loss Force: 8.671261104303582, time: 10.798698902130127


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.730197945075375, Training Loss Force: 4.622048007555927, time: 1.467592477798462
Validation Loss Energy: 6.381676568721536, Validation Loss Force: 4.619696062333244, time: 0.10562276840209961
Test Loss Energy: 9.059418281247648, Test Loss Force: 8.64200533967857, time: 10.45186185836792


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.684239019142955, Training Loss Force: 4.619709730428689, time: 1.4767768383026123
Validation Loss Energy: 2.2762441396780755, Validation Loss Force: 4.490312151069588, time: 0.10653233528137207
Test Loss Energy: 7.518680119853617, Test Loss Force: 8.540435328713553, time: 10.542862176895142


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.71897770129495, Training Loss Force: 4.584936352159883, time: 1.5060429573059082
Validation Loss Energy: 5.635534750301257, Validation Loss Force: 4.636885007053139, time: 0.11046171188354492
Test Loss Energy: 9.161478537391963, Test Loss Force: 8.613062841396701, time: 10.350907564163208


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.4716954221757454, Training Loss Force: 5.1083500883933235, time: 1.4760334491729736
Validation Loss Energy: 2.663241667951122, Validation Loss Force: 6.737146038618949, time: 0.10284662246704102
Test Loss Energy: 7.519106271293098, Test Loss Force: 10.12743412668046, time: 10.411370277404785


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.446807222708896, Training Loss Force: 5.412280941523244, time: 1.4740087985992432
Validation Loss Energy: 5.335146947032003, Validation Loss Force: 4.599707053103305, time: 0.10247015953063965
Test Loss Energy: 8.98302733590396, Test Loss Force: 8.65215686101563, time: 10.584173917770386


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.636078059990347, Training Loss Force: 4.604090110472878, time: 1.5037434101104736
Validation Loss Energy: 3.1819904145127547, Validation Loss Force: 4.477381531096416, time: 0.10654711723327637
Test Loss Energy: 7.604078717644628, Test Loss Force: 8.5719228070946, time: 10.420814990997314


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.619471521818961, Training Loss Force: 4.595572219717385, time: 1.482832908630371
Validation Loss Energy: 6.272144502493928, Validation Loss Force: 4.503404428842705, time: 0.10635089874267578
Test Loss Energy: 9.260741933829804, Test Loss Force: 8.619393066406262, time: 10.559488773345947


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.708095571137332, Training Loss Force: 4.5858064342164155, time: 1.4668893814086914
Validation Loss Energy: 4.447517145244581, Validation Loss Force: 4.528114246635457, time: 0.10507035255432129
Test Loss Energy: 8.021546540746238, Test Loss Force: 8.560769190662759, time: 10.380504846572876


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.644344636635583, Training Loss Force: 4.588564954348998, time: 1.4759604930877686
Validation Loss Energy: 5.139838495079237, Validation Loss Force: 4.581074766979507, time: 0.10279440879821777
Test Loss Energy: 8.712695367319753, Test Loss Force: 8.542213557518089, time: 11.205055475234985


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.700103849942487, Training Loss Force: 4.613634970279957, time: 1.477036476135254
Validation Loss Energy: 3.3200637665270953, Validation Loss Force: 4.570284220167846, time: 0.10491633415222168
Test Loss Energy: 7.837082083194997, Test Loss Force: 8.594356446084747, time: 10.46108078956604


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.603390038678083, Training Loss Force: 4.600818735920813, time: 1.4841601848602295
Validation Loss Energy: 6.213415960593766, Validation Loss Force: 4.557194837093626, time: 0.10665011405944824
Test Loss Energy: 9.123669395688303, Test Loss Force: 8.599442713006383, time: 10.297638893127441


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.653510395115256, Training Loss Force: 4.6342918306055125, time: 1.53873872756958
Validation Loss Energy: 4.765123062891849, Validation Loss Force: 4.52679025589377, time: 0.10521340370178223
Test Loss Energy: 8.245284668782308, Test Loss Force: 8.551621914168676, time: 10.50976824760437

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–â–‡â–â–‡â–â–‡â–‚â–†â–â–†â–â–…â–‚â–†â–ƒâ–…â–‚â–†â–ƒ
wandb:   test_error_force â–â–â–â–â–‚â–â–â–‚â–â–â–â–ˆâ–‚â–â–â–â–â–â–â–
wandb:          test_loss â–‡â–‚â–‡â–â–…â–‚â–†â–‚â–„â–â–…â–ˆâ–†â–‚â–…â–‚â–„â–ƒâ–„â–‚
wandb: train_error_energy â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒ
wandb:  train_error_force â–„â–â–â–â–â–â–â–â–â–â–â–…â–ˆâ–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–â–‚â–‚â–â–â–„â–ˆâ–â–â–â–â–‚â–â–
wandb: valid_error_energy â–ˆâ–â–†â–‚â–‡â–â–†â–ƒâ–†â–â–…â–‚â–…â–‚â–†â–„â–…â–ƒâ–†â–„
wandb:  valid_error_force â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–
wandb:         valid_loss â–ˆâ–â–…â–â–†â–â–…â–‚â–…â–â–…â–„â–„â–‚â–…â–ƒâ–„â–‚â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2994
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.24528
wandb:   test_error_force 8.55162
wandb:          test_loss 4.95245
wandb: train_error_energy 4.65351
wandb:  train_error_force 4.63429
wandb:         train_loss 1.9542
wandb: valid_error_energy 4.76512
wandb:  valid_error_force 4.52679
wandb:         valid_loss 1.93097
wandb: 
wandb: ğŸš€ View run al_72_52 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/17126whg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_153930-17126whg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.480682373046875, Uncertainty Bias: -0.24380174279212952
6.1035156e-05 0.075302124
2.4315345 6.7178717
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 974 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3906 steps.
Found uncertainty sample 10 after 2575 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1958 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 32 steps.
Found uncertainty sample 16 after 108 steps.
Found uncertainty sample 17 after 725 steps.
Found uncertainty sample 18 after 2460 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1629 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3323 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 998 steps.
Found uncertainty sample 27 after 3540 steps.
Found uncertainty sample 28 after 1237 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 916 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2573 steps.
Found uncertainty sample 35 after 3011 steps.
Found uncertainty sample 36 after 2 steps.
Found uncertainty sample 37 after 2981 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1744 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1367 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1726 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1247 steps.
Found uncertainty sample 53 after 1093 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2677 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 340 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2467 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 381 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3769 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3404 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2105 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2363 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1970 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2020 steps.
Found uncertainty sample 87 after 2030 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 160 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1231 steps.
Found uncertainty sample 94 after 782 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2151 steps.
Found uncertainty sample 99 after 3414 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_161516-6jhozlwx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_53
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6jhozlwx
Training model 53. Added 39 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.830028962554912, Training Loss Force: 4.90330685880257, time: 1.4954566955566406
Validation Loss Energy: 2.1385541125984497, Validation Loss Force: 5.090084187767403, time: 0.10587263107299805
Test Loss Energy: 7.103305132577794, Test Loss Force: 9.100013841689865, time: 10.467254161834717


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.8922337539013614, Training Loss Force: 4.9100069968423945, time: 1.462047815322876
Validation Loss Energy: 2.3279244237676124, Validation Loss Force: 4.498477205981614, time: 0.1064763069152832
Test Loss Energy: 7.28625591092277, Test Loss Force: 8.61307413107214, time: 10.337003469467163


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.2224610157975366, Training Loss Force: 4.571675597624747, time: 1.4609673023223877
Validation Loss Energy: 2.950619247027536, Validation Loss Force: 4.488941622476403, time: 0.10360908508300781
Test Loss Energy: 7.7594872019192955, Test Loss Force: 8.5617261970042, time: 10.614265203475952


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.172588352802985, Training Loss Force: 4.578024335625669, time: 1.5346219539642334
Validation Loss Energy: 4.19657035379884, Validation Loss Force: 4.482958502525324, time: 0.10669231414794922
Test Loss Energy: 8.366231794164253, Test Loss Force: 8.596435760880404, time: 10.417259216308594


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1364988173578756, Training Loss Force: 4.575905814493597, time: 1.4758427143096924
Validation Loss Energy: 2.9998103127347457, Validation Loss Force: 4.489289209013196, time: 0.10303974151611328
Test Loss Energy: 7.564389131506186, Test Loss Force: 8.646348026886423, time: 10.496539115905762


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.213967956342188, Training Loss Force: 4.575074194455158, time: 1.454383134841919
Validation Loss Energy: 2.014806736760238, Validation Loss Force: 4.500177062241628, time: 0.10425043106079102
Test Loss Energy: 7.162517367821647, Test Loss Force: 8.63454775127544, time: 10.575814247131348


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.228391166274629, Training Loss Force: 4.579456393563588, time: 1.6120028495788574
Validation Loss Energy: 3.9501061149297705, Validation Loss Force: 4.483120605663558, time: 0.11843252182006836
Test Loss Energy: 8.129102555868968, Test Loss Force: 8.624873427405207, time: 11.008076667785645


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1965421748589686, Training Loss Force: 4.569508122094972, time: 1.5481674671173096
Validation Loss Energy: 2.2751729897515895, Validation Loss Force: 4.507851577025175, time: 0.11369156837463379
Test Loss Energy: 7.291444796843887, Test Loss Force: 8.590444039604932, time: 11.575315713882446


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.2518595707644335, Training Loss Force: 4.5864495970138535, time: 1.6098761558532715
Validation Loss Energy: 2.7448856483315778, Validation Loss Force: 4.533425573773273, time: 0.11430001258850098
Test Loss Energy: 7.396302061917972, Test Loss Force: 8.596451769742771, time: 11.619288921356201


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1989870352035417, Training Loss Force: 4.580197769313013, time: 1.5329885482788086
Validation Loss Energy: 4.572604209999267, Validation Loss Force: 4.493137154523975, time: 0.10758423805236816
Test Loss Energy: 8.146031962795082, Test Loss Force: 8.627878971236274, time: 11.486337184906006


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.2299309128712332, Training Loss Force: 4.57258646444028, time: 1.6348648071289062
Validation Loss Energy: 3.287305015781918, Validation Loss Force: 4.499956842456305, time: 0.14248085021972656
Test Loss Energy: 7.512546941882709, Test Loss Force: 8.606427137635066, time: 11.440658330917358


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.160642437906078, Training Loss Force: 4.571565913147348, time: 1.586930513381958
Validation Loss Energy: 2.079165356680612, Validation Loss Force: 4.536282418915526, time: 0.11623239517211914
Test Loss Energy: 7.139508060306661, Test Loss Force: 8.651619904279585, time: 11.540055513381958


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.2065131363135557, Training Loss Force: 4.579467939544776, time: 1.5768797397613525
Validation Loss Energy: 3.7833493028790235, Validation Loss Force: 4.553772857659008, time: 0.12109160423278809
Test Loss Energy: 7.699085111360938, Test Loss Force: 8.562357061829475, time: 11.375560283660889


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.204923243453345, Training Loss Force: 4.579439925422333, time: 1.5466985702514648
Validation Loss Energy: 2.3922061114980675, Validation Loss Force: 4.546402286259653, time: 0.11409115791320801
Test Loss Energy: 7.282836148853154, Test Loss Force: 8.672217266600722, time: 12.22841477394104


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.2251551097171465, Training Loss Force: 4.599784797449635, time: 1.7440862655639648
Validation Loss Energy: 2.6938817217727964, Validation Loss Force: 4.490558423144984, time: 0.1091315746307373
Test Loss Energy: 7.350094527856076, Test Loss Force: 8.61451847740172, time: 11.281080722808838


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.161036453303683, Training Loss Force: 4.571520437076092, time: 1.6762771606445312
Validation Loss Energy: 4.4717865234666885, Validation Loss Force: 4.639201434178226, time: 0.11083674430847168
Test Loss Energy: 8.102773274704338, Test Loss Force: 8.700026292660096, time: 11.251218318939209


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.2125916641339503, Training Loss Force: 4.572914617820348, time: 1.6254994869232178
Validation Loss Energy: 3.175588453898185, Validation Loss Force: 4.4828968231719015, time: 0.11460518836975098
Test Loss Energy: 7.6619267184875435, Test Loss Force: 8.578764471655568, time: 11.435286283493042


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.2126579773494943, Training Loss Force: 4.572232729891173, time: 1.572744369506836
Validation Loss Energy: 2.235095883521777, Validation Loss Force: 4.5413973518666335, time: 0.11733555793762207
Test Loss Energy: 7.214247761212572, Test Loss Force: 8.589559947499422, time: 11.547686576843262


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.168313160282486, Training Loss Force: 4.596225686635526, time: 1.5471413135528564
Validation Loss Energy: 3.665137148004858, Validation Loss Force: 4.53110179856637, time: 0.11534500122070312
Test Loss Energy: 7.700661130933219, Test Loss Force: 8.593286323817175, time: 11.573841333389282


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.196740917619195, Training Loss Force: 4.603675680603406, time: 1.646918535232544
Validation Loss Energy: 2.627486013170903, Validation Loss Force: 4.491207503705365, time: 0.1262056827545166
Test Loss Energy: 7.487396573767641, Test Loss Force: 8.641468145117889, time: 11.360629796981812

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–…â–ˆâ–„â–â–‡â–‚â–ƒâ–‡â–ƒâ–â–„â–‚â–‚â–‡â–„â–‚â–„â–ƒ
wandb:   test_error_force â–ˆâ–‚â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–â–â–‚
wandb:          test_loss â–ˆâ–†â–ƒâ–†â–„â–‚â–ˆâ–„â–‚â–„â–‚â–ƒâ–‡â–ƒâ–â–…â–ƒâ–‚â–‡â–„
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–„â–‡â–„â–â–†â–‚â–ƒâ–ˆâ–„â–â–†â–‚â–ƒâ–ˆâ–„â–‚â–†â–ƒ
wandb:  valid_error_force â–ˆâ–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–ƒâ–â–‚â–‚â–
wandb:         valid_loss â–‚â–‚â–ƒâ–†â–ƒâ–â–†â–â–‚â–‡â–„â–â–†â–‚â–‚â–ˆâ–ƒâ–â–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3029
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.4874
wandb:   test_error_force 8.64147
wandb:          test_loss 5.73535
wandb: train_error_energy 3.19674
wandb:  train_error_force 4.60368
wandb:         train_loss 1.57682
wandb: valid_error_energy 2.62749
wandb:  valid_error_force 4.49121
wandb:         valid_loss 1.37883
wandb: 
wandb: ğŸš€ View run al_72_53 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6jhozlwx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_161516-6jhozlwx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4331765174865723, Uncertainty Bias: -0.09558787941932678
6.1035156e-05 0.00037050247
2.5473106 6.768085
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1847 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2713 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1744 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 917 steps.
Found uncertainty sample 22 after 2855 steps.
Found uncertainty sample 23 after 1896 steps.
Found uncertainty sample 24 after 2600 steps.
Found uncertainty sample 25 after 2453 steps.
Found uncertainty sample 26 after 1118 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1001 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 302 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1245 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1548 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2836 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2266 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1633 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3200 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3321 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2287 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2973 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3579 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3628 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3871 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 41 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3502 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2675 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1315 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_165446-delu030f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_54
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/delu030f
Training model 54. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.907156089628733, Training Loss Force: 4.81127474578549, time: 1.7348260879516602
Validation Loss Energy: 1.9902512286856135, Validation Loss Force: 4.500188863706361, time: 0.1089942455291748
Test Loss Energy: 7.219290697417893, Test Loss Force: 8.596526992276655, time: 9.621551513671875


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1809320286311653, Training Loss Force: 4.563065970700596, time: 1.6062242984771729
Validation Loss Energy: 2.161600257867403, Validation Loss Force: 4.496988217402796, time: 0.09822511672973633
Test Loss Energy: 7.164946224212516, Test Loss Force: 8.546989192820506, time: 9.581218242645264


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1404837422129717, Training Loss Force: 4.5730101729638175, time: 1.5741560459136963
Validation Loss Energy: 1.99799521624269, Validation Loss Force: 4.50129842406052, time: 0.10113835334777832
Test Loss Energy: 7.1316021351559495, Test Loss Force: 8.59571590767164, time: 9.828026056289673


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.205821454604282, Training Loss Force: 4.5813594773162185, time: 1.597832441329956
Validation Loss Energy: 2.0882833242026355, Validation Loss Force: 4.4810987698185345, time: 0.09902667999267578
Test Loss Energy: 7.117608090476687, Test Loss Force: 8.501602687697734, time: 9.637985467910767


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.192252263590523, Training Loss Force: 4.582463285384105, time: 1.498812198638916
Validation Loss Energy: 2.0651102575205034, Validation Loss Force: 4.533387942687611, time: 0.10069966316223145
Test Loss Energy: 7.1569032701015285, Test Loss Force: 8.60784737507492, time: 9.608675956726074


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.2071645728575504, Training Loss Force: 4.584112725638328, time: 1.7053987979888916
Validation Loss Energy: 1.9857166828633672, Validation Loss Force: 4.579807779539177, time: 0.0998389720916748
Test Loss Energy: 6.945641562447414, Test Loss Force: 8.681122404971198, time: 9.554432153701782


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1666355479987254, Training Loss Force: 4.567552811977798, time: 1.5686335563659668
Validation Loss Energy: 2.1209965391074705, Validation Loss Force: 4.546431455917769, time: 0.10187840461730957
Test Loss Energy: 7.238800375754107, Test Loss Force: 8.596666301555512, time: 9.690298080444336


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.191908973872405, Training Loss Force: 4.587608343615082, time: 1.5004544258117676
Validation Loss Energy: 2.181586149729297, Validation Loss Force: 4.587890892205501, time: 0.09922647476196289
Test Loss Energy: 7.07323093876337, Test Loss Force: 8.648690697493938, time: 9.807618141174316


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.2148582534239387, Training Loss Force: 4.592817623338894, time: 1.5026967525482178
Validation Loss Energy: 2.0896796824167487, Validation Loss Force: 4.519809800838081, time: 0.1009528636932373
Test Loss Energy: 7.113808321942116, Test Loss Force: 8.627750415361614, time: 9.58623719215393


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.192737615064008, Training Loss Force: 4.584487334003768, time: 1.5977802276611328
Validation Loss Energy: 2.2771318102283162, Validation Loss Force: 4.517879704681178, time: 0.09992218017578125
Test Loss Energy: 7.167645897580343, Test Loss Force: 8.549651774871332, time: 9.731236457824707


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.244428295019295, Training Loss Force: 4.572657117116127, time: 1.730705976486206
Validation Loss Energy: 2.170323989666562, Validation Loss Force: 4.528239386695469, time: 0.11161231994628906
Test Loss Energy: 7.14885939033975, Test Loss Force: 8.669762907014901, time: 12.616334915161133


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.236395802472144, Training Loss Force: 4.605364746736552, time: 1.7374062538146973
Validation Loss Energy: 2.136469484054274, Validation Loss Force: 4.497877557971631, time: 0.11532092094421387
Test Loss Energy: 7.141402074735466, Test Loss Force: 8.556201493368429, time: 10.988037824630737


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.2133721746205737, Training Loss Force: 4.578011540011562, time: 1.6073508262634277
Validation Loss Energy: 2.096073292938346, Validation Loss Force: 4.576564826097885, time: 0.11161303520202637
Test Loss Energy: 7.021842945233686, Test Loss Force: 8.658236735956747, time: 10.500448226928711


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1616957536087718, Training Loss Force: 4.578590827711515, time: 1.5538396835327148
Validation Loss Energy: 2.174565502892767, Validation Loss Force: 4.485381365502164, time: 0.10539793968200684
Test Loss Energy: 7.023134326020663, Test Loss Force: 8.565943737157202, time: 10.509157180786133


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1757962575591514, Training Loss Force: 4.60358253536513, time: 1.5253260135650635
Validation Loss Energy: 2.029663890183978, Validation Loss Force: 4.519136004002503, time: 0.10323071479797363
Test Loss Energy: 6.955698814295061, Test Loss Force: 8.619359962149366, time: 10.279479026794434


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.192768600867346, Training Loss Force: 4.579605702650307, time: 1.4968674182891846
Validation Loss Energy: 2.06718364127281, Validation Loss Force: 4.499307093888488, time: 0.10311412811279297
Test Loss Energy: 7.131170627998898, Test Loss Force: 8.62258863212272, time: 10.520211219787598


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.256454497866877, Training Loss Force: 4.587165078929647, time: 1.4713406562805176
Validation Loss Energy: 1.917854586600966, Validation Loss Force: 4.554068784953946, time: 0.10404849052429199
Test Loss Energy: 6.9557990643746255, Test Loss Force: 8.641191014129966, time: 10.3204185962677


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1977063923947213, Training Loss Force: 4.614353598626522, time: 1.485325813293457
Validation Loss Energy: 2.0664707660021224, Validation Loss Force: 4.507681012459393, time: 0.10476112365722656
Test Loss Energy: 7.014657232360314, Test Loss Force: 8.583406645367273, time: 10.429796934127808


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1689881855339337, Training Loss Force: 4.563304688261323, time: 1.504349946975708
Validation Loss Energy: 2.320401212668723, Validation Loss Force: 4.543555015890674, time: 0.10405158996582031
Test Loss Energy: 7.024399326925785, Test Loss Force: 8.517787437704353, time: 10.420512676239014


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.19221204165657, Training Loss Force: 4.565419149832112, time: 1.5270776748657227
Validation Loss Energy: 2.151626906821297, Validation Loss Force: 4.459533485704574, time: 0.10513162612915039
Test Loss Energy: 7.126404025369479, Test Loss Force: 8.537873085343627, time: 10.341541051864624

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–…â–…â–†â–â–ˆâ–„â–…â–†â–†â–†â–ƒâ–ƒâ–â–…â–â–ƒâ–ƒâ–…
wandb:   test_error_force â–…â–ƒâ–…â–â–…â–ˆâ–…â–‡â–†â–ƒâ–ˆâ–ƒâ–‡â–„â–†â–†â–†â–„â–‚â–‚
wandb:          test_loss â–‡â–‡â–†â–ƒâ–‡â–…â–ˆâ–…â–„â–…â–…â–†â–…â–ƒâ–„â–†â–â–„â–ƒâ–„
wandb: train_error_energy â–ˆâ–â–â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–
wandb: valid_error_energy â–‚â–…â–‚â–„â–„â–‚â–…â–†â–„â–‡â–…â–…â–„â–…â–ƒâ–„â–â–„â–ˆâ–…
wandb:  valid_error_force â–ƒâ–ƒâ–ƒâ–‚â–…â–ˆâ–†â–ˆâ–„â–„â–…â–ƒâ–‡â–‚â–„â–ƒâ–†â–„â–†â–
wandb:         valid_loss â–â–…â–â–‚â–ƒâ–ƒâ–ƒâ–‡â–ƒâ–†â–†â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–ƒâ–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3053
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.1264
wandb:   test_error_force 8.53787
wandb:          test_loss 5.44373
wandb: train_error_energy 3.19221
wandb:  train_error_force 4.56542
wandb:         train_loss 1.55202
wandb: valid_error_energy 2.15163
wandb:  valid_error_force 4.45953
wandb:         valid_loss 1.23863
wandb: 
wandb: ğŸš€ View run al_72_54 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/delu030f
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_165446-delu030f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4522705078125, Uncertainty Bias: -0.10276198387145996
0.00030517578 0.01702118
2.5097833 6.701298
(48745, 22, 3)
Found uncertainty sample 0 after 1752 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2975 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2238 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1840 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1705 steps.
Found uncertainty sample 17 after 3310 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3216 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1584 steps.
Found uncertainty sample 23 after 1277 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2640 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2398 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1455 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3697 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3143 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 6 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3330 steps.
Found uncertainty sample 45 after 3727 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 40 steps.
Found uncertainty sample 48 after 497 steps.
Found uncertainty sample 49 after 1760 steps.
Found uncertainty sample 50 after 935 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2760 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1645 steps.
Found uncertainty sample 55 after 2967 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1619 steps.
Found uncertainty sample 58 after 3664 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2410 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2204 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2212 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2200 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1633 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3559 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3269 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2116 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2596 steps.
Found uncertainty sample 95 after 1977 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3374 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_173215-jwujbexa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_55
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jwujbexa
Training model 55. Added 37 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.025936278515694, Training Loss Force: 4.951360403108899, time: 1.5482230186462402
Validation Loss Energy: 6.434348732521609, Validation Loss Force: 5.2663156833119515, time: 0.10618066787719727
Test Loss Energy: 9.735823591439306, Test Loss Force: 9.15867830617151, time: 10.41829514503479


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1005103002592365, Training Loss Force: 5.307766557167577, time: 1.5253264904022217
Validation Loss Energy: 2.757036146951992, Validation Loss Force: 4.7349186612541825, time: 0.10625529289245605
Test Loss Energy: 7.358954353638256, Test Loss Force: 8.74393164925644, time: 10.480550050735474


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.5255988524693285, Training Loss Force: 4.855887315534767, time: 1.5394012928009033
Validation Loss Energy: 2.2293646023747415, Validation Loss Force: 4.515539006619186, time: 0.10311508178710938
Test Loss Energy: 6.832714100683275, Test Loss Force: 8.61741958357431, time: 10.587405681610107


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2582484485735757, Training Loss Force: 4.575068057872307, time: 1.5039045810699463
Validation Loss Energy: 2.007055401121346, Validation Loss Force: 4.49114537901365, time: 0.10442829132080078
Test Loss Energy: 6.979391179816804, Test Loss Force: 8.627629185418439, time: 10.432523488998413


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2215822009466546, Training Loss Force: 4.562137789119539, time: 1.5053095817565918
Validation Loss Energy: 1.8037953783002132, Validation Loss Force: 4.5217456863927765, time: 0.1080169677734375
Test Loss Energy: 6.854091509162617, Test Loss Force: 8.634665311258031, time: 10.629172086715698


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2433973910046507, Training Loss Force: 4.620925726292709, time: 1.5605087280273438
Validation Loss Energy: 2.4584040898983774, Validation Loss Force: 4.550948299542915, time: 0.10692858695983887
Test Loss Energy: 7.248236522913073, Test Loss Force: 8.615063636756148, time: 10.421054363250732


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.229477637956336, Training Loss Force: 4.577663314974818, time: 1.5003480911254883
Validation Loss Energy: 2.4878337142427887, Validation Loss Force: 4.527229582118686, time: 0.1072244644165039
Test Loss Energy: 6.991955310857727, Test Loss Force: 8.62206400962523, time: 10.502947092056274


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.272191767822428, Training Loss Force: 4.577273593467164, time: 1.4763286113739014
Validation Loss Energy: 1.863954513795675, Validation Loss Force: 4.492561332112605, time: 0.10584759712219238
Test Loss Energy: 7.007478409406584, Test Loss Force: 8.65894625545185, time: 11.575031757354736


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.39448292761854, Training Loss Force: 4.857264264804253, time: 1.504103660583496
Validation Loss Energy: 2.7075823316525875, Validation Loss Force: 4.631064212909441, time: 0.10751700401306152
Test Loss Energy: 7.209123873697538, Test Loss Force: 8.660713908054857, time: 10.496540784835815


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.6530121188359406, Training Loss Force: 5.270311315855435, time: 1.5490455627441406
Validation Loss Energy: 2.8473225848933432, Validation Loss Force: 4.933299056744167, time: 0.10900402069091797
Test Loss Energy: 7.276650038579095, Test Loss Force: 8.986532001369174, time: 10.579431056976318


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.606127374058817, Training Loss Force: 4.8150720243572716, time: 1.511136770248413
Validation Loss Energy: 2.5062354264659796, Validation Loss Force: 4.5516356791963934, time: 0.10635709762573242
Test Loss Energy: 7.1627872568161965, Test Loss Force: 8.68521056385815, time: 10.51162338256836


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2287549032631553, Training Loss Force: 4.565360697746583, time: 1.6116411685943604
Validation Loss Energy: 1.9506209080971049, Validation Loss Force: 4.492079253411672, time: 0.1045989990234375
Test Loss Energy: 6.973277974452221, Test Loss Force: 8.62427714041694, time: 10.449282169342041


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.197239013641568, Training Loss Force: 4.571033302130329, time: 1.496295690536499
Validation Loss Energy: 1.9010639413158488, Validation Loss Force: 4.489840315149367, time: 0.10620689392089844
Test Loss Energy: 7.0028292245313, Test Loss Force: 8.612959387679375, time: 10.652283191680908


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2599154278489704, Training Loss Force: 4.568885008574883, time: 1.54172945022583
Validation Loss Energy: 2.6658529090254173, Validation Loss Force: 4.5205072006031255, time: 0.10874557495117188
Test Loss Energy: 7.273619359948103, Test Loss Force: 8.66032209895936, time: 10.497739553451538


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.283375929408459, Training Loss Force: 4.582738913536075, time: 1.5288939476013184
Validation Loss Energy: 2.08435321377701, Validation Loss Force: 4.556674459299593, time: 0.10544991493225098
Test Loss Energy: 6.909553788475396, Test Loss Force: 8.730139825467507, time: 10.580642938613892


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2747403080199, Training Loss Force: 4.582262497977235, time: 1.5276143550872803
Validation Loss Energy: 2.0468547275916142, Validation Loss Force: 4.518786858781688, time: 0.1062157154083252
Test Loss Energy: 7.0823677789527695, Test Loss Force: 8.688525736714373, time: 10.493087530136108


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.260721111390125, Training Loss Force: 4.575709886764315, time: 1.5377006530761719
Validation Loss Energy: 1.7916106999658985, Validation Loss Force: 4.53217461851145, time: 0.10733509063720703
Test Loss Energy: 7.034328395957027, Test Loss Force: 8.678851571393901, time: 10.474282264709473


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2453818103987055, Training Loss Force: 4.591471336318601, time: 1.5033247470855713
Validation Loss Energy: 2.458822039885284, Validation Loss Force: 4.546748314112424, time: 0.11374163627624512
Test Loss Energy: 7.172270987555584, Test Loss Force: 8.65876297193119, time: 10.697010278701782


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2392624192258763, Training Loss Force: 4.582122101637389, time: 1.5669076442718506
Validation Loss Energy: 2.4600591896600585, Validation Loss Force: 4.499503933413488, time: 0.11889052391052246
Test Loss Energy: 7.096334900484094, Test Loss Force: 8.62714581383749, time: 10.354047060012817


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2648395057953192, Training Loss Force: 4.581064836394709, time: 1.5209615230560303
Validation Loss Energy: 1.9352963721360625, Validation Loss Force: 4.520759484745462, time: 0.10895323753356934
Test Loss Energy: 6.956256736905034, Test Loss Force: 8.639648856589165, time: 10.644351482391357

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–
wandb:   test_error_force â–ˆâ–ƒâ–â–â–â–â–â–‚â–‚â–†â–‚â–â–â–‚â–ƒâ–‚â–‚â–‚â–â–
wandb:          test_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚
wandb: train_error_energy â–ˆâ–„â–‚â–â–â–â–â–â–‚â–ƒâ–ƒâ–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–…â–ˆâ–„â–â–â–‚â–â–â–„â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–†â–ƒâ–â–â–â–â–â–‚â–…â–ƒâ–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–‚â–ƒâ–‚â–â–â–‚â–â–â–â–‚â–‚â–
wandb:  valid_error_force â–ˆâ–ƒâ–â–â–â–‚â–â–â–‚â–…â–‚â–â–â–â–‚â–â–â–‚â–â–
wandb:         valid_loss â–ˆâ–‚â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3086
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.95626
wandb:   test_error_force 8.63965
wandb:          test_loss 6.53763
wandb: train_error_energy 2.26484
wandb:  train_error_force 4.58106
wandb:         train_loss 1.22494
wandb: valid_error_energy 1.9353
wandb:  valid_error_force 4.52076
wandb:         valid_loss 1.13157
wandb: 
wandb: ğŸš€ View run al_72_55 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jwujbexa
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_173215-jwujbexa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4437496662139893, Uncertainty Bias: 0.011264264583587646
0.0004043579 0.0050468445
2.6741853 7.00427
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2637 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3129 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 204 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1765 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 498 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1712 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1669 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3738 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3806 steps.
Found uncertainty sample 35 after 15 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2322 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3887 steps.
Found uncertainty sample 42 after 1384 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1875 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 758 steps.
Found uncertainty sample 53 after 1028 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 673 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1199 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1474 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1943 steps.
Found uncertainty sample 65 after 631 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3537 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3799 steps.
Found uncertainty sample 70 after 3227 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 13 steps.
Found uncertainty sample 73 after 1470 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 256 steps.
Found uncertainty sample 80 after 3152 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1916 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2482 steps.
Found uncertainty sample 89 after 3556 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2677 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2345 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_180937-fm6o1tdu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_56
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/fm6o1tdu
Training model 56. Added 33 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.8677256469816, Training Loss Force: 5.406147762581926, time: 1.5080080032348633
Validation Loss Energy: 3.0114768399664866, Validation Loss Force: 4.544428546950149, time: 0.11194658279418945
Test Loss Energy: 7.2676945210229045, Test Loss Force: 8.546839727030656, time: 10.367982864379883


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1448721313497616, Training Loss Force: 4.589624017053623, time: 1.557805061340332
Validation Loss Energy: 3.7216041507244046, Validation Loss Force: 4.523411474273463, time: 0.1080174446105957
Test Loss Energy: 7.852573355211479, Test Loss Force: 8.553052891023045, time: 10.344021081924438


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1960123314258513, Training Loss Force: 4.5532220469002755, time: 1.5632789134979248
Validation Loss Energy: 3.3172596939724266, Validation Loss Force: 4.50351843544542, time: 0.10875654220581055
Test Loss Energy: 7.484871116273267, Test Loss Force: 8.582617631821266, time: 10.454035997390747


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.1842929997966474, Training Loss Force: 4.576821072842165, time: 1.5364174842834473
Validation Loss Energy: 2.9030022295128894, Validation Loss Force: 4.5356277716264986, time: 0.1049962043762207
Test Loss Energy: 7.369763644295616, Test Loss Force: 8.61286106351305, time: 10.316007375717163


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.2272140249975796, Training Loss Force: 4.5766808140015725, time: 1.5430967807769775
Validation Loss Energy: 3.653648310751568, Validation Loss Force: 4.497264772482038, time: 0.10633587837219238
Test Loss Energy: 7.760960891612243, Test Loss Force: 8.585571521073705, time: 10.512891292572021


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.160807823680218, Training Loss Force: 4.5692993681682115, time: 1.5109477043151855
Validation Loss Energy: 3.262927754358609, Validation Loss Force: 4.511926199726507, time: 0.11234450340270996
Test Loss Energy: 7.484572986768818, Test Loss Force: 8.556629176678367, time: 10.335611581802368


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1734929304707973, Training Loss Force: 4.572416272695836, time: 1.4984917640686035
Validation Loss Energy: 2.8801938948917867, Validation Loss Force: 4.50012495766148, time: 0.9633111953735352
Test Loss Energy: 7.369776545116394, Test Loss Force: 8.569365674622766, time: 10.416611433029175


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.184753643184085, Training Loss Force: 4.554425510014259, time: 1.4868710041046143
Validation Loss Energy: 3.5024096454842466, Validation Loss Force: 4.50766809764893, time: 0.11035656929016113
Test Loss Energy: 7.731897272973058, Test Loss Force: 8.574281687083294, time: 10.516704320907593


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.222748748592857, Training Loss Force: 4.563684143088888, time: 1.5327796936035156
Validation Loss Energy: 3.2662540973950507, Validation Loss Force: 4.4839264453026715, time: 0.11190223693847656
Test Loss Energy: 7.460003782793009, Test Loss Force: 8.544443149505302, time: 10.347175598144531


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.172792748477494, Training Loss Force: 4.590020077300205, time: 1.5407423973083496
Validation Loss Energy: 2.8178679102700155, Validation Loss Force: 4.488840530684152, time: 0.10724925994873047
Test Loss Energy: 7.420798787669686, Test Loss Force: 8.585740306617934, time: 10.494135856628418


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1926452331193014, Training Loss Force: 4.559775999656148, time: 1.5556302070617676
Validation Loss Energy: 3.37597476438926, Validation Loss Force: 4.518608055457508, time: 0.10750269889831543
Test Loss Energy: 7.702417566140824, Test Loss Force: 8.589820244233591, time: 10.459308862686157


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.101922771500011, Training Loss Force: 5.217351856012428, time: 1.5471556186676025
Validation Loss Energy: 6.410505988383099, Validation Loss Force: 5.211323084342165, time: 0.10696268081665039
Test Loss Energy: 9.15625365134924, Test Loss Force: 9.0844159962564, time: 10.385571479797363


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.004280779690405, Training Loss Force: 5.341704935098112, time: 1.5423593521118164
Validation Loss Energy: 6.075069393537372, Validation Loss Force: 6.454882390482485, time: 0.11072468757629395
Test Loss Energy: 8.884113413444517, Test Loss Force: 9.783580765191628, time: 10.552260875701904


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1130298674960826, Training Loss Force: 5.45900908154933, time: 1.5302326679229736
Validation Loss Energy: 3.268960195525511, Validation Loss Force: 4.587027826595886, time: 0.10895204544067383
Test Loss Energy: 7.5547981581765695, Test Loss Force: 8.59705239819648, time: 10.37880539894104


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.184466130737942, Training Loss Force: 4.559803169836219, time: 1.532273530960083
Validation Loss Energy: 3.476379510990715, Validation Loss Force: 4.479657877775235, time: 0.10885000228881836
Test Loss Energy: 7.706207625834309, Test Loss Force: 8.568419356400327, time: 10.555296182632446


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.171446694177221, Training Loss Force: 4.540302642181228, time: 1.5717849731445312
Validation Loss Energy: 2.7153924519460046, Validation Loss Force: 4.584308145647523, time: 0.10644102096557617
Test Loss Energy: 7.312622427964473, Test Loss Force: 8.63844457790988, time: 10.43945050239563


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1685917621719146, Training Loss Force: 4.566482553485274, time: 1.50128173828125
Validation Loss Energy: 3.439883703969432, Validation Loss Force: 4.513053796281485, time: 0.10895848274230957
Test Loss Energy: 7.623330622053121, Test Loss Force: 8.532930445850148, time: 10.45341682434082


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.130483474945122, Training Loss Force: 4.544808029706029, time: 1.5365877151489258
Validation Loss Energy: 3.1003962006864136, Validation Loss Force: 4.496118026380509, time: 0.10935211181640625
Test Loss Energy: 7.259209283034524, Test Loss Force: 8.571906210665484, time: 10.639805316925049


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1842395762426308, Training Loss Force: 4.53248913640794, time: 1.542693853378296
Validation Loss Energy: 2.8899749711303837, Validation Loss Force: 4.470704128748333, time: 0.1082761287689209
Test Loss Energy: 7.099300837186554, Test Loss Force: 8.519221496952552, time: 10.37900996208191


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.173249358826829, Training Loss Force: 4.619526561126241, time: 1.5663630962371826
Validation Loss Energy: 3.7692760561835223, Validation Loss Force: 4.762091645139188, time: 0.10973381996154785
Test Loss Energy: 7.990342062025786, Test Loss Force: 8.779703636410481, time: 10.513181447982788

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ˆâ–‡â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–„
wandb:   test_error_force â–â–â–â–‚â–â–â–â–â–â–â–â–„â–ˆâ–â–â–‚â–â–â–â–‚
wandb:          test_loss â–â–ƒâ–â–â–‚â–â–â–‚â–â–â–‚â–ˆâ–‡â–‚â–‚â–â–‚â–â–â–„
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–â–â–â–â–â–â–â–â–â–â–†â–‡â–ˆâ–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–‚â–„â–ƒâ–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–‚â–â–ƒâ–‚â–â–‚â–‚â–â–‚â–ˆâ–‡â–‚â–‚â–â–‚â–‚â–â–ƒ
wandb:  valid_error_force â–â–â–â–â–â–â–â–â–â–â–â–„â–ˆâ–â–â–â–â–â–â–‚
wandb:         valid_loss â–â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–ˆâ–ˆâ–‚â–â–â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3115
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.99034
wandb:   test_error_force 8.7797
wandb:          test_loss 6.72893
wandb: train_error_energy 3.17325
wandb:  train_error_force 4.61953
wandb:         train_loss 1.57197
wandb: valid_error_energy 3.76928
wandb:  valid_error_force 4.76209
wandb:         valid_loss 1.98031
wandb: 
wandb: ğŸš€ View run al_72_56 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/fm6o1tdu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_180937-fm6o1tdu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5358023643493652, Uncertainty Bias: -0.03367134928703308
0.00025558472 0.0069732666
2.8762608 7.1254683
(48745, 22, 3)
Found uncertainty sample 0 after 993 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 14 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2623 steps.
Found uncertainty sample 6 after 2735 steps.
Found uncertainty sample 7 after 2859 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2730 steps.
Found uncertainty sample 11 after 1019 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2246 steps.
Found uncertainty sample 14 after 1993 steps.
Found uncertainty sample 15 after 2656 steps.
Found uncertainty sample 16 after 280 steps.
Found uncertainty sample 17 after 1393 steps.
Found uncertainty sample 18 after 3677 steps.
Found uncertainty sample 19 after 504 steps.
Found uncertainty sample 20 after 1743 steps.
Found uncertainty sample 21 after 2077 steps.
Found uncertainty sample 22 after 1156 steps.
Found uncertainty sample 23 after 1300 steps.
Found uncertainty sample 24 after 1468 steps.
Found uncertainty sample 25 after 3003 steps.
Found uncertainty sample 26 after 3106 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3849 steps.
Found uncertainty sample 31 after 488 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3466 steps.
Found uncertainty sample 34 after 1188 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1815 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2878 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1442 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 25 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2906 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1851 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2714 steps.
Found uncertainty sample 52 after 1526 steps.
Found uncertainty sample 53 after 2266 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2535 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3896 steps.
Found uncertainty sample 58 after 934 steps.
Found uncertainty sample 59 after 2828 steps.
Found uncertainty sample 60 after 2689 steps.
Found uncertainty sample 61 after 1351 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3906 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 998 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2401 steps.
Found uncertainty sample 71 after 1584 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 592 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 584 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1878 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3205 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_184402-9hp8sdot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_57
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9hp8sdot
Training model 57. Added 48 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.804450157633344, Training Loss Force: 4.983261384271146, time: 1.586871862411499
Validation Loss Energy: 2.1271576830407195, Validation Loss Force: 4.781127407755409, time: 0.10188913345336914
Test Loss Energy: 6.98055882417545, Test Loss Force: 8.726304856554965, time: 9.606467008590698


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2013321594455286, Training Loss Force: 4.596947842758583, time: 1.536405324935913
Validation Loss Energy: 2.2911467176075844, Validation Loss Force: 4.529729265950872, time: 0.10797786712646484
Test Loss Energy: 6.824345403762131, Test Loss Force: 8.597068365089791, time: 9.639387130737305


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.274167586778802, Training Loss Force: 4.893547373598985, time: 1.5476887226104736
Validation Loss Energy: 6.662572805632857, Validation Loss Force: 5.015222375568189, time: 0.10221457481384277
Test Loss Energy: 9.841885442965738, Test Loss Force: 8.713081032612116, time: 9.829702615737915


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.7470098714507216, Training Loss Force: 4.949550724051719, time: 1.5753931999206543
Validation Loss Energy: 1.9141862237563787, Validation Loss Force: 4.706788422710833, time: 0.10819673538208008
Test Loss Energy: 6.745663600939312, Test Loss Force: 8.651211307562614, time: 10.525609254837036


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.2849547901794978, Training Loss Force: 4.851821600271708, time: 1.5659806728363037
Validation Loss Energy: 2.4031005334663034, Validation Loss Force: 4.865127561703499, time: 0.1041114330291748
Test Loss Energy: 6.9826961285452285, Test Loss Force: 8.727352679265348, time: 9.761730194091797


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.116187002465254, Training Loss Force: 4.579487927681559, time: 1.6966838836669922
Validation Loss Energy: 2.909934699367632, Validation Loss Force: 4.510651196196925, time: 0.1031041145324707
Test Loss Energy: 7.237910172488055, Test Loss Force: 8.539652214151202, time: 10.190315246582031


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1737636926178143, Training Loss Force: 4.543959652961674, time: 1.726640224456787
Validation Loss Energy: 2.4387955109042574, Validation Loss Force: 4.47795000542597, time: 0.11829328536987305
Test Loss Energy: 7.073167884923438, Test Loss Force: 8.559532647107648, time: 11.76432752609253


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.138218716587392, Training Loss Force: 4.54027567516208, time: 1.760737419128418
Validation Loss Energy: 3.340516929591719, Validation Loss Force: 4.522355131845181, time: 0.12087631225585938
Test Loss Energy: 7.386112787085511, Test Loss Force: 8.570556551184241, time: 11.341392993927002


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.168100421150577, Training Loss Force: 4.531527958072293, time: 1.5167372226715088
Validation Loss Energy: 2.5696990277542966, Validation Loss Force: 4.476646277576563, time: 0.10752272605895996
Test Loss Energy: 7.21903091130721, Test Loss Force: 8.533082924085406, time: 10.296974182128906


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.176820235997033, Training Loss Force: 4.535933622318122, time: 1.6279101371765137
Validation Loss Energy: 3.4497092027026417, Validation Loss Force: 4.521297898740316, time: 0.10798072814941406
Test Loss Energy: 7.378169399891161, Test Loss Force: 8.56853763452006, time: 10.431980848312378


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1666956498663597, Training Loss Force: 4.546376706298071, time: 1.5905821323394775
Validation Loss Energy: 2.714465368956934, Validation Loss Force: 4.482664801921844, time: 0.11173510551452637
Test Loss Energy: 7.224159471376889, Test Loss Force: 8.496834550866241, time: 10.276960134506226


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1201763035229884, Training Loss Force: 4.545888489575932, time: 1.5578398704528809
Validation Loss Energy: 3.4986311727469985, Validation Loss Force: 4.534244105553704, time: 0.10584545135498047
Test Loss Energy: 7.277683095177425, Test Loss Force: 8.603820537638626, time: 10.296371698379517


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1223080423358116, Training Loss Force: 4.543418243054676, time: 1.5233311653137207
Validation Loss Energy: 2.6078523838978658, Validation Loss Force: 4.487242434223829, time: 0.10648870468139648
Test Loss Energy: 7.15746289945302, Test Loss Force: 8.54650601709514, time: 10.444562673568726


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.2043098700272385, Training Loss Force: 4.544670961676199, time: 1.5783064365386963
Validation Loss Energy: 3.1375468776658706, Validation Loss Force: 4.479766540318448, time: 0.1106410026550293
Test Loss Energy: 7.343236488369328, Test Loss Force: 8.506380780521404, time: 10.23215389251709


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.148312984851878, Training Loss Force: 4.552907398918369, time: 1.5359630584716797
Validation Loss Energy: 2.787703477744043, Validation Loss Force: 4.465390797588205, time: 0.10792088508605957
Test Loss Energy: 7.15123531675908, Test Loss Force: 8.528079210292365, time: 10.408630609512329


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1916425529453507, Training Loss Force: 4.5399665204202, time: 1.6114342212677002
Validation Loss Energy: 3.347803777392206, Validation Loss Force: 4.5087420309397395, time: 0.10624504089355469
Test Loss Energy: 7.33598356205648, Test Loss Force: 8.512510272210429, time: 10.281452417373657


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.2413171829390595, Training Loss Force: 4.546556461026783, time: 1.5310628414154053
Validation Loss Energy: 2.214777991963304, Validation Loss Force: 4.491445091684069, time: 0.10722899436950684
Test Loss Energy: 6.935710462580297, Test Loss Force: 8.50837789659381, time: 10.281140804290771


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1519653627508077, Training Loss Force: 4.551273488712483, time: 1.5445196628570557
Validation Loss Energy: 3.2392366479084753, Validation Loss Force: 4.500937922713263, time: 0.10880351066589355
Test Loss Energy: 7.371604173828731, Test Loss Force: 8.509052740324114, time: 10.532460451126099


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1379265026940697, Training Loss Force: 4.539403032530006, time: 1.5615532398223877
Validation Loss Energy: 2.4552508721228943, Validation Loss Force: 4.513647209555383, time: 0.11461043357849121
Test Loss Energy: 7.059120469597576, Test Loss Force: 8.566835565558273, time: 10.31657361984253


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.123960829937068, Training Loss Force: 4.538873588278122, time: 1.5324172973632812
Validation Loss Energy: 3.1120930109220004, Validation Loss Force: 4.491934741135964, time: 0.10791492462158203
Test Loss Energy: 7.533722973516026, Test Loss Force: 8.580857584943432, time: 10.26666522026062

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒ
wandb:   test_error_force â–ˆâ–„â–ˆâ–†â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–„â–ƒâ–â–‚â–â–â–â–ƒâ–„
wandb:          test_loss â–ƒâ–ƒâ–ˆâ–â–ƒâ–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–‚â–
wandb: train_error_energy â–ˆâ–â–†â–ˆâ–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–…
wandb:  train_error_force â–ˆâ–‚â–‡â–‡â–†â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–†â–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb: valid_error_energy â–â–‚â–ˆâ–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–ƒ
wandb:  valid_error_force â–…â–‚â–ˆâ–„â–†â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–‚â–
wandb:         valid_loss â–â–â–ˆâ–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3158
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.53372
wandb:   test_error_force 8.58086
wandb:          test_loss 5.4874
wandb: train_error_energy 3.12396
wandb:  train_error_force 4.53887
wandb:         train_loss 1.5285
wandb: valid_error_energy 3.11209
wandb:  valid_error_force 4.49193
wandb:         valid_loss 1.49107
wandb: 
wandb: ğŸš€ View run al_72_57 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9hp8sdot
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_184402-9hp8sdot/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3121726512908936, Uncertainty Bias: -0.07727625966072083
3.8146973e-05 0.0018501282
2.5264661 6.5795307
(48745, 22, 3)
Found uncertainty sample 0 after 894 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 300 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1595 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3763 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1296 steps.
Found uncertainty sample 23 after 520 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1984 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 31 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2385 steps.
Found uncertainty sample 40 after 2405 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1199 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 609 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3190 steps.
Found uncertainty sample 49 after 3917 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 488 steps.
Found uncertainty sample 52 after 3450 steps.
Found uncertainty sample 53 after 1959 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3033 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1858 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 40 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1850 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1939 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2453 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3743 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2324 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2991 steps.
Found uncertainty sample 85 after 2440 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1670 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_192154-zv5xpgvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_58
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zv5xpgvv
Training model 58. Added 28 samples to the dataset.
Epoch 0, Batch 100/100, Loss: 3.1011853218078613, Variance: 0.1586710810661316

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.041748526695584, Training Loss Force: 4.97545873850863, time: 1.7035579681396484
Validation Loss Energy: 5.440464777003782, Validation Loss Force: 4.622564708940231, time: 0.11993837356567383
Test Loss Energy: 8.84432961843863, Test Loss Force: 8.589838542740997, time: 10.260737419128418

Epoch 1, Batch 100/100, Loss: 1.8914692401885986, Variance: 0.17976190149784088

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.608944082931004, Training Loss Force: 4.605856693948476, time: 1.5631649494171143
Validation Loss Energy: 4.539984516135721, Validation Loss Force: 4.563838393731528, time: 0.11244869232177734
Test Loss Energy: 8.385222252352829, Test Loss Force: 8.562287099416986, time: 10.314907789230347

Epoch 2, Batch 100/100, Loss: 2.472456932067871, Variance: 0.22914734482765198

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.712322528102457, Training Loss Force: 4.587743538671493, time: 1.5570151805877686
Validation Loss Energy: 6.174122649757619, Validation Loss Force: 4.543702200196132, time: 0.10876655578613281
Test Loss Energy: 8.98315165523581, Test Loss Force: 8.581031066358442, time: 10.894117593765259

Epoch 3, Batch 100/100, Loss: 2.960599899291992, Variance: 0.2108529657125473

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.65310332805917, Training Loss Force: 4.5744137931610105, time: 1.6663475036621094
Validation Loss Energy: 5.57341362129374, Validation Loss Force: 4.508939538472177, time: 0.11849570274353027
Test Loss Energy: 9.116300870280313, Test Loss Force: 8.493169416724271, time: 11.359585285186768

Epoch 4, Batch 100/100, Loss: 2.387500047683716, Variance: 0.23571333289146423

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.626697815692741, Training Loss Force: 4.589842043956843, time: 1.7448136806488037
Validation Loss Energy: 5.772829205643143, Validation Loss Force: 4.635335452466627, time: 0.12747621536254883
Test Loss Energy: 8.527907528883434, Test Loss Force: 8.58671826018039, time: 12.40245532989502

Epoch 5, Batch 100/100, Loss: 2.2549221515655518, Variance: 0.21196557581424713

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.688733161411791, Training Loss Force: 4.590258635661958, time: 1.7379956245422363
Validation Loss Energy: 5.199882343624395, Validation Loss Force: 4.546871450150123, time: 0.1303703784942627
Test Loss Energy: 8.694188954548599, Test Loss Force: 8.516396168238, time: 11.363924741744995

Epoch 6, Batch 100/100, Loss: 2.1483752727508545, Variance: 0.22621336579322815

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.654110662121777, Training Loss Force: 4.569083454531516, time: 1.714576244354248
Validation Loss Energy: 6.247617273400836, Validation Loss Force: 4.536569439444627, time: 0.12486672401428223
Test Loss Energy: 8.935985727522084, Test Loss Force: 8.563980471458205, time: 11.430346488952637

Epoch 7, Batch 100/100, Loss: 1.984777808189392, Variance: 0.20005251467227936

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.72090230541212, Training Loss Force: 4.564160889908958, time: 1.5807631015777588
Validation Loss Energy: 5.052799797965816, Validation Loss Force: 4.501492591555769, time: 0.11784815788269043
Test Loss Energy: 8.629727675408398, Test Loss Force: 8.386267708474909, time: 11.355406284332275

Epoch 8, Batch 100/100, Loss: 2.909447193145752, Variance: 0.48987141251564026

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.7341837628916155, Training Loss Force: 4.568974083900418, time: 1.691903829574585
Validation Loss Energy: 6.015534343990659, Validation Loss Force: 4.488231307900893, time: 0.12494087219238281
Test Loss Energy: 8.645246586378345, Test Loss Force: 8.39685025199329, time: 11.384846925735474

Epoch 9, Batch 100/100, Loss: 2.671268939971924, Variance: 0.21517859399318695

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.703624275220322, Training Loss Force: 4.56408502653094, time: 1.9150488376617432
Validation Loss Energy: 5.347878723457861, Validation Loss Force: 4.472901427880349, time: 0.12531089782714844
Test Loss Energy: 8.757594868206823, Test Loss Force: 8.416326714155126, time: 11.443964004516602

Epoch 10, Batch 100/100, Loss: 2.229278802871704, Variance: 0.21653996407985687

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.752181133552754, Training Loss Force: 4.577604472793604, time: 1.7225744724273682
Validation Loss Energy: 5.914285124653272, Validation Loss Force: 4.501809895088716, time: 0.1292247772216797
Test Loss Energy: 8.658007603576552, Test Loss Force: 8.45945055101316, time: 11.487835168838501

Epoch 11, Batch 100/100, Loss: 1.9838883876800537, Variance: 0.21441803872585297

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.658063521540696, Training Loss Force: 4.574958673467862, time: 1.6986043453216553
Validation Loss Energy: 4.8896870778227495, Validation Loss Force: 4.571290016700001, time: 0.1234598159790039
Test Loss Energy: 8.642619249006158, Test Loss Force: 8.428881360189918, time: 11.548605918884277

Epoch 12, Batch 100/100, Loss: 2.4577853679656982, Variance: 0.21519877016544342

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.68532829855442, Training Loss Force: 4.591719937559173, time: 1.7366576194763184
Validation Loss Energy: 6.377756923745769, Validation Loss Force: 4.525276996378045, time: 0.11669325828552246
Test Loss Energy: 9.109667017820268, Test Loss Force: 8.518832219989962, time: 11.42872428894043

Epoch 13, Batch 100/100, Loss: 2.328888416290283, Variance: 0.200692281126976

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.660724524715723, Training Loss Force: 4.5686814743757544, time: 1.6806209087371826
Validation Loss Energy: 5.206084570015068, Validation Loss Force: 4.512128160641863, time: 0.12047696113586426
Test Loss Energy: 8.662695404644452, Test Loss Force: 8.350201285093142, time: 11.587685823440552

Epoch 14, Batch 100/100, Loss: 2.250880718231201, Variance: 0.221978560090065

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.795788926294228, Training Loss Force: 4.564637094597822, time: 1.7327425479888916
Validation Loss Energy: 5.82936044841129, Validation Loss Force: 4.551823834624702, time: 0.12521028518676758
Test Loss Energy: 8.593914495628171, Test Loss Force: 8.529148558464058, time: 11.344626665115356

Epoch 15, Batch 100/100, Loss: 2.137539863586426, Variance: 0.2030700147151947

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.7321364659431016, Training Loss Force: 4.580953559256612, time: 1.6627812385559082
Validation Loss Energy: 5.337921404590263, Validation Loss Force: 4.777444460081763, time: 0.11114382743835449
Test Loss Energy: 8.890898897763902, Test Loss Force: 8.566562118520618, time: 11.60663890838623

Epoch 16, Batch 100/100, Loss: 2.5213568210601807, Variance: 0.2267240732908249

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.668643196217781, Training Loss Force: 4.573054736482223, time: 1.6275455951690674
Validation Loss Energy: 6.059136080131363, Validation Loss Force: 4.577044010099922, time: 0.12483620643615723
Test Loss Energy: 8.697008139460015, Test Loss Force: 8.493937016726443, time: 11.342005014419556

Epoch 17, Batch 100/100, Loss: 2.2848305702209473, Variance: 0.219327911734581

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.728430516546681, Training Loss Force: 4.580848330271629, time: 1.5962646007537842
Validation Loss Energy: 4.586325750778775, Validation Loss Force: 4.556743932073123, time: 0.11665749549865723
Test Loss Energy: 8.172892476583156, Test Loss Force: 8.418868891654165, time: 11.575590372085571

Epoch 18, Batch 100/100, Loss: 2.5030038356781006, Variance: 0.22400198876857758

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.686754870744944, Training Loss Force: 4.564469536065511, time: 1.6866919994354248
Validation Loss Energy: 5.928265184311202, Validation Loss Force: 4.603766311633569, time: 0.12024569511413574
Test Loss Energy: 8.634773763955975, Test Loss Force: 8.477856349972953, time: 11.64789891242981

Epoch 19, Batch 100/100, Loss: 2.644814968109131, Variance: 0.20469939708709717

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.628526611861741, Training Loss Force: 4.594746888568767, time: 1.711714744567871
Validation Loss Energy: 5.869888682330753, Validation Loss Force: 4.586622568750297, time: 0.1282644271850586
Test Loss Energy: 9.137193979196299, Test Loss Force: 8.424519432502565, time: 11.45945930480957

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–ƒâ–‡â–ˆâ–„â–…â–‡â–„â–„â–…â–…â–„â–ˆâ–…â–„â–†â–…â–â–„â–ˆ
wandb:   test_error_force â–ˆâ–‡â–ˆâ–…â–ˆâ–†â–‡â–‚â–‚â–ƒâ–„â–ƒâ–†â–â–†â–‡â–…â–ƒâ–…â–ƒ
wandb:          test_loss â–ˆâ–„â–‚â–„â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–â–ƒâ–ƒâ–‚â–â–ƒâ–‚â–â–‚â–„
wandb: train_error_energy â–â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–†
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–â–‡â–…â–†â–„â–ˆâ–ƒâ–‡â–„â–†â–‚â–ˆâ–„â–†â–„â–‡â–â–†â–†
wandb:  valid_error_force â–„â–ƒâ–ƒâ–‚â–…â–ƒâ–‚â–‚â–â–â–‚â–ƒâ–‚â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–„â–„
wandb:         valid_loss â–ˆâ–‚â–…â–„â–…â–ƒâ–…â–‚â–„â–ƒâ–„â–‚â–†â–ƒâ–„â–„â–…â–â–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 3183
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.13719
wandb:   test_error_force 8.42452
wandb:          test_loss 5.53266
wandb: train_error_energy 4.62853
wandb:  train_error_force 4.59475
wandb:         train_loss 1.93608
wandb: valid_error_energy 5.86989
wandb:  valid_error_force 4.58662
wandb:         valid_loss 2.31271
wandb: 
wandb: ğŸš€ View run al_72_58 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zv5xpgvv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_192154-zv5xpgvv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.476231336593628, Uncertainty Bias: -0.1783827841281891
3.0517578e-05 0.07036686
2.380501 6.4181614
(48745, 22, 3)
Found uncertainty sample 0 after 2200 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1897 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1993 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2300 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2374 steps.
Found uncertainty sample 13 after 670 steps.
Found uncertainty sample 14 after 1204 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 446 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2811 steps.
Found uncertainty sample 22 after 2730 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2677 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 629 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3532 steps.
Found uncertainty sample 35 after 558 steps.
Found uncertainty sample 36 after 3438 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 997 steps.
Found uncertainty sample 40 after 1693 steps.
Found uncertainty sample 41 after 1410 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2571 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2852 steps.
Found uncertainty sample 52 after 3737 steps.
Found uncertainty sample 53 after 2306 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1294 steps.
Found uncertainty sample 58 after 2449 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1868 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2983 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1953 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1419 steps.
Found uncertainty sample 72 after 3311 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2987 steps.
Found uncertainty sample 77 after 421 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2418 steps.
Found uncertainty sample 81 after 3483 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2609 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3901 steps.
Found uncertainty sample 88 after 1027 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2251 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2117 steps.
Found uncertainty sample 97 after 3604 steps.
Found uncertainty sample 98 after 3525 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_195855-ceyiir6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_59
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ceyiir6s
Training model 59. Added 40 samples to the dataset.
Epoch 0, Batch 100/101, Loss: 1.4142811298370361, Variance: 0.16987212002277374

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.122220545049592, Training Loss Force: 4.744290924657114, time: 1.6395704746246338
Validation Loss Energy: 4.207485372663074, Validation Loss Force: 4.479647857663669, time: 0.11529421806335449
Test Loss Energy: 7.517716223592529, Test Loss Force: 8.438807647605545, time: 10.716429710388184

Epoch 1, Batch 100/101, Loss: 1.9618816375732422, Variance: 0.16959553956985474

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0987842182694996, Training Loss Force: 4.556641771028042, time: 1.604433536529541
Validation Loss Energy: 3.2554676699625897, Validation Loss Force: 4.55477175144764, time: 0.11965179443359375
Test Loss Energy: 7.360942339109871, Test Loss Force: 8.481370176349943, time: 10.718770742416382

Epoch 2, Batch 100/101, Loss: 1.1200265884399414, Variance: 0.15757623314857483

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1361389329399114, Training Loss Force: 4.5429830031058795, time: 1.788405179977417
Validation Loss Energy: 2.0534490743482654, Validation Loss Force: 4.46123156061142, time: 0.11588096618652344
Test Loss Energy: 6.948174191986741, Test Loss Force: 8.42284948385653, time: 10.76371455192566

Epoch 3, Batch 100/101, Loss: 1.3785452842712402, Variance: 0.16871434450149536

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.1629140114704346, Training Loss Force: 4.552385584786977, time: 1.5636932849884033
Validation Loss Energy: 3.7262525918147933, Validation Loss Force: 4.4768691693916365, time: 0.11240267753601074
Test Loss Energy: 7.556267986716577, Test Loss Force: 8.45281473533405, time: 10.745970010757446

Epoch 4, Batch 100/101, Loss: 2.174457550048828, Variance: 0.17694374918937683

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.151252238555656, Training Loss Force: 4.563084167036726, time: 1.641165018081665
Validation Loss Energy: 2.6918588839166153, Validation Loss Force: 4.5124926700337475, time: 0.11195802688598633
Test Loss Energy: 7.152482555428038, Test Loss Force: 8.512651749890393, time: 11.790026664733887

Epoch 5, Batch 100/101, Loss: 1.432411789894104, Variance: 0.16403409838676453

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1386101503957393, Training Loss Force: 4.544111265463651, time: 1.5691213607788086
Validation Loss Energy: 2.651719541660516, Validation Loss Force: 4.522719641237065, time: 0.11396455764770508
Test Loss Energy: 6.968968037095924, Test Loss Force: 8.471018168843441, time: 10.740403413772583

Epoch 6, Batch 100/101, Loss: 1.5378128290176392, Variance: 0.16360308229923248

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1416530422233495, Training Loss Force: 4.550934469804772, time: 1.5568969249725342
Validation Loss Energy: 4.236581995299749, Validation Loss Force: 4.581492494297267, time: 0.11484837532043457
Test Loss Energy: 7.808050936945294, Test Loss Force: 8.502457420118578, time: 10.881685018539429

Epoch 7, Batch 100/101, Loss: 1.7790032625198364, Variance: 0.16962489485740662

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.169653851569822, Training Loss Force: 4.549049740832869, time: 1.5332038402557373
Validation Loss Energy: 3.445223866761645, Validation Loss Force: 4.501610160864819, time: 0.11407637596130371
Test Loss Energy: 7.42496110820611, Test Loss Force: 8.478962766145505, time: 10.80178165435791

Epoch 8, Batch 100/101, Loss: 1.4606845378875732, Variance: 0.1722107231616974

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.154439816825931, Training Loss Force: 4.548600698737397, time: 1.52852463722229
Validation Loss Energy: 2.2822380590827325, Validation Loss Force: 4.573298715065416, time: 0.11394095420837402
Test Loss Energy: 7.112217289106687, Test Loss Force: 8.531653994388215, time: 10.77993655204773

Epoch 9, Batch 100/101, Loss: 1.314610481262207, Variance: 0.16158261895179749

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.187899526735521, Training Loss Force: 4.555883135043221, time: 1.6180007457733154
Validation Loss Energy: 3.616962344279662, Validation Loss Force: 4.521838316757483, time: 0.11376953125
Test Loss Energy: 7.599330173366363, Test Loss Force: 8.474562819158745, time: 10.877594232559204

Epoch 10, Batch 100/101, Loss: 1.8759132623672485, Variance: 0.16505442559719086

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.24300297084708, Training Loss Force: 4.558762445518117, time: 1.621079683303833
Validation Loss Energy: 2.5759691682344767, Validation Loss Force: 4.520713837570547, time: 0.11189079284667969
Test Loss Energy: 7.125936403841731, Test Loss Force: 8.446003330460785, time: 10.707692384719849

Epoch 11, Batch 100/101, Loss: 1.6781995296478271, Variance: 0.17555442452430725

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.153756063813492, Training Loss Force: 4.553693560987318, time: 1.555856466293335
Validation Loss Energy: 3.1334777103586133, Validation Loss Force: 4.5303997227492605, time: 0.11601090431213379
Test Loss Energy: 7.348084459667381, Test Loss Force: 8.510089972843286, time: 10.89105224609375

Epoch 12, Batch 100/101, Loss: 1.2979344129562378, Variance: 0.17109103500843048

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1847156710083446, Training Loss Force: 4.5741725305240974, time: 1.610588788986206
Validation Loss Energy: 4.576645877667003, Validation Loss Force: 4.504831070060664, time: 0.11959362030029297
Test Loss Energy: 7.972649790605723, Test Loss Force: 8.482070877680544, time: 10.730732679367065

Epoch 13, Batch 100/101, Loss: 1.4776463508605957, Variance: 0.1632896065711975

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.205623979728148, Training Loss Force: 4.567181420419076, time: 1.540377140045166
Validation Loss Energy: 3.4646648872234547, Validation Loss Force: 4.474637801880294, time: 0.11966395378112793
Test Loss Energy: 7.454146847465053, Test Loss Force: 8.475988503249118, time: 10.787607431411743

Epoch 14, Batch 100/101, Loss: 1.322609305381775, Variance: 0.15813252329826355

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1855609782024126, Training Loss Force: 4.540924698023114, time: 1.5982856750488281
Validation Loss Energy: 2.2633037222624823, Validation Loss Force: 4.525936765057429, time: 0.11322617530822754
Test Loss Energy: 6.929936586341194, Test Loss Force: 8.515402364362934, time: 10.930320024490356

Epoch 15, Batch 100/101, Loss: 1.3654158115386963, Variance: 0.1646454930305481

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.2099156034330902, Training Loss Force: 4.555508887734332, time: 1.571749210357666
Validation Loss Energy: 3.066037906131464, Validation Loss Force: 4.493794696511899, time: 0.11127185821533203
Test Loss Energy: 7.345154059095319, Test Loss Force: 8.537314183455733, time: 10.816879987716675

Epoch 16, Batch 100/101, Loss: 1.881809115409851, Variance: 0.1866740882396698

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.2917399215706507, Training Loss Force: 4.657482511533482, time: 1.5349822044372559
Validation Loss Energy: 2.484846830319313, Validation Loss Force: 4.476176668347801, time: 0.11485600471496582
Test Loss Energy: 7.111510567548497, Test Loss Force: 8.476110791745095, time: 10.9691321849823

Epoch 17, Batch 100/101, Loss: 1.633520483970642, Variance: 0.16743573546409607

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.19410822155465, Training Loss Force: 4.540173363822563, time: 1.5774009227752686
Validation Loss Energy: 2.8531944816060317, Validation Loss Force: 4.521576903180163, time: 0.11368346214294434
Test Loss Energy: 7.050139877863423, Test Loss Force: 8.601206532435823, time: 10.81196403503418

Epoch 18, Batch 100/101, Loss: 1.5340909957885742, Variance: 0.3201088309288025

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.230451701935991, Training Loss Force: 4.54004526953824, time: 1.5553913116455078
Validation Loss Energy: 4.141050474291497, Validation Loss Force: 4.52138785707527, time: 0.11272931098937988
Test Loss Energy: 7.991233277212352, Test Loss Force: 8.522096670913195, time: 10.828101873397827

Epoch 19, Batch 100/101, Loss: 2.229264259338379, Variance: 0.31439483165740967

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.2191742449438596, Training Loss Force: 4.532639483344153, time: 1.7737419605255127
Validation Loss Energy: 3.4469624674530497, Validation Loss Force: 4.502888727100736, time: 0.11400723457336426
Test Loss Energy: 7.485261626659715, Test Loss Force: 8.487326541029299, time: 10.845091342926025

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–â–…â–‚â–â–‡â–„â–‚â–…â–‚â–„â–ˆâ–„â–â–„â–‚â–‚â–ˆâ–…
wandb:   test_error_force â–‚â–ƒâ–â–‚â–…â–ƒâ–„â–ƒâ–…â–ƒâ–‚â–„â–ƒâ–ƒâ–…â–…â–ƒâ–ˆâ–…â–„
wandb:          test_loss â–â–ƒâ–ƒâ–ˆâ–„â–â–†â–ƒâ–ƒâ–‡â–†â–ƒâ–†â–ƒâ–ƒâ–†â–ƒâ–â–ˆâ–ƒ
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–…â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–ƒâ–â–â–
wandb: valid_error_energy â–‡â–„â–â–†â–ƒâ–ƒâ–‡â–…â–‚â–…â–‚â–„â–ˆâ–…â–‚â–„â–‚â–ƒâ–‡â–…
wandb:  valid_error_force â–‚â–†â–â–‚â–„â–…â–ˆâ–ƒâ–ˆâ–…â–„â–…â–„â–‚â–…â–ƒâ–‚â–…â–…â–ƒ
wandb:         valid_loss â–‡â–„â–â–†â–ƒâ–‚â–‡â–„â–‚â–…â–‚â–„â–ˆâ–„â–‚â–„â–‚â–ƒâ–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3219
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.48526
wandb:   test_error_force 8.48733
wandb:          test_loss 5.48579
wandb: train_error_energy 3.21917
wandb:  train_error_force 4.53264
wandb:         train_loss 1.54784
wandb: valid_error_energy 3.44696
wandb:  valid_error_force 4.50289
wandb:         valid_loss 1.61302
wandb: 
wandb: ğŸš€ View run al_72_59 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ceyiir6s
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_195855-ceyiir6s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.46830415725708, Uncertainty Bias: -0.10598638653755188
1.5258789e-05 0.0058574677
2.5544505 6.561099
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3026 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1252 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2879 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2589 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1501 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2291 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3194 steps.
Found uncertainty sample 37 after 1883 steps.
Found uncertainty sample 38 after 776 steps.
Found uncertainty sample 39 after 1871 steps.
Found uncertainty sample 40 after 74 steps.
Found uncertainty sample 41 after 640 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2883 steps.
Found uncertainty sample 45 after 3091 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1675 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 165 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1257 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3862 steps.
Found uncertainty sample 61 after 2156 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2004 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3341 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3169 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1190 steps.
Found uncertainty sample 76 after 679 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3947 steps.
Found uncertainty sample 82 after 1717 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1488 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1656 steps.
Found uncertainty sample 88 after 2006 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2387 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2035 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2558 steps.
Found uncertainty sample 99 after 2414 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_203636-bo3o3w0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_60
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bo3o3w0r
Training model 60. Added 33 samples to the dataset.
Epoch 0, Batch 100/102, Loss: 1.6638416051864624, Variance: 0.1537763625383377

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.160386272666702, Training Loss Force: 5.050588448847298, time: 1.7070186138153076
Validation Loss Energy: 3.9716406707015928, Validation Loss Force: 4.690910108583868, time: 0.11272716522216797
Test Loss Energy: 7.626325414811601, Test Loss Force: 8.732655259352892, time: 10.390910863876343

Epoch 1, Batch 100/102, Loss: 1.8917323350906372, Variance: 0.161643385887146

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.8474749290091004, Training Loss Force: 4.8472740281721185, time: 1.5629360675811768
Validation Loss Energy: 2.256228966823491, Validation Loss Force: 4.559848607974794, time: 0.11142396926879883
Test Loss Energy: 6.988530041515623, Test Loss Force: 8.525276619478454, time: 10.344681024551392

Epoch 2, Batch 100/102, Loss: 1.5009161233901978, Variance: 0.1679626852273941

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.104730013548153, Training Loss Force: 4.536129004240044, time: 1.6122281551361084
Validation Loss Energy: 2.4404951444951246, Validation Loss Force: 4.466880454174461, time: 0.11413431167602539
Test Loss Energy: 7.235765425606094, Test Loss Force: 8.475436931955935, time: 10.604302406311035

Epoch 3, Batch 100/102, Loss: 1.4334286451339722, Variance: 0.1640598475933075

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.10757938180977, Training Loss Force: 4.53963527486155, time: 1.5874009132385254
Validation Loss Energy: 2.1544823046141017, Validation Loss Force: 4.463386107267416, time: 0.12627887725830078
Test Loss Energy: 6.873635742019696, Test Loss Force: 8.473421979035715, time: 10.462204217910767

Epoch 4, Batch 100/102, Loss: 1.5173672437667847, Variance: 0.1740764081478119

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1800189521044184, Training Loss Force: 4.541961285492035, time: 1.5922880172729492
Validation Loss Energy: 2.3362392236802747, Validation Loss Force: 4.490198589805165, time: 0.11275649070739746
Test Loss Energy: 7.0800668932014235, Test Loss Force: 8.504297744469653, time: 10.63814640045166

Epoch 5, Batch 100/102, Loss: 1.7287548780441284, Variance: 0.17538034915924072

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1945380653852395, Training Loss Force: 4.548437001986648, time: 1.6054081916809082
Validation Loss Energy: 2.631809023304518, Validation Loss Force: 4.467833255449887, time: 0.12013411521911621
Test Loss Energy: 7.245822812687357, Test Loss Force: 8.496642234672583, time: 10.40303659439087

Epoch 6, Batch 100/102, Loss: 1.4982751607894897, Variance: 0.17745833098888397

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.181231941185346, Training Loss Force: 4.52465580621971, time: 1.626997947692871
Validation Loss Energy: 2.537786419763645, Validation Loss Force: 4.458316376152933, time: 0.11270475387573242
Test Loss Energy: 7.20010546318279, Test Loss Force: 8.444946526372911, time: 11.30014181137085

Epoch 7, Batch 100/102, Loss: 1.3525198698043823, Variance: 0.1683458536863327

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.139082196708258, Training Loss Force: 4.535121155658897, time: 1.6020371913909912
Validation Loss Energy: 2.8305253152011347, Validation Loss Force: 4.495031178279236, time: 0.11287450790405273
Test Loss Energy: 7.285511034831552, Test Loss Force: 8.466462129619575, time: 10.586757898330688

Epoch 8, Batch 100/102, Loss: 1.418165922164917, Variance: 0.16217665374279022

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.189445469205712, Training Loss Force: 4.607413575485064, time: 1.5941593647003174
Validation Loss Energy: 2.4127737265036986, Validation Loss Force: 4.453729391746821, time: 0.11414957046508789
Test Loss Energy: 7.280800199748022, Test Loss Force: 8.518824982659813, time: 10.412964105606079

Epoch 9, Batch 100/102, Loss: 1.6466073989868164, Variance: 0.17835018038749695

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1649804379358675, Training Loss Force: 4.539234169140624, time: 1.5760276317596436
Validation Loss Energy: 2.4430219939631126, Validation Loss Force: 4.449961829797722, time: 0.12093591690063477
Test Loss Energy: 7.017358787340712, Test Loss Force: 8.461612479559376, time: 10.682669162750244

Epoch 10, Batch 100/102, Loss: 1.400423288345337, Variance: 0.16499650478363037

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1777009521056105, Training Loss Force: 4.556976175992325, time: 1.5976760387420654
Validation Loss Energy: 2.2881930113868525, Validation Loss Force: 4.540455238710213, time: 0.11611819267272949
Test Loss Energy: 6.917618317011588, Test Loss Force: 8.519202741448785, time: 10.478926181793213

Epoch 11, Batch 100/102, Loss: 1.5167316198349, Variance: 0.16530440747737885

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1320492255711074, Training Loss Force: 4.563574692337886, time: 1.5831217765808105
Validation Loss Energy: 2.4968934537831524, Validation Loss Force: 4.462810730194339, time: 0.1136939525604248
Test Loss Energy: 6.944857370679353, Test Loss Force: 8.50040542251364, time: 10.417196273803711

Epoch 12, Batch 100/102, Loss: 1.5334938764572144, Variance: 0.16685473918914795

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1202151299834173, Training Loss Force: 4.549628107274892, time: 1.5995664596557617
Validation Loss Energy: 2.4192519513007484, Validation Loss Force: 4.487910886999904, time: 0.11744880676269531
Test Loss Energy: 7.00058579674606, Test Loss Force: 8.487294835740856, time: 10.667935848236084

Epoch 13, Batch 100/102, Loss: 1.3917639255523682, Variance: 0.16654229164123535

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1534581795718952, Training Loss Force: 4.544438401151372, time: 1.6010215282440186
Validation Loss Energy: 2.872892796265961, Validation Loss Force: 4.510724899684226, time: 0.11395382881164551
Test Loss Energy: 7.315163882663142, Test Loss Force: 8.47415330844905, time: 10.520323514938354

Epoch 14, Batch 100/102, Loss: 1.528450846672058, Variance: 0.17181448638439178

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1175748382261874, Training Loss Force: 4.546301251226203, time: 1.6957173347473145
Validation Loss Energy: 2.5604165077334313, Validation Loss Force: 4.459905120509127, time: 0.11222410202026367
Test Loss Energy: 7.254745673656554, Test Loss Force: 8.482568924440598, time: 10.632459878921509

Epoch 15, Batch 100/102, Loss: 1.4775803089141846, Variance: 0.16549763083457947

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.120945489148123, Training Loss Force: 4.541575059309331, time: 1.5888237953186035
Validation Loss Energy: 2.53062437801945, Validation Loss Force: 4.490112416845691, time: 0.11420011520385742
Test Loss Energy: 7.1786144304854425, Test Loss Force: 8.468337087766395, time: 10.443065166473389

Epoch 16, Batch 100/102, Loss: 1.4352537393569946, Variance: 0.16973775625228882

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1843775259934888, Training Loss Force: 4.532243191876273, time: 1.5838122367858887
Validation Loss Energy: 2.975136344674488, Validation Loss Force: 4.44962404070335, time: 0.11229491233825684
Test Loss Energy: 7.355801090396299, Test Loss Force: 8.507144234913715, time: 10.503708362579346

Epoch 17, Batch 100/102, Loss: 1.7193959951400757, Variance: 0.1724318265914917

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.170545304458754, Training Loss Force: 4.548086206394515, time: 1.7101390361785889
Validation Loss Energy: 2.3088111722886087, Validation Loss Force: 4.472796773381763, time: 0.15982961654663086
Test Loss Energy: 6.969058527038893, Test Loss Force: 8.472829819004394, time: 10.558970212936401

Epoch 18, Batch 100/102, Loss: 1.3971168994903564, Variance: 0.16998602449893951

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1981196876823343, Training Loss Force: 4.559518166962237, time: 1.5725934505462646
Validation Loss Energy: 2.5562780903217908, Validation Loss Force: 4.502102037008173, time: 0.11042070388793945
Test Loss Energy: 7.174560014717651, Test Loss Force: 8.486167313797528, time: 10.40673542022705

Epoch 19, Batch 100/102, Loss: 1.5930583477020264, Variance: 0.17170608043670654

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1441369784275333, Training Loss Force: 4.528627568873808, time: 1.568328857421875
Validation Loss Energy: 2.5912370348978806, Validation Loss Force: 4.480128600349727, time: 0.1123650074005127
Test Loss Energy: 7.203962664035711, Test Loss Force: 8.4259450606342, time: 10.666585922241211

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–„â–â–ƒâ–„â–„â–…â–…â–‚â–â–‚â–‚â–…â–…â–„â–…â–‚â–„â–„
wandb:   test_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–
wandb:          test_loss â–ˆâ–‡â–…â–â–‚â–…â–â–…â–…â–ƒâ–‚â–ƒâ–ƒâ–†â–…â–„â–„â–â–‚â–ƒ
wandb: train_error_energy â–ˆâ–†â–â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–â–‚â–
wandb:  train_error_force â–ˆâ–…â–â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–â–‚â–â–‚â–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–‚â–„â–ƒâ–‚â–„â–‚â–ƒâ–ƒ
wandb:  valid_error_force â–ˆâ–„â–‚â–â–‚â–‚â–â–‚â–â–â–„â–â–‚â–ƒâ–â–‚â–â–‚â–ƒâ–‚
wandb:         valid_loss â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3248
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.20396
wandb:   test_error_force 8.42595
wandb:          test_loss 5.60791
wandb: train_error_energy 3.14414
wandb:  train_error_force 4.52863
wandb:         train_loss 1.52282
wandb: valid_error_energy 2.59124
wandb:  valid_error_force 4.48013
wandb:         valid_loss 1.3607
wandb: 
wandb: ğŸš€ View run al_72_60 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bo3o3w0r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_203636-bo3o3w0r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.626262903213501, Uncertainty Bias: -0.11290636658668518
7.6293945e-06 0.008000374
2.5220442 6.516863
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2682 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2911 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 285 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 669 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2792 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2921 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2865 steps.
Found uncertainty sample 29 after 847 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 736 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3045 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3359 steps.
Found uncertainty sample 45 after 3250 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1415 steps.
Found uncertainty sample 50 after 572 steps.
Found uncertainty sample 51 after 3633 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2916 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3919 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3317 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1336 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2527 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3644 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2876 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2468 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 419 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2533 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2369 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_211605-31zi0953
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_61
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/31zi0953
Training model 61. Added 26 samples to the dataset.
Epoch 0, Batch 100/103, Loss: 1.2054842710494995, Variance: 0.15051786601543427

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.9190941928252143, Training Loss Force: 4.984574996363981, time: 1.6316542625427246
Validation Loss Energy: 3.0437874690554843, Validation Loss Force: 4.693223863679204, time: 0.11001181602478027
Test Loss Energy: 7.431675149538059, Test Loss Force: 8.604081678417096, time: 10.306571960449219

Epoch 1, Batch 100/103, Loss: 2.3573546409606934, Variance: 0.1967620849609375

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.632629919656377, Training Loss Force: 4.585534648378185, time: 1.6040172576904297
Validation Loss Energy: 6.505561220088213, Validation Loss Force: 4.534758916619088, time: 0.11411857604980469
Test Loss Energy: 8.994090343480513, Test Loss Force: 8.561375494265171, time: 10.294939994812012

Epoch 2, Batch 100/103, Loss: 2.1762309074401855, Variance: 0.19168810546398163

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.61453608968324, Training Loss Force: 4.55954052899763, time: 1.6210541725158691
Validation Loss Energy: 6.483756121304088, Validation Loss Force: 4.525647740506015, time: 0.11427712440490723
Test Loss Energy: 8.973724622356334, Test Loss Force: 8.506673202234552, time: 10.493833780288696

Epoch 3, Batch 100/103, Loss: 1.578410029411316, Variance: 0.2086561918258667

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.66762969051228, Training Loss Force: 4.567885463828347, time: 1.5945484638214111
Validation Loss Energy: 4.757925060080587, Validation Loss Force: 4.458077674828498, time: 0.11582398414611816
Test Loss Energy: 8.014701628246836, Test Loss Force: 8.458422766194296, time: 10.353785514831543

Epoch 4, Batch 100/103, Loss: 1.43193519115448, Variance: 0.21720841526985168

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.720083597474453, Training Loss Force: 4.541896757686058, time: 1.5991387367248535
Validation Loss Energy: 2.4093361602288654, Validation Loss Force: 4.467595890140327, time: 0.11796069145202637
Test Loss Energy: 6.990895286810792, Test Loss Force: 8.409689825933533, time: 10.496658086776733

Epoch 5, Batch 100/103, Loss: 2.315481185913086, Variance: 0.22063839435577393

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.660066311412751, Training Loss Force: 4.564385011895398, time: 1.6026360988616943
Validation Loss Energy: 5.079630316704385, Validation Loss Force: 4.526697402859918, time: 0.11578822135925293
Test Loss Energy: 8.334201038041353, Test Loss Force: 8.458155731095395, time: 10.336068630218506

Epoch 6, Batch 100/103, Loss: 2.33787202835083, Variance: 0.2332519143819809

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.742874781166727, Training Loss Force: 4.539106473323747, time: 1.6346940994262695
Validation Loss Energy: 5.771939197066869, Validation Loss Force: 4.452598232485507, time: 0.11118197441101074
Test Loss Energy: 8.844602368323672, Test Loss Force: 8.393731904672379, time: 10.334528923034668

Epoch 7, Batch 100/103, Loss: 1.8452863693237305, Variance: 0.23084479570388794

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.793391495744118, Training Loss Force: 4.56240705484314, time: 1.6012837886810303
Validation Loss Energy: 2.341809960373096, Validation Loss Force: 4.546531211695145, time: 0.11215758323669434
Test Loss Energy: 6.901206390848994, Test Loss Force: 8.48694630606616, time: 11.440916061401367

Epoch 8, Batch 100/103, Loss: 1.6915850639343262, Variance: 0.20940065383911133

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.369045818629477, Training Loss Force: 4.822132026098811, time: 1.5652589797973633
Validation Loss Energy: 3.1697607570109625, Validation Loss Force: 4.539222319649211, time: 0.11175394058227539
Test Loss Energy: 7.491921490606585, Test Loss Force: 8.435546838663527, time: 10.326529741287231

Epoch 9, Batch 100/103, Loss: 1.4597797393798828, Variance: 0.21211571991443634

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.71255702580093, Training Loss Force: 4.5568324571105645, time: 1.632524013519287
Validation Loss Energy: 2.8276642393451086, Validation Loss Force: 4.583679105310278, time: 0.11171364784240723
Test Loss Energy: 7.244448419443811, Test Loss Force: 8.554716082651435, time: 10.54125714302063

Epoch 10, Batch 100/103, Loss: 2.6890392303466797, Variance: 0.2233538031578064

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.694758348104393, Training Loss Force: 4.555608459948256, time: 1.6055233478546143
Validation Loss Energy: 6.017171407551521, Validation Loss Force: 4.498204213608707, time: 0.11262631416320801
Test Loss Energy: 8.824385900812459, Test Loss Force: 8.455604180507702, time: 10.312783479690552

Epoch 11, Batch 100/103, Loss: 2.4236538410186768, Variance: 0.22093698382377625

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.7150434143394495, Training Loss Force: 4.527722422441061, time: 1.5814645290374756
Validation Loss Energy: 6.5672065051308826, Validation Loss Force: 4.5119362198380735, time: 0.11322665214538574
Test Loss Energy: 9.055917763723905, Test Loss Force: 8.418716576631896, time: 10.364098072052002

Epoch 12, Batch 100/103, Loss: 1.8543720245361328, Variance: 0.22233781218528748

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.7326515002180916, Training Loss Force: 4.536384883473871, time: 1.6230566501617432
Validation Loss Energy: 4.324606448722193, Validation Loss Force: 4.5927493103005, time: 0.116058349609375
Test Loss Energy: 7.7617922985656955, Test Loss Force: 8.539879761033813, time: 10.489974975585938

Epoch 13, Batch 100/103, Loss: 1.3304550647735596, Variance: 0.2176549732685089

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.708572619773997, Training Loss Force: 4.571724362053923, time: 1.602900505065918
Validation Loss Energy: 2.3632818347803397, Validation Loss Force: 4.48061179239639, time: 0.1151278018951416
Test Loss Energy: 7.011831183177006, Test Loss Force: 8.395178037018356, time: 10.386107921600342

Epoch 14, Batch 100/103, Loss: 2.070558786392212, Variance: 0.2343667447566986

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.689380948761654, Training Loss Force: 4.548698997437062, time: 1.5862808227539062
Validation Loss Energy: 5.36371361710137, Validation Loss Force: 4.500062164962328, time: 0.11348843574523926
Test Loss Energy: 8.884452933762356, Test Loss Force: 8.354070006451302, time: 10.51926565170288

Epoch 15, Batch 100/103, Loss: 2.404934883117676, Variance: 0.22689226269721985

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.702446443544005, Training Loss Force: 4.564037572363477, time: 1.5974907875061035
Validation Loss Energy: 5.084258494902494, Validation Loss Force: 4.535604391366176, time: 0.11056828498840332
Test Loss Energy: 8.58883121084096, Test Loss Force: 8.426244118121058, time: 10.371819734573364

Epoch 16, Batch 100/103, Loss: 1.7746978998184204, Variance: 0.22449442744255066

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.7116240377558185, Training Loss Force: 4.565974668546541, time: 1.6370391845703125
Validation Loss Energy: 3.3142596725693414, Validation Loss Force: 4.432114007075026, time: 0.11302685737609863
Test Loss Energy: 7.646919144477981, Test Loss Force: 8.29130056748186, time: 10.461463212966919

Epoch 17, Batch 100/103, Loss: 1.3666443824768066, Variance: 0.21490415930747986

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.713127312830277, Training Loss Force: 4.551635473821938, time: 1.5849380493164062
Validation Loss Energy: 2.6812420190387787, Validation Loss Force: 4.4874214602171545, time: 0.11232542991638184
Test Loss Energy: 7.145963807760947, Test Loss Force: 8.392326412360056, time: 10.538379430770874

Epoch 18, Batch 100/103, Loss: 2.313655376434326, Variance: 0.2130725234746933

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.694085160906671, Training Loss Force: 4.548057865949008, time: 1.598261833190918
Validation Loss Energy: 5.808961950621991, Validation Loss Force: 4.526610561893007, time: 0.1179652214050293
Test Loss Energy: 8.536242732168125, Test Loss Force: 8.484894998618996, time: 10.421153545379639

Epoch 19, Batch 100/103, Loss: 2.1804728507995605, Variance: 0.20924794673919678

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.6735068437301, Training Loss Force: 4.542822879738863, time: 1.5818145275115967
Validation Loss Energy: 6.6037322611522935, Validation Loss Force: 4.515820237750493, time: 0.1129300594329834
Test Loss Energy: 8.835007550162416, Test Loss Force: 8.448969059649592, time: 10.54349684715271

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.039 MB of 0.049 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ˆâ–…â–â–†â–‡â–â–ƒâ–‚â–‡â–ˆâ–„â–â–‡â–†â–ƒâ–‚â–†â–‡
wandb:   test_error_force â–ˆâ–‡â–†â–…â–„â–…â–ƒâ–…â–„â–‡â–…â–„â–‡â–ƒâ–‚â–„â–â–ƒâ–…â–…
wandb:          test_loss â–ˆâ–‡â–†â–ƒâ–‚â–…â–…â–â–ƒâ–‚â–…â–…â–‚â–‚â–…â–…â–ƒâ–â–„â–…
wandb: train_error_energy â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–…â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  train_error_force â–ˆâ–‚â–â–‚â–â–‚â–â–‚â–†â–â–â–â–â–‚â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–â–â–‚â–ƒâ–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ˆâ–ˆâ–…â–â–…â–‡â–â–‚â–‚â–‡â–ˆâ–„â–â–†â–†â–ƒâ–‚â–‡â–ˆ
wandb:  valid_error_force â–ˆâ–„â–„â–‚â–‚â–„â–‚â–„â–„â–…â–ƒâ–ƒâ–…â–‚â–ƒâ–„â–â–‚â–„â–ƒ
wandb:         valid_loss â–‚â–ˆâ–‡â–„â–â–…â–†â–â–‚â–‚â–†â–‡â–ƒâ–â–…â–…â–‚â–â–†â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 3271
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.83501
wandb:   test_error_force 8.44897
wandb:          test_loss 5.12086
wandb: train_error_energy 4.67351
wandb:  train_error_force 4.54282
wandb:         train_loss 1.92122
wandb: valid_error_energy 6.60373
wandb:  valid_error_force 4.51582
wandb:         valid_loss 2.39671
wandb: 
wandb: ğŸš€ View run al_72_61 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/31zi0953
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_211605-31zi0953/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.549091339111328, Uncertainty Bias: -0.25622475147247314
2.2888184e-05 0.113773346
2.3088427 6.326327
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1839 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1735 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 453 steps.
Found uncertainty sample 13 after 3362 steps.
Found uncertainty sample 14 after 647 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1980 steps.
Found uncertainty sample 17 after 1244 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2028 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1580 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 69 steps.
Found uncertainty sample 28 after 3757 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2473 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2576 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1971 steps.
Found uncertainty sample 49 after 2775 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1367 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3273 steps.
Found uncertainty sample 54 after 3357 steps.
Found uncertainty sample 55 after 2129 steps.
Found uncertainty sample 56 after 911 steps.
Found uncertainty sample 57 after 644 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3058 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2362 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2009 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2607 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1078 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1823 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3866 steps.
Found uncertainty sample 95 after 1860 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3763 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_215415-4k32sl0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_62
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/4k32sl0i
Training model 62. Added 30 samples to the dataset.
Epoch 0, Batch 100/104, Loss: 1.5451915264129639, Variance: 0.1921723186969757

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.834286487957715, Training Loss Force: 4.9136805561267565, time: 1.7303578853607178
Validation Loss Energy: 3.2823284717050045, Validation Loss Force: 4.689266810286921, time: 0.19104266166687012
Test Loss Energy: 7.6393231071615935, Test Loss Force: 8.515228719734937, time: 10.542526006698608

Epoch 1, Batch 100/104, Loss: 1.397188663482666, Variance: 0.2095445692539215

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.553293306466985, Training Loss Force: 4.537672405366387, time: 1.6569819450378418
Validation Loss Energy: 3.060538200896194, Validation Loss Force: 4.4690920041318165, time: 0.11454510688781738
Test Loss Energy: 7.484273831354168, Test Loss Force: 8.409061129509364, time: 10.429728507995605

Epoch 2, Batch 100/104, Loss: 1.5536502599716187, Variance: 0.21250128746032715

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.670534181738189, Training Loss Force: 4.551499110214257, time: 1.6373622417449951
Validation Loss Energy: 3.8226852548566157, Validation Loss Force: 4.497262991128871, time: 0.11519098281860352
Test Loss Energy: 7.945572854065877, Test Loss Force: 8.354118671900661, time: 10.740272521972656

Epoch 3, Batch 100/104, Loss: 1.2628735303878784, Variance: 0.21923768520355225

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.695610641408107, Training Loss Force: 4.521357023821708, time: 1.609050989151001
Validation Loss Energy: 3.191480016839332, Validation Loss Force: 4.460408130109778, time: 0.11482572555541992
Test Loss Energy: 7.5804455168305065, Test Loss Force: 8.362182848363123, time: 10.490601539611816

Epoch 4, Batch 100/104, Loss: 1.4409067630767822, Variance: 0.21096867322921753

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.735604051872694, Training Loss Force: 4.569221476001619, time: 1.634565830230713
Validation Loss Energy: 3.1112189231896608, Validation Loss Force: 4.435802521477321, time: 0.11509513854980469
Test Loss Energy: 7.444963015925213, Test Loss Force: 8.355097917177327, time: 10.69534182548523

Epoch 5, Batch 100/104, Loss: 1.5660796165466309, Variance: 0.22179636359214783

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.690651705322118, Training Loss Force: 4.529242592557754, time: 1.7005510330200195
Validation Loss Energy: 3.027478958138587, Validation Loss Force: 4.504367250229697, time: 0.11597585678100586
Test Loss Energy: 7.508360766602496, Test Loss Force: 8.367578893533219, time: 10.566621541976929

Epoch 6, Batch 100/104, Loss: 1.5861668586730957, Variance: 0.21665413677692413

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.742868161727703, Training Loss Force: 4.534651739964215, time: 1.6077420711517334
Validation Loss Energy: 3.316441496195715, Validation Loss Force: 4.508929295691464, time: 0.1257784366607666
Test Loss Energy: 7.490940820713709, Test Loss Force: 8.368569913461059, time: 10.593547582626343

Epoch 7, Batch 100/104, Loss: 1.5449119806289673, Variance: 0.21633075177669525

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.639452801951384, Training Loss Force: 4.556259476807266, time: 1.8864197731018066
Validation Loss Energy: 3.8162416551117575, Validation Loss Force: 4.540012795117255, time: 0.1155846118927002
Test Loss Energy: 7.949265960582128, Test Loss Force: 8.442261085177515, time: 10.537652492523193

Epoch 8, Batch 100/104, Loss: 1.5524953603744507, Variance: 0.22375071048736572

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.776722853611296, Training Loss Force: 4.596196262936254, time: 1.6061453819274902
Validation Loss Energy: 2.396882831569989, Validation Loss Force: 4.76630298669612, time: 0.11704015731811523
Test Loss Energy: 7.214183464622331, Test Loss Force: 8.659529657940638, time: 10.614506721496582

Epoch 9, Batch 100/104, Loss: 2.1154699325561523, Variance: 0.14373159408569336

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.264595422080738, Training Loss Force: 5.352129520274612, time: 1.601853370666504
Validation Loss Energy: 6.971134125241684, Validation Loss Force: 4.628752239167272, time: 0.11581850051879883
Test Loss Energy: 9.133712879354727, Test Loss Force: 8.554554623038689, time: 10.73231554031372

Epoch 10, Batch 100/104, Loss: 1.5369919538497925, Variance: 0.20667977631092072

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.694892552681935, Training Loss Force: 4.702248318724136, time: 1.6470005512237549
Validation Loss Energy: 6.929578718552056, Validation Loss Force: 4.589933881619389, time: 0.11813950538635254
Test Loss Energy: 9.228802569984525, Test Loss Force: 8.491927053460381, time: 11.582478523254395

Epoch 11, Batch 100/104, Loss: 1.6209216117858887, Variance: 0.19721496105194092

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.3709398803104165, Training Loss Force: 4.856591026142482, time: 1.632960557937622
Validation Loss Energy: 5.470927029512433, Validation Loss Force: 4.507952668817426, time: 0.11447882652282715
Test Loss Energy: 8.525550071179335, Test Loss Force: 8.357070583944347, time: 10.670835733413696

Epoch 12, Batch 100/104, Loss: 1.713507890701294, Variance: 0.22196312248706818

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.6394240637147375, Training Loss Force: 4.547949943876324, time: 1.5888428688049316
Validation Loss Energy: 5.733584214011662, Validation Loss Force: 4.534958873512132, time: 0.11447381973266602
Test Loss Energy: 8.942048528053196, Test Loss Force: 8.380920930310607, time: 10.453970670700073

Epoch 13, Batch 100/104, Loss: 1.5791802406311035, Variance: 0.21656441688537598

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.583162485058081, Training Loss Force: 4.524778234619562, time: 1.6802101135253906
Validation Loss Energy: 5.942682120833443, Validation Loss Force: 4.549265143468846, time: 0.11494684219360352
Test Loss Energy: 9.014311234063664, Test Loss Force: 8.37991452639298, time: 10.519929885864258

Epoch 14, Batch 100/104, Loss: 1.8390661478042603, Variance: 0.22509106993675232

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.677916164931273, Training Loss Force: 4.524852582562759, time: 1.6282050609588623
Validation Loss Energy: 5.466560710229935, Validation Loss Force: 4.496602777111194, time: 0.11617684364318848
Test Loss Energy: 8.772081494342702, Test Loss Force: 8.320349541252922, time: 10.68195366859436

Epoch 15, Batch 100/104, Loss: 1.8661670684814453, Variance: 0.23217228055000305

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.714205824214941, Training Loss Force: 4.523479910779043, time: 1.5887274742126465
Validation Loss Energy: 6.177260726031179, Validation Loss Force: 4.5049940638754835, time: 0.11496949195861816
Test Loss Energy: 8.998922319905885, Test Loss Force: 8.28798034901274, time: 10.578266859054565

Epoch 16, Batch 100/104, Loss: 1.757996678352356, Variance: 0.21951593458652496

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.679594335571626, Training Loss Force: 4.529447302580642, time: 1.6291124820709229
Validation Loss Energy: 5.982212351640857, Validation Loss Force: 4.455147571537235, time: 0.11519646644592285
Test Loss Energy: 9.195968150784271, Test Loss Force: 8.339374948005146, time: 10.77430009841919

Epoch 17, Batch 100/104, Loss: 1.6457005739212036, Variance: 0.22444888949394226

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.707908399270711, Training Loss Force: 4.544703817399703, time: 1.6687562465667725
Validation Loss Energy: 5.822466166315074, Validation Loss Force: 4.605042873847173, time: 0.11543583869934082
Test Loss Energy: 9.018919282271495, Test Loss Force: 8.394870441160686, time: 10.573739290237427

Epoch 18, Batch 100/104, Loss: 1.690337896347046, Variance: 0.22620587050914764

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.698145216853145, Training Loss Force: 4.530264425550515, time: 1.6559882164001465
Validation Loss Energy: 5.952451061603587, Validation Loss Force: 4.451273573736383, time: 0.11328434944152832
Test Loss Energy: 8.832274819169973, Test Loss Force: 8.327618390158415, time: 10.614439249038696

Epoch 19, Batch 100/104, Loss: 1.6436039209365845, Variance: 0.22169558703899384

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.663543493536508, Training Loss Force: 4.514450139508252, time: 1.6024696826934814
Validation Loss Energy: 5.8740305511141555, Validation Loss Force: 4.483245523054425, time: 0.11784625053405762
Test Loss Energy: 9.03458574710773, Test Loss Force: 8.305375668393468, time: 10.708647727966309

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–„â–‚â–‚â–‚â–‚â–„â–â–ˆâ–ˆâ–†â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–‡
wandb:   test_error_force â–…â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–ˆâ–†â–…â–‚â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–‚â–
wandb:          test_loss â–ƒâ–â–‚â–â–â–â–â–‚â–â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  train_error_force â–„â–â–â–â–â–â–â–â–‚â–ˆâ–ƒâ–„â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–â–â–â–‚â–ƒâ–„â–†â–‚â–â–â–â–â–‚â–â–
wandb: valid_error_energy â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–ˆâ–ˆâ–†â–†â–†â–†â–‡â–†â–†â–†â–†
wandb:  valid_error_force â–†â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–…â–â–‚
wandb:         valid_loss â–â–â–‚â–â–â–â–â–‚â–â–ˆâ–…â–„â–ƒâ–„â–ƒâ–„â–„â–„â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3298
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.03459
wandb:   test_error_force 8.30538
wandb:          test_loss 5.30124
wandb: train_error_energy 4.66354
wandb:  train_error_force 4.51445
wandb:         train_loss 1.91618
wandb: valid_error_energy 5.87403
wandb:  valid_error_force 4.48325
wandb:         valid_loss 2.23124
wandb: 
wandb: ğŸš€ View run al_72_62 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/4k32sl0i
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_215415-4k32sl0i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.529008626937866, Uncertainty Bias: -0.22236362099647522
0.0001487732 0.9115486
2.3215208 6.282909
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2073 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1271 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3095 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2706 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3076 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3891 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2072 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 566 steps.
Found uncertainty sample 42 after 3763 steps.
Found uncertainty sample 43 after 2742 steps.
Found uncertainty sample 44 after 476 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3057 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 677 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3659 steps.
Found uncertainty sample 57 after 1180 steps.
Found uncertainty sample 58 after 2474 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 861 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 583 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2814 steps.
Found uncertainty sample 71 after 1105 steps.
Found uncertainty sample 72 after 1768 steps.
Found uncertainty sample 73 after 1455 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3809 steps.
Found uncertainty sample 81 after 178 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1251 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3862 steps.
Found uncertainty sample 93 after 484 steps.
Found uncertainty sample 94 after 3594 steps.
Found uncertainty sample 95 after 973 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1994 steps.
Found uncertainty sample 98 after 1562 steps.
Found uncertainty sample 99 after 3936 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_223218-ftov8h7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_63
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ftov8h7e
Training model 63. Added 32 samples to the dataset.
Epoch 0, Batch 100/104, Loss: 1.4050112962722778, Variance: 0.21928836405277252

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.460523815680114, Training Loss Force: 4.68783486783045, time: 1.6699507236480713
Validation Loss Energy: 4.179924276456716, Validation Loss Force: 4.514605577559456, time: 0.13262248039245605
Test Loss Energy: 7.370446354891873, Test Loss Force: 8.275543416847073, time: 10.625109910964966

Epoch 1, Batch 100/104, Loss: 1.7472437620162964, Variance: 0.3510744571685791

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.706822651668871, Training Loss Force: 4.571415019732846, time: 1.693053960800171
Validation Loss Energy: 4.1697324869784556, Validation Loss Force: 4.534660719525734, time: 0.11774682998657227
Test Loss Energy: 7.637768074447771, Test Loss Force: 8.331130705649473, time: 10.664799928665161

Epoch 2, Batch 100/104, Loss: 1.7162673473358154, Variance: 0.2290075719356537

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.680365372451441, Training Loss Force: 4.569933687546968, time: 1.640526294708252
Validation Loss Energy: 4.38755056289306, Validation Loss Force: 4.473426481726447, time: 0.11372876167297363
Test Loss Energy: 7.509965506997179, Test Loss Force: 8.277125165195178, time: 10.83246898651123

Epoch 3, Batch 100/104, Loss: 1.5528576374053955, Variance: 0.22582103312015533

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.648589285269312, Training Loss Force: 4.596199495920969, time: 1.6376492977142334
Validation Loss Energy: 4.126247429470217, Validation Loss Force: 4.440597256196583, time: 0.11690807342529297
Test Loss Energy: 7.62968665336747, Test Loss Force: 8.266152999635322, time: 10.621269464492798

Epoch 4, Batch 100/104, Loss: 1.4994350671768188, Variance: 0.21886523067951202

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.713728835859147, Training Loss Force: 4.577625741807855, time: 1.6011574268341064
Validation Loss Energy: 4.558830564639612, Validation Loss Force: 4.492546413279828, time: 0.11412262916564941
Test Loss Energy: 7.758414186118632, Test Loss Force: 8.344756420587158, time: 10.890087366104126

Epoch 5, Batch 100/104, Loss: 1.6377819776535034, Variance: 0.2206610143184662

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.774451204395034, Training Loss Force: 4.636683923968069, time: 1.5920100212097168
Validation Loss Energy: 4.550303227027161, Validation Loss Force: 4.525131593425755, time: 0.11773967742919922
Test Loss Energy: 7.680781784508938, Test Loss Force: 8.384247723931475, time: 10.58522915840149

Epoch 6, Batch 100/104, Loss: 1.4087094068527222, Variance: 0.22061976790428162

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.725795852819283, Training Loss Force: 4.553187036546567, time: 1.6437954902648926
Validation Loss Energy: 4.3126709371621725, Validation Loss Force: 4.498550909468917, time: 0.11283040046691895
Test Loss Energy: 7.771950555935871, Test Loss Force: 8.330992627462855, time: 10.725950717926025

Epoch 7, Batch 100/104, Loss: 1.3683496713638306, Variance: 0.2142808437347412

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.70391495767199, Training Loss Force: 4.5715600244499335, time: 1.8366611003875732
Validation Loss Energy: 3.957309461800535, Validation Loss Force: 4.4793804320194095, time: 0.12537240982055664
Test Loss Energy: 7.470202936674382, Test Loss Force: 8.298729952680919, time: 10.696868658065796

Epoch 8, Batch 100/104, Loss: 1.3841025829315186, Variance: 0.2138088047504425

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.684094993933227, Training Loss Force: 4.589257211495409, time: 1.6747007369995117
Validation Loss Energy: 4.199318981736172, Validation Loss Force: 4.478138383523424, time: 0.11874675750732422
Test Loss Energy: 7.634850460447398, Test Loss Force: 8.298501174706065, time: 10.677493572235107

Epoch 9, Batch 100/104, Loss: 1.5110297203063965, Variance: 0.22723965346813202

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.693195765616353, Training Loss Force: 4.537223315955842, time: 1.6634435653686523
Validation Loss Energy: 4.078733841773854, Validation Loss Force: 4.4646150182837925, time: 0.11607718467712402
Test Loss Energy: 7.384844708449786, Test Loss Force: 8.319643341976287, time: 10.82911467552185

Epoch 10, Batch 100/104, Loss: 1.6978338956832886, Variance: 0.38690006732940674

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.622658730987099, Training Loss Force: 4.547963710824481, time: 1.6183350086212158
Validation Loss Energy: 4.24358761196893, Validation Loss Force: 4.502554278043553, time: 0.11278104782104492
Test Loss Energy: 7.563066180664387, Test Loss Force: 8.382791565644897, time: 10.733008861541748

Epoch 11, Batch 100/104, Loss: 1.518038272857666, Variance: 0.220843106508255

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.67202411023773, Training Loss Force: 4.5662566962729745, time: 1.6177136898040771
Validation Loss Energy: 4.243364497484711, Validation Loss Force: 4.47295442313708, time: 0.11667656898498535
Test Loss Energy: 7.389521133572526, Test Loss Force: 8.252847527230147, time: 10.855796337127686

Epoch 12, Batch 100/104, Loss: 1.3625754117965698, Variance: 0.22171422839164734

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.771647742039468, Training Loss Force: 4.537459567919671, time: 1.6713314056396484
Validation Loss Energy: 3.7564861631105764, Validation Loss Force: 4.507248366308856, time: 0.11384916305541992
Test Loss Energy: 7.425519753616454, Test Loss Force: 8.324480793031551, time: 11.64104437828064

Epoch 13, Batch 100/104, Loss: 1.5549155473709106, Variance: 0.21615242958068848

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.668927402251699, Training Loss Force: 4.576617209014464, time: 1.6276071071624756
Validation Loss Energy: 4.647719642355693, Validation Loss Force: 4.460495861753275, time: 0.1263408660888672
Test Loss Energy: 7.653509577620379, Test Loss Force: 8.260782462323409, time: 10.710093021392822

Epoch 14, Batch 100/104, Loss: 1.5088708400726318, Variance: 0.21727177500724792

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.696230855268872, Training Loss Force: 4.553742942915672, time: 1.6373329162597656
Validation Loss Energy: 4.661021451795127, Validation Loss Force: 4.6494856313520465, time: 0.1159510612487793
Test Loss Energy: 7.874886654935033, Test Loss Force: 8.364527552138131, time: 10.827063083648682

Epoch 15, Batch 100/104, Loss: 1.4671317338943481, Variance: 0.21793466806411743

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.648881553510689, Training Loss Force: 4.568294191753898, time: 1.6589114665985107
Validation Loss Energy: 4.56289939794315, Validation Loss Force: 4.493330208673494, time: 0.12810659408569336
Test Loss Energy: 7.6185786223227705, Test Loss Force: 8.26671077768522, time: 10.625735759735107

Epoch 16, Batch 100/104, Loss: 1.7153469324111938, Variance: 0.22487862408161163

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.72210301349704, Training Loss Force: 4.555317517806408, time: 1.635892391204834
Validation Loss Energy: 4.433030067941374, Validation Loss Force: 4.453390934645011, time: 0.11920452117919922
Test Loss Energy: 7.5279131857566535, Test Loss Force: 8.266546417544543, time: 10.865411520004272

Epoch 17, Batch 100/104, Loss: 1.5204570293426514, Variance: 0.21802881360054016

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.752599970276713, Training Loss Force: 4.541411435690113, time: 1.6347219944000244
Validation Loss Energy: 4.176887291975407, Validation Loss Force: 4.452822460315456, time: 0.11745285987854004
Test Loss Energy: 7.548798157339454, Test Loss Force: 8.249418450362228, time: 10.737930297851562

Epoch 18, Batch 100/104, Loss: 1.551148772239685, Variance: 0.22141802310943604

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.696838494746038, Training Loss Force: 4.578318829499248, time: 1.6495482921600342
Validation Loss Energy: 4.43952844429613, Validation Loss Force: 4.464033629143775, time: 0.11744570732116699
Test Loss Energy: 7.621015550761629, Test Loss Force: 8.191383022720407, time: 10.699600458145142

Epoch 19, Batch 100/104, Loss: 1.4902100563049316, Variance: 0.21711456775665283

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.657688328054982, Training Loss Force: 4.538512467540389, time: 1.647791862487793
Validation Loss Energy: 4.4484574770478345, Validation Loss Force: 4.498136299519199, time: 0.1156761646270752
Test Loss Energy: 7.607415693424239, Test Loss Force: 8.253157464028364, time: 10.8159761428833

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–ƒâ–…â–†â–…â–‡â–‚â–…â–â–„â–â–‚â–…â–ˆâ–„â–ƒâ–ƒâ–„â–„
wandb:   test_error_force â–„â–†â–„â–„â–‡â–ˆâ–†â–…â–…â–†â–ˆâ–ƒâ–†â–„â–‡â–„â–„â–ƒâ–â–ƒ
wandb:          test_loss â–â–„â–ƒâ–„â–†â–…â–‡â–„â–„â–‚â–…â–â–ƒâ–…â–ˆâ–„â–‚â–ƒâ–„â–„
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–„â–ƒâ–†â–‚â–ƒâ–ƒâ–â–â–‚â–â–ƒâ–‚â–‚â–‚â–â–ƒâ–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–ƒâ–â–â–‚â–â–â–â–‚â–â–â–â–‚â–â–‚â–
wandb: valid_error_energy â–„â–„â–†â–„â–‡â–‡â–…â–ƒâ–„â–ƒâ–…â–…â–â–ˆâ–ˆâ–‡â–†â–„â–†â–†
wandb:  valid_error_force â–ƒâ–„â–‚â–â–ƒâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ˆâ–ƒâ–â–â–‚â–ƒ
wandb:         valid_loss â–„â–„â–…â–ƒâ–†â–†â–„â–‚â–ƒâ–ƒâ–„â–„â–â–†â–ˆâ–†â–…â–ƒâ–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 3326
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.60742
wandb:   test_error_force 8.25316
wandb:          test_loss 4.55324
wandb: train_error_energy 4.65769
wandb:  train_error_force 4.53851
wandb:         train_loss 1.91731
wandb: valid_error_energy 4.44846
wandb:  valid_error_force 4.49814
wandb:         valid_loss 1.82879
wandb: 
wandb: ğŸš€ View run al_72_63 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ftov8h7e
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_223218-ftov8h7e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.632739543914795, Uncertainty Bias: -0.26979660987854004
0.00038528442 0.0061655045
2.2916787 6.394322
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2204 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2807 steps.
Found uncertainty sample 8 after 1418 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3446 steps.
Found uncertainty sample 13 after 2652 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1633 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3652 steps.
Found uncertainty sample 27 after 2309 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3797 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2819 steps.
Found uncertainty sample 42 after 2124 steps.
Found uncertainty sample 43 after 3431 steps.
Found uncertainty sample 44 after 571 steps.
Found uncertainty sample 45 after 2827 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2156 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1986 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3965 steps.
Found uncertainty sample 61 after 1940 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2202 steps.
Found uncertainty sample 70 after 1839 steps.
Found uncertainty sample 71 after 3478 steps.
Found uncertainty sample 72 after 3103 steps.
Found uncertainty sample 73 after 2395 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1996 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3355 steps.
Found uncertainty sample 80 after 3090 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 795 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1354 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2731 steps.
Found uncertainty sample 89 after 2732 steps.
Found uncertainty sample 90 after 1145 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2203 steps.
Found uncertainty sample 95 after 1362 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_231115-wo9c2zzo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_64
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wo9c2zzo
Training model 64. Added 33 samples to the dataset.
Epoch 0, Batch 100/105, Loss: 1.6803871393203735, Variance: 0.21823790669441223

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.315150367051102, Training Loss Force: 4.695105837852683, time: 1.6317846775054932
Validation Loss Energy: 7.197617890531409, Validation Loss Force: 4.627879079223041, time: 0.11885452270507812
Test Loss Energy: 9.456782027632192, Test Loss Force: 8.225648474733768, time: 10.896723985671997

Epoch 1, Batch 100/105, Loss: 1.5002161264419556, Variance: 0.21851122379302979

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.749800117424706, Training Loss Force: 4.545204977296731, time: 1.6797468662261963
Validation Loss Energy: 5.107618715001778, Validation Loss Force: 4.831670780297363, time: 0.11697649955749512
Test Loss Energy: 8.696922072588983, Test Loss Force: 8.224883840544722, time: 11.10480546951294

Epoch 2, Batch 100/105, Loss: 2.222470760345459, Variance: 0.22503748536109924

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.722888989274324, Training Loss Force: 4.552269968163508, time: 1.976311206817627
Validation Loss Energy: 2.7047325005884306, Validation Loss Force: 4.356263246975698, time: 0.13396930694580078
Test Loss Energy: 7.075249225891744, Test Loss Force: 8.238085668040213, time: 11.108358144760132

Epoch 3, Batch 100/105, Loss: 2.012579917907715, Variance: 0.2261863350868225

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.662116156936264, Training Loss Force: 4.540644098197155, time: 1.7755522727966309
Validation Loss Energy: 4.100062799700937, Validation Loss Force: 4.251657661378694, time: 0.13642263412475586
Test Loss Energy: 7.461807906503666, Test Loss Force: 8.288274421508666, time: 11.237700939178467

Epoch 4, Batch 100/105, Loss: 1.499705195426941, Variance: 0.21925562620162964

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.7348493093581885, Training Loss Force: 4.576507665867796, time: 1.6767656803131104
Validation Loss Energy: 5.838027844916529, Validation Loss Force: 4.609098569671102, time: 0.12257122993469238
Test Loss Energy: 8.590715917466305, Test Loss Force: 8.309184775042487, time: 11.394543409347534

Epoch 5, Batch 100/105, Loss: 1.6274778842926025, Variance: 0.21997681260108948

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.710591268176597, Training Loss Force: 4.523695646758154, time: 1.7386271953582764
Validation Loss Energy: 5.674437128340204, Validation Loss Force: 4.8879178972353055, time: 0.13272452354431152
Test Loss Energy: 8.391084202982698, Test Loss Force: 8.279701869235716, time: 11.166032314300537

Epoch 6, Batch 100/105, Loss: 2.204432249069214, Variance: 0.20559224486351013

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.742509895656493, Training Loss Force: 4.550340677856847, time: 1.8550708293914795
Validation Loss Energy: 2.981389339630432, Validation Loss Force: 4.283331234041192, time: 0.12840843200683594
Test Loss Energy: 6.8914620975714325, Test Loss Force: 8.223352175267344, time: 11.337972402572632

Epoch 7, Batch 100/105, Loss: 1.9883756637573242, Variance: 0.21831172704696655

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.634313199624259, Training Loss Force: 4.579037912630753, time: 1.6724848747253418
Validation Loss Energy: 3.80151231377778, Validation Loss Force: 4.57093248427469, time: 0.13132572174072266
Test Loss Energy: 7.809342415660061, Test Loss Force: 8.391820843812937, time: 11.129350423812866

Epoch 8, Batch 100/105, Loss: 1.5980778932571411, Variance: 0.222550168633461

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.672859037706086, Training Loss Force: 4.5452526497005445, time: 1.763545274734497
Validation Loss Energy: 5.298968257986044, Validation Loss Force: 4.542485016421442, time: 0.12599468231201172
Test Loss Energy: 8.788039888921515, Test Loss Force: 8.268158999157423, time: 11.159335613250732

Epoch 9, Batch 100/105, Loss: 1.7279551029205322, Variance: 0.2196359783411026

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.605354398585619, Training Loss Force: 4.538060614422394, time: 1.901947021484375
Validation Loss Energy: 4.801262042606783, Validation Loss Force: 4.375328773034425, time: 0.13975000381469727
Test Loss Energy: 8.184361362214648, Test Loss Force: 8.229069227739371, time: 11.17821979522705

Epoch 10, Batch 100/105, Loss: 2.4527554512023926, Variance: 0.21908797323703766

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.714821780486664, Training Loss Force: 4.557086170309097, time: 1.7009718418121338
Validation Loss Energy: 2.0884780854822735, Validation Loss Force: 4.165615111801105, time: 0.12318563461303711
Test Loss Energy: 6.959754808565593, Test Loss Force: 8.340093430224828, time: 11.330752611160278

Epoch 11, Batch 100/105, Loss: 1.9811254739761353, Variance: 0.22957253456115723

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.713326601705589, Training Loss Force: 4.527259884208459, time: 1.721879482269287
Validation Loss Energy: 4.3326306282878955, Validation Loss Force: 4.765174647910656, time: 0.12187814712524414
Test Loss Energy: 7.587147746205455, Test Loss Force: 8.36435730700348, time: 11.37329363822937

Epoch 12, Batch 100/105, Loss: 1.437749981880188, Variance: 0.21864020824432373

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.691466113441249, Training Loss Force: 4.563314107563818, time: 1.6934561729431152
Validation Loss Energy: 5.825815332938974, Validation Loss Force: 4.13093498610724, time: 0.1323847770690918
Test Loss Energy: 8.674764251888023, Test Loss Force: 8.227502737473893, time: 12.074948072433472

Epoch 13, Batch 100/105, Loss: 1.8864703178405762, Variance: 0.21890294551849365

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.702712871161063, Training Loss Force: 4.5395235040566515, time: 1.73173189163208
Validation Loss Energy: 5.984102664243687, Validation Loss Force: 4.289755832685597, time: 0.1312415599822998
Test Loss Energy: 8.330491066960363, Test Loss Force: 8.288491098406373, time: 11.29224443435669

Epoch 14, Batch 100/105, Loss: 2.6837923526763916, Variance: 0.2117035835981369

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.730823782022546, Training Loss Force: 4.518294121650968, time: 1.8370583057403564
Validation Loss Energy: 3.153592676102097, Validation Loss Force: 4.1582589396731855, time: 0.12337279319763184
Test Loss Energy: 7.042485025581526, Test Loss Force: 8.225170922861597, time: 11.136313676834106

Epoch 15, Batch 100/105, Loss: 2.090893268585205, Variance: 0.2116386741399765

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.609479334970969, Training Loss Force: 4.574199184850231, time: 1.6652112007141113
Validation Loss Energy: 3.7122879705509804, Validation Loss Force: 4.632578585770895, time: 0.12454438209533691
Test Loss Energy: 7.507260459258867, Test Loss Force: 8.360495519865637, time: 11.288507223129272

Epoch 16, Batch 100/105, Loss: 1.291393756866455, Variance: 0.22283875942230225

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.655430541277685, Training Loss Force: 4.533972930585159, time: 1.912585735321045
Validation Loss Energy: 6.086824394643094, Validation Loss Force: 4.4386226262104955, time: 0.13133525848388672
Test Loss Energy: 9.276136210699995, Test Loss Force: 8.263991546738378, time: 11.109095573425293

Epoch 17, Batch 100/105, Loss: 1.7624825239181519, Variance: 0.2230321764945984

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.713127289492739, Training Loss Force: 4.554384994227091, time: 1.7354726791381836
Validation Loss Energy: 4.545439093757417, Validation Loss Force: 4.485981681519585, time: 0.12974143028259277
Test Loss Energy: 8.44434703574688, Test Loss Force: 8.263036512942458, time: 11.262585401535034

Epoch 18, Batch 100/105, Loss: 2.335765838623047, Variance: 0.23285585641860962

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.6438616894572995, Training Loss Force: 4.521312607627898, time: 1.7261009216308594
Validation Loss Energy: 1.9311129384454198, Validation Loss Force: 4.065477308394092, time: 0.13162946701049805
Test Loss Energy: 6.808622651430062, Test Loss Force: 8.18575279489399, time: 11.405763387680054

Epoch 19, Batch 100/105, Loss: 2.2545642852783203, Variance: 0.23007217049598694

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.67268398688718, Training Loss Force: 4.5518827189501785, time: 1.6354939937591553
Validation Loss Energy: 4.896651278030788, Validation Loss Force: 4.626819470980618, time: 0.12358689308166504
Test Loss Energy: 7.684685988370373, Test Loss Force: 8.27034232259456, time: 11.182279109954834

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.039 MB of 0.049 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–‚â–ƒâ–†â–…â–â–„â–†â–…â–â–ƒâ–†â–…â–‚â–ƒâ–ˆâ–…â–â–ƒ
wandb:   test_error_force â–‚â–‚â–ƒâ–„â–…â–„â–‚â–ˆâ–„â–‚â–†â–‡â–‚â–„â–‚â–‡â–„â–„â–â–„
wandb:          test_loss â–ˆâ–†â–‚â–‚â–…â–„â–â–„â–†â–…â–‚â–‚â–…â–„â–‚â–„â–ˆâ–†â–‚â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–â–ƒâ–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–…â–‚â–„â–†â–†â–‚â–ƒâ–…â–…â–â–„â–†â–†â–ƒâ–ƒâ–‡â–„â–â–…
wandb:  valid_error_force â–†â–ˆâ–ƒâ–ƒâ–†â–ˆâ–ƒâ–…â–…â–„â–‚â–‡â–‚â–ƒâ–‚â–†â–„â–…â–â–†
wandb:         valid_loss â–ˆâ–…â–‚â–ƒâ–…â–…â–‚â–ƒâ–…â–„â–â–„â–…â–…â–‚â–ƒâ–†â–„â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3355
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.68469
wandb:   test_error_force 8.27034
wandb:          test_loss 4.51822
wandb: train_error_energy 4.67268
wandb:  train_error_force 4.55188
wandb:         train_loss 1.92106
wandb: valid_error_energy 4.89665
wandb:  valid_error_force 4.62682
wandb:         valid_loss 1.96139
wandb: 
wandb: ğŸš€ View run al_72_64 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wo9c2zzo
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_231115-wo9c2zzo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.704101085662842, Uncertainty Bias: -0.30817168951034546
6.67572e-06 0.080848694
2.2179 6.6215267
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 910 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3369 steps.
Found uncertainty sample 6 after 2846 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1107 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 261 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3910 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3056 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2545 steps.
Found uncertainty sample 33 after 2228 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1969 steps.
Found uncertainty sample 44 after 2119 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1059 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 49 steps.
Found uncertainty sample 52 after 3075 steps.
Found uncertainty sample 53 after 2249 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3999 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 203 steps.
Found uncertainty sample 65 after 3157 steps.
Found uncertainty sample 66 after 1411 steps.
Found uncertainty sample 67 after 1639 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3333 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2213 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2528 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2955 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2285 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 395 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_235051-hhzvpfhj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_65
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hhzvpfhj
Training model 65. Added 26 samples to the dataset.
Epoch 0, Batch 100/106, Loss: 1.4598946571350098, Variance: 0.18414007127285004

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.286049284183135, Training Loss Force: 4.707009407133601, time: 1.8891716003417969
Validation Loss Energy: 3.099049200799648, Validation Loss Force: 4.692243228760538, time: 0.13733863830566406
Test Loss Energy: 6.895292221389887, Test Loss Force: 8.236790008741378, time: 10.671934604644775

Epoch 1, Batch 100/106, Loss: 1.360105276107788, Variance: 0.1641262024641037

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.117249615563507, Training Loss Force: 4.512074089851144, time: 1.7495718002319336
Validation Loss Energy: 3.3868481070116814, Validation Loss Force: 4.462962293659668, time: 0.11260223388671875
Test Loss Energy: 7.285167065794027, Test Loss Force: 8.229905820202571, time: 11.992119073867798

Epoch 2, Batch 100/106, Loss: 1.6839863061904907, Variance: 0.16970416903495789

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.217772835804836, Training Loss Force: 4.497795876206817, time: 2.1635429859161377
Validation Loss Energy: 2.8993491937278466, Validation Loss Force: 4.623856635324903, time: 0.14345836639404297
Test Loss Energy: 6.984576652254888, Test Loss Force: 8.237020003818786, time: 10.307116508483887

Epoch 3, Batch 100/106, Loss: 1.2881654500961304, Variance: 0.16265743970870972

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.124825821919127, Training Loss Force: 4.501658891797339, time: 1.730882167816162
Validation Loss Energy: 3.1549137721448868, Validation Loss Force: 4.1790240993227785, time: 0.11533880233764648
Test Loss Energy: 7.023530772696593, Test Loss Force: 8.401850099970162, time: 9.801130056381226

Epoch 4, Batch 100/106, Loss: 1.3782844543457031, Variance: 0.16897930204868317

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1504331129561725, Training Loss Force: 4.509992671103714, time: 1.768855333328247
Validation Loss Energy: 3.3292283090121426, Validation Loss Force: 4.395662325656161, time: 0.11556339263916016
Test Loss Energy: 7.477241130655677, Test Loss Force: 8.269774896325542, time: 10.08562970161438

Epoch 5, Batch 100/106, Loss: 1.799290657043457, Variance: 0.1764698028564453

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.2317429992896867, Training Loss Force: 4.514278984941949, time: 1.6226937770843506
Validation Loss Energy: 2.5149774913581533, Validation Loss Force: 4.4103843189083225, time: 0.11653757095336914
Test Loss Energy: 6.878547541253557, Test Loss Force: 8.307281613691591, time: 9.88473653793335

Epoch 6, Batch 100/106, Loss: 1.0466619729995728, Variance: 0.1661185473203659

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.2239527280600426, Training Loss Force: 4.5227651413663175, time: 1.7121045589447021
Validation Loss Energy: 3.1361256176189376, Validation Loss Force: 4.757424870955784, time: 0.11212396621704102
Test Loss Energy: 7.002219181019882, Test Loss Force: 8.317773089026709, time: 9.741798877716064

Epoch 7, Batch 100/106, Loss: 1.7189885377883911, Variance: 0.17265939712524414

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1678362044755337, Training Loss Force: 4.517992345859885, time: 1.736149549484253
Validation Loss Energy: 3.8997073288865725, Validation Loss Force: 4.921196691770796, time: 0.11536335945129395
Test Loss Energy: 7.364873370523064, Test Loss Force: 8.229252128875324, time: 10.020241260528564

Epoch 8, Batch 100/106, Loss: 2.1136927604675293, Variance: 0.16587814688682556

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.2220921918537404, Training Loss Force: 4.517794771106573, time: 1.6961019039154053
Validation Loss Energy: 2.6048093502380922, Validation Loss Force: 4.463440883877315, time: 0.11313652992248535
Test Loss Energy: 6.8557713951479196, Test Loss Force: 8.295174465023305, time: 9.761374950408936

Epoch 9, Batch 100/106, Loss: 1.2852951288223267, Variance: 0.1681237816810608

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1600018247987975, Training Loss Force: 4.532722540058704, time: 1.69761061668396
Validation Loss Energy: 3.3845005062061646, Validation Loss Force: 4.508097477985327, time: 0.11673235893249512
Test Loss Energy: 7.1574310379464325, Test Loss Force: 8.34874985065672, time: 10.002163887023926

Epoch 10, Batch 100/106, Loss: 1.3430287837982178, Variance: 0.1695222109556198

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.231273663145727, Training Loss Force: 4.505068317733693, time: 1.7013299465179443
Validation Loss Energy: 2.9426055700232165, Validation Loss Force: 4.386579205855475, time: 0.11380600929260254
Test Loss Energy: 7.227456956608597, Test Loss Force: 8.325125670857528, time: 9.818937301635742

Epoch 11, Batch 100/106, Loss: 2.038844347000122, Variance: 0.17132866382598877

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.185928531574698, Training Loss Force: 4.506755591086309, time: 1.6898033618927002
Validation Loss Energy: 3.0586446224792243, Validation Loss Force: 4.308143999202412, time: 0.11287546157836914
Test Loss Energy: 6.880534664027958, Test Loss Force: 8.280164060434238, time: 9.72934603691101

Epoch 12, Batch 100/106, Loss: 1.7518815994262695, Variance: 0.31042277812957764

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.190884523919637, Training Loss Force: 4.52563624573652, time: 1.6473073959350586
Validation Loss Energy: 2.998856175444445, Validation Loss Force: 4.474171755357867, time: 0.11770153045654297
Test Loss Energy: 6.907868943146916, Test Loss Force: 8.330184974993784, time: 12.631059169769287

Epoch 13, Batch 100/106, Loss: 1.5265852212905884, Variance: 0.16373175382614136

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.2007461538727524, Training Loss Force: 4.506162366871119, time: 1.9186220169067383
Validation Loss Energy: 3.182474645682099, Validation Loss Force: 4.200729442329528, time: 0.14495015144348145
Test Loss Energy: 7.068351399742104, Test Loss Force: 8.245179589929956, time: 11.780978441238403

Epoch 14, Batch 100/106, Loss: 1.8988977670669556, Variance: 0.16960963606834412

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1843362413173866, Training Loss Force: 4.513878604811048, time: 1.8020102977752686
Validation Loss Energy: 2.909753706463517, Validation Loss Force: 4.5999339529630054, time: 0.13015460968017578
Test Loss Energy: 6.935285749746712, Test Loss Force: 8.29437716492081, time: 10.650613069534302

Epoch 15, Batch 100/106, Loss: 1.255881667137146, Variance: 0.16226917505264282

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1757479805863493, Training Loss Force: 4.50876914826054, time: 1.712705135345459
Validation Loss Energy: 3.263841736979593, Validation Loss Force: 4.444632911797378, time: 0.12203717231750488
Test Loss Energy: 6.94734236534275, Test Loss Force: 8.270657076507497, time: 10.527849197387695

Epoch 16, Batch 100/106, Loss: 1.5497533082962036, Variance: 0.16116060316562653

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.130472261920259, Training Loss Force: 4.507446369595241, time: 1.6820759773254395
Validation Loss Energy: 4.3621895120715175, Validation Loss Force: 4.645554259134594, time: 0.12344789505004883
Test Loss Energy: 7.438457884884428, Test Loss Force: 8.357547781411176, time: 10.37618350982666

Epoch 17, Batch 100/106, Loss: 1.6860485076904297, Variance: 0.17111191153526306

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1885809454344667, Training Loss Force: 4.608157603470848, time: 1.9340810775756836
Validation Loss Energy: 2.8322436901117842, Validation Loss Force: 4.507428282978766, time: 0.12005209922790527
Test Loss Energy: 7.038406605846642, Test Loss Force: 8.293632102300467, time: 10.395395517349243

Epoch 18, Batch 100/106, Loss: 1.172434687614441, Variance: 0.15573683381080627

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.22185463538482, Training Loss Force: 4.512728985017146, time: 1.654083013534546
Validation Loss Energy: 3.0682833017990006, Validation Loss Force: 4.561818042347476, time: 0.1283726692199707
Test Loss Energy: 7.078061441608633, Test Loss Force: 8.399361391045517, time: 10.331634759902954

Epoch 19, Batch 100/106, Loss: 1.324735164642334, Variance: 0.15625816583633423

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.177622178385014, Training Loss Force: 4.508145512901713, time: 1.6808722019195557
Validation Loss Energy: 3.2985297303166132, Validation Loss Force: 4.57427949843018, time: 0.11615371704101562
Test Loss Energy: 7.339442257418229, Test Loss Force: 8.326744613113654, time: 10.49094820022583

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–‚â–ƒâ–ˆâ–â–ƒâ–‡â–â–„â–…â–â–‚â–ƒâ–‚â–‚â–ˆâ–ƒâ–„â–†
wandb:   test_error_force â–â–â–â–ˆâ–ƒâ–„â–…â–â–„â–†â–…â–ƒâ–…â–‚â–„â–ƒâ–†â–„â–ˆâ–…
wandb:          test_loss â–â–ˆâ–ƒâ–…â–ˆâ–ƒâ–„â–‡â–ƒâ–„â–‡â–„â–„â–†â–„â–ƒâ–ˆâ–ƒâ–„â–‡
wandb: train_error_energy â–ˆâ–â–‚â–â–â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–â–‚â–
wandb:  train_error_force â–ˆâ–â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–…â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–
wandb: valid_error_energy â–ƒâ–„â–‚â–ƒâ–„â–â–ƒâ–†â–â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–„â–ˆâ–‚â–ƒâ–„
wandb:  valid_error_force â–†â–„â–…â–â–ƒâ–ƒâ–†â–ˆâ–„â–„â–ƒâ–‚â–„â–â–…â–„â–…â–„â–…â–…
wandb:         valid_loss â–ƒâ–„â–‚â–â–„â–â–ƒâ–†â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–ˆâ–‚â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3378
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.33944
wandb:   test_error_force 8.32674
wandb:          test_loss 5.47541
wandb: train_error_energy 3.17762
wandb:  train_error_force 4.50815
wandb:         train_loss 1.5318
wandb: valid_error_energy 3.29853
wandb:  valid_error_force 4.57428
wandb:         valid_loss 1.62599
wandb: 
wandb: ğŸš€ View run al_72_65 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hhzvpfhj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_235051-hhzvpfhj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6565637588500977, Uncertainty Bias: -0.122386634349823
7.6293945e-06 0.025953293
2.5395317 6.761206
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3340 steps.
Found uncertainty sample 2 after 1772 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3382 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3610 steps.
Found uncertainty sample 11 after 1710 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2942 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2871 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 788 steps.
Found uncertainty sample 27 after 1838 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1544 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1080 steps.
Found uncertainty sample 39 after 1063 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1440 steps.
Found uncertainty sample 46 after 2200 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1790 steps.
Found uncertainty sample 49 after 1540 steps.
Found uncertainty sample 50 after 1906 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3302 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3934 steps.
Found uncertainty sample 60 after 854 steps.
Found uncertainty sample 61 after 1775 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2376 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 108 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2223 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3170 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1560 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3084 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 588 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3439 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1202 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_002911-wr0mc9ej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_66
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wr0mc9ej
Training model 66. Added 30 samples to the dataset.
Epoch 0, Batch 100/107, Loss: 3.7791879177093506, Variance: 0.15354697406291962

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.216030527969239, Training Loss Force: 5.101855167638784, time: 1.765368938446045
Validation Loss Energy: 6.073056761350379, Validation Loss Force: 4.851138298387537, time: 0.11883759498596191
Test Loss Energy: 8.627020289061154, Test Loss Force: 8.502253208029817, time: 11.89329981803894

Epoch 1, Batch 100/107, Loss: 1.638961911201477, Variance: 0.12545228004455566

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.795627337229098, Training Loss Force: 4.896102404829136, time: 1.8574912548065186
Validation Loss Energy: 5.900945238789885, Validation Loss Force: 5.7807626846434035, time: 0.13882708549499512
Test Loss Energy: 8.692038798321938, Test Loss Force: 9.423367139113678, time: 12.039459228515625

Epoch 2, Batch 100/107, Loss: 1.1510968208312988, Variance: 0.15117934346199036

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.894099929129252, Training Loss Force: 4.948308780153266, time: 1.7516255378723145
Validation Loss Energy: 3.345326471809186, Validation Loss Force: 4.862399270881494, time: 0.12170839309692383
Test Loss Energy: 7.436059159942491, Test Loss Force: 8.533710505998037, time: 10.41063117980957

Epoch 3, Batch 100/107, Loss: 1.6325129270553589, Variance: 0.2146863043308258

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.628090378022223, Training Loss Force: 4.558028518700061, time: 1.7588090896606445
Validation Loss Energy: 3.61825018839666, Validation Loss Force: 4.394672041741171, time: 0.12001252174377441
Test Loss Energy: 7.215451055950709, Test Loss Force: 8.26440291807612, time: 10.56360125541687

Epoch 4, Batch 100/107, Loss: 2.0659334659576416, Variance: 0.19656528532505035

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.536186759626129, Training Loss Force: 4.5072285591599694, time: 1.6779251098632812
Validation Loss Energy: 5.453527514003539, Validation Loss Force: 4.504733986313039, time: 0.11699175834655762
Test Loss Energy: 8.274839824314993, Test Loss Force: 8.228159996170705, time: 10.44482135772705

Epoch 5, Batch 100/107, Loss: 2.2798268795013428, Variance: 0.21975404024124146

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.683466424706906, Training Loss Force: 4.500270015164443, time: 1.778745174407959
Validation Loss Energy: 6.525711812895044, Validation Loss Force: 4.191698946670329, time: 0.11976504325866699
Test Loss Energy: 8.813685592129444, Test Loss Force: 8.231182229695452, time: 10.414089679718018

Epoch 6, Batch 100/107, Loss: 1.529981255531311, Variance: 0.21159890294075012

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.649443345024521, Training Loss Force: 4.52067713045779, time: 1.7205219268798828
Validation Loss Energy: 3.9543873003754757, Validation Loss Force: 4.456384053304571, time: 0.11881303787231445
Test Loss Energy: 7.463270486055457, Test Loss Force: 8.180750633955933, time: 10.59208083152771

Epoch 7, Batch 100/107, Loss: 1.4065700769424438, Variance: 0.21981851756572723

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.686793378522735, Training Loss Force: 4.504256700201293, time: 1.6586384773254395
Validation Loss Energy: 2.2166724239453335, Validation Loss Force: 4.192266530323299, time: 0.1211099624633789
Test Loss Energy: 6.645035636679714, Test Loss Force: 8.22219120398823, time: 10.443007230758667

Epoch 8, Batch 100/107, Loss: 2.019491672515869, Variance: 0.23360121250152588

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.690124612996817, Training Loss Force: 4.50812188696323, time: 1.6755540370941162
Validation Loss Energy: 5.0754773144636856, Validation Loss Force: 4.801813074519905, time: 0.12122249603271484
Test Loss Energy: 8.379840805418574, Test Loss Force: 8.340942109775487, time: 10.481208324432373

Epoch 9, Batch 100/107, Loss: 2.3424618244171143, Variance: 0.21625056862831116

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.736476499341024, Training Loss Force: 4.513276952386105, time: 1.6915900707244873
Validation Loss Energy: 6.236609772617993, Validation Loss Force: 4.384414713310959, time: 0.11968159675598145
Test Loss Energy: 8.876983416821522, Test Loss Force: 8.181725523777473, time: 10.526337146759033

Epoch 10, Batch 100/107, Loss: 1.874847412109375, Variance: 0.3477816581726074

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.719052485717201, Training Loss Force: 4.504221106434266, time: 1.7100260257720947
Validation Loss Energy: 3.7101834502297684, Validation Loss Force: 4.615578538709795, time: 0.11862587928771973
Test Loss Energy: 7.045074891583621, Test Loss Force: 8.232046820180686, time: 10.436219453811646

Epoch 11, Batch 100/107, Loss: 1.7249301671981812, Variance: 0.22597266733646393

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.689060148347259, Training Loss Force: 4.513593629532017, time: 1.6216158866882324
Validation Loss Energy: 2.871398055400872, Validation Loss Force: 4.687307989810194, time: 0.12312483787536621
Test Loss Energy: 6.853487712045356, Test Loss Force: 8.16750167054993, time: 10.545035123825073

Epoch 12, Batch 100/107, Loss: 2.1016464233398438, Variance: 0.21083049476146698

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.664501266939125, Training Loss Force: 4.512530132556785, time: 1.7094783782958984
Validation Loss Energy: 4.866358328296091, Validation Loss Force: 4.565940538915183, time: 0.11959147453308105
Test Loss Energy: 8.200418486660638, Test Loss Force: 8.154719631519058, time: 10.440520286560059

Epoch 13, Batch 100/107, Loss: 2.2508058547973633, Variance: 0.2285483479499817

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.695654542967371, Training Loss Force: 4.4968607133040015, time: 1.7067718505859375
Validation Loss Energy: 6.375829499618619, Validation Loss Force: 4.3906892329510105, time: 0.12223196029663086
Test Loss Energy: 8.70483614673095, Test Loss Force: 8.346127073921698, time: 10.484318494796753

Epoch 14, Batch 100/107, Loss: 1.70319664478302, Variance: 0.21441447734832764

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.655787284718926, Training Loss Force: 4.537264104749321, time: 1.6784822940826416
Validation Loss Energy: 3.4936247167814822, Validation Loss Force: 4.336968371696666, time: 0.12488055229187012
Test Loss Energy: 7.262124959463584, Test Loss Force: 8.192824118779937, time: 10.577346563339233

Epoch 15, Batch 100/107, Loss: 1.3956642150878906, Variance: 0.21493686735630035

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.651477100952422, Training Loss Force: 4.503962768604588, time: 1.7001230716705322
Validation Loss Energy: 2.002634342340474, Validation Loss Force: 4.246522242866161, time: 0.1301593780517578
Test Loss Energy: 6.463004822323077, Test Loss Force: 8.177359124054291, time: 11.387386798858643

Epoch 16, Batch 100/107, Loss: 1.9754762649536133, Variance: 0.23010341823101044

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.706285278884389, Training Loss Force: 4.532754409428065, time: 1.6662287712097168
Validation Loss Energy: 5.724982430681423, Validation Loss Force: 4.453391083091108, time: 0.12405824661254883
Test Loss Energy: 8.42654803469169, Test Loss Force: 8.310385952675027, time: 10.688858985900879

Epoch 17, Batch 100/107, Loss: 2.2456772327423096, Variance: 0.21710467338562012

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.67049249246332, Training Loss Force: 4.510136601557624, time: 1.6429762840270996
Validation Loss Energy: 5.509433947148211, Validation Loss Force: 4.441111770369774, time: 0.11925148963928223
Test Loss Energy: 8.468524806017063, Test Loss Force: 8.172641489984064, time: 10.509275913238525

Epoch 18, Batch 100/107, Loss: 1.8624299764633179, Variance: 0.22556576132774353

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.7077932328394825, Training Loss Force: 4.489861139917062, time: 1.721677541732788
Validation Loss Energy: 4.335948250116123, Validation Loss Force: 4.833592860365012, time: 0.12303280830383301
Test Loss Energy: 7.512596341790507, Test Loss Force: 8.185025037513446, time: 10.330368757247925

Epoch 19, Batch 100/107, Loss: 1.40127694606781, Variance: 0.22221432626247406

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.6910469231663905, Training Loss Force: 4.547234217728219, time: 1.6570336818695068
Validation Loss Energy: 2.954230977686009, Validation Loss Force: 4.786399767792687, time: 0.11845183372497559
Test Loss Energy: 6.831393425496829, Test Loss Force: 8.249459785216876, time: 10.516698598861694

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–‡â–„â–ƒâ–†â–ˆâ–„â–‚â–‡â–ˆâ–ƒâ–‚â–†â–ˆâ–ƒâ–â–‡â–‡â–„â–‚
wandb:   test_error_force â–ƒâ–ˆâ–ƒâ–‚â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–‚â–â–â–‚
wandb:          test_loss â–…â–ˆâ–„â–‚â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–â–â–‚â–‚â–‚â–â–‚â–‚â–â–
wandb: train_error_energy â–†â–â–…â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–ˆâ–†â–†â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–â–ˆâ–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb: valid_error_energy â–‡â–‡â–ƒâ–„â–†â–ˆâ–„â–â–†â–ˆâ–„â–‚â–…â–ˆâ–ƒâ–â–‡â–†â–…â–‚
wandb:  valid_error_force â–„â–ˆâ–„â–‚â–‚â–â–‚â–â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–„â–„
wandb:         valid_loss â–†â–ˆâ–‚â–‚â–ƒâ–„â–‚â–â–ƒâ–„â–‚â–‚â–ƒâ–„â–‚â–â–ƒâ–ƒâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3405
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.83139
wandb:   test_error_force 8.24946
wandb:          test_loss 4.28865
wandb: train_error_energy 4.69105
wandb:  train_error_force 4.54723
wandb:         train_loss 1.92992
wandb: valid_error_energy 2.95423
wandb:  valid_error_force 4.7864
wandb:         valid_loss 1.63189
wandb: 
wandb: ğŸš€ View run al_72_66 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wr0mc9ej
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_002911-wr0mc9ej/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5660769939422607, Uncertainty Bias: -0.2460455596446991
0.00010681152 0.021438599
2.3734028 6.538549
(48745, 22, 3)
Found uncertainty sample 0 after 2108 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2177 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2672 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 948 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2813 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3888 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3890 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 619 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2058 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 792 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 661 steps.
Found uncertainty sample 35 after 1267 steps.
Found uncertainty sample 36 after 632 steps.
Found uncertainty sample 37 after 363 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2720 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2646 steps.
Found uncertainty sample 44 after 3691 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1036 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1751 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3971 steps.
Found uncertainty sample 58 after 3859 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3963 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2198 steps.
Found uncertainty sample 70 after 1088 steps.
Found uncertainty sample 71 after 340 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3703 steps.
Found uncertainty sample 79 after 1442 steps.
Found uncertainty sample 80 after 1780 steps.
Found uncertainty sample 81 after 2903 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1994 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2794 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2615 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 112 steps.
Found uncertainty sample 98 after 3034 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_010702-cxn5swx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_67
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/cxn5swx4
Training model 67. Added 34 samples to the dataset.
Epoch 0, Batch 100/108, Loss: 1.6088203191757202, Variance: 0.2229490876197815

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.349013577377597, Training Loss Force: 4.890425799208376, time: 1.8108980655670166
Validation Loss Energy: 3.8362709674571076, Validation Loss Force: 4.410847322285755, time: 0.13717198371887207
Test Loss Energy: 7.46057408161059, Test Loss Force: 8.182212229566579, time: 11.374724626541138

Epoch 1, Batch 100/108, Loss: 1.4231902360916138, Variance: 0.21966113150119781

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.7049708260164085, Training Loss Force: 4.502257084833285, time: 1.8056256771087646
Validation Loss Energy: 3.876985204336469, Validation Loss Force: 4.615578241817601, time: 0.1279447078704834
Test Loss Energy: 7.074154456131587, Test Loss Force: 8.191188351596514, time: 11.319785356521606

Epoch 2, Batch 100/108, Loss: 1.6294469833374023, Variance: 0.21868515014648438

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.738279528316999, Training Loss Force: 4.502068735600348, time: 2.023698568344116
Validation Loss Energy: 4.229428229425479, Validation Loss Force: 4.534321668639535, time: 0.1305522918701172
Test Loss Energy: 7.526798739505164, Test Loss Force: 8.19859759631303, time: 11.48748779296875

Epoch 3, Batch 100/108, Loss: 1.4816772937774658, Variance: 0.2236696481704712

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.719996092583572, Training Loss Force: 4.509579254557919, time: 1.7515039443969727
Validation Loss Energy: 3.652378465723866, Validation Loss Force: 4.508961137379333, time: 0.12344956398010254
Test Loss Energy: 7.201969297198768, Test Loss Force: 8.216456785654433, time: 11.408024787902832

Epoch 4, Batch 100/108, Loss: 1.4055569171905518, Variance: 0.21436816453933716

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.696612729325371, Training Loss Force: 4.544197911196999, time: 1.7847561836242676
Validation Loss Energy: 3.9129747730544846, Validation Loss Force: 4.484691833380274, time: 0.13206243515014648
Test Loss Energy: 7.515138894679415, Test Loss Force: 8.18082407979988, time: 11.646667957305908

Epoch 5, Batch 100/108, Loss: 1.3466922044754028, Variance: 0.20939913392066956

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.755939347150111, Training Loss Force: 4.569287173708424, time: 1.8379487991333008
Validation Loss Energy: 3.5625311684498087, Validation Loss Force: 4.593520339329799, time: 0.13216328620910645
Test Loss Energy: 7.371365936495501, Test Loss Force: 8.251510402506272, time: 11.353060483932495

Epoch 6, Batch 100/108, Loss: 1.4122143983840942, Variance: 0.2164463847875595

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.654782150991657, Training Loss Force: 4.511942380351111, time: 1.7654592990875244
Validation Loss Energy: 4.5254895711893575, Validation Loss Force: 4.25097874315276, time: 0.13793039321899414
Test Loss Energy: 7.490688994733542, Test Loss Force: 8.141220625817667, time: 11.66878628730774

Epoch 7, Batch 100/108, Loss: 1.685178279876709, Variance: 0.23321080207824707

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.704216822929767, Training Loss Force: 4.517484462823654, time: 1.8241124153137207
Validation Loss Energy: 3.610203667693316, Validation Loss Force: 4.4340715657599254, time: 0.13785266876220703
Test Loss Energy: 7.396329798799228, Test Loss Force: 8.08305599411247, time: 11.367465734481812

Epoch 8, Batch 100/108, Loss: 1.3062474727630615, Variance: 0.2100931704044342

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.6957499090641655, Training Loss Force: 4.526464449698252, time: 1.8029825687408447
Validation Loss Energy: 4.184836060923689, Validation Loss Force: 4.468043900461935, time: 0.13518142700195312
Test Loss Energy: 7.543181284998564, Test Loss Force: 8.155079828590674, time: 11.661720275878906

Epoch 9, Batch 100/108, Loss: 1.2899227142333984, Variance: 0.16210833191871643

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.1845660034538295, Training Loss Force: 4.756667552572971, time: 1.7518441677093506
Validation Loss Energy: 6.121481808084074, Validation Loss Force: 7.284128267984593, time: 0.1384265422821045
Test Loss Energy: 7.903597034039054, Test Loss Force: 10.11968699377597, time: 11.47588849067688

Epoch 10, Batch 100/108, Loss: 1.467882752418518, Variance: 0.15416216850280762

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.8231392298248807, Training Loss Force: 5.069935809281522, time: 1.7702147960662842
Validation Loss Energy: 2.2364952848808843, Validation Loss Force: 5.245115131259021, time: 0.13433361053466797
Test Loss Energy: 6.391652686227763, Test Loss Force: 8.819451571191612, time: 11.476640701293945

Epoch 11, Batch 100/108, Loss: 2.556851387023926, Variance: 0.2094062864780426

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.089157174175859, Training Loss Force: 4.998809234893723, time: 2.0225658416748047
Validation Loss Energy: 5.556699184523816, Validation Loss Force: 4.473926225512957, time: 0.13820600509643555
Test Loss Energy: 8.36467625082694, Test Loss Force: 8.223472216087332, time: 11.092262983322144

Epoch 12, Batch 100/108, Loss: 2.529507637023926, Variance: 0.21162018179893494

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.7038787699312214, Training Loss Force: 4.486650707462536, time: 1.7359890937805176
Validation Loss Energy: 5.32147981174715, Validation Loss Force: 4.249461178700213, time: 0.12128496170043945
Test Loss Energy: 8.435456073590096, Test Loss Force: 8.139068149634985, time: 11.88791275024414

Epoch 13, Batch 100/108, Loss: 2.374234199523926, Variance: 0.22753697633743286

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.699470918729505, Training Loss Force: 4.4922182814287845, time: 1.828758955001831
Validation Loss Energy: 5.720412369130401, Validation Loss Force: 4.6847137458140375, time: 0.1418321132659912
Test Loss Energy: 8.487793299859831, Test Loss Force: 8.240248883637411, time: 9.975204229354858

Epoch 14, Batch 100/108, Loss: 2.7675232887268066, Variance: 0.20812636613845825

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.63012147504236, Training Loss Force: 4.486795648582524, time: 1.7204790115356445
Validation Loss Energy: 5.019094072454533, Validation Loss Force: 4.722248935296988, time: 0.11442112922668457
Test Loss Energy: 7.967514221704082, Test Loss Force: 8.118704429035697, time: 9.524579524993896

Epoch 15, Batch 100/108, Loss: 2.3419437408447266, Variance: 0.22448889911174774

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.613700518268522, Training Loss Force: 4.487842898687346, time: 1.7044610977172852
Validation Loss Energy: 6.207125557221306, Validation Loss Force: 4.589893801173122, time: 0.11557817459106445
Test Loss Energy: 8.472939563416546, Test Loss Force: 8.197893145746967, time: 9.534599781036377

Epoch 16, Batch 100/108, Loss: 2.271134376525879, Variance: 0.21379287540912628

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.672083710632106, Training Loss Force: 4.473785203782287, time: 1.91444730758667
Validation Loss Energy: 5.414616674537046, Validation Loss Force: 4.421248049645945, time: 0.1139829158782959
Test Loss Energy: 8.11217896865163, Test Loss Force: 8.13588171451932, time: 9.538575410842896

Epoch 17, Batch 100/108, Loss: 2.120922088623047, Variance: 0.2168978750705719

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.678724247835154, Training Loss Force: 4.484304318966814, time: 1.6640310287475586
Validation Loss Energy: 6.533283157640978, Validation Loss Force: 4.392811863696092, time: 0.11332440376281738
Test Loss Energy: 8.72704999845019, Test Loss Force: 8.119632304190656, time: 9.58381199836731

Epoch 18, Batch 100/108, Loss: 2.469465494155884, Variance: 0.21833688020706177

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.74743477539608, Training Loss Force: 4.557048646552319, time: 1.6753947734832764
Validation Loss Energy: 4.819360739233891, Validation Loss Force: 4.376013109542909, time: 0.1127927303314209
Test Loss Energy: 8.037503181951251, Test Loss Force: 8.15214830884385, time: 9.766315937042236

Epoch 19, Batch 100/108, Loss: 1.992903232574463, Variance: 0.22931988537311554

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.632954249237589, Training Loss Force: 4.48292588974245, time: 1.7171046733856201
Validation Loss Energy: 5.618619614407805, Validation Loss Force: 4.368712975816716, time: 0.1123359203338623
Test Loss Energy: 8.209620318261278, Test Loss Force: 8.11783265951067, time: 10.512316942214966

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–„â–ƒâ–„â–„â–„â–„â–„â–†â–â–‡â–‡â–‡â–†â–‡â–†â–ˆâ–†â–†
wandb:   test_error_force â–â–â–â–â–â–‚â–â–â–â–ˆâ–„â–â–â–‚â–â–â–â–â–â–
wandb:          test_loss â–â–â–â–â–â–‚â–â–â–â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: train_error_energy â–ˆâ–…â–…â–…â–…â–…â–…â–…â–…â–ƒâ–â–‚â–…â–…â–…â–…â–…â–…â–…â–…
wandb:  train_error_force â–†â–â–â–â–‚â–‚â–â–‚â–‚â–„â–ˆâ–‡â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–†â–„â–‚â–‚â–â–â–â–â–‚â–
wandb: valid_error_energy â–„â–„â–„â–ƒâ–„â–ƒâ–…â–ƒâ–„â–‡â–â–†â–†â–‡â–†â–‡â–†â–ˆâ–…â–‡
wandb:  valid_error_force â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–ˆâ–ƒâ–‚â–â–‚â–‚â–‚â–â–â–â–
wandb:         valid_loss â–â–‚â–‚â–â–â–â–‚â–â–‚â–ˆâ–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3435
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.20962
wandb:   test_error_force 8.11783
wandb:          test_loss 4.76515
wandb: train_error_energy 4.63295
wandb:  train_error_force 4.48293
wandb:         train_loss 1.89427
wandb: valid_error_energy 5.61862
wandb:  valid_error_force 4.36871
wandb:         valid_loss 2.13553
wandb: 
wandb: ğŸš€ View run al_72_67 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/cxn5swx4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_010702-cxn5swx4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.67730450630188, Uncertainty Bias: -0.2770867347717285
1.5258789e-05 0.05256462
2.1926818 6.4297986
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2312 steps.
Found uncertainty sample 15 after 3151 steps.
Found uncertainty sample 16 after 3317 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2486 steps.
Found uncertainty sample 22 after 1124 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 538 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2200 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 390 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1494 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3322 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 806 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3021 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1485 steps.
Found uncertainty sample 66 after 2893 steps.
Found uncertainty sample 67 after 3454 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1373 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2528 steps.
Found uncertainty sample 75 after 654 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2103 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3671 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1616 steps.
Found uncertainty sample 90 after 2687 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1742 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1856 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_014629-5v8rjzzm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_68
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/5v8rjzzm
Training model 68. Added 24 samples to the dataset.
Epoch 0, Batch 100/108, Loss: 1.202110767364502, Variance: 0.1759951263666153

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.079106192006128, Training Loss Force: 4.607861238462208, time: 1.7264840602874756
Validation Loss Energy: 2.1856464844937658, Validation Loss Force: 4.594822953833476, time: 0.12139058113098145
Test Loss Energy: 6.426726196411049, Test Loss Force: 8.14512382242181, time: 9.535320520401001

Epoch 1, Batch 100/108, Loss: 1.3889431953430176, Variance: 0.17245903611183167

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1221740420867996, Training Loss Force: 4.454907641408995, time: 1.7572534084320068
Validation Loss Energy: 1.9617509140217322, Validation Loss Force: 4.415245483256121, time: 0.11187219619750977
Test Loss Energy: 6.248470906465637, Test Loss Force: 8.152764116105308, time: 9.474741220474243

Epoch 2, Batch 100/108, Loss: 1.5188647508621216, Variance: 0.17648234963417053

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1931179329343764, Training Loss Force: 4.495991187437385, time: 1.7063963413238525
Validation Loss Energy: 2.04810056146308, Validation Loss Force: 4.513838630797832, time: 0.11175870895385742
Test Loss Energy: 6.468938136665505, Test Loss Force: 8.213856042672592, time: 9.684153318405151

Epoch 3, Batch 100/108, Loss: 1.4402951002120972, Variance: 0.16819553077220917

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.1583217945537334, Training Loss Force: 4.4670132557024935, time: 1.701500654220581
Validation Loss Energy: 1.9365361939405885, Validation Loss Force: 4.1999742228095895, time: 0.11440801620483398
Test Loss Energy: 6.487137380264369, Test Loss Force: 8.150838837063123, time: 10.502498388290405

Epoch 4, Batch 100/108, Loss: 1.315781831741333, Variance: 0.15731191635131836

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1979383488284703, Training Loss Force: 4.4654766365439595, time: 1.727064847946167
Validation Loss Energy: 2.085357191844474, Validation Loss Force: 4.50890057137164, time: 0.11179256439208984
Test Loss Energy: 6.310618226494266, Test Loss Force: 8.190148190570042, time: 9.701598167419434

Epoch 5, Batch 100/108, Loss: 1.5766003131866455, Variance: 0.18341375887393951

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.196193313411099, Training Loss Force: 4.462842406942098, time: 1.768045425415039
Validation Loss Energy: 2.050403628439411, Validation Loss Force: 4.481313793990452, time: 0.1253359317779541
Test Loss Energy: 6.226808145727078, Test Loss Force: 8.173594975588225, time: 9.50679326057434

Epoch 6, Batch 100/108, Loss: 1.3556655645370483, Variance: 0.17306077480316162

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1602868384269134, Training Loss Force: 4.481157253457362, time: 1.7334916591644287
Validation Loss Energy: 2.081147446083088, Validation Loss Force: 4.542369822249949, time: 0.11281871795654297
Test Loss Energy: 6.2741005938163585, Test Loss Force: 8.218560078769427, time: 9.52348780632019

Epoch 7, Batch 100/108, Loss: 1.3081185817718506, Variance: 0.16919924318790436

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.175496008060225, Training Loss Force: 4.493976048160749, time: 1.687255859375
Validation Loss Energy: 2.03931782234025, Validation Loss Force: 4.480783099192657, time: 0.11116838455200195
Test Loss Energy: 6.322639229016641, Test Loss Force: 8.267487093260875, time: 9.692956686019897

Epoch 8, Batch 100/108, Loss: 1.384207010269165, Variance: 0.16390669345855713

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.185518605068229, Training Loss Force: 4.496445366519034, time: 1.7564263343811035
Validation Loss Energy: 2.138467791192878, Validation Loss Force: 4.442750021499413, time: 0.13137006759643555
Test Loss Energy: 6.351892177051828, Test Loss Force: 8.106624446003215, time: 11.207468271255493

Epoch 9, Batch 100/108, Loss: 1.4707084894180298, Variance: 0.16464775800704956

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.2131338696678364, Training Loss Force: 4.510053556332757, time: 1.8090858459472656
Validation Loss Energy: 1.9906308795794205, Validation Loss Force: 4.57336789094675, time: 0.13254690170288086
Test Loss Energy: 6.4017332798641, Test Loss Force: 8.127686319478899, time: 11.556029319763184

Epoch 10, Batch 100/108, Loss: 1.3453837633132935, Variance: 0.16856761276721954

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1816852722201525, Training Loss Force: 4.474238448890575, time: 1.866708517074585
Validation Loss Energy: 1.9575980973386546, Validation Loss Force: 4.358856897187466, time: 0.13534975051879883
Test Loss Energy: 6.439782615125212, Test Loss Force: 8.135780732312929, time: 11.259831666946411

Epoch 11, Batch 100/108, Loss: 1.3414390087127686, Variance: 0.17389582097530365

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.204597294378457, Training Loss Force: 4.473838712415105, time: 1.763744831085205
Validation Loss Energy: 1.911342293424589, Validation Loss Force: 4.341588162690279, time: 0.13351845741271973
Test Loss Energy: 6.2484426426395965, Test Loss Force: 8.149640839752205, time: 11.469082593917847

Epoch 12, Batch 100/108, Loss: 1.4115413427352905, Variance: 0.16938044130802155

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.2290651316312506, Training Loss Force: 4.459139843766097, time: 1.7554538249969482
Validation Loss Energy: 2.037570537552155, Validation Loss Force: 4.459782875148013, time: 0.1331164836883545
Test Loss Energy: 6.1935742510841845, Test Loss Force: 8.20653063347242, time: 11.54079532623291

Epoch 13, Batch 100/108, Loss: 1.144747257232666, Variance: 0.15966646373271942

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1145515617838546, Training Loss Force: 4.4720806611614545, time: 1.8723604679107666
Validation Loss Energy: 2.3986247722985823, Validation Loss Force: 4.45317657848053, time: 0.13382697105407715
Test Loss Energy: 6.453136447538301, Test Loss Force: 8.204729969877077, time: 11.204695224761963

Epoch 14, Batch 100/108, Loss: 1.6032973527908325, Variance: 0.17645962536334991

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.137283262138109, Training Loss Force: 4.468808616408596, time: 1.810563087463379
Validation Loss Energy: 2.1335164458409794, Validation Loss Force: 4.701249750375026, time: 0.13494610786437988
Test Loss Energy: 6.3218590196454505, Test Loss Force: 8.27050127805377, time: 11.461003065109253

Epoch 15, Batch 100/108, Loss: 1.6648976802825928, Variance: 0.1746543049812317

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.2248012999466686, Training Loss Force: 4.499161208486381, time: 1.8661103248596191
Validation Loss Energy: 2.4627057609055076, Validation Loss Force: 4.283261761267663, time: 0.15230178833007812
Test Loss Energy: 6.383341727066417, Test Loss Force: 8.14147537797352, time: 11.331143379211426

Epoch 16, Batch 100/108, Loss: 1.633120059967041, Variance: 0.17273792624473572

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.198552943504874, Training Loss Force: 4.452359428073505, time: 1.8569309711456299
Validation Loss Energy: 1.797711259335693, Validation Loss Force: 4.620154983443, time: 0.13721990585327148
Test Loss Energy: 6.287018677866357, Test Loss Force: 8.101851746202943, time: 11.42026948928833

Epoch 17, Batch 100/108, Loss: 1.3189791440963745, Variance: 0.1604069173336029

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1829241456190567, Training Loss Force: 4.470466396447034, time: 1.7736666202545166
Validation Loss Energy: 1.8748157951726918, Validation Loss Force: 4.350606114654257, time: 0.13099384307861328
Test Loss Energy: 6.259807041648718, Test Loss Force: 8.12657410691371, time: 11.368777990341187

Epoch 18, Batch 100/108, Loss: 1.374678373336792, Variance: 0.16600708663463593

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.168738770576322, Training Loss Force: 4.466802528220392, time: 1.8183355331420898
Validation Loss Energy: 2.0083620236696498, Validation Loss Force: 4.329188757076241, time: 0.13306355476379395
Test Loss Energy: 6.197393479269979, Test Loss Force: 8.148173727542618, time: 11.316115617752075

Epoch 19, Batch 100/108, Loss: 1.426002860069275, Variance: 0.16992723941802979

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.172462827510159, Training Loss Force: 4.484535247488654, time: 1.946843147277832
Validation Loss Energy: 2.094588238181105, Validation Loss Force: 4.194664973917136, time: 0.17310047149658203
Test Loss Energy: 6.439256274228134, Test Loss Force: 8.135464758965822, time: 11.30966854095459

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–‚â–ˆâ–ˆâ–„â–‚â–ƒâ–„â–…â–†â–‡â–‚â–â–‡â–„â–†â–ƒâ–ƒâ–â–‡
wandb:   test_error_force â–ƒâ–ƒâ–†â–ƒâ–…â–„â–†â–ˆâ–â–‚â–‚â–ƒâ–…â–…â–ˆâ–ƒâ–â–‚â–ƒâ–‚
wandb:          test_loss â–ƒâ–„â–…â–ˆâ–„â–„â–ƒâ–„â–ƒâ–†â–…â–‚â–â–‡â–†â–ƒâ–ƒâ–„â–‚â–†
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:  train_error_force â–ˆâ–â–ƒâ–‚â–‚â–â–‚â–ƒâ–ƒâ–„â–‚â–‚â–â–‚â–‚â–ƒâ–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–
wandb: valid_error_energy â–…â–ƒâ–„â–‚â–„â–„â–„â–„â–…â–ƒâ–ƒâ–‚â–„â–‡â–…â–ˆâ–â–‚â–ƒâ–„
wandb:  valid_error_force â–‡â–„â–…â–â–…â–…â–†â–…â–„â–†â–ƒâ–ƒâ–…â–…â–ˆâ–‚â–‡â–ƒâ–ƒâ–
wandb:         valid_loss â–ˆâ–…â–…â–â–†â–†â–…â–…â–…â–…â–ƒâ–ƒâ–…â–‡â–ˆâ–‡â–…â–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3456
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.43926
wandb:   test_error_force 8.13546
wandb:          test_loss 4.96457
wandb: train_error_energy 3.17246
wandb:  train_error_force 4.48454
wandb:         train_loss 1.51429
wandb: valid_error_energy 2.09459
wandb:  valid_error_force 4.19466
wandb:         valid_loss 1.1171
wandb: 
wandb: ğŸš€ View run al_72_68 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/5v8rjzzm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_014629-5v8rjzzm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.7694754600524902, Uncertainty Bias: -0.14103513956069946
8.010864e-05 0.006392479
2.458869 6.2596874
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2618 steps.
Found uncertainty sample 3 after 1894 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2709 steps.
Found uncertainty sample 10 after 1763 steps.
Found uncertainty sample 11 after 2744 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2111 steps.
Found uncertainty sample 15 after 196 steps.
Found uncertainty sample 16 after 459 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 49 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2728 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1910 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1808 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3544 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2355 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2642 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2928 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 135 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3067 steps.
Found uncertainty sample 66 after 2717 steps.
Found uncertainty sample 67 after 3997 steps.
Found uncertainty sample 68 after 3882 steps.
Found uncertainty sample 69 after 3272 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2218 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3596 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1748 steps.
Found uncertainty sample 86 after 1572 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1097 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3680 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2410 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_022444-zerhhkhc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_69
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zerhhkhc
Training model 69. Added 29 samples to the dataset.
Epoch 0, Batch 100/109, Loss: 1.5006572008132935, Variance: 0.17106130719184875

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.492300941996223, Training Loss Force: 4.674458170137288, time: 1.701763391494751
Validation Loss Energy: 2.2637777477626373, Validation Loss Force: 4.373613626826391, time: 0.12206006050109863
Test Loss Energy: 6.310455608069319, Test Loss Force: 8.184412354614874, time: 9.473496913909912

Epoch 1, Batch 100/109, Loss: 1.5069029331207275, Variance: 0.17202535271644592

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1099626637036426, Training Loss Force: 4.503763810715724, time: 1.7113046646118164
Validation Loss Energy: 3.6581617030049514, Validation Loss Force: 4.458798974415207, time: 0.1143639087677002
Test Loss Energy: 7.0837901871253415, Test Loss Force: 8.176656939817125, time: 9.39153504371643

Epoch 2, Batch 100/109, Loss: 1.1425755023956299, Variance: 0.16013160347938538

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1810396928445823, Training Loss Force: 4.449353824544839, time: 1.7816500663757324
Validation Loss Energy: 4.300122565889509, Validation Loss Force: 4.457750202737888, time: 0.11753201484680176
Test Loss Energy: 7.537990454511293, Test Loss Force: 8.152303501077911, time: 9.599129676818848

Epoch 3, Batch 100/109, Loss: 1.6156734228134155, Variance: 0.16359788179397583

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.11259430556166, Training Loss Force: 4.461892732719274, time: 1.6874096393585205
Validation Loss Energy: 2.530936337492895, Validation Loss Force: 4.42889807082344, time: 0.11292219161987305
Test Loss Energy: 6.582904232248886, Test Loss Force: 8.174438119887027, time: 9.441109657287598

Epoch 4, Batch 100/109, Loss: 0.8045634031295776, Variance: 0.1511690765619278

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1769966135770322, Training Loss Force: 4.472418940612175, time: 1.7394609451293945
Validation Loss Energy: 2.3686160226171373, Validation Loss Force: 4.363987639647934, time: 0.11206197738647461
Test Loss Energy: 6.363265741635951, Test Loss Force: 8.159155531995141, time: 9.4046151638031

Epoch 5, Batch 100/109, Loss: 1.4957295656204224, Variance: 0.16737397015094757

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.118922495275334, Training Loss Force: 4.477330282464636, time: 1.8744583129882812
Validation Loss Energy: 3.8717314742844002, Validation Loss Force: 4.491096243355449, time: 0.11915040016174316
Test Loss Energy: 6.9603990451976925, Test Loss Force: 8.232103641616142, time: 9.560403108596802

Epoch 6, Batch 100/109, Loss: 1.8499988317489624, Variance: 0.17505836486816406

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.17720304830367, Training Loss Force: 4.4607900914513285, time: 1.6904513835906982
Validation Loss Energy: 2.040477705921388, Validation Loss Force: 4.3769278343943805, time: 0.11448192596435547
Test Loss Energy: 6.299130235616892, Test Loss Force: 8.14883073442511, time: 9.47969102859497

Epoch 7, Batch 100/109, Loss: 1.5431698560714722, Variance: 0.17427052557468414

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.128532862928197, Training Loss Force: 4.460737578303942, time: 1.7150115966796875
Validation Loss Energy: 3.1375018613868693, Validation Loss Force: 4.386418884070407, time: 0.1128075122833252
Test Loss Energy: 6.8630578547346595, Test Loss Force: 8.234045144029192, time: 9.634840965270996

Epoch 8, Batch 100/109, Loss: 1.4681789875030518, Variance: 0.16783277690410614

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1982403930653978, Training Loss Force: 4.470809886378468, time: 1.7002513408660889
Validation Loss Energy: 4.538975156897231, Validation Loss Force: 4.386493107119049, time: 0.11510300636291504
Test Loss Energy: 7.484261124057359, Test Loss Force: 8.159587967134602, time: 9.421618938446045

Epoch 9, Batch 100/109, Loss: 1.9495776891708374, Variance: 0.16258928179740906

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1613070350438575, Training Loss Force: 4.470771695555687, time: 1.7346813678741455
Validation Loss Energy: 2.7407686071579462, Validation Loss Force: 4.296504934498668, time: 0.11761736869812012
Test Loss Energy: 6.662158395036144, Test Loss Force: 8.137588255516937, time: 10.521213293075562

Epoch 10, Batch 100/109, Loss: 1.7654290199279785, Variance: 0.1581994742155075

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.133064881762063, Training Loss Force: 4.503396451567338, time: 1.7375807762145996
Validation Loss Energy: 2.719875190080298, Validation Loss Force: 4.440037762855916, time: 0.1141974925994873
Test Loss Energy: 6.4267710589978195, Test Loss Force: 8.10402900278021, time: 9.701140880584717

Epoch 11, Batch 100/109, Loss: 1.4006915092468262, Variance: 0.16564622521400452

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.16866225044349, Training Loss Force: 4.46594267591646, time: 1.7438116073608398
Validation Loss Energy: 3.489813882795026, Validation Loss Force: 4.414514237780893, time: 0.11361360549926758
Test Loss Energy: 6.760688237700809, Test Loss Force: 8.140600127348652, time: 9.544279098510742

Epoch 12, Batch 100/109, Loss: 1.6614561080932617, Variance: 0.16875137388706207

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.2043426645021644, Training Loss Force: 4.465871331904971, time: 1.7868149280548096
Validation Loss Energy: 2.1135882252878804, Validation Loss Force: 4.53472380911708, time: 0.1126105785369873
Test Loss Energy: 6.3344394276843605, Test Loss Force: 8.160288817688505, time: 9.521160125732422

Epoch 13, Batch 100/109, Loss: 1.2731945514678955, Variance: 0.16409115493297577

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.158474560937484, Training Loss Force: 4.484315993737872, time: 1.8882524967193604
Validation Loss Energy: 3.3770749355277645, Validation Loss Force: 4.470975265545025, time: 0.1128389835357666
Test Loss Energy: 7.123531985098179, Test Loss Force: 8.136901450606334, time: 9.502536535263062

Epoch 14, Batch 100/109, Loss: 1.3140888214111328, Variance: 0.16323022544384003

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.142190462934609, Training Loss Force: 4.457744283960467, time: 1.7472431659698486
Validation Loss Energy: 4.446322822168873, Validation Loss Force: 4.3913523416675835, time: 0.11736941337585449
Test Loss Energy: 7.448486021866889, Test Loss Force: 8.156932589771326, time: 9.554519891738892

Epoch 15, Batch 100/109, Loss: 1.5297255516052246, Variance: 0.16253255307674408

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.2056409961997465, Training Loss Force: 4.4497843318458745, time: 1.6603772640228271
Validation Loss Energy: 2.6624289997915342, Validation Loss Force: 4.345625451198145, time: 0.11318182945251465
Test Loss Energy: 6.726720574776239, Test Loss Force: 8.157784020626615, time: 9.701210737228394

Epoch 16, Batch 100/109, Loss: 1.4743410348892212, Variance: 0.17180080711841583

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.154202746321907, Training Loss Force: 4.460342546896376, time: 1.7318170070648193
Validation Loss Energy: 2.458056132246341, Validation Loss Force: 4.241748958607956, time: 0.1211545467376709
Test Loss Energy: 6.516865511251811, Test Loss Force: 8.165260667643347, time: 9.468138694763184

Epoch 17, Batch 100/109, Loss: 1.3503412008285522, Variance: 0.16616688668727875

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1574051075864635, Training Loss Force: 4.451048863797091, time: 1.7061591148376465
Validation Loss Energy: 3.6629257836051248, Validation Loss Force: 4.410015281910472, time: 0.11290645599365234
Test Loss Energy: 6.8643916802245935, Test Loss Force: 8.124768201849882, time: 9.534155368804932

Epoch 18, Batch 100/109, Loss: 1.8568297624588013, Variance: 0.16611918807029724

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1028266956993007, Training Loss Force: 4.469745329705822, time: 1.729600429534912
Validation Loss Energy: 2.0882130720870955, Validation Loss Force: 4.380986647586352, time: 0.11358809471130371
Test Loss Energy: 6.27425155883407, Test Loss Force: 8.174990717090411, time: 9.755610704421997

Epoch 19, Batch 100/109, Loss: 1.26156485080719, Variance: 0.1660022735595703

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1589236212768985, Training Loss Force: 4.4583593615122785, time: 1.646747350692749
Validation Loss Energy: 3.47826626088721, Validation Loss Force: 4.35343831774436, time: 0.12032127380371094
Test Loss Energy: 6.887331605899001, Test Loss Force: 8.104668713749357, time: 9.59599494934082

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–ˆâ–ƒâ–â–…â–â–„â–ˆâ–ƒâ–‚â–„â–â–†â–ˆâ–„â–‚â–„â–â–„
wandb:   test_error_force â–…â–…â–„â–…â–„â–ˆâ–ƒâ–ˆâ–„â–ƒâ–â–ƒâ–„â–ƒâ–„â–„â–„â–‚â–…â–
wandb:          test_loss â–â–…â–‡â–‚â–‚â–‡â–â–ƒâ–ˆâ–‚â–ƒâ–†â–â–…â–ˆâ–‚â–‚â–…â–â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–â–‚â–‚â–â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–†â–‡â–‚â–‚â–†â–â–„â–ˆâ–ƒâ–ƒâ–…â–â–…â–ˆâ–ƒâ–‚â–†â–â–…
wandb:  valid_error_force â–„â–†â–†â–…â–„â–‡â–„â–„â–„â–‚â–†â–…â–ˆâ–†â–…â–ƒâ–â–…â–„â–„
wandb:         valid_loss â–‚â–…â–‡â–‚â–‚â–†â–â–ƒâ–ˆâ–‚â–ƒâ–…â–‚â–„â–ˆâ–‚â–‚â–…â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3482
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.88733
wandb:   test_error_force 8.10467
wandb:          test_loss 4.94731
wandb: train_error_energy 3.15892
wandb:  train_error_force 4.45836
wandb:         train_loss 1.50414
wandb: valid_error_energy 3.47827
wandb:  valid_error_force 4.35344
wandb:         valid_loss 1.58405
wandb: 
wandb: ğŸš€ View run al_72_69 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zerhhkhc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_022444-zerhhkhc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5794787406921387, Uncertainty Bias: -0.129377543926239
0.00010681152 0.00016593933
2.4489844 6.2900558
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2370 steps.
Found uncertainty sample 3 after 1759 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1743 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 704 steps.
Found uncertainty sample 16 after 3152 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2818 steps.
Found uncertainty sample 24 after 411 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3487 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2441 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3513 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3190 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3033 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2454 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2757 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2924 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 567 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2626 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3732 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2111 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 783 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2910 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2323 steps.
Found uncertainty sample 79 after 3125 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1969 steps.
Found uncertainty sample 82 after 333 steps.
Found uncertainty sample 83 after 532 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 650 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3004 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3404 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_030252-jfrw66dp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_70
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jfrw66dp
Training model 70. Added 29 samples to the dataset.
Epoch 0, Batch 100/110, Loss: 1.6021479368209839, Variance: 0.1352900117635727

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.444309620648838, Training Loss Force: 4.817841715961062, time: 1.7361974716186523
Validation Loss Energy: 2.1988334708769504, Validation Loss Force: 4.715192550062537, time: 0.11294031143188477
Test Loss Energy: 6.090765497851967, Test Loss Force: 8.344311809758901, time: 9.453635931015015

Epoch 1, Batch 100/110, Loss: 1.0228595733642578, Variance: 0.15009064972400665

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1392002304868893, Training Loss Force: 4.69046001731788, time: 1.737048864364624
Validation Loss Energy: 2.9602204808192716, Validation Loss Force: 4.379472942732336, time: 0.11910843849182129
Test Loss Energy: 6.591516519889218, Test Loss Force: 8.079027174804198, time: 9.467625141143799

Epoch 2, Batch 100/110, Loss: 1.927599310874939, Variance: 0.16601979732513428

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0762350356206976, Training Loss Force: 4.448966437987476, time: 1.7125344276428223
Validation Loss Energy: 3.1233589563602173, Validation Loss Force: 4.338925781935469, time: 0.11392736434936523
Test Loss Energy: 6.876700285013781, Test Loss Force: 8.210393810252265, time: 9.6306893825531

Epoch 3, Batch 100/110, Loss: 1.267112135887146, Variance: 0.1581522673368454

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.084860799068444, Training Loss Force: 4.439238431903413, time: 1.7376058101654053
Validation Loss Energy: 2.6140225088200006, Validation Loss Force: 4.304153471215191, time: 0.11203670501708984
Test Loss Energy: 6.5774817139323725, Test Loss Force: 8.178715587185456, time: 9.47921633720398

Epoch 4, Batch 100/110, Loss: 1.274838924407959, Variance: 0.15814951062202454

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1019907010400303, Training Loss Force: 4.441036853673005, time: 1.736185073852539
Validation Loss Energy: 3.539853132390599, Validation Loss Force: 4.42016068198333, time: 0.11422848701477051
Test Loss Energy: 6.754687957070002, Test Loss Force: 8.138391958231733, time: 9.478084087371826

Epoch 5, Batch 100/110, Loss: 1.900805115699768, Variance: 0.1654386967420578

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1288637404762794, Training Loss Force: 4.44320295078488, time: 1.9757888317108154
Validation Loss Energy: 3.172781338198522, Validation Loss Force: 4.384314809087486, time: 0.1140284538269043
Test Loss Energy: 6.915146262806409, Test Loss Force: 8.20326748825308, time: 9.51152753829956

Epoch 6, Batch 100/110, Loss: 1.6170467138290405, Variance: 0.3360035717487335

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1555708600227046, Training Loss Force: 4.435654628679125, time: 1.7542657852172852
Validation Loss Energy: 2.783980301178033, Validation Loss Force: 4.47816050199192, time: 0.11473774909973145
Test Loss Energy: 6.583097574352745, Test Loss Force: 8.149692564279256, time: 9.475988149642944

Epoch 7, Batch 100/110, Loss: 1.134237289428711, Variance: 0.1590624451637268

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.180156750290159, Training Loss Force: 4.466292486173315, time: 1.7376892566680908
Validation Loss Energy: 3.5734356476411357, Validation Loss Force: 4.180024032234091, time: 0.1131887435913086
Test Loss Energy: 6.851014624935134, Test Loss Force: 8.060789088846148, time: 9.639163255691528

Epoch 8, Batch 100/110, Loss: 1.9702855348587036, Variance: 0.17925326526165009

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.173221231892382, Training Loss Force: 4.449601494440193, time: 1.6658456325531006
Validation Loss Energy: 3.4449460498905764, Validation Loss Force: 4.497990228559471, time: 0.11254644393920898
Test Loss Energy: 6.999540865237151, Test Loss Force: 8.189843705085572, time: 9.52927565574646

Epoch 9, Batch 100/110, Loss: 1.2163201570510864, Variance: 0.15621748566627502

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.165135275133785, Training Loss Force: 4.456276532446798, time: 1.726853609085083
Validation Loss Energy: 2.8742780581343017, Validation Loss Force: 4.372062810448053, time: 0.11988139152526855
Test Loss Energy: 6.519615169762573, Test Loss Force: 8.125288758012395, time: 9.545784711837769

Epoch 10, Batch 100/110, Loss: 1.2469916343688965, Variance: 0.15238195657730103

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.106633309210929, Training Loss Force: 4.4581603539066466, time: 1.7248718738555908
Validation Loss Energy: 3.237349230004543, Validation Loss Force: 4.353721404451885, time: 0.11233973503112793
Test Loss Energy: 6.682751574441601, Test Loss Force: 8.068903812370545, time: 9.640292167663574

Epoch 11, Batch 100/110, Loss: 1.7541931867599487, Variance: 0.16860944032669067

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.158691956761756, Training Loss Force: 4.469123708169667, time: 1.758509635925293
Validation Loss Energy: 3.260140159320738, Validation Loss Force: 4.380960817965424, time: 0.11497902870178223
Test Loss Energy: 6.740557869703225, Test Loss Force: 8.157164375528357, time: 9.489512920379639

Epoch 12, Batch 100/110, Loss: 1.2904452085494995, Variance: 0.16311833262443542

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.17104112585483, Training Loss Force: 4.464297921225872, time: 1.6808297634124756
Validation Loss Energy: 2.8109550353001143, Validation Loss Force: 4.4266905289107115, time: 0.12791061401367188
Test Loss Energy: 6.760269626701305, Test Loss Force: 8.188779850196681, time: 9.54448676109314

Epoch 13, Batch 100/110, Loss: 1.1506950855255127, Variance: 0.15797832608222961

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1624063797313107, Training Loss Force: 4.454260518387807, time: 1.9652388095855713
Validation Loss Energy: 3.5705482968258906, Validation Loss Force: 4.379058035890423, time: 0.11456894874572754
Test Loss Energy: 6.736994389272502, Test Loss Force: 8.171511407928461, time: 10.481704950332642

Epoch 14, Batch 100/110, Loss: 1.9561998844146729, Variance: 0.17510178685188293

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1263533563794996, Training Loss Force: 4.4601035268152085, time: 1.726985216140747
Validation Loss Energy: 3.467122783479254, Validation Loss Force: 4.320960389903724, time: 0.11382889747619629
Test Loss Energy: 7.183322612192133, Test Loss Force: 8.191623691927136, time: 9.541167974472046

Epoch 15, Batch 100/110, Loss: 1.2977641820907593, Variance: 0.16008254885673523

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1938527772340732, Training Loss Force: 4.442982751242207, time: 1.7322347164154053
Validation Loss Energy: 2.653882067294242, Validation Loss Force: 4.45803328944541, time: 0.11579322814941406
Test Loss Energy: 6.664563956270604, Test Loss Force: 8.12955214702493, time: 9.673401117324829

Epoch 16, Batch 100/110, Loss: 1.371188759803772, Variance: 0.15412300825119019

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.051534966688007, Training Loss Force: 4.465049619874285, time: 1.746612548828125
Validation Loss Energy: 3.663407416967767, Validation Loss Force: 4.4259773938593545, time: 0.11675620079040527
Test Loss Energy: 7.087012764591069, Test Loss Force: 8.175844162460276, time: 9.522822141647339

Epoch 17, Batch 100/110, Loss: 1.7453529834747314, Variance: 0.1683422029018402

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1473600324313358, Training Loss Force: 4.461759132643131, time: 1.7262077331542969
Validation Loss Energy: 3.357741835378682, Validation Loss Force: 4.336931111726248, time: 0.11605477333068848
Test Loss Energy: 7.0457739304733735, Test Loss Force: 8.185968236036228, time: 9.493488073348999

Epoch 18, Batch 100/110, Loss: 1.536916971206665, Variance: 0.15547874569892883

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.188955914298898, Training Loss Force: 4.4668077101887524, time: 1.7316741943359375
Validation Loss Energy: 2.691533564294415, Validation Loss Force: 4.367245883037246, time: 0.11436271667480469
Test Loss Energy: 6.66325410443678, Test Loss Force: 8.166826705575692, time: 9.68097448348999

Epoch 19, Batch 100/110, Loss: 1.4671214818954468, Variance: 0.1592734158039093

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.165610998654867, Training Loss Force: 4.459749964648244, time: 1.7321140766143799
Validation Loss Energy: 3.544134466282401, Validation Loss Force: 4.368135223606081, time: 0.11558246612548828
Test Loss Energy: 6.773201530228038, Test Loss Force: 8.07689433547541, time: 9.482931852340698

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–†â–„â–…â–†â–„â–†â–‡â–„â–…â–…â–…â–…â–ˆâ–…â–‡â–‡â–…â–…
wandb:   test_error_force â–ˆâ–â–…â–„â–ƒâ–…â–ƒâ–â–„â–ƒâ–â–ƒâ–„â–„â–„â–ƒâ–„â–„â–„â–
wandb:          test_loss â–‡â–†â–„â–ƒâ–…â–„â–â–„â–„â–‚â–„â–‚â–‚â–…â–…â–â–ˆâ–„â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–â–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–†â–â–â–â–â–â–‚â–â–â–â–‚â–‚â–â–â–â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–…â–…â–ƒâ–‡â–†â–„â–ˆâ–‡â–„â–†â–†â–„â–ˆâ–‡â–ƒâ–ˆâ–‡â–ƒâ–‡
wandb:  valid_error_force â–ˆâ–„â–ƒâ–ƒâ–„â–„â–…â–â–…â–„â–ƒâ–„â–„â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒ
wandb:         valid_loss â–â–„â–„â–â–ˆâ–„â–„â–†â–†â–ƒâ–…â–…â–ƒâ–‡â–†â–‚â–ˆâ–†â–‚â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 3508
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.7732
wandb:   test_error_force 8.07689
wandb:          test_loss 4.94118
wandb: train_error_energy 3.16561
wandb:  train_error_force 4.45975
wandb:         train_loss 1.5082
wandb: valid_error_energy 3.54413
wandb:  valid_error_force 4.36814
wandb:         valid_loss 1.62401
wandb: 
wandb: ğŸš€ View run al_72_70 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jfrw66dp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_030252-jfrw66dp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.681936740875244, Uncertainty Bias: -0.13412776589393616
7.6293945e-06 0.03409195
2.4329178 6.274809
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1667 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1375 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2807 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1075 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 547 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1770 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1519 steps.
Found uncertainty sample 56 after 3549 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1154 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2851 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3247 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 711 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2398 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_034257-rss5f6gc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_71
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rss5f6gc
Training model 71. Added 13 samples to the dataset.
Epoch 0, Batch 100/110, Loss: 1.0131275653839111, Variance: 0.14573825895786285

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8905820622024696, Training Loss Force: 4.849870000573021, time: 1.8178069591522217
Validation Loss Energy: 2.182344894844046, Validation Loss Force: 4.536043940260238, time: 0.11534929275512695
Test Loss Energy: 6.071272087187284, Test Loss Force: 8.151995084492082, time: 9.68661117553711

Epoch 1, Batch 100/110, Loss: 1.012939453125, Variance: 0.13880272209644318

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.3958349635668084, Training Loss Force: 4.821919678699582, time: 1.7101073265075684
Validation Loss Energy: 2.2011696413329758, Validation Loss Force: 4.473198097405773, time: 0.11927509307861328
Test Loss Energy: 6.225367641897526, Test Loss Force: 8.173909743490848, time: 9.660648107528687

Epoch 2, Batch 100/110, Loss: 1.2247507572174072, Variance: 0.12523499131202698

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.269397686914404, Training Loss Force: 4.539237827543092, time: 1.806527853012085
Validation Loss Energy: 4.9435357511668565, Validation Loss Force: 4.703636466727176, time: 0.12138628959655762
Test Loss Energy: 8.152807390862883, Test Loss Force: 8.267933564717179, time: 9.875619173049927

Epoch 3, Batch 100/110, Loss: 1.6107666492462158, Variance: 0.30528128147125244

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.7080608220235405, Training Loss Force: 4.571616935491522, time: 1.7091538906097412
Validation Loss Energy: 4.8463382938318205, Validation Loss Force: 4.442422846300997, time: 0.11445975303649902
Test Loss Energy: 7.671802759619458, Test Loss Force: 8.050847289201956, time: 9.693830966949463

Epoch 4, Batch 100/110, Loss: 2.725740909576416, Variance: 0.3427698314189911

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.602946102749617, Training Loss Force: 4.4664577431163615, time: 1.7469329833984375
Validation Loss Energy: 3.957064080401723, Validation Loss Force: 4.38088837626995, time: 0.11650371551513672
Test Loss Energy: 6.958257275786928, Test Loss Force: 8.0699684390237, time: 9.899970769882202

Epoch 5, Batch 100/110, Loss: 1.194926142692566, Variance: 0.20539668202400208

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.63805536215693, Training Loss Force: 4.459541036212886, time: 1.7826876640319824
Validation Loss Energy: 6.321172685720892, Validation Loss Force: 4.341486477113638, time: 0.12703156471252441
Test Loss Energy: 8.461024982756243, Test Loss Force: 8.134047526976538, time: 9.725053548812866

Epoch 6, Batch 100/110, Loss: 2.6548898220062256, Variance: 0.2100829780101776

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.631098721566397, Training Loss Force: 4.456178695672607, time: 1.7227141857147217
Validation Loss Energy: 4.1769549091727205, Validation Loss Force: 4.445994756293872, time: 0.11663484573364258
Test Loss Energy: 7.187868576511499, Test Loss Force: 8.042658324753209, time: 9.721735715866089

Epoch 7, Batch 100/110, Loss: 1.410857915878296, Variance: 0.21778976917266846

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.693795333920903, Training Loss Force: 4.451604994493182, time: 1.7465505599975586
Validation Loss Energy: 4.863899318694561, Validation Loss Force: 4.533073830745756, time: 0.12211036682128906
Test Loss Energy: 7.560366619214036, Test Loss Force: 8.061336213751254, time: 9.853074789047241

Epoch 8, Batch 100/110, Loss: 2.4901204109191895, Variance: 0.22963950037956238

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.697774952806861, Training Loss Force: 4.470847466950363, time: 1.7296817302703857
Validation Loss Energy: 3.2772340985383717, Validation Loss Force: 4.432375272206248, time: 0.1159353256225586
Test Loss Energy: 6.751363544027123, Test Loss Force: 8.020806537728475, time: 9.652429819107056

Epoch 9, Batch 100/110, Loss: 1.3901050090789795, Variance: 0.21824118494987488

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.724199060880944, Training Loss Force: 4.453717938455659, time: 1.8121662139892578
Validation Loss Energy: 5.832071445262961, Validation Loss Force: 4.467479805292251, time: 0.1202547550201416
Test Loss Energy: 8.317136971074882, Test Loss Force: 8.142422600862226, time: 9.674097537994385

Epoch 10, Batch 100/110, Loss: 2.4789915084838867, Variance: 0.20917654037475586

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.646589273569847, Training Loss Force: 4.468772627751546, time: 1.6762659549713135
Validation Loss Energy: 4.492784520819873, Validation Loss Force: 4.2806474770483725, time: 0.11455607414245605
Test Loss Energy: 7.432681222366485, Test Loss Force: 8.07329799094404, time: 9.923094034194946

Epoch 11, Batch 100/110, Loss: 1.578771948814392, Variance: 0.37289440631866455

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.675799415973516, Training Loss Force: 4.476939123940227, time: 1.7475078105926514
Validation Loss Energy: 5.840955795739382, Validation Loss Force: 4.331654595198246, time: 0.12004590034484863
Test Loss Energy: 8.157163685370588, Test Loss Force: 7.965356541358741, time: 9.691753625869751

Epoch 12, Batch 100/110, Loss: 2.302082061767578, Variance: 0.2090996503829956

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.614855984078808, Training Loss Force: 4.515684166659681, time: 1.7168183326721191
Validation Loss Energy: 3.3560394555350155, Validation Loss Force: 4.438209055383459, time: 0.12074732780456543
Test Loss Energy: 6.839880491470657, Test Loss Force: 8.065014094827475, time: 9.89104676246643

Epoch 13, Batch 100/110, Loss: 1.4987616539001465, Variance: 0.21855822205543518

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.714029509977567, Training Loss Force: 4.458502130802996, time: 1.7473907470703125
Validation Loss Energy: 6.451377281233388, Validation Loss Force: 4.415670632878746, time: 0.11716294288635254
Test Loss Energy: 8.52422451359298, Test Loss Force: 8.08980522649593, time: 9.687255382537842

Epoch 14, Batch 100/110, Loss: 2.016847848892212, Variance: 0.19836211204528809

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.7001002846735185, Training Loss Force: 4.4670202215730965, time: 1.7062807083129883
Validation Loss Energy: 4.030182690080516, Validation Loss Force: 4.70604441087124, time: 0.11546564102172852
Test Loss Energy: 7.124409021739442, Test Loss Force: 8.10268713089004, time: 9.724969863891602

Epoch 15, Batch 100/110, Loss: 1.2896642684936523, Variance: 0.20876175165176392

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.689339340712679, Training Loss Force: 4.497493486083145, time: 1.7122197151184082
Validation Loss Energy: 5.692452249814541, Validation Loss Force: 4.416000776999108, time: 0.11543965339660645
Test Loss Energy: 8.266007376345497, Test Loss Force: 8.077279291957087, time: 9.882504224777222

Epoch 16, Batch 100/110, Loss: 2.235182762145996, Variance: 0.23047876358032227

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.655287624122769, Training Loss Force: 4.531014188378772, time: 1.7154178619384766
Validation Loss Energy: 3.6591254150685266, Validation Loss Force: 4.407078127429588, time: 0.12227106094360352
Test Loss Energy: 7.13162865493465, Test Loss Force: 7.987239520716817, time: 10.68064022064209

Epoch 17, Batch 100/110, Loss: 1.6399438381195068, Variance: 0.21962504088878632

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.720088452821365, Training Loss Force: 4.4816344591527475, time: 1.8038783073425293
Validation Loss Energy: 5.9690436983506885, Validation Loss Force: 4.4396852033748635, time: 0.11481881141662598
Test Loss Energy: 8.422768476588079, Test Loss Force: 7.973940499887839, time: 9.76789140701294

Epoch 18, Batch 100/110, Loss: 2.505028247833252, Variance: 0.20967431366443634

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.6735770048225005, Training Loss Force: 4.458697614070471, time: 1.787452220916748
Validation Loss Energy: 4.318857354043484, Validation Loss Force: 4.441020624466041, time: 0.1165916919708252
Test Loss Energy: 7.235907621423198, Test Loss Force: 8.092615663191268, time: 9.666491508483887

Epoch 19, Batch 100/110, Loss: 1.591111183166504, Variance: 0.2107779085636139

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.61779814288006, Training Loss Force: 4.516456452082767, time: 1.687760591506958
Validation Loss Energy: 4.441707484558179, Validation Loss Force: 4.425436159388652, time: 0.11584830284118652
Test Loss Energy: 7.334932468091522, Test Loss Force: 8.13066508239049, time: 9.717412948608398

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–‡â–†â–„â–ˆâ–„â–…â–ƒâ–‡â–…â–‡â–ƒâ–ˆâ–„â–‡â–„â–ˆâ–„â–…
wandb:   test_error_force â–…â–†â–ˆâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–‚â–…â–ƒâ–â–ƒâ–„â–„â–„â–‚â–â–„â–…
wandb:          test_loss â–ƒâ–„â–ˆâ–‚â–â–ƒâ–â–‚â–â–‚â–â–‚â–â–‚â–â–ƒâ–â–‚â–â–‚
wandb: train_error_energy â–†â–„â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–ˆâ–ˆâ–ƒâ–ƒâ–â–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–…â–â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb: valid_error_energy â–â–â–†â–…â–„â–ˆâ–„â–…â–ƒâ–‡â–…â–‡â–ƒâ–ˆâ–„â–‡â–ƒâ–‡â–…â–…
wandb:  valid_error_force â–…â–„â–ˆâ–„â–ƒâ–‚â–„â–…â–ƒâ–„â–â–‚â–„â–ƒâ–ˆâ–ƒâ–ƒâ–„â–„â–ƒ
wandb:         valid_loss â–â–â–ˆâ–…â–ƒâ–†â–„â–„â–ƒâ–…â–ƒâ–…â–ƒâ–†â–„â–…â–ƒâ–…â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3519
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.33493
wandb:   test_error_force 8.13067
wandb:          test_loss 4.55121
wandb: train_error_energy 4.6178
wandb:  train_error_force 4.51646
wandb:         train_loss 1.89405
wandb: valid_error_energy 4.44171
wandb:  valid_error_force 4.42544
wandb:         valid_loss 1.81251
wandb: 
wandb: ğŸš€ View run al_72_71 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rss5f6gc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_034257-rss5f6gc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5239524841308594, Uncertainty Bias: -0.20391160249710083
8.010864e-05 0.067542076
2.4603386 6.2037745
(48745, 22, 3)
Found uncertainty sample 0 after 1427 steps.
Found uncertainty sample 1 after 2884 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1847 steps.
Found uncertainty sample 10 after 3053 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3217 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2271 steps.
Found uncertainty sample 33 after 968 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1591 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1926 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 700 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1762 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1846 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3184 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_042334-3yfmszr7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_72
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3yfmszr7
Training model 72. Added 13 samples to the dataset.
Epoch 0, Batch 100/111, Loss: 1.0697524547576904, Variance: 0.1409493088722229

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7913942237747644, Training Loss Force: 4.792641717556582, time: 1.753675937652588
Validation Loss Energy: 1.6594712394656257, Validation Loss Force: 4.527939822471148, time: 0.11728072166442871
Test Loss Energy: 5.817902881600413, Test Loss Force: 8.152131274071284, time: 9.7062246799469

Epoch 1, Batch 100/111, Loss: 1.3389273881912231, Variance: 0.16092637181282043

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0754640658057073, Training Loss Force: 4.4730897518150385, time: 1.7097845077514648
Validation Loss Energy: 3.077267704944992, Validation Loss Force: 4.433254666886565, time: 0.12217020988464355
Test Loss Energy: 6.753191900203056, Test Loss Force: 8.071692709614886, time: 10.723607540130615

Epoch 2, Batch 100/111, Loss: 1.5223337411880493, Variance: 0.37747305631637573

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0802676370798157, Training Loss Force: 4.397180925219332, time: 1.7694156169891357
Validation Loss Energy: 2.3870326165615814, Validation Loss Force: 4.4348235936887725, time: 0.12088561058044434
Test Loss Energy: 6.182405469834279, Test Loss Force: 8.077762325453993, time: 9.908619165420532

Epoch 3, Batch 100/111, Loss: 1.483347773551941, Variance: 0.16919457912445068

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.1182056721592732, Training Loss Force: 4.407158559135948, time: 1.72698974609375
Validation Loss Energy: 3.394244508031965, Validation Loss Force: 4.359382990156244, time: 0.1176307201385498
Test Loss Energy: 7.025760646809107, Test Loss Force: 8.077912378810591, time: 9.728732109069824

Epoch 4, Batch 100/111, Loss: 1.6842375993728638, Variance: 0.1638176143169403

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0587245787568675, Training Loss Force: 4.409360273536343, time: 1.767951250076294
Validation Loss Energy: 2.490130732040655, Validation Loss Force: 4.3106641685960225, time: 0.11601042747497559
Test Loss Energy: 6.36610088877745, Test Loss Force: 8.067836870424594, time: 9.909826755523682

Epoch 5, Batch 100/111, Loss: 1.3802694082260132, Variance: 0.1644035279750824

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.099422979045485, Training Loss Force: 4.433023765000323, time: 1.756096601486206
Validation Loss Energy: 3.2503087227436374, Validation Loss Force: 4.436938059898503, time: 0.12005138397216797
Test Loss Energy: 7.033949067991772, Test Loss Force: 8.023293292760513, time: 9.78322696685791

Epoch 6, Batch 100/111, Loss: 1.370665431022644, Variance: 0.155388742685318

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.145807912006919, Training Loss Force: 4.417335536100932, time: 1.8135778903961182
Validation Loss Energy: 2.9036023228611647, Validation Loss Force: 4.315262880243821, time: 0.1169121265411377
Test Loss Energy: 6.4244397666670805, Test Loss Force: 8.044695243809803, time: 9.811015129089355

Epoch 7, Batch 100/111, Loss: 1.381382942199707, Variance: 0.16424334049224854

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1098235810289028, Training Loss Force: 4.425944900212275, time: 1.6967942714691162
Validation Loss Energy: 3.2100569696803682, Validation Loss Force: 4.415075512474729, time: 0.11809563636779785
Test Loss Energy: 6.876801843128853, Test Loss Force: 8.131304709421526, time: 9.933071374893188

Epoch 8, Batch 100/111, Loss: 1.3692010641098022, Variance: 0.16378222405910492

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.143206485426286, Training Loss Force: 4.413130282840018, time: 1.7186758518218994
Validation Loss Energy: 2.077864152414858, Validation Loss Force: 4.441818076900656, time: 0.11621999740600586
Test Loss Energy: 6.05848266626619, Test Loss Force: 8.065307582088264, time: 9.716099500656128

Epoch 9, Batch 100/111, Loss: 1.3599445819854736, Variance: 0.16922754049301147

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0975331990431796, Training Loss Force: 4.425375260380255, time: 1.7346296310424805
Validation Loss Energy: 3.2173078193022637, Validation Loss Force: 4.421571959030222, time: 0.11626529693603516
Test Loss Energy: 6.8193531988162555, Test Loss Force: 8.090030182955283, time: 9.74191689491272

Epoch 10, Batch 100/111, Loss: 1.5835212469100952, Variance: 0.1599874198436737

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1153770769111415, Training Loss Force: 4.429416548908633, time: 1.9920737743377686
Validation Loss Energy: 2.2347013137951928, Validation Loss Force: 4.366090378615978, time: 0.11609458923339844
Test Loss Energy: 6.022881306631511, Test Loss Force: 8.012487849266408, time: 9.752524852752686

Epoch 11, Batch 100/111, Loss: 1.4311532974243164, Variance: 0.16043975949287415

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1244898799131997, Training Loss Force: 4.416839858533871, time: 1.7760047912597656
Validation Loss Energy: 2.968972640046061, Validation Loss Force: 4.415569095748203, time: 0.1163933277130127
Test Loss Energy: 6.64169718498838, Test Loss Force: 8.101174766714127, time: 9.779600858688354

Epoch 12, Batch 100/111, Loss: 1.2574390172958374, Variance: 0.1647171974182129

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1402126646568056, Training Loss Force: 4.415156628236755, time: 1.7181665897369385
Validation Loss Energy: 2.5977018995461747, Validation Loss Force: 4.383797919776739, time: 0.11571073532104492
Test Loss Energy: 6.463745391923062, Test Loss Force: 8.084440648789641, time: 9.909124612808228

Epoch 13, Batch 100/111, Loss: 1.3820658922195435, Variance: 0.16541743278503418

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1599042882092, Training Loss Force: 4.421336511483757, time: 1.7493226528167725
Validation Loss Energy: 3.1250974086055234, Validation Loss Force: 4.300262402113152, time: 0.12030696868896484
Test Loss Energy: 6.873314881609449, Test Loss Force: 8.083666226484631, time: 9.735781908035278

Epoch 14, Batch 100/111, Loss: 1.4880341291427612, Variance: 0.16006533801555634

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.114170110841809, Training Loss Force: 4.452758092884057, time: 1.703197956085205
Validation Loss Energy: 2.7854223807901097, Validation Loss Force: 4.457674198336077, time: 0.11763381958007812
Test Loss Energy: 6.504623989331703, Test Loss Force: 8.029568519656838, time: 9.72470760345459

Epoch 15, Batch 100/111, Loss: 1.6300179958343506, Variance: 0.17854803800582886

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.148032961532, Training Loss Force: 4.434037226566773, time: 1.7404530048370361
Validation Loss Energy: 3.1921072387118863, Validation Loss Force: 4.358548871535598, time: 0.11627316474914551
Test Loss Energy: 6.807285438104851, Test Loss Force: 8.093503187432724, time: 9.918671131134033

Epoch 16, Batch 100/111, Loss: 1.387184500694275, Variance: 0.16428615152835846

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.129239164048325, Training Loss Force: 4.430713536502813, time: 1.7943990230560303
Validation Loss Energy: 2.5713219147128665, Validation Loss Force: 4.349321313682254, time: 0.11848640441894531
Test Loss Energy: 6.1627326554547865, Test Loss Force: 8.003977392539992, time: 9.72318148612976

Epoch 17, Batch 100/111, Loss: 1.7598190307617188, Variance: 0.16922704875469208

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.139490745207338, Training Loss Force: 4.417859438486762, time: 1.741750717163086
Validation Loss Energy: 3.4310574330285735, Validation Loss Force: 4.388506036198237, time: 0.11991667747497559
Test Loss Energy: 6.686223723216668, Test Loss Force: 8.080801411885405, time: 9.95271110534668

Epoch 18, Batch 100/111, Loss: 1.656267523765564, Variance: 0.16885948181152344

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1139506362960168, Training Loss Force: 4.421895218461315, time: 1.7998566627502441
Validation Loss Energy: 2.737903968595585, Validation Loss Force: 4.505415947683968, time: 0.11833953857421875
Test Loss Energy: 6.175122029687789, Test Loss Force: 8.052553209990224, time: 10.760221481323242

Epoch 19, Batch 100/111, Loss: 1.5002104043960571, Variance: 0.18266728520393372

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1479244263715866, Training Loss Force: 4.410262821795779, time: 1.6875677108764648
Validation Loss Energy: 3.3282213249112083, Validation Loss Force: 4.246951548979509, time: 0.11656928062438965
Test Loss Energy: 6.867187441740824, Test Loss Force: 8.035810327528361, time: 9.793158531188965

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–ƒâ–ˆâ–„â–ˆâ–„â–‡â–‚â–‡â–‚â–†â–…â–‡â–…â–‡â–ƒâ–†â–ƒâ–‡
wandb:   test_error_force â–ˆâ–„â–„â–„â–„â–‚â–ƒâ–‡â–„â–…â–â–†â–…â–…â–‚â–…â–â–…â–ƒâ–ƒ
wandb:          test_loss â–ˆâ–ˆâ–ƒâ–‡â–…â–ˆâ–…â–ˆâ–‚â–†â–â–…â–„â–…â–…â–…â–‚â–…â–‚â–…
wandb: train_error_energy â–ˆâ–â–â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–‚â–â–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–
wandb: valid_error_energy â–â–‡â–„â–ˆâ–„â–‡â–†â–‡â–ƒâ–‡â–ƒâ–†â–…â–‡â–…â–‡â–…â–ˆâ–…â–ˆ
wandb:  valid_error_force â–ˆâ–†â–†â–„â–ƒâ–†â–ƒâ–…â–†â–…â–„â–…â–„â–‚â–†â–„â–„â–…â–‡â–
wandb:         valid_loss â–â–‡â–„â–ˆâ–„â–ˆâ–†â–‡â–ƒâ–‡â–ƒâ–†â–„â–†â–†â–‡â–…â–ˆâ–†â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 3530
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.86719
wandb:   test_error_force 8.03581
wandb:          test_loss 4.85569
wandb: train_error_energy 3.14792
wandb:  train_error_force 4.41026
wandb:         train_loss 1.48989
wandb: valid_error_energy 3.32822
wandb:  valid_error_force 4.24695
wandb:         valid_loss 1.49253
wandb: 
wandb: ğŸš€ View run al_72_72 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3yfmszr7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_042334-3yfmszr7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.521681308746338, Uncertainty Bias: -0.12435957789421082
0.00038146973 0.033720255
2.5847912 6.2892594
(48745, 22, 3)
Found uncertainty sample 0 after 2326 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1600 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2427 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1620 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3043 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1501 steps.
Found uncertainty sample 33 after 943 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1401 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2474 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3037 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2515 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3597 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 590 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_050353-4be0xpq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_73
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/4be0xpq3
Training model 73. Added 13 samples to the dataset.
Epoch 0, Batch 100/111, Loss: 1.1419538259506226, Variance: 0.1352173388004303

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3662656002546556, Training Loss Force: 4.689030012683383, time: 1.7794976234436035
Validation Loss Energy: 2.1700169660258513, Validation Loss Force: 4.365413464412357, time: 0.11990237236022949
Test Loss Energy: 6.248703496629532, Test Loss Force: 8.049237475215005, time: 9.61234974861145

Epoch 1, Batch 100/111, Loss: 1.1202831268310547, Variance: 0.12956008315086365

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.216952121467973, Training Loss Force: 4.416924107712165, time: 1.75581955909729
Validation Loss Energy: 2.2997006641829736, Validation Loss Force: 4.327761299404748, time: 0.12059736251831055
Test Loss Energy: 6.110960132128807, Test Loss Force: 8.119644018219862, time: 9.632139921188354

Epoch 2, Batch 100/111, Loss: 1.0942625999450684, Variance: 0.12708230316638947

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.183596439878201, Training Loss Force: 4.433990470058184, time: 1.7376749515533447
Validation Loss Energy: 2.0197504000266027, Validation Loss Force: 4.333800235088406, time: 0.11632633209228516
Test Loss Energy: 6.100636726532391, Test Loss Force: 8.084590995929618, time: 9.855802059173584

Epoch 3, Batch 100/111, Loss: 1.1670290231704712, Variance: 0.1207231804728508

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1782290292030226, Training Loss Force: 4.441126217785891, time: 1.8275043964385986
Validation Loss Energy: 1.862889672828324, Validation Loss Force: 4.252751041108247, time: 0.1196286678314209
Test Loss Energy: 5.949355126923153, Test Loss Force: 8.090506655290131, time: 9.74189805984497

Epoch 4, Batch 100/111, Loss: 1.2497155666351318, Variance: 0.11677757650613785

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1926096917177746, Training Loss Force: 4.4525217747212915, time: 1.7481520175933838
Validation Loss Energy: 2.4941847949575138, Validation Loss Force: 4.655220178313222, time: 0.11584115028381348
Test Loss Energy: 6.424828141295018, Test Loss Force: 8.120088372570569, time: 10.907796621322632

Epoch 5, Batch 100/111, Loss: 1.4576815366744995, Variance: 0.12154674530029297

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.180363421292271, Training Loss Force: 4.4413970998169825, time: 1.767834186553955
Validation Loss Energy: 2.1890473845825693, Validation Loss Force: 4.468807507186369, time: 0.12139725685119629
Test Loss Energy: 6.30557434132201, Test Loss Force: 8.053161663340834, time: 9.648260593414307

Epoch 6, Batch 100/111, Loss: 1.4072248935699463, Variance: 0.1509874165058136

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.872532071246543, Training Loss Force: 4.913891707468073, time: 1.7914135456085205
Validation Loss Energy: 2.473214928139764, Validation Loss Force: 4.470276678211201, time: 0.11577582359313965
Test Loss Energy: 6.308519860079852, Test Loss Force: 8.127530698227845, time: 9.669491052627563

Epoch 7, Batch 100/111, Loss: 1.3415942192077637, Variance: 0.15916401147842407

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0992653563715504, Training Loss Force: 4.416602088006587, time: 1.7546465396881104
Validation Loss Energy: 1.9432415041549607, Validation Loss Force: 4.332621869968156, time: 0.11673903465270996
Test Loss Energy: 5.939327703414605, Test Loss Force: 8.107946958501566, time: 9.833319425582886

Epoch 8, Batch 100/111, Loss: 1.419458270072937, Variance: 0.16153961420059204

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.156351020237703, Training Loss Force: 4.417739855125257, time: 1.7299084663391113
Validation Loss Energy: 2.724289309006122, Validation Loss Force: 4.457576817696258, time: 0.11513376235961914
Test Loss Energy: 6.6476716756357, Test Loss Force: 8.104881366281138, time: 9.773494243621826

Epoch 9, Batch 100/111, Loss: 1.3100674152374268, Variance: 0.16546761989593506

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1868590733824362, Training Loss Force: 4.405139597929535, time: 1.82887601852417
Validation Loss Energy: 1.844569680181688, Validation Loss Force: 4.264905065323473, time: 0.1157078742980957
Test Loss Energy: 5.788654079175085, Test Loss Force: 8.063374354573634, time: 9.687368631362915

Epoch 10, Batch 100/111, Loss: 1.366877794265747, Variance: 0.1694933921098709

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.2129078549124195, Training Loss Force: 4.44049787354048, time: 1.9897291660308838
Validation Loss Energy: 2.9438672876270915, Validation Loss Force: 4.4052465994812815, time: 0.11537694931030273
Test Loss Energy: 6.4620797917373105, Test Loss Force: 8.05488526242716, time: 9.659546613693237

Epoch 11, Batch 100/111, Loss: 1.530515193939209, Variance: 0.16784141957759857

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.175423858269735, Training Loss Force: 4.412040459798713, time: 1.7926030158996582
Validation Loss Energy: 2.035905714571101, Validation Loss Force: 4.436640573919544, time: 0.11515212059020996
Test Loss Energy: 6.021428967528821, Test Loss Force: 8.051055210888741, time: 9.732412338256836

Epoch 12, Batch 100/111, Loss: 1.2635085582733154, Variance: 0.16363167762756348

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1523489646086165, Training Loss Force: 4.397699246834315, time: 1.7780158519744873
Validation Loss Energy: 2.6409329657819574, Validation Loss Force: 4.552968873596111, time: 0.11508369445800781
Test Loss Energy: 6.35520204082276, Test Loss Force: 8.058690934608615, time: 9.927737474441528

Epoch 13, Batch 100/111, Loss: 0.9960740804672241, Variance: 0.1580796241760254

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1362289060122235, Training Loss Force: 4.409448707289757, time: 1.7373199462890625
Validation Loss Energy: 2.0588173305643895, Validation Loss Force: 4.378064634607391, time: 0.11876940727233887
Test Loss Energy: 6.009920544717144, Test Loss Force: 8.106455103203219, time: 9.752275228500366

Epoch 14, Batch 100/111, Loss: 1.300506830215454, Variance: 0.16382022202014923

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.132891512768661, Training Loss Force: 4.404061385780275, time: 1.7813019752502441
Validation Loss Energy: 2.7920117546025023, Validation Loss Force: 4.406428230415673, time: 0.11661648750305176
Test Loss Energy: 6.457048585882494, Test Loss Force: 8.113771325843864, time: 9.783128261566162

Epoch 15, Batch 100/111, Loss: 1.4307793378829956, Variance: 0.16666315495967865

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.166046175273382, Training Loss Force: 4.411182790405336, time: 1.7375357151031494
Validation Loss Energy: 2.1674530792565903, Validation Loss Force: 4.409224361104136, time: 0.11694049835205078
Test Loss Energy: 6.140640877723025, Test Loss Force: 8.080493785716753, time: 9.818830966949463

Epoch 16, Batch 100/111, Loss: 1.3874680995941162, Variance: 0.16559135913848877

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.187714931332222, Training Loss Force: 4.397178008454123, time: 1.7835049629211426
Validation Loss Energy: 2.4969307508650953, Validation Loss Force: 4.34164442376115, time: 0.11792302131652832
Test Loss Energy: 6.4397337328357445, Test Loss Force: 8.07120687351784, time: 9.667736053466797

Epoch 17, Batch 100/111, Loss: 1.0264350175857544, Variance: 0.162334144115448

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1257286124443366, Training Loss Force: 4.398784034744483, time: 1.7296669483184814
Validation Loss Energy: 1.945305869806857, Validation Loss Force: 4.248625724064692, time: 0.11565375328063965
Test Loss Energy: 5.849181799432413, Test Loss Force: 8.047287268886548, time: 9.91784954071045

Epoch 18, Batch 100/111, Loss: 1.374110460281372, Variance: 0.1758924424648285

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.171442410569803, Training Loss Force: 4.410893890227679, time: 1.727858066558838
Validation Loss Energy: 2.712328190494319, Validation Loss Force: 4.289259280490179, time: 0.11629056930541992
Test Loss Energy: 6.487641843626408, Test Loss Force: 7.984802011706049, time: 9.767523288726807

Epoch 19, Batch 100/111, Loss: 1.364027976989746, Variance: 0.17134732007980347

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.160133856086595, Training Loss Force: 4.403765881757317, time: 1.70267653465271
Validation Loss Energy: 2.01963598519712, Validation Loss Force: 4.25276618261017, time: 0.1157693862915039
Test Loss Energy: 5.8705660488675075, Test Loss Force: 8.009875040181635, time: 9.7469322681427

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–„â–‚â–†â–…â–…â–‚â–ˆâ–â–†â–ƒâ–†â–ƒâ–†â–„â–†â–â–‡â–‚
wandb:   test_error_force â–„â–ˆâ–†â–†â–ˆâ–„â–ˆâ–‡â–‡â–…â–„â–„â–…â–‡â–‡â–†â–…â–„â–â–‚
wandb:          test_loss â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ƒâ–‚â–„â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:  train_error_force â–…â–â–â–‚â–‚â–‚â–ˆâ–â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb: valid_error_energy â–ƒâ–„â–‚â–â–…â–ƒâ–…â–‚â–‡â–â–ˆâ–‚â–†â–‚â–‡â–ƒâ–…â–‚â–‡â–‚
wandb:  valid_error_force â–ƒâ–‚â–‚â–â–ˆâ–…â–…â–‚â–…â–â–„â–„â–†â–ƒâ–„â–„â–ƒâ–â–‚â–
wandb:         valid_loss â–ƒâ–ƒâ–‚â–â–‡â–„â–†â–ƒâ–‡â–‚â–ˆâ–„â–‡â–ƒâ–‡â–…â–…â–ƒâ–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3541
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.87057
wandb:   test_error_force 8.00988
wandb:          test_loss 4.55796
wandb: train_error_energy 3.16013
wandb:  train_error_force 4.40377
wandb:         train_loss 1.48061
wandb: valid_error_energy 2.01964
wandb:  valid_error_force 4.25277
wandb:         valid_loss 1.12231
wandb: 
wandb: ğŸš€ View run al_72_73 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/4be0xpq3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_050353-4be0xpq3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6174261569976807, Uncertainty Bias: -0.11424392461776733
0.00020980835 0.0004119873
2.5473447 6.11146
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3745 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1294 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2460 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3811 steps.
Found uncertainty sample 27 after 3832 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3621 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 188 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1452 steps.
Found uncertainty sample 47 after 3076 steps.
Found uncertainty sample 48 after 1062 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1683 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 547 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1885 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2800 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3085 steps.
Found uncertainty sample 86 after 2834 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3819 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2052 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_054350-6lku803d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_74
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6lku803d
Training model 74. Added 18 samples to the dataset.
Epoch 0, Batch 100/112, Loss: 1.343238115310669, Variance: 0.15520823001861572

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5030890468227023, Training Loss Force: 4.749836169945172, time: 1.8205413818359375
Validation Loss Energy: 3.3304836434338347, Validation Loss Force: 4.306409555001731, time: 0.12335586547851562
Test Loss Energy: 6.901733657396867, Test Loss Force: 8.011301528678871, time: 9.792099952697754

Epoch 1, Batch 100/112, Loss: 1.249603271484375, Variance: 0.15771406888961792

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0929578643063533, Training Loss Force: 4.388552442833989, time: 1.8191416263580322
Validation Loss Energy: 3.2672280151278144, Validation Loss Force: 4.427158431009355, time: 0.12073945999145508
Test Loss Energy: 6.387707403989231, Test Loss Force: 7.9973288649008465, time: 9.743006229400635

Epoch 2, Batch 100/112, Loss: 1.786958932876587, Variance: 0.17135989665985107

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0814073109194697, Training Loss Force: 4.387384726070396, time: 1.7565126419067383
Validation Loss Energy: 2.8049371789622697, Validation Loss Force: 4.292140916130679, time: 0.11596322059631348
Test Loss Energy: 6.5050342741372775, Test Loss Force: 7.964614255690783, time: 9.955698490142822

Epoch 3, Batch 100/112, Loss: 1.2049185037612915, Variance: 0.15763872861862183

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.1729365100968847, Training Loss Force: 4.3958089917256915, time: 1.7600104808807373
Validation Loss Energy: 3.2011627475384774, Validation Loss Force: 4.230724163854779, time: 0.11916375160217285
Test Loss Energy: 6.731708300691439, Test Loss Force: 8.070844018406156, time: 9.774836778640747

Epoch 4, Batch 100/112, Loss: 1.3859471082687378, Variance: 0.16411222517490387

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1196696069486256, Training Loss Force: 4.413864027969845, time: 1.7192306518554688
Validation Loss Energy: 3.392601729296358, Validation Loss Force: 4.197043822626131, time: 0.11590313911437988
Test Loss Energy: 6.664647425723537, Test Loss Force: 7.9984726638421595, time: 9.920303106307983

Epoch 5, Batch 100/112, Loss: 1.648268461227417, Variance: 0.16896727681159973

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.167879171912054, Training Loss Force: 4.3853600869798735, time: 1.8127071857452393
Validation Loss Energy: 2.478484838816437, Validation Loss Force: 4.222233492428358, time: 0.12393069267272949
Test Loss Energy: 6.541565532767947, Test Loss Force: 8.057439123644421, time: 9.824471712112427

Epoch 6, Batch 100/112, Loss: 1.2497081756591797, Variance: 0.16051670908927917

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1469370333673248, Training Loss Force: 4.39577670469953, time: 1.892176628112793
Validation Loss Energy: 3.0138372071363695, Validation Loss Force: 4.528825451887551, time: 0.11525106430053711
Test Loss Energy: 6.645324509676211, Test Loss Force: 8.107210853942568, time: 9.868944644927979

Epoch 7, Batch 100/112, Loss: 1.3289730548858643, Variance: 0.1408269703388214

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.3139374226003673, Training Loss Force: 5.327252856613162, time: 1.7107715606689453
Validation Loss Energy: 2.2656599700531657, Validation Loss Force: 4.495368076697025, time: 0.11773896217346191
Test Loss Energy: 6.182170755569944, Test Loss Force: 8.12363421667229, time: 10.009130954742432

Epoch 8, Batch 100/112, Loss: 1.8541700839996338, Variance: 0.13504254817962646

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.4312088709086574, Training Loss Force: 5.213443343925924, time: 1.755573034286499
Validation Loss Energy: 2.420463642569839, Validation Loss Force: 4.557704600991703, time: 0.11916041374206543
Test Loss Energy: 6.014278912029778, Test Loss Force: 8.107216184012387, time: 9.845766305923462

Epoch 9, Batch 100/112, Loss: 1.4949051141738892, Variance: 0.16131749749183655

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1299932463830364, Training Loss Force: 4.439277655218059, time: 1.7828400135040283
Validation Loss Energy: 4.2920478404276805, Validation Loss Force: 4.436338189219374, time: 0.11730051040649414
Test Loss Energy: 7.317775847703614, Test Loss Force: 8.062943985244258, time: 9.876850605010986

Epoch 10, Batch 100/112, Loss: 1.85933518409729, Variance: 0.15563304722309113

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1376608961972896, Training Loss Force: 4.397208208852588, time: 1.9835562705993652
Validation Loss Energy: 2.2587699928937703, Validation Loss Force: 4.4779408017679385, time: 0.11881470680236816
Test Loss Energy: 5.935824691063782, Test Loss Force: 8.070132801495994, time: 9.872685670852661

Epoch 11, Batch 100/112, Loss: 1.130641222000122, Variance: 0.16833601891994476

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.092287756422564, Training Loss Force: 4.400447007128568, time: 1.8304691314697266
Validation Loss Energy: 2.429199398502878, Validation Loss Force: 4.320435187611528, time: 0.11614060401916504
Test Loss Energy: 6.125268947042304, Test Loss Force: 7.974494680257193, time: 10.867577314376831

Epoch 12, Batch 100/112, Loss: 1.2797118425369263, Variance: 0.1648472547531128

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.120172845182775, Training Loss Force: 4.385351975460986, time: 1.810554027557373
Validation Loss Energy: 4.306719213560668, Validation Loss Force: 4.364187299648782, time: 0.11626410484313965
Test Loss Energy: 7.423952032258732, Test Loss Force: 7.988061270124697, time: 10.004061937332153

Epoch 13, Batch 100/112, Loss: 1.5162030458450317, Variance: 0.15645065903663635

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0908380580133548, Training Loss Force: 4.383649832865993, time: 1.8365004062652588
Validation Loss Energy: 2.300862626009473, Validation Loss Force: 4.415991870233271, time: 0.11615729331970215
Test Loss Energy: 5.982655836299508, Test Loss Force: 7.98828173822692, time: 9.950403690338135

Epoch 14, Batch 100/112, Loss: 1.3972759246826172, Variance: 0.16870486736297607

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.153382188814028, Training Loss Force: 4.380292280363008, time: 1.8050644397735596
Validation Loss Energy: 2.2739021427127315, Validation Loss Force: 4.308934920008747, time: 0.12555789947509766
Test Loss Energy: 5.963729576773382, Test Loss Force: 7.992300480299082, time: 9.921005964279175

Epoch 15, Batch 100/112, Loss: 1.536273717880249, Variance: 0.1600603312253952

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1574150401752665, Training Loss Force: 4.393380796618052, time: 1.8458549976348877
Validation Loss Energy: 4.116489844826516, Validation Loss Force: 4.400497066598643, time: 0.1713705062866211
Test Loss Energy: 7.392408135811466, Test Loss Force: 8.047604662186636, time: 9.913840532302856

Epoch 16, Batch 100/112, Loss: 1.6651251316070557, Variance: 0.36837926506996155

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1297646804809767, Training Loss Force: 4.387893197029475, time: 1.7793223857879639
Validation Loss Energy: 1.739819916312695, Validation Loss Force: 4.295916048830738, time: 0.11758828163146973
Test Loss Energy: 5.884435212295924, Test Loss Force: 8.00757584718212, time: 9.847556352615356

Epoch 17, Batch 100/112, Loss: 1.0509848594665527, Variance: 0.1632748246192932

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.139568958049332, Training Loss Force: 4.392108341854944, time: 1.7566514015197754
Validation Loss Energy: 2.2896677862518566, Validation Loss Force: 4.280555143575861, time: 0.1174783706665039
Test Loss Energy: 6.115660281424947, Test Loss Force: 7.998133066581057, time: 10.024430990219116

Epoch 18, Batch 100/112, Loss: 1.7261239290237427, Variance: 0.28492337465286255

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.15292116328203, Training Loss Force: 4.386816378980354, time: 1.7813136577606201
Validation Loss Energy: 4.485601659510535, Validation Loss Force: 4.360738748362749, time: 0.11714911460876465
Test Loss Energy: 7.545055235888095, Test Loss Force: 8.077738174595213, time: 9.881111860275269

Epoch 19, Batch 100/112, Loss: 1.368499517440796, Variance: 0.15695346891880035

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1687107407721666, Training Loss Force: 4.402173281492251, time: 1.7866101264953613
Validation Loss Energy: 1.918488006098082, Validation Loss Force: 4.273392767827949, time: 0.12035942077636719
Test Loss Energy: 5.86512674759275, Test Loss Force: 7.9996288459859235, time: 9.876083612442017

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–„â–…â–„â–„â–„â–‚â–‚â–‡â–â–‚â–‡â–â–â–‡â–â–‚â–ˆâ–
wandb:   test_error_force â–ƒâ–‚â–â–†â–‚â–…â–‡â–ˆâ–‡â–…â–†â–â–‚â–‚â–‚â–…â–ƒâ–‚â–†â–ƒ
wandb:          test_loss â–†â–„â–„â–„â–…â–„â–„â–ˆâ–…â–‡â–‚â–‚â–‡â–‚â–â–‡â–‚â–‚â–‡â–
wandb: train_error_energy â–ˆâ–…â–…â–†â–…â–†â–†â–‡â–â–†â–†â–…â–…â–…â–†â–†â–†â–†â–†â–†
wandb:  train_error_force â–„â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–…â–„â–…â–…â–ƒâ–„â–‚â–ƒâ–ˆâ–‚â–ƒâ–ˆâ–‚â–‚â–‡â–â–‚â–ˆâ–
wandb:  valid_error_force â–ƒâ–…â–ƒâ–‚â–â–â–‡â–‡â–ˆâ–†â–†â–ƒâ–„â–…â–ƒâ–…â–ƒâ–ƒâ–„â–‚
wandb:         valid_loss â–…â–…â–ƒâ–„â–…â–‚â–„â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–ˆâ–ƒâ–‚â–‡â–â–‚â–ˆâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3557
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.86513
wandb:   test_error_force 7.99963
wandb:          test_loss 4.48881
wandb: train_error_energy 3.16871
wandb:  train_error_force 4.40217
wandb:         train_loss 1.48628
wandb: valid_error_energy 1.91849
wandb:  valid_error_force 4.27339
wandb:         valid_loss 1.0985
wandb: 
wandb: ğŸš€ View run al_72_74 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6lku803d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_054350-6lku803d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.629739284515381, Uncertainty Bias: -0.1240256130695343
0.000114917755 0.0041332245
2.4659655 6.416756
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2120 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2551 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1455 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2115 steps.
Found uncertainty sample 29 after 3848 steps.
Found uncertainty sample 30 after 2994 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3709 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 980 steps.
Found uncertainty sample 62 after 685 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2634 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2187 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2789 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1555 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3026 steps.
Found uncertainty sample 94 after 829 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2316 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_062401-n4jxgg87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_75
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/n4jxgg87
Training model 75. Added 16 samples to the dataset.
Epoch 0, Batch 100/112, Loss: 1.2693281173706055, Variance: 0.13752661645412445

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8790100694071685, Training Loss Force: 4.55224216235391, time: 1.795802354812622
Validation Loss Energy: 2.190025347471485, Validation Loss Force: 4.367766483500425, time: 0.1198415756225586
Test Loss Energy: 6.141684426584777, Test Loss Force: 8.040437903004227, time: 10.715839385986328

Epoch 1, Batch 100/112, Loss: 1.1705505847930908, Variance: 0.1270778477191925

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.174655192831876, Training Loss Force: 4.455567795930418, time: 1.777885913848877
Validation Loss Energy: 2.2228400995068625, Validation Loss Force: 4.715925873783125, time: 0.11548733711242676
Test Loss Energy: 6.098872587671821, Test Loss Force: 8.28755274031445, time: 9.691664457321167

Epoch 2, Batch 100/112, Loss: 1.2151111364364624, Variance: 0.12518203258514404

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2033800315551955, Training Loss Force: 4.437886720588144, time: 1.7433099746704102
Validation Loss Energy: 2.3297933601324328, Validation Loss Force: 4.379683439298286, time: 0.11575675010681152
Test Loss Energy: 6.124185324729131, Test Loss Force: 8.117510348836458, time: 9.855706691741943

Epoch 3, Batch 100/112, Loss: 1.234655499458313, Variance: 0.12183981388807297

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.16768856115629, Training Loss Force: 4.410076940720015, time: 1.7562105655670166
Validation Loss Energy: 2.138690683007952, Validation Loss Force: 4.363204883376948, time: 0.1151893138885498
Test Loss Energy: 6.098529376408875, Test Loss Force: 8.058648720735453, time: 9.673618793487549

Epoch 4, Batch 100/112, Loss: 1.0432032346725464, Variance: 0.1164042055606842

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.196885922694383, Training Loss Force: 4.438720103605361, time: 1.7186462879180908
Validation Loss Energy: 2.2311069884416264, Validation Loss Force: 4.506937817073336, time: 0.11520910263061523
Test Loss Energy: 6.281325606045279, Test Loss Force: 8.046399723660564, time: 9.838513135910034

Epoch 5, Batch 100/112, Loss: 1.256028413772583, Variance: 0.12593959271907806

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.184393041434403, Training Loss Force: 4.431992873071524, time: 1.7490875720977783
Validation Loss Energy: 2.276589239742739, Validation Loss Force: 4.549933744691018, time: 0.1186058521270752
Test Loss Energy: 6.050730608992737, Test Loss Force: 7.990508434349428, time: 9.682750463485718

Epoch 6, Batch 100/112, Loss: 1.51358163356781, Variance: 0.1258741170167923

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1810359044479486, Training Loss Force: 4.434773599163866, time: 1.818763256072998
Validation Loss Energy: 2.235483105166545, Validation Loss Force: 4.388544038399142, time: 0.11726927757263184
Test Loss Energy: 6.177935798259666, Test Loss Force: 8.11964093582603, time: 9.724802017211914

Epoch 7, Batch 100/112, Loss: 1.0767333507537842, Variance: 0.11906394362449646

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2001438963624387, Training Loss Force: 4.409134606882565, time: 1.728186845779419
Validation Loss Energy: 2.4844532626038855, Validation Loss Force: 4.545215533934907, time: 0.11665177345275879
Test Loss Energy: 6.31776460270627, Test Loss Force: 8.011177799245386, time: 9.881036520004272

Epoch 8, Batch 100/112, Loss: 0.996232271194458, Variance: 0.12416017800569534

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2340453394378175, Training Loss Force: 4.556442899292767, time: 1.774482250213623
Validation Loss Energy: 2.939281045451466, Validation Loss Force: 5.985872290169425, time: 0.11857414245605469
Test Loss Energy: 5.866552627538707, Test Loss Force: 9.366398853936621, time: 9.7149498462677

Epoch 9, Batch 100/112, Loss: 1.2576910257339478, Variance: 0.15565262734889984

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0549893484053707, Training Loss Force: 4.811375027088559, time: 1.7749130725860596
Validation Loss Energy: 3.686778770524347, Validation Loss Force: 4.29962764660116, time: 0.12132477760314941
Test Loss Energy: 6.3993340093244635, Test Loss Force: 8.007542106394572, time: 9.72305965423584

Epoch 10, Batch 100/112, Loss: 2.0708107948303223, Variance: 0.16730043292045593

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1681968034843675, Training Loss Force: 4.386816665269256, time: 1.9523773193359375
Validation Loss Energy: 2.480219357240166, Validation Loss Force: 4.360912578742671, time: 0.12421870231628418
Test Loss Energy: 6.400805940980382, Test Loss Force: 8.028140392034894, time: 9.778465032577515

Epoch 11, Batch 100/112, Loss: 1.3389490842819214, Variance: 0.1653670370578766

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1386843382652017, Training Loss Force: 4.378143431651406, time: 1.776721477508545
Validation Loss Energy: 3.183402211120985, Validation Loss Force: 4.3802987483715325, time: 0.1335921287536621
Test Loss Energy: 6.741783498972765, Test Loss Force: 8.016126281763782, time: 9.749354839324951

Epoch 12, Batch 100/112, Loss: 1.0590986013412476, Variance: 0.157697856426239

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.140993172770036, Training Loss Force: 4.400306952212014, time: 1.8118491172790527
Validation Loss Energy: 3.5740004108182575, Validation Loss Force: 4.395883213448921, time: 0.11593961715698242
Test Loss Energy: 6.371154827869678, Test Loss Force: 7.980697368307456, time: 9.898650884628296

Epoch 13, Batch 100/112, Loss: 2.0931570529937744, Variance: 0.17141711711883545

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1100002758292304, Training Loss Force: 4.3722127900465395, time: 1.7350099086761475
Validation Loss Energy: 2.6854506143429107, Validation Loss Force: 4.433028138142109, time: 0.11703300476074219
Test Loss Energy: 6.387331083806158, Test Loss Force: 8.030782458213313, time: 9.795035362243652

Epoch 14, Batch 100/112, Loss: 1.3009767532348633, Variance: 0.16689848899841309

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.162931677212156, Training Loss Force: 4.3690212811304265, time: 1.7326669692993164
Validation Loss Energy: 3.2375353814105385, Validation Loss Force: 4.263927399326753, time: 0.1180732250213623
Test Loss Energy: 6.741233914214789, Test Loss Force: 7.946718777107629, time: 9.752862453460693

Epoch 15, Batch 100/112, Loss: 1.4535188674926758, Variance: 0.16230416297912598

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1710381830615657, Training Loss Force: 4.402541592164555, time: 1.7707958221435547
Validation Loss Energy: 3.4019465595665586, Validation Loss Force: 4.358737991863539, time: 0.11648368835449219
Test Loss Energy: 6.494682273625619, Test Loss Force: 8.060696626357656, time: 9.906887531280518

Epoch 16, Batch 100/112, Loss: 1.9600814580917358, Variance: 0.17015902698040009

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1401235712245517, Training Loss Force: 4.378166298977446, time: 1.7728431224822998
Validation Loss Energy: 2.5815294394774395, Validation Loss Force: 4.411459513990959, time: 0.11757707595825195
Test Loss Energy: 6.289936739536635, Test Loss Force: 7.960939897683456, time: 9.781944274902344

Epoch 17, Batch 100/112, Loss: 1.0535825490951538, Variance: 0.1574477106332779

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.161675655233205, Training Loss Force: 4.397307769794461, time: 1.8476006984710693
Validation Loss Energy: 3.340397319148831, Validation Loss Force: 4.34704682257965, time: 0.11659622192382812
Test Loss Energy: 6.672380221532964, Test Loss Force: 8.0484110229415, time: 9.934168338775635

Epoch 18, Batch 100/112, Loss: 1.2795305252075195, Variance: 0.15538930892944336

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1842728120268027, Training Loss Force: 4.39742636894831, time: 1.7289087772369385
Validation Loss Energy: 3.2934876101762245, Validation Loss Force: 4.398363896180654, time: 0.11729955673217773
Test Loss Energy: 6.384334747519149, Test Loss Force: 7.947306497745718, time: 9.771604299545288

Epoch 19, Batch 100/112, Loss: 1.739329218864441, Variance: 0.1613122820854187

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1638471486017012, Training Loss Force: 4.386926802995561, time: 1.7992618083953857
Validation Loss Energy: 2.4786189598653343, Validation Loss Force: 4.311625505522041, time: 0.12605643272399902
Test Loss Energy: 6.172827917275385, Test Loss Force: 8.002745757032551, time: 9.744360208511353

wandb: - 0.039 MB of 0.059 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–…â–â–…â–…â–ˆâ–…â–…â–ˆâ–†â–„â–‡â–…â–ƒ
wandb:   test_error_force â–â–ƒâ–‚â–‚â–â–â–‚â–â–ˆâ–â–â–â–â–â–â–‚â–â–‚â–â–
wandb:          test_loss â–„â–†â–…â–…â–†â–…â–…â–…â–ˆâ–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–
wandb: train_error_energy â–†â–â–â–â–â–â–â–â–â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–ˆâ–â–â–â–â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–‚â–ˆâ–†â–…â–†â–…â–…â–†â–…â–†â–†â–†
wandb: valid_error_energy â–â–â–‚â–â–â–‚â–â–ƒâ–…â–ˆâ–ƒâ–†â–‡â–ƒâ–†â–‡â–ƒâ–†â–†â–ƒ
wandb:  valid_error_force â–â–ƒâ–â–â–‚â–‚â–‚â–‚â–ˆâ–â–â–â–‚â–‚â–â–â–‚â–â–‚â–
wandb:         valid_loss â–â–‚â–â–â–‚â–‚â–â–‚â–ˆâ–„â–‚â–ƒâ–„â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3571
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.17283
wandb:   test_error_force 8.00275
wandb:          test_loss 4.67849
wandb: train_error_energy 3.16385
wandb:  train_error_force 4.38693
wandb:         train_loss 1.47883
wandb: valid_error_energy 2.47862
wandb:  valid_error_force 4.31163
wandb:         valid_loss 1.24519
wandb: 
wandb: ğŸš€ View run al_72_75 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/n4jxgg87
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_062401-n4jxgg87/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5197787284851074, Uncertainty Bias: -0.09287947416305542
0.00023269653 0.0012521744
2.4898791 6.3848553
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3167 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 363 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2376 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3660 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2766 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2351 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3814 steps.
Found uncertainty sample 42 after 2003 steps.
Found uncertainty sample 43 after 3246 steps.
Found uncertainty sample 44 after 2396 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3921 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3213 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2099 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3546 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2403 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2589 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_070504-shu4qpdz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_76
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/shu4qpdz
Training model 76. Added 16 samples to the dataset.
Epoch 0, Batch 100/113, Loss: 1.5788397789001465, Variance: 0.17350995540618896

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.046486204488542, Training Loss Force: 4.891917984231614, time: 1.7300162315368652
Validation Loss Energy: 5.8059300875310385, Validation Loss Force: 4.375898509155806, time: 0.1192326545715332
Test Loss Energy: 8.184758643608424, Test Loss Force: 8.0339956486007, time: 9.829828262329102

Epoch 1, Batch 100/113, Loss: 2.2288918495178223, Variance: 0.20049792528152466

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.715125896451173, Training Loss Force: 4.406713889313093, time: 1.8077309131622314
Validation Loss Energy: 3.4250331192854975, Validation Loss Force: 4.344792965484569, time: 0.11797285079956055
Test Loss Energy: 6.680915167202203, Test Loss Force: 7.902109287044739, time: 9.840118408203125

Epoch 2, Batch 100/113, Loss: 2.2591958045959473, Variance: 0.19605422019958496

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.646947994253621, Training Loss Force: 4.418791227325407, time: 1.8352317810058594
Validation Loss Energy: 3.6152078598558486, Validation Loss Force: 4.433487727259304, time: 0.11665678024291992
Test Loss Energy: 6.3432371928942155, Test Loss Force: 7.950589086294986, time: 10.009015083312988

Epoch 3, Batch 100/113, Loss: 1.6062045097351074, Variance: 0.12986527383327484

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.4544559018909404, Training Loss Force: 4.953828351966202, time: 1.7387917041778564
Validation Loss Energy: 2.084699501410452, Validation Loss Force: 4.4043617122953655, time: 0.12158632278442383
Test Loss Energy: 6.1843663619501275, Test Loss Force: 8.227316432181366, time: 9.89684009552002

Epoch 4, Batch 100/113, Loss: 0.9702135324478149, Variance: 0.11964017897844315

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1438334285833838, Training Loss Force: 4.408278197208415, time: 1.8406496047973633
Validation Loss Energy: 1.8388249646628487, Validation Loss Force: 4.320230331997275, time: 0.12094283103942871
Test Loss Energy: 5.78651313049248, Test Loss Force: 7.997809942173527, time: 10.023688793182373

Epoch 5, Batch 100/113, Loss: 2.2325429916381836, Variance: 0.13214340806007385

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.090069618539192, Training Loss Force: 5.024404070802725, time: 1.799229621887207
Validation Loss Energy: 5.957839580711991, Validation Loss Force: 4.584291890799871, time: 0.11929464340209961
Test Loss Energy: 8.45650829884666, Test Loss Force: 8.335015351931887, time: 9.876038551330566

Epoch 6, Batch 100/113, Loss: 1.8297450542449951, Variance: 0.13654214143753052

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.550582477782436, Training Loss Force: 5.246538921129598, time: 1.7722969055175781
Validation Loss Energy: 6.57867693506811, Validation Loss Force: 4.851668102508748, time: 0.12759709358215332
Test Loss Energy: 8.610922293751722, Test Loss Force: 8.306223009597637, time: 9.793936252593994

Epoch 7, Batch 100/113, Loss: 1.201114296913147, Variance: 0.1254035234451294

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.7790895130481417, Training Loss Force: 4.923921615625125, time: 1.7458820343017578
Validation Loss Energy: 1.5951951184638187, Validation Loss Force: 4.537971512833486, time: 0.11732792854309082
Test Loss Energy: 5.745476901981436, Test Loss Force: 8.339115644538584, time: 11.041740894317627

Epoch 8, Batch 100/113, Loss: 1.6402692794799805, Variance: 0.13784439861774445

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.7438031974533055, Training Loss Force: 4.6311480330639565, time: 1.7683513164520264
Validation Loss Energy: 2.3173366543248437, Validation Loss Force: 4.3139158803570545, time: 0.12143135070800781
Test Loss Energy: 6.015988777909094, Test Loss Force: 7.963027186599314, time: 9.868937730789185

Epoch 9, Batch 100/113, Loss: 1.323805332183838, Variance: 0.1486242413520813

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1465607808610714, Training Loss Force: 4.37264065658697, time: 1.8084790706634521
Validation Loss Energy: 2.640666653483428, Validation Loss Force: 4.31871707248155, time: 0.11867642402648926
Test Loss Energy: 6.353561796940277, Test Loss Force: 7.9277106639371375, time: 10.03141450881958

Epoch 10, Batch 100/113, Loss: 1.1506438255310059, Variance: 0.15645769238471985

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0189436763609874, Training Loss Force: 4.351597305010017, time: 1.7450635433197021
Validation Loss Energy: 4.490019415365743, Validation Loss Force: 4.363271090336338, time: 0.11964702606201172
Test Loss Energy: 7.496428335104691, Test Loss Force: 8.006392604325189, time: 9.82634949684143

Epoch 11, Batch 100/113, Loss: 1.7859184741973877, Variance: 0.1540660262107849

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.124033439923205, Training Loss Force: 4.369989874989823, time: 1.767467737197876
Validation Loss Energy: 2.879405237888435, Validation Loss Force: 4.2928055093082245, time: 0.11963391304016113
Test Loss Energy: 6.536032444647894, Test Loss Force: 7.981084686714208, time: 9.853861331939697

Epoch 12, Batch 100/113, Loss: 1.0681285858154297, Variance: 0.1533183753490448

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.191276502166262, Training Loss Force: 4.388635018778908, time: 1.768432855606079
Validation Loss Energy: 2.2439683583104153, Validation Loss Force: 4.308273889537536, time: 0.12250566482543945
Test Loss Energy: 5.962803378048957, Test Loss Force: 7.9274352047165175, time: 9.990464210510254

Epoch 13, Batch 100/113, Loss: 1.2058632373809814, Variance: 0.15501338243484497

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0805881869879563, Training Loss Force: 4.358481923659405, time: 1.7603325843811035
Validation Loss Energy: 3.1463117661455016, Validation Loss Force: 4.3990004330458135, time: 0.11766171455383301
Test Loss Energy: 6.282028016449011, Test Loss Force: 7.9543783812190485, time: 9.911540508270264

Epoch 14, Batch 100/113, Loss: 2.054509162902832, Variance: 0.16452841460704803

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.154326995922273, Training Loss Force: 4.361222736500872, time: 1.7171387672424316
Validation Loss Energy: 2.289992066751376, Validation Loss Force: 4.376588041277695, time: 0.12374663352966309
Test Loss Energy: 5.863733361020799, Test Loss Force: 7.939878537162873, time: 9.890784978866577

Epoch 15, Batch 100/113, Loss: 1.3306853771209717, Variance: 0.1584547609090805

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0720177747189084, Training Loss Force: 4.345303063057945, time: 2.0416886806488037
Validation Loss Energy: 3.008413803195104, Validation Loss Force: 4.420321449106691, time: 0.1223452091217041
Test Loss Energy: 6.5557552814761495, Test Loss Force: 7.987492654732491, time: 9.85376524925232

Epoch 16, Batch 100/113, Loss: 1.4143542051315308, Variance: 0.16472452878952026

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.127836684110307, Training Loss Force: 4.372305618343286, time: 1.713658332824707
Validation Loss Energy: 4.363069055197932, Validation Loss Force: 4.379863504414293, time: 0.11807847023010254
Test Loss Energy: 7.5050199506544715, Test Loss Force: 7.999859899616132, time: 9.937026262283325

Epoch 17, Batch 100/113, Loss: 1.8291829824447632, Variance: 0.15837866067886353

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.2006094813802224, Training Loss Force: 4.385980692210137, time: 1.7889745235443115
Validation Loss Energy: 2.979219131911171, Validation Loss Force: 4.390596454140207, time: 0.11793208122253418
Test Loss Energy: 6.865890299535425, Test Loss Force: 8.014792290729249, time: 10.09114670753479

Epoch 18, Batch 100/113, Loss: 1.3233702182769775, Variance: 0.153799906373024

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.09067247751708, Training Loss Force: 4.3498311603423145, time: 1.7149198055267334
Validation Loss Energy: 2.0153606262607333, Validation Loss Force: 4.323964642020581, time: 0.11929583549499512
Test Loss Energy: 5.847326121402533, Test Loss Force: 7.97817551082524, time: 9.927040100097656

Epoch 19, Batch 100/113, Loss: 1.126230001449585, Variance: 0.1561538726091385

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0575619026245056, Training Loss Force: 4.393913042100482, time: 1.74281907081604
Validation Loss Energy: 5.972519860610816, Validation Loss Force: 5.340720949538965, time: 0.1174325942993164
Test Loss Energy: 8.03571276813146, Test Loss Force: 8.633865446380034, time: 9.925782203674316

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–ƒâ–‚â–‚â–â–ˆâ–ˆâ–â–‚â–‚â–…â–ƒâ–‚â–‚â–â–ƒâ–…â–„â–â–‡
wandb:   test_error_force â–‚â–â–â–„â–‚â–…â–…â–…â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–ˆ
wandb:          test_loss â–ƒâ–â–â–…â–„â–ˆâ–ˆâ–„â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–†
wandb: train_error_energy â–ˆâ–‡â–‡â–‚â–â–ƒâ–‡â–…â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒ
wandb:  train_error_force â–…â–â–‚â–†â–â–†â–ˆâ–…â–ƒâ–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–„â–„â–‚â–â–„â–‡â–†â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚
wandb: valid_error_energy â–‡â–„â–„â–‚â–â–‡â–ˆâ–â–‚â–‚â–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–…â–ƒâ–‚â–‡
wandb:  valid_error_force â–‚â–â–‚â–‚â–â–ƒâ–…â–ƒâ–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–ˆ
wandb:         valid_loss â–„â–‚â–‚â–â–â–‡â–ˆâ–â–â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–‚â–â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 3585
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.03571
wandb:   test_error_force 8.63387
wandb:          test_loss 6.355
wandb: train_error_energy 3.05756
wandb:  train_error_force 4.39391
wandb:         train_loss 1.45439
wandb: valid_error_energy 5.97252
wandb:  valid_error_force 5.34072
wandb:         valid_loss 3.38408
wandb: 
wandb: ğŸš€ View run al_72_76 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/shu4qpdz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_070504-shu4qpdz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5485522747039795, Uncertainty Bias: -0.007369786500930786
0.00013399124 0.024290085
3.6332042 7.28544
(48745, 22, 3)
Found uncertainty sample 0 after 3779 steps.
Found uncertainty sample 1 after 2527 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1754 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 217 steps.
Found uncertainty sample 9 after 2486 steps.
Found uncertainty sample 10 after 1901 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1321 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 646 steps.
Found uncertainty sample 16 after 3464 steps.
Found uncertainty sample 17 after 2059 steps.
Found uncertainty sample 18 after 2419 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 171 steps.
Found uncertainty sample 21 after 3423 steps.
Found uncertainty sample 22 after 1393 steps.
Found uncertainty sample 23 after 1590 steps.
Found uncertainty sample 24 after 1559 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 493 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3271 steps.
Found uncertainty sample 29 after 774 steps.
Found uncertainty sample 30 after 2075 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1594 steps.
Found uncertainty sample 34 after 3303 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2393 steps.
Found uncertainty sample 37 after 3018 steps.
Found uncertainty sample 38 after 1051 steps.
Found uncertainty sample 39 after 536 steps.
Found uncertainty sample 40 after 3842 steps.
Found uncertainty sample 41 after 2348 steps.
Found uncertainty sample 42 after 1928 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3327 steps.
Found uncertainty sample 45 after 1576 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1719 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1329 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 667 steps.
Found uncertainty sample 52 after 1901 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2144 steps.
Found uncertainty sample 55 after 2634 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 949 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1550 steps.
Found uncertainty sample 61 after 86 steps.
Found uncertainty sample 62 after 98 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 673 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3343 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 815 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 319 steps.
Found uncertainty sample 75 after 2271 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 651 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1650 steps.
Found uncertainty sample 82 after 3089 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 736 steps.
Found uncertainty sample 86 after 3164 steps.
Found uncertainty sample 87 after 802 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1260 steps.
Found uncertainty sample 90 after 1693 steps.
Found uncertainty sample 91 after 1639 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 92 steps.
Found uncertainty sample 94 after 71 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2503 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_073609-be6dkftz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_77
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/be6dkftz
Training model 77. Added 58 samples to the dataset.
Epoch 0, Batch 100/114, Loss: 1.4812490940093994, Variance: 0.19074633717536926

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.309328081610097, Training Loss Force: 4.833109305016057, time: 1.7566397190093994
Validation Loss Energy: 3.252159177569346, Validation Loss Force: 4.232389580620221, time: 0.10870695114135742
Test Loss Energy: 6.68822146416165, Test Loss Force: 7.922654523801205, time: 8.624562740325928

Epoch 1, Batch 100/114, Loss: 2.162158489227295, Variance: 0.20143750309944153

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.656094195728989, Training Loss Force: 4.38739871034849, time: 1.8397841453552246
Validation Loss Energy: 5.884883519509724, Validation Loss Force: 4.41436519789922, time: 0.10687828063964844
Test Loss Energy: 7.876944208776355, Test Loss Force: 7.887290872223355, time: 8.611786603927612

Epoch 2, Batch 100/114, Loss: 1.6306567192077637, Variance: 0.21276824176311493

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.724069399127951, Training Loss Force: 4.411060459629647, time: 1.761664628982544
Validation Loss Energy: 1.9186239085001464, Validation Loss Force: 4.282894654069075, time: 0.114654541015625
Test Loss Energy: 5.815478809681666, Test Loss Force: 7.897305982477876, time: 8.83165955543518

Epoch 3, Batch 100/114, Loss: 2.1755032539367676, Variance: 0.2023845911026001

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.6311648339713045, Training Loss Force: 4.437424767773786, time: 1.743614912033081
Validation Loss Energy: 6.217031959077535, Validation Loss Force: 4.591991344527762, time: 0.10960912704467773
Test Loss Energy: 8.467122186253302, Test Loss Force: 8.049696614330678, time: 8.6142737865448

Epoch 4, Batch 100/114, Loss: 2.07684063911438, Variance: 0.21217989921569824

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.723068351894288, Training Loss Force: 4.40365317126007, time: 1.8262953758239746
Validation Loss Energy: 2.914284132906564, Validation Loss Force: 4.336357812898533, time: 0.1084141731262207
Test Loss Energy: 6.405492615878676, Test Loss Force: 7.868050796093159, time: 8.662745237350464

Epoch 5, Batch 100/114, Loss: 1.9246209859848022, Variance: 0.20998504757881165

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.716825308686577, Training Loss Force: 4.408374753305182, time: 1.7586286067962646
Validation Loss Energy: 6.38210015966014, Validation Loss Force: 4.381814976809204, time: 0.1079413890838623
Test Loss Energy: 8.003936799138627, Test Loss Force: 7.8472098756954285, time: 8.809433937072754

Epoch 6, Batch 100/114, Loss: 1.8436622619628906, Variance: 0.2234523743391037

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.759414165853694, Training Loss Force: 4.404045830719771, time: 1.8508319854736328
Validation Loss Energy: 2.142167290606371, Validation Loss Force: 4.434486324155741, time: 0.10756301879882812
Test Loss Energy: 5.866348072702673, Test Loss Force: 7.967429183074864, time: 8.653925657272339

Epoch 7, Batch 100/114, Loss: 2.2626795768737793, Variance: 0.23040491342544556

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.701837111540601, Training Loss Force: 4.428253830387128, time: 1.7628624439239502
Validation Loss Energy: 6.682063407091159, Validation Loss Force: 4.366235113560831, time: 0.11934924125671387
Test Loss Energy: 8.746043727893339, Test Loss Force: 7.929803352871235, time: 8.620152950286865

Epoch 8, Batch 100/114, Loss: 1.4157483577728271, Variance: 0.20980650186538696

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.720261025244908, Training Loss Force: 4.419992777727873, time: 1.7637226581573486
Validation Loss Energy: 3.5773083836501605, Validation Loss Force: 4.487001357761836, time: 0.10902523994445801
Test Loss Energy: 6.967365138676374, Test Loss Force: 7.855332470749004, time: 8.848486185073853

Epoch 9, Batch 100/114, Loss: 2.3717453479766846, Variance: 0.21215258538722992

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.703786700037343, Training Loss Force: 4.405363985185948, time: 1.7973344326019287
Validation Loss Energy: 5.6686922643752675, Validation Loss Force: 4.381596464154001, time: 0.10813713073730469
Test Loss Energy: 7.505295715316536, Test Loss Force: 7.804115048779945, time: 8.625391483306885

Epoch 10, Batch 100/114, Loss: 2.435695171356201, Variance: 0.16035118699073792

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.3139884244380773, Training Loss Force: 4.91242984419333, time: 1.7974340915679932
Validation Loss Energy: 3.133109192922103, Validation Loss Force: 4.350306253537741, time: 0.10797858238220215
Test Loss Energy: 6.076262958449896, Test Loss Force: 7.943342979953362, time: 9.159979104995728

Epoch 11, Batch 100/114, Loss: 2.0087382793426514, Variance: 0.17088109254837036

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1839810942564917, Training Loss Force: 4.380524558324361, time: 2.052642583847046
Validation Loss Energy: 3.571432590227418, Validation Loss Force: 4.192238919349204, time: 0.1740107536315918
Test Loss Energy: 6.5876814600437275, Test Loss Force: 7.91123428030293, time: 11.375407934188843

Epoch 12, Batch 100/114, Loss: 1.9376845359802246, Variance: 0.17228856682777405

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.130112687347638, Training Loss Force: 4.367351541500226, time: 2.0271387100219727
Validation Loss Energy: 3.6917917210066196, Validation Loss Force: 4.36137959016473, time: 0.1298530101776123
Test Loss Energy: 6.485987206690124, Test Loss Force: 7.871568119891288, time: 11.593360662460327

Epoch 13, Batch 100/114, Loss: 1.8254891633987427, Variance: 0.1628829538822174

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1458626122029743, Training Loss Force: 4.3520773619712125, time: 1.7729852199554443
Validation Loss Energy: 3.504945141937402, Validation Loss Force: 4.3248714992288955, time: 0.11789631843566895
Test Loss Energy: 6.4972775419775655, Test Loss Force: 7.8840815453205195, time: 9.772891283035278

Epoch 14, Batch 100/114, Loss: 1.5387024879455566, Variance: 0.16033104062080383

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0936171459667396, Training Loss Force: 4.354406401154854, time: 1.8476533889770508
Validation Loss Energy: 3.262420662490282, Validation Loss Force: 4.358991834689898, time: 0.11974382400512695
Test Loss Energy: 6.545258706901008, Test Loss Force: 7.926027697889617, time: 9.617157697677612

Epoch 15, Batch 100/114, Loss: 1.9802645444869995, Variance: 0.16302846372127533

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.204656267249178, Training Loss Force: 4.365689949175027, time: 1.8247928619384766
Validation Loss Energy: 3.3962440769623967, Validation Loss Force: 4.374521820049583, time: 0.12066245079040527
Test Loss Energy: 6.481775630805976, Test Loss Force: 7.957444222922186, time: 9.618841171264648

Epoch 16, Batch 100/114, Loss: 1.8337159156799316, Variance: 0.16711074113845825

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1023513686078523, Training Loss Force: 4.356077044785511, time: 1.9865107536315918
Validation Loss Energy: 3.58683810353453, Validation Loss Force: 4.269443804747968, time: 0.12042450904846191
Test Loss Energy: 6.302061489559712, Test Loss Force: 7.86754378660853, time: 9.64584469795227

Epoch 17, Batch 100/114, Loss: 1.687305212020874, Variance: 0.15745210647583008

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.143151847786641, Training Loss Force: 4.36003958482368, time: 1.789151906967163
Validation Loss Energy: 4.043997529232168, Validation Loss Force: 4.4241047463421, time: 0.11634182929992676
Test Loss Energy: 6.6125636552322185, Test Loss Force: 7.886225256965823, time: 9.606575965881348

Epoch 18, Batch 100/114, Loss: 1.7645783424377441, Variance: 0.15991099178791046

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.137288945735504, Training Loss Force: 4.3642308490459545, time: 1.8708207607269287
Validation Loss Energy: 3.488860710404357, Validation Loss Force: 4.312136160096702, time: 0.11921095848083496
Test Loss Energy: 6.4742212990708765, Test Loss Force: 7.930724694843503, time: 9.781214714050293

Epoch 19, Batch 100/114, Loss: 2.0050551891326904, Variance: 0.15983232855796814

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.137481970586452, Training Loss Force: 4.352077039686922, time: 1.8006162643432617
Validation Loss Energy: 3.9445169709208856, Validation Loss Force: 4.306435978407048, time: 0.12163186073303223
Test Loss Energy: 6.637655038173948, Test Loss Force: 7.873097684384367, time: 9.604832410812378

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–â–‡â–‚â–†â–â–ˆâ–„â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒ
wandb:   test_error_force â–„â–ƒâ–„â–ˆâ–ƒâ–‚â–†â–…â–‚â–â–…â–„â–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–…â–ƒ
wandb:          test_loss â–ƒâ–†â–â–ˆâ–‚â–†â–â–‡â–ƒâ–„â–‡â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–ˆâ–‡
wandb: train_error_energy â–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–†â–‚â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–‡â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–‡â–â–‡â–‚â–ˆâ–â–ˆâ–ƒâ–‡â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„
wandb:  valid_error_force â–‚â–…â–ƒâ–ˆâ–„â–„â–…â–„â–†â–„â–„â–â–„â–ƒâ–„â–„â–‚â–…â–ƒâ–ƒ
wandb:         valid_loss â–‚â–‡â–â–ˆâ–‚â–ˆâ–‚â–ˆâ–ƒâ–†â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3637
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.63766
wandb:   test_error_force 7.8731
wandb:          test_loss 4.82721
wandb: train_error_energy 3.13748
wandb:  train_error_force 4.35208
wandb:         train_loss 1.46149
wandb: valid_error_energy 3.94452
wandb:  valid_error_force 4.30644
wandb:         valid_loss 1.77512
wandb: 
wandb: ğŸš€ View run al_72_77 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/be6dkftz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_073609-be6dkftz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.755856513977051, Uncertainty Bias: -0.13829141855239868
9.918213e-05 0.0062675476
2.3604875 6.4089727
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2584 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3728 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3949 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 73 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1595 steps.
Found uncertainty sample 16 after 2304 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2767 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3416 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3959 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3058 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2355 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2601 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3115 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2739 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3681 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3407 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2742 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_081645-w7q9wzu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_78
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/w7q9wzu3
Training model 78. Added 17 samples to the dataset.
Epoch 0, Batch 100/115, Loss: 5.621844291687012, Variance: 0.13109014928340912

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5635925725672988, Training Loss Force: 4.757094552572613, time: 2.046370029449463
Validation Loss Energy: 6.703927142083711, Validation Loss Force: 4.559072086439895, time: 0.14429426193237305
Test Loss Energy: 8.005725697409256, Test Loss Force: 8.021352809262826, time: 11.397921323776245

Epoch 1, Batch 100/115, Loss: 1.5353612899780273, Variance: 0.13739106059074402

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.606358620753942, Training Loss Force: 4.685557334004855, time: 1.8613102436065674
Validation Loss Energy: 2.214198977960843, Validation Loss Force: 4.850656590801846, time: 0.132110595703125
Test Loss Energy: 5.867345492911196, Test Loss Force: 8.24334554228402, time: 11.351176500320435

Epoch 2, Batch 100/115, Loss: 1.490653157234192, Variance: 0.15473832190036774

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.146931997820418, Training Loss Force: 4.400125384678588, time: 2.185110092163086
Validation Loss Energy: 3.1150768517004814, Validation Loss Force: 4.232375181348785, time: 0.13166117668151855
Test Loss Energy: 6.209875178426242, Test Loss Force: 7.912536015788094, time: 11.452606201171875

Epoch 3, Batch 100/115, Loss: 1.9394042491912842, Variance: 0.1637551188468933

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.077126039607264, Training Loss Force: 4.329887258569496, time: 1.932227373123169
Validation Loss Energy: 1.9153432497501435, Validation Loss Force: 4.352884168463196, time: 0.13952159881591797
Test Loss Energy: 5.736973967042089, Test Loss Force: 7.8994796087319985, time: 11.488812923431396

Epoch 4, Batch 100/115, Loss: 1.138689637184143, Variance: 0.14996333420276642

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.067040022813952, Training Loss Force: 4.347452831691574, time: 1.997340202331543
Validation Loss Energy: 3.4301849410917797, Validation Loss Force: 4.246192692530188, time: 0.13252472877502441
Test Loss Energy: 6.8562470514178315, Test Loss Force: 7.938603305135109, time: 11.548738479614258

Epoch 5, Batch 100/115, Loss: 1.3152457475662231, Variance: 0.1563674807548523

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0602276132583133, Training Loss Force: 4.346249221698937, time: 1.9552030563354492
Validation Loss Energy: 4.042529842668309, Validation Loss Force: 4.269326532331112, time: 0.1368710994720459
Test Loss Energy: 7.3183454913376345, Test Loss Force: 7.940518215489419, time: 11.417982816696167

Epoch 6, Batch 100/115, Loss: 1.5334018468856812, Variance: 0.15698635578155518

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1145105898631953, Training Loss Force: 4.341887280285473, time: 1.8921046257019043
Validation Loss Energy: 2.636326089598809, Validation Loss Force: 4.43584519973029, time: 0.1335430145263672
Test Loss Energy: 6.239619022161057, Test Loss Force: 7.92482797518427, time: 11.572376489639282

Epoch 7, Batch 100/115, Loss: 1.0385522842407227, Variance: 0.15340957045555115

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.100987975889898, Training Loss Force: 4.350876209101179, time: 2.0452799797058105
Validation Loss Energy: 2.6747139534645648, Validation Loss Force: 4.319250142416901, time: 0.1338481903076172
Test Loss Energy: 6.045296124832697, Test Loss Force: 7.919062464776537, time: 11.42434024810791

Epoch 8, Batch 100/115, Loss: 1.733660101890564, Variance: 0.3563673496246338

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1110100169332044, Training Loss Force: 4.3571810336892804, time: 1.883732795715332
Validation Loss Energy: 3.3040194896633657, Validation Loss Force: 4.294607496483169, time: 0.1349637508392334
Test Loss Energy: 6.255438634405797, Test Loss Force: 7.8969379208719195, time: 11.5958571434021

Epoch 9, Batch 100/115, Loss: 2.095198154449463, Variance: 0.17365625500679016

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.096410462667502, Training Loss Force: 4.349546450260485, time: 1.9972031116485596
Validation Loss Energy: 2.123404000801717, Validation Loss Force: 4.321696237207966, time: 0.1329967975616455
Test Loss Energy: 5.8146161078038485, Test Loss Force: 7.841250638467507, time: 11.540356397628784

Epoch 10, Batch 100/115, Loss: 1.1874076128005981, Variance: 0.16107578575611115

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.116723834042313, Training Loss Force: 4.3497399962183785, time: 1.8986883163452148
Validation Loss Energy: 2.8800561740250306, Validation Loss Force: 4.372980058883178, time: 0.13762784004211426
Test Loss Energy: 6.70921422626399, Test Loss Force: 7.986030019221963, time: 11.525326490402222

Epoch 11, Batch 100/115, Loss: 1.2009575366973877, Variance: 0.15972638130187988

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.085991212784169, Training Loss Force: 4.377339151422411, time: 2.1264708042144775
Validation Loss Energy: 4.3612298080525695, Validation Loss Force: 4.393496645542867, time: 0.14054179191589355
Test Loss Energy: 7.39071482905544, Test Loss Force: 7.854419660152703, time: 11.459643125534058

Epoch 12, Batch 100/115, Loss: 2.0470526218414307, Variance: 0.17313773930072784

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.176073832943111, Training Loss Force: 4.349211894709362, time: 1.9328727722167969
Validation Loss Energy: 2.683873597228402, Validation Loss Force: 4.283066257757538, time: 0.1314685344696045
Test Loss Energy: 6.353479015313501, Test Loss Force: 7.940433405358384, time: 10.499458074569702

Epoch 13, Batch 100/115, Loss: 1.1034077405929565, Variance: 0.15415844321250916

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1443955367903396, Training Loss Force: 4.372102205460601, time: 1.824847936630249
Validation Loss Energy: 2.503458816439309, Validation Loss Force: 4.563553525670837, time: 0.10987019538879395
Test Loss Energy: 5.933963515087869, Test Loss Force: 7.955850214947177, time: 11.299107313156128

Epoch 14, Batch 100/115, Loss: 1.3275659084320068, Variance: 0.1648421436548233

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1011313583617217, Training Loss Force: 4.384789533252426, time: 1.9667677879333496
Validation Loss Energy: 3.4956666670726886, Validation Loss Force: 4.275235726125744, time: 0.13079404830932617
Test Loss Energy: 6.510682714201378, Test Loss Force: 7.943863834562476, time: 9.296720504760742

Epoch 15, Batch 100/115, Loss: 1.6719294786453247, Variance: 0.1683865189552307

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1542652498709165, Training Loss Force: 4.37039641652004, time: 1.8358790874481201
Validation Loss Energy: 2.19840698523945, Validation Loss Force: 4.3514022310739975, time: 0.10868263244628906
Test Loss Energy: 5.664623485087455, Test Loss Force: 7.865822491156927, time: 8.752188682556152

Epoch 16, Batch 100/115, Loss: 1.1715553998947144, Variance: 0.1691371351480484

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.122920048366045, Training Loss Force: 4.353233977173524, time: 1.947660207748413
Validation Loss Energy: 3.2955325293893765, Validation Loss Force: 4.19140361315978, time: 0.11236763000488281
Test Loss Energy: 6.70246320553252, Test Loss Force: 7.879714364506614, time: 8.7175452709198

Epoch 17, Batch 100/115, Loss: 1.1822842359542847, Variance: 0.15907999873161316

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.112383616424351, Training Loss Force: 4.377783885603192, time: 1.8451204299926758
Validation Loss Energy: 4.532523837955314, Validation Loss Force: 4.3247968308419615, time: 0.10990214347839355
Test Loss Energy: 7.538768511802675, Test Loss Force: 7.981384499644033, time: 8.666117191314697

Epoch 18, Batch 100/115, Loss: 1.6089355945587158, Variance: 0.15541771054267883

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1132677997821414, Training Loss Force: 4.349829811270579, time: 1.768815517425537
Validation Loss Energy: 2.69878003475644, Validation Loss Force: 4.296427297189788, time: 0.11091732978820801
Test Loss Energy: 6.563390256747898, Test Loss Force: 7.9461649791229885, time: 8.835933923721313

Epoch 19, Batch 100/115, Loss: 1.1409599781036377, Variance: 0.1606384515762329

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1641796623303478, Training Loss Force: 4.362587103644308, time: 1.8117749691009521
Validation Loss Energy: 2.4562209673686524, Validation Loss Force: 4.346739390712172, time: 0.10892748832702637
Test Loss Energy: 5.947271549936932, Test Loss Force: 7.900974642020356, time: 8.569753646850586

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–ƒâ–â–…â–†â–ƒâ–‚â–ƒâ–â–„â–†â–ƒâ–‚â–„â–â–„â–‡â–„â–‚
wandb:   test_error_force â–„â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–„â–â–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–ƒâ–‚
wandb:          test_loss â–ˆâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–„â–‚â–
wandb: train_error_energy â–‡â–ˆâ–‚â–â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‡â–‚â–â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚
wandb:         train_loss â–ˆâ–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–â–ƒâ–â–ƒâ–„â–‚â–‚â–ƒâ–â–‚â–…â–‚â–‚â–ƒâ–â–ƒâ–…â–‚â–‚
wandb:  valid_error_force â–…â–ˆâ–â–ƒâ–‚â–‚â–„â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–…â–‚â–ƒâ–â–‚â–‚â–ƒ
wandb:         valid_loss â–ˆâ–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–â–‚â–ƒâ–â–‚â–‚â–â–‚â–ƒâ–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3652
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.94727
wandb:   test_error_force 7.90097
wandb:          test_loss 4.47559
wandb: train_error_energy 3.16418
wandb:  train_error_force 4.36259
wandb:         train_loss 1.46877
wandb: valid_error_energy 2.45622
wandb:  valid_error_force 4.34674
wandb:         valid_loss 1.2777
wandb: 
wandb: ğŸš€ View run al_72_78 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/w7q9wzu3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_081645-w7q9wzu3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.633491277694702, Uncertainty Bias: -0.12312990427017212
5.9604645e-05 0.0068683624
2.4608562 6.4092383
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3750 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2767 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2199 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3409 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 501 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3833 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2977 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2913 steps.
Found uncertainty sample 79 after 3084 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1457 steps.
Found uncertainty sample 82 after 2595 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 818 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1166 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3248 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2389 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_085725-fxjjbnv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_72_79
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/fxjjbnv2
Training model 79. Added 15 samples to the dataset.
Epoch 0, Batch 100/115, Loss: 1.3698500394821167, Variance: 0.14560425281524658

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.588749390925487, Training Loss Force: 4.693197701022683, time: 1.8639397621154785
Validation Loss Energy: 1.8459898268828911, Validation Loss Force: 5.279691641576979, time: 0.12120270729064941
Test Loss Energy: 6.031419451275284, Test Loss Force: 8.633137236666355, time: 9.788722038269043

Epoch 1, Batch 100/115, Loss: 0.8167557716369629, Variance: 0.13483628630638123

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.2261692248526788, Training Loss Force: 4.7085185464846635, time: 1.8761873245239258
Validation Loss Energy: 1.9649504840910927, Validation Loss Force: 4.364641099368183, time: 0.12476253509521484
Test Loss Energy: 5.785254711733946, Test Loss Force: 7.906582311480417, time: 9.774848461151123

Epoch 2, Batch 100/115, Loss: 0.9980471730232239, Variance: 0.12206213176250458

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.135273405119402, Training Loss Force: 4.422336047236346, time: 1.7432079315185547
Validation Loss Energy: 2.1581617638044617, Validation Loss Force: 4.362207474049289, time: 0.12503838539123535
Test Loss Energy: 6.0974541339167505, Test Loss Force: 7.920402744174279, time: 10.051860094070435

Epoch 3, Batch 100/115, Loss: 1.0827840566635132, Variance: 0.11985456943511963

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1184562897975305, Training Loss Force: 4.351643077767247, time: 1.8161070346832275
Validation Loss Energy: 2.4045849573276312, Validation Loss Force: 4.3583437190291505, time: 0.12042856216430664
Test Loss Energy: 6.179985797671327, Test Loss Force: 7.957685843427467, time: 9.903754949569702

Epoch 4, Batch 100/115, Loss: 1.22572922706604, Variance: 0.12111017853021622

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1370201390433925, Training Loss Force: 4.3495529889883615, time: 1.8985199928283691
Validation Loss Energy: 1.9021349242404753, Validation Loss Force: 4.331358742126356, time: 0.13584041595458984
Test Loss Energy: 5.692935507923605, Test Loss Force: 7.946407644191382, time: 10.080737590789795

Epoch 5, Batch 100/115, Loss: 0.9851570129394531, Variance: 0.11951033025979996

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1342709137718727, Training Loss Force: 4.358223423475253, time: 1.8623466491699219
Validation Loss Energy: 2.026025736120188, Validation Loss Force: 4.3372202847237595, time: 0.1190028190612793
Test Loss Energy: 5.744549409211189, Test Loss Force: 7.995451663741268, time: 9.938007593154907

Epoch 6, Batch 100/115, Loss: 0.9627127051353455, Variance: 0.12543365359306335

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1442968979953156, Training Loss Force: 4.367108177983226, time: 1.8462564945220947
Validation Loss Energy: 2.3328798513871867, Validation Loss Force: 4.37899197737713, time: 0.12244367599487305
Test Loss Energy: 6.078352560326935, Test Loss Force: 8.078955664199949, time: 9.879847288131714

Epoch 7, Batch 100/115, Loss: 1.5726442337036133, Variance: 0.12205953896045685

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1361987677472882, Training Loss Force: 4.369191265269661, time: 1.815169095993042
Validation Loss Energy: 2.400168240595105, Validation Loss Force: 4.193335193777655, time: 0.12011456489562988
Test Loss Energy: 6.311318442849139, Test Loss Force: 8.02525497063031, time: 11.149532556533813

Epoch 8, Batch 100/115, Loss: 1.0522613525390625, Variance: 0.12233968079090118

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1379644285486834, Training Loss Force: 4.355491797779401, time: 1.798954963684082
Validation Loss Energy: 1.743087660252234, Validation Loss Force: 4.371758644394716, time: 0.12108206748962402
Test Loss Energy: 5.888360890323157, Test Loss Force: 7.971058874350999, time: 9.934391736984253

Epoch 9, Batch 100/115, Loss: 1.3690247535705566, Variance: 0.11613097786903381

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.153643041368059, Training Loss Force: 4.363915706541697, time: 1.8302719593048096
Validation Loss Energy: 1.846471645803155, Validation Loss Force: 4.358841161901153, time: 0.12086200714111328
Test Loss Energy: 5.690554027599501, Test Loss Force: 8.054416162656077, time: 10.109715700149536

Epoch 10, Batch 100/115, Loss: 1.120661973953247, Variance: 0.11832296848297119

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.165403654058968, Training Loss Force: 4.367094349261137, time: 1.768747329711914
Validation Loss Energy: 2.1050499768872792, Validation Loss Force: 4.284973493215457, time: 0.12068462371826172
Test Loss Energy: 6.158512669438603, Test Loss Force: 7.951466682523631, time: 9.902718782424927

Epoch 11, Batch 100/115, Loss: 1.1157047748565674, Variance: 0.11452220380306244

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.122718375716566, Training Loss Force: 4.379350996199668, time: 1.8539485931396484
Validation Loss Energy: 2.5053739937634334, Validation Loss Force: 4.303699374603596, time: 0.11974501609802246
Test Loss Energy: 6.17994298923657, Test Loss Force: 7.9146832108648555, time: 9.932470083236694

Epoch 12, Batch 100/115, Loss: 1.0158047676086426, Variance: 0.11270780861377716

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1442306064861927, Training Loss Force: 4.376586270251212, time: 1.8108041286468506
Validation Loss Energy: 1.8250443423366207, Validation Loss Force: 4.360417511008225, time: 0.1198577880859375
Test Loss Energy: 5.617688289241193, Test Loss Force: 7.954053249291784, time: 10.0728919506073

Epoch 13, Batch 100/115, Loss: 1.0283169746398926, Variance: 0.11464090645313263

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.195656759247609, Training Loss Force: 4.3946930165293, time: 1.886124610900879
Validation Loss Energy: 1.7855117735031747, Validation Loss Force: 4.387345781501856, time: 0.1183781623840332
Test Loss Energy: 5.679214283077805, Test Loss Force: 7.992633623652372, time: 10.195770978927612

Epoch 14, Batch 100/115, Loss: 0.8369311094284058, Variance: 0.11319782584905624

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1501027965412782, Training Loss Force: 4.375865039078793, time: 1.8431470394134521
Validation Loss Energy: 2.3547542002756945, Validation Loss Force: 4.381530108748513, time: 0.1260831356048584
Test Loss Energy: 6.12202811070661, Test Loss Force: 7.999107744225715, time: 11.289448976516724

Epoch 15, Batch 100/115, Loss: 1.706611156463623, Variance: 0.1181885153055191

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.132728001502797, Training Loss Force: 4.362667264536843, time: 2.037027597427368
Validation Loss Energy: 2.3969631409086203, Validation Loss Force: 4.331786266886538, time: 0.13416767120361328
Test Loss Energy: 6.172641418458889, Test Loss Force: 7.954327936748136, time: 11.163353204727173

Epoch 16, Batch 100/115, Loss: 1.0275568962097168, Variance: 0.11360658705234528

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1446198418345417, Training Loss Force: 4.387587198744453, time: 1.9502835273742676
Validation Loss Energy: 1.8135215109270524, Validation Loss Force: 4.266615461256393, time: 0.13318490982055664
Test Loss Energy: 5.703850688835018, Test Loss Force: 7.969662295799354, time: 11.199382305145264

Epoch 17, Batch 100/115, Loss: 1.1757930517196655, Variance: 0.1656438708305359

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9065096819513614, Training Loss Force: 4.701183398842046, time: 1.9325346946716309
Validation Loss Energy: 3.49178977457294, Validation Loss Force: 4.346884570995317, time: 0.13660264015197754
Test Loss Energy: 6.14362407536462, Test Loss Force: 7.92122291041619, time: 11.463089942932129

Epoch 18, Batch 100/115, Loss: 1.3044065237045288, Variance: 0.15864333510398865

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.144466485957119, Training Loss Force: 4.36314757931089, time: 1.8378682136535645
Validation Loss Energy: 3.362050112237141, Validation Loss Force: 4.296640020447198, time: 0.13147234916687012
Test Loss Energy: 6.172340001378567, Test Loss Force: 7.9223954651541195, time: 11.290014028549194

Epoch 19, Batch 100/115, Loss: 2.062711000442505, Variance: 0.16344192624092102

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.168366233396987, Training Loss Force: 4.332525142491165, time: 1.8660740852355957
Validation Loss Energy: 2.2771175594029773, Validation Loss Force: 4.3042437264423405, time: 0.13499212265014648
Test Loss Energy: 5.565973774142247, Test Loss Force: 7.9290032501685985, time: 11.381168842315674

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–†â–‡â–‚â–ƒâ–†â–ˆâ–„â–‚â–‡â–‡â–â–‚â–†â–‡â–‚â–†â–‡â–
wandb:   test_error_force â–ˆâ–â–â–â–â–‚â–ƒâ–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–â–â–
wandb:          test_loss â–†â–ƒâ–†â–‡â–†â–†â–ˆâ–ˆâ–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–†â–‚â–‚â–
wandb: train_error_energy â–ˆâ–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–†â–†
wandb:  train_error_force â–ˆâ–ˆâ–ƒâ–â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–
wandb:         train_loss â–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–„â–„
wandb: valid_error_energy â–â–‚â–ƒâ–„â–‚â–‚â–ƒâ–„â–â–â–‚â–„â–â–â–ƒâ–„â–â–ˆâ–‡â–ƒ
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb:         valid_loss â–…â–ƒâ–ƒâ–„â–‚â–‚â–„â–ƒâ–â–‚â–‚â–„â–â–â–„â–„â–â–ˆâ–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3665
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.56597
wandb:   test_error_force 7.929
wandb:          test_loss 4.33179
wandb: train_error_energy 3.16837
wandb:  train_error_force 4.33253
wandb:         train_loss 1.45663
wandb: valid_error_energy 2.27712
wandb:  valid_error_force 4.30424
wandb:         valid_loss 1.20969
wandb: 
wandb: ğŸš€ View run al_72_79 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/fxjjbnv2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_085725-fxjjbnv2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3369698524475098, Uncertainty Bias: -0.06053587794303894
2.5391579e-05 0.002149582
2.4405105 6.299453
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1109 steps.
Found uncertainty sample 3 after 3110 steps.
Found uncertainty sample 4 after 2484 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2401 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1326 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3626 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1853 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2940 steps.
Found uncertainty sample 47 after 1278 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3770 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3221 steps.
