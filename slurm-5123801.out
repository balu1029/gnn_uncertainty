wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_211207-ixdn7o5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_60
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/ixdn7o5w
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
59
0.0 1.0
Uncertainty Slope: 0.04418506845831871, Uncertainty Bias: 0.2551638185977936
0.25516382 0.04418507
0.0014572144 0.0017471313
3.8687837 7.084953
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
0.25516382 0.04418507
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 11.451026027123484, Test Loss Force: 12.623542689794228, time: 6.831987619400024

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ
wandb:    max_uncertainty ‚ñÅ
wandb:  test_error_energy ‚ñÅ
wandb:   test_error_force ‚ñÅ
wandb:          test_loss ‚ñÅ
wandb: train_error_energy ‚ñÅ
wandb:  train_error_force ‚ñÅ
wandb:         train_loss ‚ñÅ
wandb: valid_error_energy ‚ñÅ
wandb:  valid_error_force ‚ñÅ
wandb:         valid_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.45103
wandb:   test_error_force 12.62354
wandb:          test_loss 10.22045
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: üöÄ View run al_60 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/ixdn7o5w
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_211207-ixdn7o5w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
0.25516382 0.04418507
0.25516382 0.04418507
Traceback (most recent call last):
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 941, in <module>
    al.improve_model(
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 501, in improve_model
    if num_new_samples > 1:
       ^^^^^^^^^^^^^^^^^^^
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
