wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_222141-xojgcy7o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/xojgcy7o
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
81
Uncertainty Slope: 2.3552730083465576, Uncertainty Bias: -0.2349499762058258
4.5776367e-05 0.00051546097
1.7527838 3.3228517
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 12.772676397174088, Test Loss Force: 21.023475997797508, time: 7.61781644821167

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.050 MB uploadedwandb: | 0.039 MB of 0.050 MB uploadedwandb: / 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.77268
wandb:   test_error_force 21.02348
wandb:          test_loss 735.60501
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_82 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/xojgcy7o
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_222141-xojgcy7o/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 3913 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2498 steps.
Found uncertainty sample 4 after 3015 steps.
Found uncertainty sample 5 after 3969 steps.
Found uncertainty sample 6 after 1228 steps.
Found uncertainty sample 7 after 3181 steps.
Found uncertainty sample 8 after 3356 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 861 steps.
Found uncertainty sample 13 after 2717 steps.
Found uncertainty sample 14 after 896 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1351 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2347 steps.
Found uncertainty sample 22 after 807 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2213 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1465 steps.
Found uncertainty sample 34 after 915 steps.
Found uncertainty sample 35 after 974 steps.
Found uncertainty sample 36 after 869 steps.
Found uncertainty sample 37 after 2689 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1262 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 834 steps.
Found uncertainty sample 46 after 409 steps.
Found uncertainty sample 47 after 2548 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2287 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1822 steps.
Found uncertainty sample 61 after 3584 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3108 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2063 steps.
Found uncertainty sample 78 after 958 steps.
Found uncertainty sample 79 after 319 steps.
Found uncertainty sample 80 after 2917 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 784 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2070 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1040 steps.
Found uncertainty sample 90 after 1050 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2437 steps.
Found uncertainty sample 94 after 3164 steps.
Found uncertainty sample 95 after 779 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1094 steps.
Found uncertainty sample 99 after 44 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_225351-gjv6243v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/gjv6243v
Training model 0. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.382370462105245, Training Loss Force: 3.046931450184915, time: 0.6013073921203613
Validation Loss Energy: 1.452338128075987, Validation Loss Force: 2.7134319614506834, time: 0.03792262077331543
Test Loss Energy: 14.76673642298695, Test Loss Force: 14.44081928736917, time: 7.9592273235321045


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.113100192951064, Training Loss Force: 2.622671522750193, time: 0.43931078910827637
Validation Loss Energy: 1.2312333442329149, Validation Loss Force: 2.5615604704706354, time: 0.03926897048950195
Test Loss Energy: 12.609298514218242, Test Loss Force: 14.084346423667922, time: 7.935298204421997


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2946671580397298, Training Loss Force: 2.508621709850347, time: 0.4378063678741455
Validation Loss Energy: 1.4150038603857127, Validation Loss Force: 2.5444031447694617, time: 0.03571295738220215
Test Loss Energy: 11.114499846861538, Test Loss Force: 14.342669917492278, time: 7.962716341018677


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.3027472007582923, Training Loss Force: 2.3911864352558156, time: 0.4105072021484375
Validation Loss Energy: 1.2362074389492228, Validation Loss Force: 2.521574435921507, time: 0.03519296646118164
Test Loss Energy: 11.124806663023678, Test Loss Force: 13.14191844804932, time: 8.152730226516724


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9680047109989518, Training Loss Force: 2.323569967802389, time: 0.42102646827697754
Validation Loss Energy: 1.1909149759834894, Validation Loss Force: 2.5107371285892017, time: 0.036485910415649414
Test Loss Energy: 9.990486050099268, Test Loss Force: 13.828550651335227, time: 7.940162420272827


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7735211080327575, Training Loss Force: 2.2624868811181593, time: 0.4304687976837158
Validation Loss Energy: 2.760765187138845, Validation Loss Force: 2.477017894483065, time: 0.03821396827697754
Test Loss Energy: 11.315447787811898, Test Loss Force: 13.882989475636512, time: 7.953918218612671


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.8727672232381654, Training Loss Force: 2.262848899914411, time: 0.42263174057006836
Validation Loss Energy: 3.948850260946738, Validation Loss Force: 2.5268826456912796, time: 0.04136395454406738
Test Loss Energy: 12.852234753994056, Test Loss Force: 13.72908268374005, time: 8.213577032089233


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.5469632757297807, Training Loss Force: 2.2076202798969473, time: 0.453876256942749
Validation Loss Energy: 2.0982964216912894, Validation Loss Force: 2.4277347550840136, time: 0.040354251861572266
Test Loss Energy: 10.247354635382202, Test Loss Force: 13.22405246900994, time: 7.951897621154785


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.531194225475404, Training Loss Force: 2.179563584024294, time: 0.4625539779663086
Validation Loss Energy: 2.5110555454678782, Validation Loss Force: 2.4204677248375144, time: 0.03470039367675781
Test Loss Energy: 12.019950353533941, Test Loss Force: 13.205373316277054, time: 8.32078742980957


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.656535599012252, Training Loss Force: 2.204928218169685, time: 0.4713263511657715
Validation Loss Energy: 2.6792535835656435, Validation Loss Force: 2.4158141623567695, time: 0.03661370277404785
Test Loss Energy: 10.50037795534476, Test Loss Force: 12.599797839639239, time: 7.925015211105347


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.180357980943408, Training Loss Force: 2.1499458990921365, time: 0.41820454597473145
Validation Loss Energy: 1.102723409367027, Validation Loss Force: 2.4788250772714147, time: 0.03714561462402344
Test Loss Energy: 10.637213997868757, Test Loss Force: 13.051794703727479, time: 8.188876628875732


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1834427382652755, Training Loss Force: 2.1454868092458415, time: 0.4090559482574463
Validation Loss Energy: 2.5803210140224895, Validation Loss Force: 2.461511215160654, time: 0.041341304779052734
Test Loss Energy: 10.520523991789052, Test Loss Force: 12.540992424422413, time: 7.926935911178589


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.106071908685509, Training Loss Force: 2.147554869556159, time: 0.40192675590515137
Validation Loss Energy: 1.4677948181751375, Validation Loss Force: 2.467906050362554, time: 0.03946638107299805
Test Loss Energy: 10.383592404382727, Test Loss Force: 12.580518389541846, time: 7.970338344573975


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6706849792978788, Training Loss Force: 2.0925046322655994, time: 0.47159886360168457
Validation Loss Energy: 1.5853272754813583, Validation Loss Force: 2.4109853592581794, time: 0.03701472282409668
Test Loss Energy: 11.184315708078406, Test Loss Force: 12.669004226258528, time: 8.167998552322388


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.907420069197882, Training Loss Force: 2.0585205538278952, time: 0.4390745162963867
Validation Loss Energy: 2.3898694214807015, Validation Loss Force: 2.37687912617642, time: 0.03534841537475586
Test Loss Energy: 11.012945840095655, Test Loss Force: 12.084707334968318, time: 7.933903694152832


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2520665774288897, Training Loss Force: 2.1330447542433535, time: 0.47138094902038574
Validation Loss Energy: 1.8959451673219743, Validation Loss Force: 2.4681151366905802, time: 0.04050135612487793
Test Loss Energy: 12.53983775316458, Test Loss Force: 12.071963650989279, time: 8.035467147827148


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.5880010419291497, Training Loss Force: 2.112657336305815, time: 0.41320347785949707
Validation Loss Energy: 4.452909523951514, Validation Loss Force: 2.3738506031226563, time: 0.03641915321350098
Test Loss Energy: 10.562927924142805, Test Loss Force: 12.172351785423222, time: 8.006997108459473


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.563025001195195, Training Loss Force: 2.0428849573169967, time: 0.39514827728271484
Validation Loss Energy: 1.4488802989088745, Validation Loss Force: 2.3566565370124044, time: 0.04192042350769043
Test Loss Energy: 12.083173571238254, Test Loss Force: 12.086017095869193, time: 8.207552433013916


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.341782031889293, Training Loss Force: 2.043544977530046, time: 0.41287875175476074
Validation Loss Energy: 1.128336039211944, Validation Loss Force: 2.436483648496662, time: 0.03965330123901367
Test Loss Energy: 11.52262816587674, Test Loss Force: 12.333099463121547, time: 7.995253562927246


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.568797866462944, Training Loss Force: 2.0215545726579798, time: 0.4657723903656006
Validation Loss Energy: 1.2971384013717568, Validation Loss Force: 2.3172340780716194, time: 0.0517880916595459
Test Loss Energy: 11.799989922973433, Test Loss Force: 12.171336969041947, time: 8.373367309570312

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: - 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: \ 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.7%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–…â–ƒâ–ƒâ–â–ƒâ–…â–â–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–…â–‚â–„â–ƒâ–„
wandb:   test_error_force â–ˆâ–‡â–ˆâ–„â–†â–†â–†â–„â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–â–â–â–â–‚â–
wandb:          test_loss â–ˆâ–†â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb: train_error_energy â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–„â–†â–ƒâ–„â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–„â–†â–ƒâ–
wandb:  train_error_force â–ˆâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–â–‚â–â–â–„â–‡â–ƒâ–„â–„â–â–„â–‚â–‚â–„â–ƒâ–ˆâ–‚â–â–
wandb:  valid_error_force â–ˆâ–…â–…â–…â–„â–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–‚â–„â–‚â–‚â–ƒâ–
wandb:         valid_loss â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 836
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.79999
wandb:   test_error_force 12.17134
wandb:          test_loss 95.59286
wandb: train_error_energy 1.5688
wandb:  train_error_force 2.02155
wandb:         train_loss -4.75774
wandb: valid_error_energy 1.29714
wandb:  valid_error_force 2.31723
wandb:         valid_loss -4.45434
wandb: 
wandb: ğŸš€ View run al_82_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/gjv6243v
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_225351-gjv6243v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 4.997287750244141, Uncertainty Bias: -1.0144296884536743
1.5258789e-05 0.0015742779
1.4662691 5.351666
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1518 steps.
Found uncertainty sample 8 after 3224 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2022 steps.
Found uncertainty sample 11 after 1380 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1835 steps.
Found uncertainty sample 14 after 1471 steps.
Found uncertainty sample 15 after 1718 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2433 steps.
Found uncertainty sample 20 after 2126 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3821 steps.
Found uncertainty sample 23 after 830 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 486 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2468 steps.
Found uncertainty sample 37 after 3271 steps.
Found uncertainty sample 38 after 3147 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3375 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 892 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 128 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3994 steps.
Found uncertainty sample 53 after 3817 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3888 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3027 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 130 steps.
Found uncertainty sample 70 after 775 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 15 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2781 steps.
Found uncertainty sample 82 after 2476 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 106 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 159 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3635 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3617 steps.
Found uncertainty sample 94 after 1190 steps.
Found uncertainty sample 95 after 323 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_233031-cot573no
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cot573no
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)
Training model 1. Added 33 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.466303567128735, Training Loss Force: 2.4001207351931497, time: 0.481644868850708
Validation Loss Energy: 1.18152635411459, Validation Loss Force: 2.5017183601716884, time: 0.04314780235290527
Test Loss Energy: 11.108980244797397, Test Loss Force: 12.004734114052695, time: 8.652525663375854


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9792548341891292, Training Loss Force: 2.156952325735062, time: 0.49355220794677734
Validation Loss Energy: 1.417128124037864, Validation Loss Force: 2.4359434531486412, time: 0.03995180130004883
Test Loss Energy: 11.654612105482514, Test Loss Force: 11.604849594386492, time: 8.571175575256348


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0672727069430636, Training Loss Force: 2.148823975446001, time: 0.4938836097717285
Validation Loss Energy: 1.6419057241084418, Validation Loss Force: 2.428390070380479, time: 0.03816342353820801
Test Loss Energy: 11.105525580796419, Test Loss Force: 11.609901637876463, time: 8.797674179077148


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.672818264329649, Training Loss Force: 2.4139090528590286, time: 0.44246912002563477
Validation Loss Energy: 3.124477868818504, Validation Loss Force: 2.4174078054341748, time: 0.03976011276245117
Test Loss Energy: 13.377957880590857, Test Loss Force: 11.62235124935957, time: 8.962642431259155


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.4239140964841988, Training Loss Force: 2.102032229429684, time: 0.44036078453063965
Validation Loss Energy: 1.9160544178907128, Validation Loss Force: 2.519842069966189, time: 0.04129171371459961
Test Loss Energy: 13.390620167921888, Test Loss Force: 11.643423724684538, time: 8.555107116699219


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2506210364308306, Training Loss Force: 2.139477227305241, time: 0.4239773750305176
Validation Loss Energy: 1.0725210117516737, Validation Loss Force: 2.454862759801542, time: 0.04197859764099121
Test Loss Energy: 11.914916310142514, Test Loss Force: 11.742043133972988, time: 8.621751546859741


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5963483067283448, Training Loss Force: 2.1162774085157197, time: 0.44312143325805664
Validation Loss Energy: 1.556078124479722, Validation Loss Force: 2.4721686058230494, time: 0.04169774055480957
Test Loss Energy: 12.741934932711937, Test Loss Force: 11.92904859622138, time: 8.79728078842163


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.992409510022596, Training Loss Force: 2.132299395932859, time: 0.44156908988952637
Validation Loss Energy: 6.032666953416635, Validation Loss Force: 2.438608802825397, time: 0.045369625091552734
Test Loss Energy: 16.63732709754062, Test Loss Force: 11.970510244045078, time: 8.641120195388794


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0185003218583923, Training Loss Force: 2.0942993554487304, time: 0.4294126033782959
Validation Loss Energy: 1.4791393658218663, Validation Loss Force: 2.4286537106492574, time: 0.044713497161865234
Test Loss Energy: 11.43862959043139, Test Loss Force: 11.636733167369739, time: 8.603567123413086


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9526199203546715, Training Loss Force: 2.0981274555718774, time: 0.4782290458679199
Validation Loss Energy: 1.7898750496406781, Validation Loss Force: 2.3950331189747667, time: 0.04043936729431152
Test Loss Energy: 12.081375122676295, Test Loss Force: 11.669601590829938, time: 8.769199132919312


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6352837862588694, Training Loss Force: 2.046885451957517, time: 0.4472987651824951
Validation Loss Energy: 3.5117647556466838, Validation Loss Force: 2.390895258235991, time: 0.042287349700927734
Test Loss Energy: 10.813620781829238, Test Loss Force: 11.873737445139298, time: 8.649685859680176


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0749538680029938, Training Loss Force: 2.0245672836988273, time: 0.4375152587890625
Validation Loss Energy: 1.0503449461704335, Validation Loss Force: 2.423662136404994, time: 0.04283308982849121
Test Loss Energy: 12.374008131357153, Test Loss Force: 11.7846868961524, time: 8.604734420776367


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7348327755701765, Training Loss Force: 2.050614329118745, time: 0.4422016143798828
Validation Loss Energy: 1.0065370184006006, Validation Loss Force: 2.5513045522783475, time: 0.04295706748962402
Test Loss Energy: 12.457776520532736, Test Loss Force: 11.641589052166028, time: 8.836100578308105


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5814563870960805, Training Loss Force: 2.0758103131817536, time: 0.4627723693847656
Validation Loss Energy: 2.43435181409355, Validation Loss Force: 2.400933851341853, time: 0.041177988052368164
Test Loss Energy: 13.767865292980654, Test Loss Force: 11.801191818743112, time: 9.060612916946411


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0403093620827146, Training Loss Force: 2.0010907269232656, time: 0.47629833221435547
Validation Loss Energy: 1.5885436199597123, Validation Loss Force: 2.3981947981777956, time: 0.04021120071411133
Test Loss Energy: 11.382794987322095, Test Loss Force: 11.804563048265372, time: 8.676916360855103


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6675439211427925, Training Loss Force: 2.0111295069121615, time: 0.4447445869445801
Validation Loss Energy: 1.200191483937414, Validation Loss Force: 2.3897117717253846, time: 0.03931117057800293
Test Loss Energy: 12.966607014420907, Test Loss Force: 11.583936102500102, time: 8.60536789894104


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.4748764236750387, Training Loss Force: 2.0344721600063256, time: 0.4365553855895996
Validation Loss Energy: 0.9959400824113241, Validation Loss Force: 2.4301965851613914, time: 0.04355287551879883
Test Loss Energy: 12.346482401073363, Test Loss Force: 11.745724612729756, time: 8.79629111289978


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.102946598408146, Training Loss Force: 1.9958781694566081, time: 0.43877267837524414
Validation Loss Energy: 1.2734525276465531, Validation Loss Force: 2.5629372337999072, time: 0.04736161231994629
Test Loss Energy: 12.056281471074055, Test Loss Force: 11.719553937282223, time: 8.647892236709595


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.546692170664339, Training Loss Force: 2.053324995942932, time: 0.4486570358276367
Validation Loss Energy: 1.0809344540959822, Validation Loss Force: 2.378949058556965, time: 0.0436556339263916
Test Loss Energy: 12.25655770664668, Test Loss Force: 11.861583020663653, time: 8.626583099365234


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8863420415052037, Training Loss Force: 2.0135180788405287, time: 0.4673326015472412
Validation Loss Energy: 1.0015388754165324, Validation Loss Force: 2.41605909841729, time: 0.04373502731323242
Test Loss Energy: 12.510654151995762, Test Loss Force: 11.67106783567908, time: 8.760938882827759

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–â–„â–„â–‚â–ƒâ–ˆâ–‚â–ƒâ–â–ƒâ–ƒâ–…â–‚â–„â–ƒâ–‚â–ƒâ–ƒ
wandb:   test_error_force â–ˆâ–â–â–‚â–‚â–„â–‡â–‡â–‚â–‚â–†â–„â–‚â–…â–…â–â–„â–ƒâ–†â–‚
wandb:          test_loss â–‚â–‚â–â–‚â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–†â–…â–…â–…â–†â–…â–†â–‡â–ˆâ–‡
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–â–„â–„â–‚â–â–‚â–â–â–‚â–â–ƒâ–‚â–â–‚
wandb:  train_error_force â–ˆâ–„â–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–â–â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–„â–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–‚â–„â–‚â–â–‚â–ˆâ–‚â–‚â–„â–â–â–ƒâ–‚â–â–â–â–â–
wandb:  valid_error_force â–†â–ƒâ–ƒâ–‚â–†â–„â–…â–ƒâ–ƒâ–‚â–â–ƒâ–ˆâ–‚â–‚â–â–ƒâ–ˆâ–â–‚
wandb:         valid_loss â–„â–ƒâ–‚â–…â–…â–ƒâ–„â–‡â–ƒâ–‚â–„â–‚â–‡â–ƒâ–‚â–‚â–‚â–ˆâ–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 865
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.51065
wandb:   test_error_force 11.67107
wandb:          test_loss 101.29494
wandb: train_error_energy 1.88634
wandb:  train_error_force 2.01352
wandb:         train_loss -5.02472
wandb: valid_error_energy 1.00154
wandb:  valid_error_force 2.41606
wandb:         valid_loss -4.05225
wandb: 
wandb: ğŸš€ View run al_82_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cot573no
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_233031-cot573no/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 8.951004981994629, Uncertainty Bias: -1.777572751045227
3.4332275e-05 0.001455307
0.9110428 6.0103264
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3480 steps.
Found uncertainty sample 5 after 906 steps.
Found uncertainty sample 6 after 3533 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2292 steps.
Found uncertainty sample 9 after 1927 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 410 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 783 steps.
Found uncertainty sample 18 after 3303 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3114 steps.
Found uncertainty sample 21 after 295 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 541 steps.
Found uncertainty sample 29 after 1167 steps.
Found uncertainty sample 30 after 141 steps.
Found uncertainty sample 31 after 2194 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2948 steps.
Found uncertainty sample 34 after 1638 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1788 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 365 steps.
Found uncertainty sample 39 after 2619 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 619 steps.
Found uncertainty sample 45 after 3281 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 428 steps.
Found uncertainty sample 49 after 1713 steps.
Found uncertainty sample 50 after 1563 steps.
Found uncertainty sample 51 after 4 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3954 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2782 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1066 steps.
Found uncertainty sample 61 after 304 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1896 steps.
Found uncertainty sample 65 after 217 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 976 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 279 steps.
Found uncertainty sample 71 after 1089 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1361 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 542 steps.
Found uncertainty sample 76 after 1088 steps.
Found uncertainty sample 77 after 3764 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 685 steps.
Found uncertainty sample 80 after 429 steps.
Found uncertainty sample 81 after 3606 steps.
Found uncertainty sample 82 after 490 steps.
Found uncertainty sample 83 after 3158 steps.
Found uncertainty sample 84 after 1041 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1148 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1307 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 322 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2782 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_000250-11fklf1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/11fklf1b
Training model 2. Added 48 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9007022952610932, Training Loss Force: 2.5133715733241515, time: 0.47434425354003906
Validation Loss Energy: 2.2947750000059046, Validation Loss Force: 2.4151920247630474, time: 0.04349231719970703
Test Loss Energy: 12.519610879659668, Test Loss Force: 11.363079101035453, time: 8.941375494003296


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.3855413859348102, Training Loss Force: 2.2058954778674824, time: 0.4817650318145752
Validation Loss Energy: 1.6364856230928406, Validation Loss Force: 2.591692504635876, time: 0.04221367835998535
Test Loss Energy: 13.92826327986046, Test Loss Force: 11.762920532473213, time: 9.001195192337036


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.4557036659920146, Training Loss Force: 2.239749745454132, time: 0.46288037300109863
Validation Loss Energy: 1.4244463681879265, Validation Loss Force: 2.386530942975806, time: 0.04048323631286621
Test Loss Energy: 13.112281907526706, Test Loss Force: 11.633413368591155, time: 9.158451318740845


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.278674535014645, Training Loss Force: 2.1701592490506836, time: 0.46782493591308594
Validation Loss Energy: 3.69949065517317, Validation Loss Force: 2.4282344246474756, time: 0.03942728042602539
Test Loss Energy: 11.303289977832588, Test Loss Force: 11.42275988812108, time: 8.989985942840576


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.365328010666488, Training Loss Force: 2.1443031650468036, time: 0.4627702236175537
Validation Loss Energy: 1.7401109448864227, Validation Loss Force: 2.4456696414427674, time: 0.047800302505493164
Test Loss Energy: 12.466552459503063, Test Loss Force: 11.373875700717303, time: 8.952699661254883


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.138612179336935, Training Loss Force: 2.2115471547948484, time: 0.46036338806152344
Validation Loss Energy: 1.4659386481746834, Validation Loss Force: 2.448482175424981, time: 0.04408144950866699
Test Loss Energy: 13.581072483264045, Test Loss Force: 11.352948466297446, time: 9.014191150665283


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.7371126811529836, Training Loss Force: 2.1742370159939215, time: 0.4930846691131592
Validation Loss Energy: 4.506564326692566, Validation Loss Force: 2.4945544257397536, time: 0.06356525421142578
Test Loss Energy: 16.64899556234367, Test Loss Force: 11.494857159116775, time: 9.183424234390259


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0183734952896257, Training Loss Force: 2.1645686180214105, time: 0.4642341136932373
Validation Loss Energy: 1.81592511302277, Validation Loss Force: 2.4018583736357453, time: 0.044869422912597656
Test Loss Energy: 13.491870533247603, Test Loss Force: 11.691635549195409, time: 9.006359338760376


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8280685169435005, Training Loss Force: 2.129061089613096, time: 0.5144991874694824
Validation Loss Energy: 1.0976336380294096, Validation Loss Force: 2.4230778525660797, time: 0.04028606414794922
Test Loss Energy: 13.539745747295022, Test Loss Force: 11.221226772655223, time: 8.997417211532593


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.766361892309812, Training Loss Force: 2.175852676442911, time: 0.4359402656555176
Validation Loss Energy: 1.2647011848732992, Validation Loss Force: 2.4201212516464508, time: 0.044679880142211914
Test Loss Energy: 13.375516643329151, Test Loss Force: 11.398841356032271, time: 9.2198486328125


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2491874044437368, Training Loss Force: 2.1749968053501827, time: 0.4604368209838867
Validation Loss Energy: 1.8667248519747355, Validation Loss Force: 2.3902675539136204, time: 0.04143095016479492
Test Loss Energy: 12.577436373431738, Test Loss Force: 11.155446567039146, time: 9.38367223739624


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0036907417157495, Training Loss Force: 2.1422247328474815, time: 0.46097326278686523
Validation Loss Energy: 1.6823392123063121, Validation Loss Force: 2.410934368023762, time: 0.04446864128112793
Test Loss Energy: 13.48498741725128, Test Loss Force: 11.217886395050648, time: 9.006162166595459


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.985017340501979, Training Loss Force: 2.1412000017596755, time: 0.4292294979095459
Validation Loss Energy: 1.2190201642479217, Validation Loss Force: 2.408879799814286, time: 0.04574322700500488
Test Loss Energy: 12.91591036545447, Test Loss Force: 11.16705234406568, time: 9.190192461013794


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.195444989072009, Training Loss Force: 2.1376139266818788, time: 0.4761037826538086
Validation Loss Energy: 1.9915831241819806, Validation Loss Force: 2.374950143365248, time: 0.043324947357177734
Test Loss Energy: 11.920832487121356, Test Loss Force: 11.231229732868702, time: 9.028960466384888


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2263582157053814, Training Loss Force: 2.144688639890514, time: 0.5225222110748291
Validation Loss Energy: 1.7568743688684503, Validation Loss Force: 2.411408653304588, time: 0.04710888862609863
Test Loss Energy: 13.765708638545515, Test Loss Force: 11.377632639832589, time: 9.081086158752441


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.291035244826185, Training Loss Force: 2.1307441957785627, time: 0.46299219131469727
Validation Loss Energy: 4.739508763028337, Validation Loss Force: 2.4501831450307234, time: 0.04005074501037598
Test Loss Energy: 15.996574162700005, Test Loss Force: 11.230867605220613, time: 9.223462104797363


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.986853476037985, Training Loss Force: 2.0876668454765186, time: 0.47653985023498535
Validation Loss Energy: 3.1580447972288264, Validation Loss Force: 2.3675031964488387, time: 0.04297757148742676
Test Loss Energy: 15.048431046532933, Test Loss Force: 11.443517301760053, time: 9.022614002227783


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9073098127786845, Training Loss Force: 2.1047720358845594, time: 0.46903061866760254
Validation Loss Energy: 1.0512050057465796, Validation Loss Force: 2.4356499752143086, time: 0.042701005935668945
Test Loss Energy: 13.499038222744035, Test Loss Force: 11.202691335951831, time: 9.015439748764038


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.399391414489765, Training Loss Force: 2.1470147224104625, time: 0.4445834159851074
Validation Loss Energy: 2.400687133928165, Validation Loss Force: 2.3696593017888574, time: 0.04465126991271973
Test Loss Energy: 14.796864561025037, Test Loss Force: 11.167205330592811, time: 9.23496699333191


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.376246887849544, Training Loss Force: 2.085077602578192, time: 0.4307847023010254
Validation Loss Energy: 4.481396033128348, Validation Loss Force: 2.503310667234218, time: 0.04259610176086426
Test Loss Energy: 11.709796197586185, Test Loss Force: 11.253806066641365, time: 9.008400917053223

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–ƒâ–â–ƒâ–„â–ˆâ–„â–„â–„â–ƒâ–„â–ƒâ–‚â–„â–‡â–†â–„â–†â–‚
wandb:   test_error_force â–ƒâ–ˆâ–‡â–„â–„â–ƒâ–…â–‡â–‚â–„â–â–‚â–â–‚â–„â–‚â–„â–‚â–â–‚
wandb:          test_loss â–…â–†â–…â–‚â–ƒâ–ƒâ–ƒâ–†â–‚â–„â–â–„â–„â–…â–†â–„â–ˆâ–†â–„â–‡
wandb: train_error_energy â–ˆâ–…â–…â–„â–…â–ƒâ–‡â–ƒâ–â–â–„â–‚â–‚â–„â–„â–„â–‚â–‚â–…â–…
wandb:  train_error_force â–ˆâ–ƒâ–„â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–
wandb:         train_loss â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–
wandb: valid_error_energy â–ƒâ–‚â–‚â–†â–‚â–‚â–ˆâ–‚â–â–â–ƒâ–‚â–â–ƒâ–‚â–ˆâ–…â–â–„â–ˆ
wandb:  valid_error_force â–‚â–ˆâ–‚â–ƒâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–„â–â–ƒâ–â–…
wandb:         valid_loss â–„â–ˆâ–â–…â–„â–ƒâ–‡â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‡â–‚â–‚â–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 908
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.7098
wandb:   test_error_force 11.25381
wandb:          test_loss 89.77596
wandb: train_error_energy 2.37625
wandb:  train_error_force 2.08508
wandb:         train_loss -4.90088
wandb: valid_error_energy 4.4814
wandb:  valid_error_force 2.50331
wandb:         valid_loss -3.87154
wandb: 
wandb: ğŸš€ View run al_82_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/11fklf1b
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_000250-11fklf1b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 8.400369644165039, Uncertainty Bias: -1.6998862028121948
3.8146973e-06 0.13284397
1.0790886 4.9533997
(48745, 22, 3)
Found uncertainty sample 0 after 2982 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 305 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1418 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3819 steps.
Found uncertainty sample 11 after 121 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2772 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3865 steps.
Found uncertainty sample 17 after 2904 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3967 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2521 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1016 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1303 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1822 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1939 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 789 steps.
Found uncertainty sample 46 after 1382 steps.
Found uncertainty sample 47 after 2833 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2959 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3839 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 175 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 835 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3501 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 893 steps.
Found uncertainty sample 76 after 2245 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 86 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 805 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2565 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1012 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2099 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1161 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_004013-w93uq4ff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w93uq4ff
Training model 3. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.195195308733145, Training Loss Force: 2.408465360577581, time: 0.48578333854675293
Validation Loss Energy: 1.1437702397273555, Validation Loss Force: 2.4845804066862103, time: 0.04413437843322754
Test Loss Energy: 13.050328085820079, Test Loss Force: 11.33938861479467, time: 9.172506093978882


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7663904484120547, Training Loss Force: 2.2355131172562634, time: 0.49400806427001953
Validation Loss Energy: 1.2577285232377164, Validation Loss Force: 2.461281643271202, time: 0.04421091079711914
Test Loss Energy: 12.537704428860064, Test Loss Force: 11.280904537968985, time: 9.208829641342163


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7002450329192174, Training Loss Force: 2.209326899113742, time: 0.5675599575042725
Validation Loss Energy: 1.1062639601218518, Validation Loss Force: 2.4387586591606065, time: 0.0419769287109375
Test Loss Energy: 12.800697320322278, Test Loss Force: 11.336768668639156, time: 9.41872763633728


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5660932779468233, Training Loss Force: 2.191036309927826, time: 0.4910242557525635
Validation Loss Energy: 2.5834134431211346, Validation Loss Force: 2.423666367118767, time: 0.04304099082946777
Test Loss Energy: 12.691089960446558, Test Loss Force: 11.195416037801754, time: 9.152533054351807


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.339060519693381, Training Loss Force: 2.1839116543332335, time: 0.4927492141723633
Validation Loss Energy: 1.7503974800862758, Validation Loss Force: 2.468647983956785, time: 0.048276424407958984
Test Loss Energy: 13.694316601538224, Test Loss Force: 11.348299432977077, time: 9.282951593399048


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.880759036935312, Training Loss Force: 2.246052630583958, time: 0.48519349098205566
Validation Loss Energy: 1.5960287546346479, Validation Loss Force: 2.5426195649105803, time: 0.04970550537109375
Test Loss Energy: 13.872206497244198, Test Loss Force: 11.279015627443425, time: 9.38874864578247


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.3088069768307844, Training Loss Force: 2.2543264519514645, time: 0.49613213539123535
Validation Loss Energy: 2.239955192293359, Validation Loss Force: 2.4850426678331563, time: 0.04408121109008789
Test Loss Energy: 14.219492782764203, Test Loss Force: 11.251412515551104, time: 9.620762825012207


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8872109236835513, Training Loss Force: 2.1868071882395914, time: 0.49309396743774414
Validation Loss Energy: 1.2633640566520028, Validation Loss Force: 2.3542748678275607, time: 0.04310894012451172
Test Loss Energy: 13.184705604495488, Test Loss Force: 11.301194402360244, time: 9.18355941772461


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.016144614634326, Training Loss Force: 2.209704735254009, time: 0.48369359970092773
Validation Loss Energy: 2.7976708167232083, Validation Loss Force: 2.4679882152774013, time: 0.04225802421569824
Test Loss Energy: 12.113788018691048, Test Loss Force: 11.23476084583258, time: 9.37277603149414


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.539649904445542, Training Loss Force: 2.1973547621903675, time: 0.47855114936828613
Validation Loss Energy: 1.0822492040681129, Validation Loss Force: 2.3903588482634506, time: 0.045783042907714844
Test Loss Energy: 12.918072764986734, Test Loss Force: 11.199249379247656, time: 9.170544385910034


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6515853485730014, Training Loss Force: 2.1461821711758513, time: 0.4627401828765869
Validation Loss Energy: 1.517114586648694, Validation Loss Force: 2.416168206298795, time: 0.04268956184387207
Test Loss Energy: 12.415391968555323, Test Loss Force: 11.3428168662712, time: 9.273979902267456


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.198369643623678, Training Loss Force: 2.190723244530956, time: 0.5184206962585449
Validation Loss Energy: 3.864454201257188, Validation Loss Force: 2.4567443140846317, time: 0.04551577568054199
Test Loss Energy: 12.152649068092984, Test Loss Force: 11.254571619486368, time: 9.17837119102478


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9519389350168332, Training Loss Force: 2.181311253535192, time: 0.4731578826904297
Validation Loss Energy: 1.0684261261580617, Validation Loss Force: 2.3689100201128106, time: 0.060652732849121094
Test Loss Energy: 13.674619708579984, Test Loss Force: 11.306142162078268, time: 9.347986936569214


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.646860353830243, Training Loss Force: 2.1618532359952436, time: 0.46243906021118164
Validation Loss Energy: 1.781700865293669, Validation Loss Force: 2.3642353040632025, time: 0.04756021499633789
Test Loss Energy: 13.924469300723684, Test Loss Force: 11.390897257695618, time: 9.244697093963623


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.3236006398587152, Training Loss Force: 2.1516500495678637, time: 0.45656347274780273
Validation Loss Energy: 2.3319391484686904, Validation Loss Force: 2.3610564793359377, time: 0.044130563735961914
Test Loss Energy: 12.43892692214639, Test Loss Force: 11.1683198094869, time: 9.18378472328186


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0805024051121306, Training Loss Force: 2.1439535721842238, time: 0.5001571178436279
Validation Loss Energy: 1.1773598803905623, Validation Loss Force: 2.417187362979706, time: 0.0408177375793457
Test Loss Energy: 13.672939580106814, Test Loss Force: 11.425412103815646, time: 9.367600917816162


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1756012001800684, Training Loss Force: 2.1402257566776735, time: 0.49546337127685547
Validation Loss Energy: 1.1194416315124314, Validation Loss Force: 2.3697708590309676, time: 0.042077064514160156
Test Loss Energy: 13.623341340550137, Test Loss Force: 11.409501253179814, time: 9.228129625320435


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.085939582995648, Training Loss Force: 2.1584990481821027, time: 0.4895598888397217
Validation Loss Energy: 1.25676815121133, Validation Loss Force: 2.4014622452251397, time: 0.04250025749206543
Test Loss Energy: 14.152819830091099, Test Loss Force: 11.190610529859574, time: 9.564953565597534


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0519551313809496, Training Loss Force: 2.1440535320749827, time: 0.5168471336364746
Validation Loss Energy: 2.3186736341000422, Validation Loss Force: 2.391943139236727, time: 0.04551434516906738
Test Loss Energy: 14.3709331979358, Test Loss Force: 11.526705100373446, time: 9.342435121536255


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.309131934615622, Training Loss Force: 2.149025585657453, time: 0.46689867973327637
Validation Loss Energy: 3.048907523396948, Validation Loss Force: 2.4755489461273794, time: 0.04531073570251465
Test Loss Energy: 12.270822251203388, Test Loss Force: 11.211547897474281, time: 9.266096353530884

wandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–ƒâ–ƒâ–†â–†â–ˆâ–„â–â–ƒâ–‚â–â–†â–‡â–‚â–†â–†â–‡â–ˆâ–
wandb:   test_error_force â–„â–ƒâ–„â–‚â–…â–ƒâ–ƒâ–„â–‚â–‚â–„â–ƒâ–„â–…â–â–†â–†â–â–ˆâ–‚
wandb:          test_loss â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–„â–†â–†â–…â–ˆâ–†
wandb: train_error_energy â–ˆâ–‚â–â–â–ƒâ–‚â–ƒâ–‚â–‚â–„â–â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–„â–„â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–„â–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–â–‚â–‚â–â–‚â–â–â–â–â–
wandb: valid_error_energy â–â–â–â–…â–ƒâ–‚â–„â–â–…â–â–‚â–ˆâ–â–ƒâ–„â–â–â–â–„â–†
wandb:  valid_error_force â–†â–…â–„â–„â–…â–ˆâ–†â–â–…â–‚â–ƒâ–…â–‚â–â–â–ƒâ–‚â–ƒâ–‚â–†
wandb:         valid_loss â–‡â–…â–…â–†â–…â–ˆâ–‡â–â–†â–ƒâ–„â–‡â–‚â–‚â–ƒâ–ƒâ–‚â–„â–„â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 935
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.27082
wandb:   test_error_force 11.21155
wandb:          test_loss 93.14198
wandb: train_error_energy 2.30913
wandb:  train_error_force 2.14903
wandb:         train_loss -4.83438
wandb: valid_error_energy 3.04891
wandb:  valid_error_force 2.47555
wandb:         valid_loss -3.97647
wandb: 
wandb: ğŸš€ View run al_82_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w93uq4ff
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_004013-w93uq4ff/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 8.279213905334473, Uncertainty Bias: -1.663530707359314
2.5749207e-05 0.2742796
1.0641323 5.122614
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2524 steps.
Found uncertainty sample 6 after 2269 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1811 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 917 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1901 steps.
Found uncertainty sample 23 after 493 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2794 steps.
Found uncertainty sample 26 after 1080 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1596 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2084 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1964 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2367 steps.
Found uncertainty sample 42 after 3331 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1813 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 525 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1721 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1346 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2205 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3426 steps.
Found uncertainty sample 63 after 3149 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3105 steps.
Found uncertainty sample 66 after 3737 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 712 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1592 steps.
Found uncertainty sample 73 after 2244 steps.
Found uncertainty sample 74 after 382 steps.
Found uncertainty sample 75 after 908 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3841 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1393 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 320 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3135 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3426 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_011737-4mldum5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/4mldum5f
Training model 4. Added 32 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.660065904835906, Training Loss Force: 2.445059592628807, time: 0.4973008632659912
Validation Loss Energy: 2.055307471040179, Validation Loss Force: 2.4737689289748324, time: 0.04487013816833496
Test Loss Energy: 12.394531264412015, Test Loss Force: 11.273332504619686, time: 9.293431520462036


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.167497097115873, Training Loss Force: 2.319357436681435, time: 0.48873472213745117
Validation Loss Energy: 1.2046797145773074, Validation Loss Force: 2.4341213515275144, time: 0.04608750343322754
Test Loss Energy: 14.328276318095503, Test Loss Force: 11.0502963486439, time: 9.325865507125854


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1174307746633074, Training Loss Force: 2.274499343756402, time: 0.47200965881347656
Validation Loss Energy: 1.8019500634206231, Validation Loss Force: 2.395310342061447, time: 0.04470682144165039
Test Loss Energy: 14.7310939569958, Test Loss Force: 11.323492877681396, time: 9.521727561950684


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.517839287596752, Training Loss Force: 2.243902214799762, time: 0.5303068161010742
Validation Loss Energy: 2.0014700795994664, Validation Loss Force: 2.391886581273661, time: 0.04450273513793945
Test Loss Energy: 14.996806359198548, Test Loss Force: 11.176918825579811, time: 9.644082069396973


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8466138164613919, Training Loss Force: 2.203507715251056, time: 0.4807014465332031
Validation Loss Energy: 1.370960459994061, Validation Loss Force: 2.376013611206199, time: 0.04371237754821777
Test Loss Energy: 12.737253653168656, Test Loss Force: 11.148419520504836, time: 9.277785778045654


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.817440471704342, Training Loss Force: 2.197266306273575, time: 0.517308235168457
Validation Loss Energy: 1.0651182646607316, Validation Loss Force: 2.3967512341047454, time: 0.04666399955749512
Test Loss Energy: 13.306136075810626, Test Loss Force: 11.230822236673584, time: 9.543798923492432


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.158783879250984, Training Loss Force: 2.1871435190904873, time: 0.47156381607055664
Validation Loss Energy: 1.2167113078737966, Validation Loss Force: 2.4078677685460446, time: 0.045900583267211914
Test Loss Energy: 14.116523225102798, Test Loss Force: 11.490099743046883, time: 9.34586477279663


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.211730676711055, Training Loss Force: 2.1971263587153596, time: 0.46520185470581055
Validation Loss Energy: 1.7682116797679366, Validation Loss Force: 2.4251168339353404, time: 0.04649066925048828
Test Loss Energy: 14.199316603212909, Test Loss Force: 11.280217061553518, time: 9.374972581863403


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.059714028792208, Training Loss Force: 2.1945584770700775, time: 0.5227086544036865
Validation Loss Energy: 1.1148562057903404, Validation Loss Force: 2.4098130062048697, time: 0.043843984603881836
Test Loss Energy: 14.401695026715448, Test Loss Force: 10.904587316044545, time: 9.509964227676392


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0087556237080184, Training Loss Force: 2.228129984563642, time: 0.5584414005279541
Validation Loss Energy: 1.523969233636935, Validation Loss Force: 2.4757250774218083, time: 0.04407024383544922
Test Loss Energy: 13.646272065675333, Test Loss Force: 11.470986476412389, time: 9.35324215888977


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.610235407054774, Training Loss Force: 2.2230949790616097, time: 0.49654388427734375
Validation Loss Energy: 1.4567878369536351, Validation Loss Force: 2.375069048689173, time: 0.04558873176574707
Test Loss Energy: 13.962764196917895, Test Loss Force: 11.074621365007312, time: 9.335968732833862


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7096062164424668, Training Loss Force: 2.1825427507459545, time: 0.48603057861328125
Validation Loss Energy: 1.2698937180217622, Validation Loss Force: 2.445056410614882, time: 0.045989274978637695
Test Loss Energy: 14.038752129760368, Test Loss Force: 11.286115243134784, time: 9.47771692276001


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7161374867763777, Training Loss Force: 2.2060504388742856, time: 0.4964311122894287
Validation Loss Energy: 1.3001673697638125, Validation Loss Force: 2.4768110348464982, time: 0.04732918739318848
Test Loss Energy: 13.087672802638911, Test Loss Force: 11.243616320822861, time: 9.32608938217163


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8099381951261768, Training Loss Force: 2.247693562841658, time: 0.5291728973388672
Validation Loss Energy: 5.81068006575197, Validation Loss Force: 2.494153398607938, time: 0.053568124771118164
Test Loss Energy: 18.584860729406227, Test Loss Force: 11.52993763149974, time: 9.352330207824707


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.5804547735333108, Training Loss Force: 2.217301551674234, time: 0.5288693904876709
Validation Loss Energy: 2.378328924985556, Validation Loss Force: 2.416508890092064, time: 0.04477071762084961
Test Loss Energy: 15.856390743065921, Test Loss Force: 11.07640355755581, time: 9.901570320129395


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.8466359019788046, Training Loss Force: 2.213969383325619, time: 0.5240843296051025
Validation Loss Energy: 1.1021937908034378, Validation Loss Force: 2.3745555736386637, time: 0.04415702819824219
Test Loss Energy: 14.079503894357165, Test Loss Force: 11.058827444818265, time: 9.34619140625


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.124448018612486, Training Loss Force: 2.1908090949793126, time: 0.4636499881744385
Validation Loss Energy: 3.0233765017940133, Validation Loss Force: 2.3865797075187642, time: 0.04298090934753418
Test Loss Energy: 12.293924154108865, Test Loss Force: 11.39111632216616, time: 9.302392959594727


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1552277919360736, Training Loss Force: 2.183929742490187, time: 0.483168363571167
Validation Loss Energy: 1.0786694635436047, Validation Loss Force: 2.4223223361539468, time: 0.04435157775878906
Test Loss Energy: 13.816709148123843, Test Loss Force: 11.429862166515733, time: 9.350785255432129


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.561690207600648, Training Loss Force: 2.2053233415097613, time: 0.6292006969451904
Validation Loss Energy: 3.2114047860206694, Validation Loss Force: 2.422673262727929, time: 0.06599783897399902
Test Loss Energy: 15.921101455950227, Test Loss Force: 11.192711472707561, time: 9.362856388092041


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.910319785932175, Training Loss Force: 2.170904362429671, time: 0.4827141761779785
Validation Loss Energy: 1.0458953486273586, Validation Loss Force: 2.401942542572906, time: 0.04678988456726074
Test Loss Energy: 13.57714863322226, Test Loss Force: 11.283707114793211, time: 9.294643640518188

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–„â–„â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ˆâ–…â–ƒâ–â–ƒâ–…â–‚
wandb:   test_error_force â–…â–ƒâ–†â–„â–„â–…â–ˆâ–…â–â–‡â–ƒâ–…â–…â–ˆâ–ƒâ–ƒâ–†â–‡â–„â–…
wandb:          test_loss â–„â–â–„â–‚â–‚â–ƒâ–†â–„â–â–…â–ƒâ–„â–„â–†â–ƒâ–ƒâ–†â–ˆâ–…â–‡
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–â–â–ƒâ–ƒâ–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–…â–„â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–…â–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–ˆâ–ƒâ–â–„â–â–„â–
wandb:  valid_error_force â–‡â–„â–‚â–‚â–â–‚â–ƒâ–„â–ƒâ–‡â–â–…â–‡â–ˆâ–ƒâ–â–‚â–„â–„â–ƒ
wandb:         valid_loss â–†â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–„â–ƒâ–…â–‚â–„â–…â–ˆâ–„â–â–„â–ƒâ–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 963
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.57715
wandb:   test_error_force 11.28371
wandb:          test_loss 93.55783
wandb: train_error_energy 1.91032
wandb:  train_error_force 2.1709
wandb:         train_loss -4.84219
wandb: valid_error_energy 1.0459
wandb:  valid_error_force 2.40194
wandb:         valid_loss -4.23657
wandb: 
wandb: ğŸš€ View run al_82_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/4mldum5f
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_011737-4mldum5f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 8.273946762084961, Uncertainty Bias: -1.6927597522735596
8.010864e-05 0.0012187958
0.95247173 5.407244
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2813 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 572 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3183 steps.
Found uncertainty sample 17 after 3834 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2642 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 415 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1050 steps.
Found uncertainty sample 30 after 1754 steps.
Found uncertainty sample 31 after 190 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2376 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1354 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3934 steps.
Found uncertainty sample 55 after 1806 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3434 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1297 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3993 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2589 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3017 steps.
Found uncertainty sample 75 after 2950 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 842 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 898 steps.
Found uncertainty sample 83 after 2243 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3478 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 217 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1645 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_015632-8l6kyp0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8l6kyp0h
Training model 5. Added 25 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.1339453533047283, Training Loss Force: 2.426160735622953, time: 0.5351893901824951
Validation Loss Energy: 1.0728589121806191, Validation Loss Force: 2.4010157935875545, time: 0.04918169975280762
Test Loss Energy: 13.733624859186513, Test Loss Force: 11.068162868580009, time: 9.886079549789429


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.259492696732674, Training Loss Force: 2.23327841485546, time: 0.5727529525756836
Validation Loss Energy: 1.742592147179496, Validation Loss Force: 2.36795588282251, time: 0.05461740493774414
Test Loss Energy: 12.987381528117643, Test Loss Force: 11.152105853682142, time: 10.447927236557007


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.736358208392718, Training Loss Force: 2.218833249631816, time: 0.5370750427246094
Validation Loss Energy: 1.0841349890649754, Validation Loss Force: 2.365057621219114, time: 0.0466001033782959
Test Loss Energy: 13.640370330714186, Test Loss Force: 11.083476620825872, time: 9.440231561660767


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.282461701508314, Training Loss Force: 2.222710849644819, time: 0.5110523700714111
Validation Loss Energy: 3.7231986844783935, Validation Loss Force: 2.3876373859619213, time: 0.04575324058532715
Test Loss Energy: 16.13583235589274, Test Loss Force: 11.274808383698263, time: 9.223730564117432


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2669292177050404, Training Loss Force: 2.2174882417959045, time: 0.4709510803222656
Validation Loss Energy: 1.8628498521627272, Validation Loss Force: 2.427596700213538, time: 0.04650378227233887
Test Loss Energy: 14.739860182461813, Test Loss Force: 11.043079065715698, time: 9.208120822906494


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0352973351771615, Training Loss Force: 2.1972350859044534, time: 0.47251009941101074
Validation Loss Energy: 1.2682230314198661, Validation Loss Force: 2.3484257947023295, time: 0.046016693115234375
Test Loss Energy: 14.517684485351086, Test Loss Force: 11.051635790992183, time: 9.438241720199585


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7151238555225794, Training Loss Force: 2.202811482703307, time: 0.5145406723022461
Validation Loss Energy: 1.712105401064793, Validation Loss Force: 2.387301823559008, time: 0.04634666442871094
Test Loss Energy: 13.211621156034235, Test Loss Force: 11.003171312778145, time: 9.226353645324707


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7938337928044632, Training Loss Force: 2.211113928069808, time: 0.5290329456329346
Validation Loss Energy: 1.1979306127642362, Validation Loss Force: 2.4000171224680686, time: 0.04567122459411621
Test Loss Energy: 13.654751194834784, Test Loss Force: 11.281325422292223, time: 9.181028127670288


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8038367301154745, Training Loss Force: 2.1952881566784064, time: 0.5448176860809326
Validation Loss Energy: 1.090990749398946, Validation Loss Force: 2.3721393907362014, time: 0.044626474380493164
Test Loss Energy: 14.426557857848895, Test Loss Force: 10.721757331630911, time: 9.360694885253906


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.027025023769836, Training Loss Force: 2.2044694843467614, time: 0.48598527908325195
Validation Loss Energy: 1.1090668079962178, Validation Loss Force: 2.3661195303760434, time: 0.045218706130981445
Test Loss Energy: 13.908439724298212, Test Loss Force: 11.043452879413621, time: 9.209367752075195


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6954053767349115, Training Loss Force: 2.215479026263441, time: 0.536776065826416
Validation Loss Energy: 1.2872130355265987, Validation Loss Force: 2.4214049392727244, time: 0.05116081237792969
Test Loss Energy: 14.19181441103217, Test Loss Force: 11.185829191429084, time: 9.262756824493408


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8682076453232848, Training Loss Force: 2.1892152364156376, time: 0.5123882293701172
Validation Loss Energy: 1.55543383130598, Validation Loss Force: 2.364616958979323, time: 0.045842885971069336
Test Loss Energy: 14.425488491024288, Test Loss Force: 11.176864107260267, time: 9.349798440933228


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.1146832744078865, Training Loss Force: 2.1663894940953368, time: 0.4903683662414551
Validation Loss Energy: 1.423997467189736, Validation Loss Force: 2.3556131093945867, time: 0.049466609954833984
Test Loss Energy: 14.557262207640163, Test Loss Force: 11.054994047413627, time: 9.644230365753174


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.912530644508177, Training Loss Force: 2.2060090942419004, time: 0.5175924301147461
Validation Loss Energy: 1.4823857706349206, Validation Loss Force: 2.382895646499389, time: 0.04663276672363281
Test Loss Energy: 12.85351475883587, Test Loss Force: 10.833793547897496, time: 9.253105878829956


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9475304506978324, Training Loss Force: 2.1956416762705078, time: 0.48923301696777344
Validation Loss Energy: 1.2467905694514516, Validation Loss Force: 2.351205596320092, time: 0.04585528373718262
Test Loss Energy: 13.5447257765521, Test Loss Force: 10.91161990715717, time: 9.406781911849976


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.436484478118803, Training Loss Force: 2.1486501902583397, time: 0.4854764938354492
Validation Loss Energy: 2.6702526286798043, Validation Loss Force: 2.3353693666617077, time: 0.04371356964111328
Test Loss Energy: 12.801678104464248, Test Loss Force: 10.939588401630857, time: 9.207572221755981


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.7972525399154584, Training Loss Force: 2.1959895142079495, time: 0.551255464553833
Validation Loss Energy: 3.6462319808427237, Validation Loss Force: 2.339811838792113, time: 0.04573845863342285
Test Loss Energy: 12.490475062590084, Test Loss Force: 11.206167800544586, time: 9.220248222351074


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.295657412691152, Training Loss Force: 2.179018257309701, time: 0.5014359951019287
Validation Loss Energy: 1.090271639392172, Validation Loss Force: 2.341508577684083, time: 0.04651689529418945
Test Loss Energy: 13.94174022849253, Test Loss Force: 11.20053186026364, time: 9.285300493240356


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5741055244814521, Training Loss Force: 2.1825463134522898, time: 0.6178364753723145
Validation Loss Energy: 1.1573126431789647, Validation Loss Force: 2.3919475926196454, time: 0.06750273704528809
Test Loss Energy: 13.477980030887004, Test Loss Force: 11.021158568355245, time: 9.301836013793945


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.568739000535511, Training Loss Force: 2.2194446129120258, time: 0.47185444831848145
Validation Loss Energy: 1.7627016204173804, Validation Loss Force: 2.3613797949358246, time: 0.04703259468078613
Test Loss Energy: 13.458922191382735, Test Loss Force: 10.8185882343599, time: 9.265696287155151

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–ƒâ–ˆâ–…â–…â–‚â–ƒâ–…â–„â–„â–…â–…â–‚â–ƒâ–‚â–â–„â–ƒâ–ƒ
wandb:   test_error_force â–…â–†â–†â–ˆâ–…â–…â–…â–ˆâ–â–…â–‡â–‡â–…â–‚â–ƒâ–„â–‡â–‡â–…â–‚
wandb:          test_loss â–â–„â–„â–…â–ƒâ–„â–…â–‡â–‚â–…â–…â–…â–…â–ƒâ–„â–…â–ˆâ–ˆâ–…â–„
wandb: train_error_energy â–„â–„â–‚â–„â–„â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ˆâ–‡â–ƒâ–…â–‡â–„â–â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚â–‚â–ƒ
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–â–‚
wandb: valid_error_energy â–â–ƒâ–â–ˆâ–ƒâ–‚â–ƒâ–â–â–â–‚â–‚â–‚â–‚â–â–…â–ˆâ–â–â–ƒ
wandb:  valid_error_force â–†â–ƒâ–ƒâ–…â–ˆâ–‚â–…â–†â–„â–ƒâ–ˆâ–ƒâ–ƒâ–…â–‚â–â–â–â–…â–ƒ
wandb:         valid_loss â–‚â–‚â–‚â–ˆâ–‡â–â–„â–„â–ƒâ–‚â–†â–‚â–ƒâ–„â–â–ƒâ–…â–â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 985
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.45892
wandb:   test_error_force 10.81859
wandb:          test_loss 87.52567
wandb: train_error_energy 1.56874
wandb:  train_error_force 2.21944
wandb:         train_loss -4.80862
wandb: valid_error_energy 1.7627
wandb:  valid_error_force 2.36138
wandb:         valid_loss -4.36617
wandb: 
wandb: ğŸš€ View run al_82_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8l6kyp0h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_015632-8l6kyp0h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 7.472349643707275, Uncertainty Bias: -1.5068577527999878
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:1004: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
0.00010871887 0.0023784637
1.0731388 4.795739
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1834 steps.
Found uncertainty sample 2 after 1113 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 213 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3923 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1755 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1822 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 169 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1276 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 608 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1015 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1636 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2767 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 122 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3865 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 522 steps.
Found uncertainty sample 63 after 444 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2213 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1687 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 529 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3952 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2372 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 367 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_023506-q16w80wz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/q16w80wz
Training model 6. Added 22 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.253427527040747, Training Loss Force: 2.571573206121927, time: 0.5425920486450195
Validation Loss Energy: 1.6041036285425732, Validation Loss Force: 2.4919837104500173, time: 0.04687190055847168
Test Loss Energy: 14.489778175025274, Test Loss Force: 10.88127687823777, time: 9.246855735778809


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.986781396259853, Training Loss Force: 2.287147148325251, time: 0.4976480007171631
Validation Loss Energy: 2.73916405329239, Validation Loss Force: 2.4888906133439344, time: 0.04747796058654785
Test Loss Energy: 12.431785705796376, Test Loss Force: 11.25444589419122, time: 9.283262252807617


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9265327060172637, Training Loss Force: 2.2764111972048076, time: 0.49808239936828613
Validation Loss Energy: 1.3178358324894635, Validation Loss Force: 2.4561005775837543, time: 0.04652595520019531
Test Loss Energy: 15.161862262848425, Test Loss Force: 10.930951855877495, time: 9.411929368972778


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.059389650575651, Training Loss Force: 2.23701018408614, time: 0.5254461765289307
Validation Loss Energy: 1.7274474165537905, Validation Loss Force: 2.4412465415280575, time: 0.050240278244018555
Test Loss Energy: 14.48391754175737, Test Loss Force: 10.936470455347571, time: 9.299652814865112


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9895110764445496, Training Loss Force: 2.2665988429096187, time: 0.5168790817260742
Validation Loss Energy: 1.6068807581305846, Validation Loss Force: 2.4321171065450184, time: 0.047300100326538086
Test Loss Energy: 14.537747768147971, Test Loss Force: 10.98347235400982, time: 9.241926193237305


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.702969775086747, Training Loss Force: 2.242694690795709, time: 0.4805305004119873
Validation Loss Energy: 2.3664591008235836, Validation Loss Force: 2.4459595566707653, time: 0.04698920249938965
Test Loss Energy: 15.378169385213644, Test Loss Force: 10.841730063825118, time: 9.452064990997314


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.87907257631195, Training Loss Force: 2.2363393445751565, time: 0.4896972179412842
Validation Loss Energy: 1.2453178357202854, Validation Loss Force: 2.407949042784308, time: 0.04677391052246094
Test Loss Energy: 12.924920412469463, Test Loss Force: 10.869685883644587, time: 9.294341802597046


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6493725964342059, Training Loss Force: 2.248764255084284, time: 0.5140225887298584
Validation Loss Energy: 1.5928946864057143, Validation Loss Force: 2.4201005434158795, time: 0.04780912399291992
Test Loss Energy: 13.088680101896351, Test Loss Force: 10.730868575360791, time: 9.295289993286133


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7090150403537612, Training Loss Force: 2.236999113254541, time: 0.4942624568939209
Validation Loss Energy: 1.3728453543143397, Validation Loss Force: 2.4252375206124333, time: 0.04921746253967285
Test Loss Energy: 14.441068163857507, Test Loss Force: 11.087786380979496, time: 9.429900169372559


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.38045630600575, Training Loss Force: 2.24218637888602, time: 0.5484871864318848
Validation Loss Energy: 4.404075062881508, Validation Loss Force: 2.4519783036851934, time: 0.04828453063964844
Test Loss Energy: 17.14820538746513, Test Loss Force: 10.934205324898352, time: 9.279224395751953


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.7132307555228996, Training Loss Force: 2.2337204562073807, time: 0.5028557777404785
Validation Loss Energy: 1.047567816582422, Validation Loss Force: 2.354194929604173, time: 0.04721570014953613
Test Loss Energy: 13.59547278838296, Test Loss Force: 10.724653238304072, time: 9.659673690795898


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.21832729118012, Training Loss Force: 2.2152045912548473, time: 0.5384032726287842
Validation Loss Energy: 1.4791758835617985, Validation Loss Force: 2.424090997180051, time: 0.05744194984436035
Test Loss Energy: 13.072759817549894, Test Loss Force: 10.810623613155999, time: 9.428323745727539


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9297044018526537, Training Loss Force: 2.1966339288171834, time: 0.5155889987945557
Validation Loss Energy: 1.5089901688557996, Validation Loss Force: 2.454618714417605, time: 0.04921102523803711
Test Loss Energy: 13.202069475065322, Test Loss Force: 10.720250465401028, time: 9.220056533813477


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2880686054391814, Training Loss Force: 2.1984552406586833, time: 0.5283722877502441
Validation Loss Energy: 1.873874201577612, Validation Loss Force: 2.3969422842319514, time: 0.04546618461608887
Test Loss Energy: 12.981192860062924, Test Loss Force: 10.926811384896743, time: 9.309842109680176


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0511156860968285, Training Loss Force: 2.2010249574164686, time: 0.5228738784790039
Validation Loss Energy: 1.6490391528673845, Validation Loss Force: 2.4575926835306166, time: 0.04630851745605469
Test Loss Energy: 14.993506770850926, Test Loss Force: 10.824173886388076, time: 9.263943433761597


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7353807668234515, Training Loss Force: 2.2199599344105136, time: 0.6186573505401611
Validation Loss Energy: 1.1269209767895727, Validation Loss Force: 2.416667430523965, time: 0.06679654121398926
Test Loss Energy: 13.912734804609508, Test Loss Force: 10.847108066965358, time: 9.35941219329834


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8869680971812415, Training Loss Force: 2.2155482045390684, time: 0.5155816078186035
Validation Loss Energy: 1.7615833759665311, Validation Loss Force: 2.4266125025885374, time: 0.045481204986572266
Test Loss Energy: 13.074658665414718, Test Loss Force: 10.557276413342944, time: 9.227410793304443


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.647178639329994, Training Loss Force: 2.221002307829094, time: 0.49578189849853516
Validation Loss Energy: 2.2535146299346316, Validation Loss Force: 2.430813378695611, time: 0.04590439796447754
Test Loss Energy: 12.61294107367256, Test Loss Force: 10.824041623247007, time: 9.24103569984436


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.221758297413162, Training Loss Force: 2.1785111062200615, time: 0.5402913093566895
Validation Loss Energy: 1.9285998202414303, Validation Loss Force: 2.403033398718806, time: 0.04671621322631836
Test Loss Energy: 14.876279621506045, Test Loss Force: 10.997117360722523, time: 9.492723226547241


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7055610783234563, Training Loss Force: 2.2009733921131596, time: 0.4849107265472412
Validation Loss Energy: 1.9772581500170083, Validation Loss Force: 2.424275589902025, time: 0.046721458435058594
Test Loss Energy: 12.834355806554823, Test Loss Force: 10.768421682520845, time: 9.33301067352295

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–…â–„â–„â–…â–‚â–‚â–„â–ˆâ–ƒâ–‚â–‚â–‚â–…â–ƒâ–‚â–â–…â–‚
wandb:   test_error_force â–„â–ˆâ–…â–…â–…â–„â–„â–ƒâ–†â–…â–ƒâ–„â–ƒâ–…â–„â–„â–â–„â–…â–ƒ
wandb:          test_loss â–ƒâ–ˆâ–‚â–‚â–…â–‚â–‚â–â–‡â–…â–‚â–„â–‚â–†â–…â–†â–‚â–†â–ˆâ–…
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–
wandb: valid_error_energy â–‚â–…â–‚â–‚â–‚â–„â–â–‚â–‚â–ˆâ–â–‚â–‚â–ƒâ–‚â–â–‚â–„â–ƒâ–ƒ
wandb:  valid_error_force â–ˆâ–ˆâ–†â–…â–…â–†â–„â–„â–…â–†â–â–…â–†â–ƒâ–†â–„â–…â–…â–ƒâ–…
wandb:         valid_loss â–‡â–‡â–„â–…â–„â–…â–ƒâ–„â–„â–ˆâ–â–ƒâ–†â–ƒâ–…â–ƒâ–…â–…â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1004
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.83436
wandb:   test_error_force 10.76842
wandb:          test_loss 85.19752
wandb: train_error_energy 1.70556
wandb:  train_error_force 2.20097
wandb:         train_loss -4.81754
wandb: valid_error_energy 1.97726
wandb:  valid_error_force 2.42428
wandb:         valid_loss -4.11025
wandb: 
wandb: ğŸš€ View run al_82_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/q16w80wz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_023506-q16w80wz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 8.683627128601074, Uncertainty Bias: -1.7858269214630127
0.00011444092 0.036580086
1.0969217 4.899245
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1443 steps.
Found uncertainty sample 2 after 1549 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 901 steps.
Found uncertainty sample 7 after 416 steps.
Found uncertainty sample 8 after 2525 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2587 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2590 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1025 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1352 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 783 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 304 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1772 steps.
Found uncertainty sample 38 after 3009 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 671 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3832 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1109 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1446 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1427 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1549 steps.
Found uncertainty sample 65 after 1743 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3256 steps.
Found uncertainty sample 69 after 3034 steps.
Found uncertainty sample 70 after 2360 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1069 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1218 steps.
Found uncertainty sample 76 after 541 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2226 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1032 steps.
Found uncertainty sample 85 after 1902 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1247 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2114 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2347 steps.
Found uncertainty sample 97 after 20 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_031133-usqfauwk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/usqfauwk
Training model 7. Added 33 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.331370013908425, Training Loss Force: 2.435804048768191, time: 0.554459810256958
Validation Loss Energy: 2.5318595237719115, Validation Loss Force: 2.4783116022209053, time: 0.05027437210083008
Test Loss Energy: 12.525464998397798, Test Loss Force: 10.987501919434607, time: 9.380767822265625


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.788815820947937, Training Loss Force: 2.300699989814797, time: 0.550356388092041
Validation Loss Energy: 1.3832440034291675, Validation Loss Force: 2.4888819292472433, time: 0.04889845848083496
Test Loss Energy: 13.709999550886097, Test Loss Force: 11.073527436959845, time: 9.440754413604736


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.362224603362362, Training Loss Force: 2.32327564529973, time: 0.5776810646057129
Validation Loss Energy: 1.3584126082827384, Validation Loss Force: 2.5159311090871133, time: 0.04672408103942871
Test Loss Energy: 13.56932891250781, Test Loss Force: 10.452165981610587, time: 9.621949911117554


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9842288987222012, Training Loss Force: 2.2826845748220417, time: 0.552823543548584
Validation Loss Energy: 1.1370036583863288, Validation Loss Force: 2.4534180823827625, time: 0.04924130439758301
Test Loss Energy: 13.326920536173082, Test Loss Force: 10.851494308724476, time: 9.427265405654907


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1390595749334804, Training Loss Force: 2.2930743003021576, time: 0.5430870056152344
Validation Loss Energy: 3.0115670209705874, Validation Loss Force: 2.4667370373464332, time: 0.04833865165710449
Test Loss Energy: 12.298518497089056, Test Loss Force: 10.388835873389773, time: 9.35919189453125


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9486038798813674, Training Loss Force: 2.301167756962443, time: 0.5398266315460205
Validation Loss Energy: 2.1932436588606277, Validation Loss Force: 2.39492957782191, time: 0.04752373695373535
Test Loss Energy: 15.310703716391357, Test Loss Force: 10.82122050076428, time: 9.593375444412231


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9883158643791452, Training Loss Force: 2.271980096382832, time: 0.5198938846588135
Validation Loss Energy: 2.245983291411916, Validation Loss Force: 2.412048381760839, time: 0.049549102783203125
Test Loss Energy: 15.46118101172936, Test Loss Force: 10.507451909291403, time: 9.381653785705566


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.708094936269163, Training Loss Force: 2.261724583043536, time: 0.516960859298706
Validation Loss Energy: 1.1107752370183488, Validation Loss Force: 2.407900946248788, time: 0.049646854400634766
Test Loss Energy: 13.855734706889757, Test Loss Force: 10.376085455709235, time: 9.422743797302246


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9358724846920767, Training Loss Force: 2.2643934110822537, time: 0.5889339447021484
Validation Loss Energy: 1.4047516162343325, Validation Loss Force: 2.501522188654126, time: 0.04860544204711914
Test Loss Energy: 13.572167046446967, Test Loss Force: 10.485067817100743, time: 9.616389989852905


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8805316041878604, Training Loss Force: 2.292391522477694, time: 0.5248682498931885
Validation Loss Energy: 1.0888720524754432, Validation Loss Force: 2.447548078357814, time: 0.04704427719116211
Test Loss Energy: 13.252020595088595, Test Loss Force: 10.882715083095828, time: 9.819672584533691


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.726105699998578, Training Loss Force: 2.232816780468833, time: 0.5507268905639648
Validation Loss Energy: 1.9681362857849305, Validation Loss Force: 2.3880221582460845, time: 0.047592878341674805
Test Loss Energy: 12.89450336879228, Test Loss Force: 10.48452509195143, time: 9.383434057235718


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.5205170881082943, Training Loss Force: 2.291527498715996, time: 0.5151801109313965
Validation Loss Energy: 1.095625385002287, Validation Loss Force: 2.371035842448983, time: 0.04793071746826172
Test Loss Energy: 13.750215058231081, Test Loss Force: 10.498931519888952, time: 9.551446199417114


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.511690631609814, Training Loss Force: 2.233891216452108, time: 0.520601749420166
Validation Loss Energy: 3.3665038662709406, Validation Loss Force: 2.385513567648062, time: 0.05008673667907715
Test Loss Energy: 16.587104069344992, Test Loss Force: 10.764234028997294, time: 9.416138410568237


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6885065116919362, Training Loss Force: 2.237314747823198, time: 0.5091574192047119
Validation Loss Energy: 1.7809406728294714, Validation Loss Force: 2.477205827242228, time: 0.049411773681640625
Test Loss Energy: 15.32380795651058, Test Loss Force: 11.036244554546768, time: 9.388099431991577


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7085589006578645, Training Loss Force: 2.282710846407486, time: 0.5108823776245117
Validation Loss Energy: 1.6673522427704965, Validation Loss Force: 2.457224388763252, time: 0.04822278022766113
Test Loss Energy: 13.384401473340871, Test Loss Force: 10.756198913772893, time: 9.586519241333008


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.940827733501579, Training Loss Force: 2.279612553687998, time: 0.591912031173706
Validation Loss Energy: 1.3117667622480558, Validation Loss Force: 2.417677457769893, time: 0.04687619209289551
Test Loss Energy: 13.967688864329942, Test Loss Force: 10.693966562109887, time: 9.357425451278687


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7590889349805998, Training Loss Force: 2.2520963961638185, time: 0.5902965068817139
Validation Loss Energy: 1.4613837281255846, Validation Loss Force: 2.4224621723775894, time: 0.04994797706604004
Test Loss Energy: 13.616607023502036, Test Loss Force: 10.728857236442416, time: 9.365355014801025


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8373933336317556, Training Loss Force: 2.2663510743541764, time: 0.6098830699920654
Validation Loss Energy: 3.719798749289222, Validation Loss Force: 2.3759474784698584, time: 0.048825979232788086
Test Loss Energy: 16.965442665454862, Test Loss Force: 10.698461167965617, time: 9.558671236038208


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.4165168353320436, Training Loss Force: 2.233780387945385, time: 0.4977889060974121
Validation Loss Energy: 1.825218766500931, Validation Loss Force: 2.422790609367833, time: 0.04890894889831543
Test Loss Energy: 13.107148341481569, Test Loss Force: 10.896104745422688, time: 9.389688730239868


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2100147244428907, Training Loss Force: 2.2453388700347263, time: 0.5250442028045654
Validation Loss Energy: 1.097074738473131, Validation Loss Force: 2.371024263653395, time: 0.04999947547912598
Test Loss Energy: 14.179897755235322, Test Loss Force: 10.759276714324717, time: 9.425990581512451

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–ƒâ–ƒâ–â–†â–†â–ƒâ–ƒâ–‚â–‚â–ƒâ–‡â–†â–ƒâ–„â–ƒâ–ˆâ–‚â–„
wandb:   test_error_force â–‡â–ˆâ–‚â–†â–â–…â–‚â–â–‚â–†â–‚â–‚â–…â–ˆâ–…â–„â–…â–„â–†â–…
wandb:          test_loss â–‡â–ˆâ–ƒâ–…â–â–†â–ƒâ–‚â–ƒâ–†â–ƒâ–„â–…â–ˆâ–†â–…â–†â–…â–ˆâ–‡
wandb: train_error_energy â–ˆâ–â–ƒâ–‚â–‚â–‚â–‚â–„â–‚â–‚â–â–ƒâ–ƒâ–â–â–‚â–â–â–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–ƒâ–â–â–ƒâ–ƒâ–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–…â–‚â–‚â–â–†â–„â–„â–â–‚â–â–ƒâ–â–‡â–ƒâ–ƒâ–‚â–‚â–ˆâ–ƒâ–
wandb:  valid_error_force â–†â–‡â–ˆâ–…â–†â–‚â–ƒâ–ƒâ–‡â–…â–‚â–â–‚â–†â–…â–ƒâ–ƒâ–â–„â–
wandb:         valid_loss â–†â–†â–†â–…â–ˆâ–„â–„â–ƒâ–‡â–…â–ƒâ–‚â–…â–…â–†â–ƒâ–ƒâ–„â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1033
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.1799
wandb:   test_error_force 10.75928
wandb:          test_loss 83.9503
wandb: train_error_energy 2.21001
wandb:  train_error_force 2.24534
wandb:         train_loss -4.7077
wandb: valid_error_energy 1.09707
wandb:  valid_error_force 2.37102
wandb:         valid_loss -4.3841
wandb: 
wandb: ğŸš€ View run al_82_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/usqfauwk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_031133-usqfauwk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 8.022601127624512, Uncertainty Bias: -1.6773453950881958
0.0002593994 0.0054569244
1.2472535 4.614768
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1085 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1588 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 992 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1948 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1549 steps.
Found uncertainty sample 15 after 2823 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1254 steps.
Found uncertainty sample 28 after 2971 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 246 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2810 steps.
Found uncertainty sample 34 after 2265 steps.
Found uncertainty sample 35 after 319 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 985 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3939 steps.
Found uncertainty sample 42 after 3377 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 411 steps.
Found uncertainty sample 45 after 2731 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1731 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1038 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1082 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3001 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2654 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1945 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3680 steps.
Found uncertainty sample 71 after 3062 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 459 steps.
Found uncertainty sample 74 after 1080 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 99 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1826 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 453 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 328 steps.
Found uncertainty sample 92 after 2562 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 320 steps.
Found uncertainty sample 96 after 2895 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 311 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_034748-3k50cdqo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3k50cdqo
Training model 8. Added 35 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.1894651009851764, Training Loss Force: 2.5488534365163447, time: 0.5567138195037842
Validation Loss Energy: 1.0951143593123827, Validation Loss Force: 2.4765235689791054, time: 0.05520343780517578
Test Loss Energy: 13.711241447827167, Test Loss Force: 10.684653974176577, time: 9.517895460128784


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6443429394215558, Training Loss Force: 2.317169333742894, time: 0.5885868072509766
Validation Loss Energy: 2.2695786501293, Validation Loss Force: 2.429068097929829, time: 0.050607919692993164
Test Loss Energy: 15.412376467599788, Test Loss Force: 10.444351553660132, time: 9.502639532089233


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.86651264500412, Training Loss Force: 2.2963042524055814, time: 0.5638885498046875
Validation Loss Energy: 4.056209744317529, Validation Loss Force: 2.4255454720412515, time: 0.060503482818603516
Test Loss Energy: 12.099242412045058, Test Loss Force: 10.490421935186209, time: 9.62604022026062


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.812303042438712, Training Loss Force: 2.339444270974019, time: 0.5116431713104248
Validation Loss Energy: 2.3995272503470275, Validation Loss Force: 2.4635909449836193, time: 0.05411028861999512
Test Loss Energy: 15.74849848121154, Test Loss Force: 10.667922726469039, time: 9.56277871131897


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.3528443102522703, Training Loss Force: 2.3472408411949974, time: 0.5387709140777588
Validation Loss Energy: 1.7903383127987809, Validation Loss Force: 2.494578251338368, time: 0.05275583267211914
Test Loss Energy: 13.045811786626825, Test Loss Force: 10.493843732754929, time: 9.469547986984253


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.283257461354614, Training Loss Force: 2.2971288453711463, time: 0.5540692806243896
Validation Loss Energy: 4.229923742498217, Validation Loss Force: 2.4595791149814383, time: 0.04912734031677246
Test Loss Energy: 17.438743520157868, Test Loss Force: 10.52694504249401, time: 9.670014381408691


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.344443974279382, Training Loss Force: 2.337719508515125, time: 0.5638158321380615
Validation Loss Energy: 2.4789675855248086, Validation Loss Force: 2.447464800097237, time: 0.05162310600280762
Test Loss Energy: 12.55975401370319, Test Loss Force: 10.405879366193481, time: 9.4702787399292


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6488014666522919, Training Loss Force: 2.2794375918035, time: 0.5450057983398438
Validation Loss Energy: 1.4205456500895635, Validation Loss Force: 2.566973780077286, time: 0.052521705627441406
Test Loss Energy: 14.97617800506288, Test Loss Force: 10.67247764651814, time: 9.44584345817566


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.933645715059048, Training Loss Force: 2.3223450226253775, time: 0.5864386558532715
Validation Loss Energy: 1.8248665039120733, Validation Loss Force: 2.486271356180386, time: 0.049565792083740234
Test Loss Energy: 13.37251340779604, Test Loss Force: 10.327291133375848, time: 9.69655990600586


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.436369789248529, Training Loss Force: 2.298403884920737, time: 0.5604257583618164
Validation Loss Energy: 1.2084568512996805, Validation Loss Force: 2.486252651972128, time: 0.05012869834899902
Test Loss Energy: 14.705194126504592, Test Loss Force: 10.47187159480553, time: 9.897644758224487


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4706110916891846, Training Loss Force: 2.3205716528017457, time: 0.5848569869995117
Validation Loss Energy: 1.1872417144176917, Validation Loss Force: 2.452198968808808, time: 0.05080842971801758
Test Loss Energy: 14.33365732901792, Test Loss Force: 10.38771176492948, time: 9.522226095199585


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5916166048026439, Training Loss Force: 2.3346725825113595, time: 0.59255051612854
Validation Loss Energy: 2.0907782206481835, Validation Loss Force: 2.4768678154787094, time: 0.049189090728759766
Test Loss Energy: 15.828578429430674, Test Loss Force: 10.538416299377033, time: 9.701277732849121


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1903708273835147, Training Loss Force: 2.3121810798885427, time: 0.5378150939941406
Validation Loss Energy: 1.0931725730253194, Validation Loss Force: 2.499885570431557, time: 0.04845714569091797
Test Loss Energy: 13.780294031854396, Test Loss Force: 10.501796770500013, time: 9.499626159667969


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8191898389221692, Training Loss Force: 2.3390524387681113, time: 0.5812914371490479
Validation Loss Energy: 3.135824865825838, Validation Loss Force: 2.439990019537587, time: 0.05439400672912598
Test Loss Energy: 16.79875210446987, Test Loss Force: 10.595485767279294, time: 9.544642686843872


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8421191844004443, Training Loss Force: 2.299910136907459, time: 0.5621533393859863
Validation Loss Energy: 3.158156354470936, Validation Loss Force: 2.4434576461471207, time: 0.050675153732299805
Test Loss Energy: 12.653355048009177, Test Loss Force: 10.654287069528856, time: 9.675209999084473


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.263432095936929, Training Loss Force: 2.29427757678118, time: 0.5475223064422607
Validation Loss Energy: 1.8797252787251564, Validation Loss Force: 2.433817630812469, time: 0.05366015434265137
Test Loss Energy: 14.900432420189286, Test Loss Force: 10.684423237645886, time: 9.561033010482788


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9653010460989246, Training Loss Force: 2.2807582228607206, time: 0.5696640014648438
Validation Loss Energy: 1.7661125777292752, Validation Loss Force: 2.4191853732261164, time: 0.049865007400512695
Test Loss Energy: 15.372572350245461, Test Loss Force: 10.463393435597542, time: 9.562443733215332


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4503312208873789, Training Loss Force: 2.312340550291582, time: 0.5469532012939453
Validation Loss Energy: 1.093260081999669, Validation Loss Force: 2.4174394244528963, time: 0.052207231521606445
Test Loss Energy: 13.632382328084155, Test Loss Force: 10.464754664547916, time: 9.779876708984375


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5981168951296918, Training Loss Force: 2.308887829416641, time: 0.5528249740600586
Validation Loss Energy: 2.6926999052807847, Validation Loss Force: 2.452618477479736, time: 0.04906964302062988
Test Loss Energy: 15.96905361792596, Test Loss Force: 10.581703717616639, time: 9.446465969085693


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9041598447080796, Training Loss Force: 2.2788320397866033, time: 0.5370676517486572
Validation Loss Energy: 1.6094488013905697, Validation Loss Force: 2.5062942111205047, time: 0.049602508544921875
Test Loss Energy: 13.479539932011054, Test Loss Force: 10.563735343450466, time: 9.54478907585144

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–…â–â–†â–‚â–ˆâ–‚â–…â–ƒâ–„â–„â–†â–ƒâ–‡â–‚â–…â–…â–ƒâ–†â–ƒ
wandb:   test_error_force â–ˆâ–ƒâ–„â–ˆâ–„â–…â–ƒâ–ˆâ–â–„â–‚â–…â–„â–†â–‡â–ˆâ–„â–„â–†â–†
wandb:          test_loss â–„â–â–„â–†â–„â–„â–‚â–‡â–ƒâ–…â–„â–„â–„â–†â–ˆâ–ˆâ–†â–…â–†â–‡
wandb: train_error_energy â–„â–‚â–ƒâ–ƒâ–…â–…â–…â–‚â–ˆâ–†â–â–‚â–„â–ƒâ–ƒâ–…â–ƒâ–â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–â–ƒâ–ƒâ–â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–ƒâ–„â–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–
wandb: valid_error_energy â–â–„â–ˆâ–„â–ƒâ–ˆâ–„â–‚â–ƒâ–â–â–ƒâ–â–†â–†â–ƒâ–ƒâ–â–…â–‚
wandb:  valid_error_force â–„â–‚â–â–ƒâ–…â–ƒâ–‚â–ˆâ–„â–„â–ƒâ–„â–…â–‚â–‚â–‚â–â–â–ƒâ–…
wandb:         valid_loss â–ƒâ–„â–†â–…â–…â–ˆâ–„â–‡â–„â–ƒâ–‚â–…â–…â–†â–…â–‚â–‚â–â–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1064
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.47954
wandb:   test_error_force 10.56374
wandb:          test_loss 77.4097
wandb: train_error_energy 1.90416
wandb:  train_error_force 2.27883
wandb:         train_loss -4.66306
wandb: valid_error_energy 1.60945
wandb:  valid_error_force 2.50629
wandb:         valid_loss -4.04262
wandb: 
wandb: ğŸš€ View run al_82_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3k50cdqo
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_034748-3k50cdqo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 8.357911109924316, Uncertainty Bias: -1.7772870063781738
2.2888184e-05 0.01047492
1.3277725 4.6855073
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1111 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2513 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 637 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1205 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 969 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2730 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2634 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1534 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1935 steps.
Found uncertainty sample 29 after 874 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2093 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 857 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2836 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2179 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1783 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3146 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3103 steps.
Found uncertainty sample 67 after 2990 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2955 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3788 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2227 steps.
Found uncertainty sample 77 after 3030 steps.
Found uncertainty sample 78 after 857 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2196 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3971 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3137 steps.
Found uncertainty sample 90 after 1215 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1136 steps.
Found uncertainty sample 94 after 2988 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2651 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_042612-kirn30k1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kirn30k1
Training model 9. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.100248184955262, Training Loss Force: 2.631291317540236, time: 0.6501014232635498
Validation Loss Energy: 1.182208278373994, Validation Loss Force: 2.5856123009371714, time: 0.05130767822265625
Test Loss Energy: 13.615644696417231, Test Loss Force: 11.072897252965882, time: 9.496318817138672


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2568149175000127, Training Loss Force: 2.399968058912257, time: 0.5502331256866455
Validation Loss Energy: 2.5668608868203004, Validation Loss Force: 2.5276846999549116, time: 0.049345970153808594
Test Loss Energy: 16.221532132939434, Test Loss Force: 10.571967051048777, time: 9.515840768814087


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.849523562837748, Training Loss Force: 2.3341757391619993, time: 0.5713574886322021
Validation Loss Energy: 7.903757122662712, Validation Loss Force: 2.5456623387896835, time: 0.050537824630737305
Test Loss Energy: 11.837430968096927, Test Loss Force: 10.21782900507878, time: 9.587042570114136


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.8160163590638456, Training Loss Force: 2.3815881078265986, time: 0.5111403465270996
Validation Loss Energy: 1.3324549525962066, Validation Loss Force: 2.467317090471575, time: 0.04831886291503906
Test Loss Energy: 13.59124664457395, Test Loss Force: 10.554513417999567, time: 9.091309547424316


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6869272718863004, Training Loss Force: 2.3613727522288377, time: 0.605515718460083
Validation Loss Energy: 1.43947419751202, Validation Loss Force: 2.481757184584992, time: 0.05022239685058594
Test Loss Energy: 13.751189239241935, Test Loss Force: 10.276844839141084, time: 10.141886472702026


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5105929795400415, Training Loss Force: 2.3455933286505677, time: 0.5842111110687256
Validation Loss Energy: 2.269861217275482, Validation Loss Force: 2.560627709418344, time: 0.05718183517456055
Test Loss Energy: 12.831796780812343, Test Loss Force: 10.269949598751476, time: 9.462148904800415


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.843985382558493, Training Loss Force: 2.3973821830346713, time: 0.5438826084136963
Validation Loss Energy: 2.674922446008202, Validation Loss Force: 2.523325951423375, time: 0.04846024513244629
Test Loss Energy: 15.894265561675367, Test Loss Force: 10.401467761136251, time: 8.45871114730835


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.39025654133386, Training Loss Force: 2.3553685614145774, time: 0.5695409774780273
Validation Loss Energy: 1.8615170659897764, Validation Loss Force: 2.5885666751653416, time: 0.05196976661682129
Test Loss Energy: 15.612995329200222, Test Loss Force: 10.459861525221644, time: 8.557978630065918


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6182034555721223, Training Loss Force: 2.366626942463808, time: 0.5605568885803223
Validation Loss Energy: 1.9527204554740578, Validation Loss Force: 2.5075064219509353, time: 0.0466463565826416
Test Loss Energy: 13.308708960667271, Test Loss Force: 10.189323553869052, time: 8.995954036712646


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9940466783547457, Training Loss Force: 2.3389306574569817, time: 0.5482516288757324
Validation Loss Energy: 2.6443383934767284, Validation Loss Force: 2.5269728266953804, time: 0.04882025718688965
Test Loss Energy: 16.479852945407583, Test Loss Force: 10.340849455339777, time: 8.495985984802246


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.541587811517985, Training Loss Force: 2.3442025626130043, time: 0.5469057559967041
Validation Loss Energy: 2.367890863431899, Validation Loss Force: 2.4871989958423213, time: 0.046662092208862305
Test Loss Energy: 15.89567349751926, Test Loss Force: 10.491113132857766, time: 8.524164199829102


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9236852823644353, Training Loss Force: 2.3245918205471816, time: 0.5429868698120117
Validation Loss Energy: 1.423917640300921, Validation Loss Force: 2.551895070853348, time: 0.04750323295593262
Test Loss Energy: 15.655431596378227, Test Loss Force: 10.268803447211543, time: 8.545481204986572


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.124167894875384, Training Loss Force: 2.368257198710779, time: 0.5542013645172119
Validation Loss Energy: 1.7503030683684024, Validation Loss Force: 2.448877858497295, time: 0.051132917404174805
Test Loss Energy: 13.439440678944772, Test Loss Force: 10.325066181300684, time: 8.683401346206665


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3123455678320424, Training Loss Force: 2.26658841980666, time: 0.5290532112121582
Validation Loss Energy: 1.1940990334356838, Validation Loss Force: 2.4445351421442654, time: 0.049063682556152344
Test Loss Energy: 14.217494817984269, Test Loss Force: 10.291799121778924, time: 8.521827697753906


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.563148159332819, Training Loss Force: 2.307321827439156, time: 0.583667516708374
Validation Loss Energy: 1.1433017438443234, Validation Loss Force: 2.544143289876164, time: 0.05267930030822754
Test Loss Energy: 14.706978678646554, Test Loss Force: 10.050084736389435, time: 8.552102327346802


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7572276223350074, Training Loss Force: 2.380166301710094, time: 0.5922017097473145
Validation Loss Energy: 1.7000631196492992, Validation Loss Force: 2.4805307229292217, time: 0.0458369255065918
Test Loss Energy: 13.583841676037679, Test Loss Force: 10.109819775471786, time: 8.705324172973633


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6856764247780636, Training Loss Force: 2.2851269176861955, time: 0.5965795516967773
Validation Loss Energy: 1.26341616123215, Validation Loss Force: 2.4666043265354602, time: 0.0463714599609375
Test Loss Energy: 14.457777242578246, Test Loss Force: 10.24577441657294, time: 8.550828456878662


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.304141431303919, Training Loss Force: 2.3074409172603736, time: 0.5560224056243896
Validation Loss Energy: 1.1534585742666734, Validation Loss Force: 2.525400559855984, time: 0.047586917877197266
Test Loss Energy: 14.016302626467928, Test Loss Force: 10.525048241786363, time: 8.54794716835022


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.695356921363445, Training Loss Force: 2.2914078894298315, time: 0.5519676208496094
Validation Loss Energy: 3.7638184354168325, Validation Loss Force: 2.4763654738854965, time: 0.050731658935546875
Test Loss Energy: 17.532979350390494, Test Loss Force: 10.22786684157587, time: 9.740070343017578


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.41755807211681, Training Loss Force: 2.2962196074429526, time: 0.6333341598510742
Validation Loss Energy: 1.7822791370656434, Validation Loss Force: 2.4405533724767845, time: 0.056191205978393555
Test Loss Energy: 13.72445938211282, Test Loss Force: 10.1177852920155, time: 10.107832193374634

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–â–ƒâ–ƒâ–‚â–†â–†â–ƒâ–‡â–†â–†â–ƒâ–„â–…â–ƒâ–„â–„â–ˆâ–ƒ
wandb:   test_error_force â–ˆâ–…â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–â–â–‚â–„â–‚â–
wandb:          test_loss â–ˆâ–ƒâ–‚â–„â–‚â–‚â–ƒâ–ƒâ–â–‚â–„â–‚â–ƒâ–„â–â–‚â–ƒâ–†â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–‚â–„â–„â–â–â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–â–â–â–ƒâ–â–ƒ
wandb:  train_error_force â–ˆâ–„â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–â–‚
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–â–ƒâ–â–‚â–â–‚
wandb: valid_error_energy â–â–‚â–ˆâ–â–â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–â–â–‚â–â–â–„â–‚
wandb:  valid_error_force â–ˆâ–…â–†â–‚â–ƒâ–‡â–…â–ˆâ–„â–…â–ƒâ–†â–â–â–†â–ƒâ–‚â–…â–ƒâ–
wandb:         valid_loss â–„â–„â–ˆâ–‚â–‚â–…â–„â–…â–„â–„â–ƒâ–„â–‚â–â–„â–ƒâ–â–‚â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1091
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.72446
wandb:   test_error_force 10.11779
wandb:          test_loss 70.30148
wandb: train_error_energy 2.41756
wandb:  train_error_force 2.29622
wandb:         train_loss -4.61153
wandb: valid_error_energy 1.78228
wandb:  valid_error_force 2.44055
wandb:         valid_loss -4.1104
wandb: 
wandb: ğŸš€ View run al_82_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kirn30k1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_042612-kirn30k1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 9.219253540039062, Uncertainty Bias: -1.9519388675689697
3.0517578e-05 0.03184843
1.1439921 4.760912
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1481 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1110 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1409 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1745 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3638 steps.
Found uncertainty sample 27 after 1325 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3874 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3095 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1763 steps.
Found uncertainty sample 39 after 2724 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1390 steps.
Found uncertainty sample 45 after 3729 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 421 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3572 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2888 steps.
Found uncertainty sample 69 after 2319 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1871 steps.
Found uncertainty sample 76 after 2164 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1519 steps.
Found uncertainty sample 82 after 3036 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 609 steps.
Found uncertainty sample 87 after 2091 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2735 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1678 steps.
Found uncertainty sample 98 after 3927 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_050523-knlymukh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/knlymukh
Training model 10. Added 25 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.990939145734711, Training Loss Force: 2.5302585135267637, time: 0.5780158042907715
Validation Loss Energy: 1.230372839318477, Validation Loss Force: 2.4806418348330395, time: 0.05138421058654785
Test Loss Energy: 14.103049200314805, Test Loss Force: 9.977938165745348, time: 9.502408266067505


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.4156353399466632, Training Loss Force: 2.3767449457490835, time: 0.531580924987793
Validation Loss Energy: 5.606410071352196, Validation Loss Force: 2.5906911614866384, time: 0.049805402755737305
Test Loss Energy: 12.344666530690903, Test Loss Force: 10.318995590846889, time: 9.50340223312378


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.378783621743516, Training Loss Force: 2.398803333867689, time: 0.5772988796234131
Validation Loss Energy: 1.989139552974569, Validation Loss Force: 2.5323649827331676, time: 0.05184531211853027
Test Loss Energy: 13.51132752643176, Test Loss Force: 10.131797984944281, time: 9.682766199111938


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6831944017901381, Training Loss Force: 2.367630792231431, time: 0.5826663970947266
Validation Loss Energy: 1.223749322903709, Validation Loss Force: 2.4547863842844886, time: 0.049833059310913086
Test Loss Energy: 14.54883707866311, Test Loss Force: 10.202251076292901, time: 9.4852876663208


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7463737913615802, Training Loss Force: 2.349124899476836, time: 0.551288366317749
Validation Loss Energy: 3.2425486287850056, Validation Loss Force: 2.5101915891816784, time: 0.05091094970703125
Test Loss Energy: 17.365472192864768, Test Loss Force: 10.143816951967551, time: 9.51237678527832


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.4158774990048344, Training Loss Force: 2.3558575301350837, time: 0.5592164993286133
Validation Loss Energy: 1.6680553205987636, Validation Loss Force: 2.4832535212456266, time: 0.05063676834106445
Test Loss Energy: 15.489294430008643, Test Loss Force: 10.109353667161587, time: 9.652258396148682


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.530529025323126, Training Loss Force: 2.383447560606461, time: 0.5497338771820068
Validation Loss Energy: 2.0920730417317537, Validation Loss Force: 2.4956294723762933, time: 0.05264997482299805
Test Loss Energy: 13.295735402854763, Test Loss Force: 10.133290642317878, time: 9.530019760131836


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7557305651806363, Training Loss Force: 2.347493447178452, time: 0.5303506851196289
Validation Loss Energy: 1.163034238218152, Validation Loss Force: 2.4985586849909733, time: 0.05504965782165527
Test Loss Energy: 14.993388017081916, Test Loss Force: 10.166874894620914, time: 9.544544458389282


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6944505831863053, Training Loss Force: 2.327022900015507, time: 0.6036701202392578
Validation Loss Energy: 1.795946569242691, Validation Loss Force: 2.4600318013551097, time: 0.05010795593261719
Test Loss Energy: 15.493901913965862, Test Loss Force: 10.170830128188395, time: 9.678994178771973


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.887718852946916, Training Loss Force: 2.3224985874310096, time: 0.5611774921417236
Validation Loss Energy: 1.1037769684309844, Validation Loss Force: 2.449522485674756, time: 0.05354666709899902
Test Loss Energy: 14.843717464883486, Test Loss Force: 10.160493234204448, time: 9.924104452133179


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0653701728525693, Training Loss Force: 2.342458452450733, time: 0.6078536510467529
Validation Loss Energy: 1.255250883650978, Validation Loss Force: 2.4580182042684844, time: 0.0493321418762207
Test Loss Energy: 14.418659864849326, Test Loss Force: 10.081599928335596, time: 9.582298994064331


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6135707555998573, Training Loss Force: 2.341788097443954, time: 0.5698933601379395
Validation Loss Energy: 1.6047154120210099, Validation Loss Force: 2.4789987592052385, time: 0.051232099533081055
Test Loss Energy: 15.4710995255436, Test Loss Force: 10.015891126069521, time: 9.653591871261597


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.232868619484695, Training Loss Force: 2.336891170310661, time: 0.5574314594268799
Validation Loss Energy: 1.0579945220096367, Validation Loss Force: 2.4489366431518196, time: 0.05034613609313965
Test Loss Energy: 14.330893844035584, Test Loss Force: 10.009123812018764, time: 9.446492433547974


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1669826291867205, Training Loss Force: 2.326654191719728, time: 0.5772855281829834
Validation Loss Energy: 2.9105342360430426, Validation Loss Force: 2.450272212689095, time: 0.051279544830322266
Test Loss Energy: 16.90709025487703, Test Loss Force: 10.129967392750434, time: 9.510670185089111


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8015724531304893, Training Loss Force: 2.34567591981778, time: 0.5624468326568604
Validation Loss Energy: 1.2062151296730523, Validation Loss Force: 2.4694369007408072, time: 0.055603742599487305
Test Loss Energy: 15.147732229108776, Test Loss Force: 10.12495123746459, time: 9.733256816864014


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.262419328129674, Training Loss Force: 2.3183798571528564, time: 0.5390658378601074
Validation Loss Energy: 1.302447613152686, Validation Loss Force: 2.5002311529460366, time: 0.050185441970825195
Test Loss Energy: 13.822765860810556, Test Loss Force: 10.1848645797399, time: 9.501682043075562


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7929218458788532, Training Loss Force: 2.3136697685189236, time: 0.5608720779418945
Validation Loss Energy: 1.059023253463823, Validation Loss Force: 2.4748027818193754, time: 0.05167794227600098
Test Loss Energy: 14.239238201274953, Test Loss Force: 10.230145695905648, time: 9.572584867477417


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7677278562951948, Training Loss Force: 2.314367308247433, time: 0.623079776763916
Validation Loss Energy: 2.4208642985864115, Validation Loss Force: 2.4754618824913215, time: 0.054050445556640625
Test Loss Energy: 13.359539108530248, Test Loss Force: 9.898843646243455, time: 9.713783502578735


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9221437462529183, Training Loss Force: 2.3244531835559386, time: 0.5382919311523438
Validation Loss Energy: 2.8600985611446688, Validation Loss Force: 2.415081803535813, time: 0.051131248474121094
Test Loss Energy: 16.695381234053926, Test Loss Force: 10.032293583547277, time: 9.472229719161987


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.179266532073448, Training Loss Force: 2.320650096335102, time: 0.5849266052246094
Validation Loss Energy: 1.125551116203825, Validation Loss Force: 2.5194339174217033, time: 0.05012917518615723
Test Loss Energy: 14.714630369259739, Test Loss Force: 10.000258642177082, time: 9.510955572128296

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–ƒâ–„â–ˆâ–…â–‚â–…â–…â–„â–„â–…â–„â–‡â–…â–ƒâ–„â–‚â–‡â–„
wandb:   test_error_force â–‚â–ˆâ–…â–†â–…â–…â–…â–…â–†â–…â–„â–ƒâ–ƒâ–…â–…â–†â–‡â–â–ƒâ–ƒ
wandb:          test_loss â–â–†â–ƒâ–…â–„â–„â–„â–…â–…â–†â–„â–„â–ƒâ–…â–…â–‡â–ˆâ–„â–†â–…
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–â–â–ƒâ–â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–‚â–â–„â–‚â–ƒâ–â–‚â–â–â–‚â–â–„â–â–â–â–ƒâ–„â–
wandb:  valid_error_force â–„â–ˆâ–†â–ƒâ–…â–„â–„â–„â–ƒâ–‚â–ƒâ–„â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–â–…
wandb:         valid_loss â–‚â–ˆâ–„â–â–„â–‚â–ƒâ–ƒâ–‚â–â–â–‚â–â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1113
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.71463
wandb:   test_error_force 10.00026
wandb:          test_loss 66.46753
wandb: train_error_energy 2.17927
wandb:  train_error_force 2.32065
wandb:         train_loss -4.62198
wandb: valid_error_energy 1.12555
wandb:  valid_error_force 2.51943
wandb:         valid_loss -4.02618
wandb: 
wandb: ğŸš€ View run al_82_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/knlymukh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_050523-knlymukh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 8.891397476196289, Uncertainty Bias: -1.8940259218215942
4.196167e-05 0.0032954216
1.2264973 4.523018
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 559 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1073 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 315 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2803 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3903 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1095 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1963 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1046 steps.
Found uncertainty sample 45 after 1092 steps.
Found uncertainty sample 46 after 3431 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1893 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2969 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2945 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3344 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1348 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1696 steps.
Found uncertainty sample 86 after 1233 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1339 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2389 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_054531-s6fkpffg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/s6fkpffg
Training model 11. Added 19 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4740781604223843, Training Loss Force: 2.5769227055551345, time: 0.6035671234130859
Validation Loss Energy: 4.906970211591373, Validation Loss Force: 2.6058560436700504, time: 0.051957130432128906
Test Loss Energy: 12.513124352567734, Test Loss Force: 9.87611030624096, time: 9.281500339508057


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0294523483100924, Training Loss Force: 2.3569068295029347, time: 0.5942564010620117
Validation Loss Energy: 3.044542540129325, Validation Loss Force: 2.51885230561254, time: 0.05414438247680664
Test Loss Energy: 12.791334280923216, Test Loss Force: 9.826413406765528, time: 9.263973951339722


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9628034695282193, Training Loss Force: 2.3643987184752975, time: 0.5627346038818359
Validation Loss Energy: 1.2046060110900052, Validation Loss Force: 2.5776694698327813, time: 0.05022144317626953
Test Loss Energy: 13.819934707723995, Test Loss Force: 10.181606358889525, time: 9.507222890853882


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5738982681905282, Training Loss Force: 2.374103654236495, time: 0.5495288372039795
Validation Loss Energy: 1.0327343774227236, Validation Loss Force: 2.4558331519394954, time: 0.04997539520263672
Test Loss Energy: 14.494516397247947, Test Loss Force: 9.987993652561125, time: 9.273617029190063


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.318747584997507, Training Loss Force: 2.330433255590543, time: 0.5502040386199951
Validation Loss Energy: 1.5950431096601985, Validation Loss Force: 2.4708174494455597, time: 0.050719499588012695
Test Loss Energy: 15.151036839753157, Test Loss Force: 10.012242905456183, time: 9.275663375854492


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0136949976503393, Training Loss Force: 2.335240595857567, time: 0.5914766788482666
Validation Loss Energy: 2.24450343226808, Validation Loss Force: 2.489552386045632, time: 0.05006885528564453
Test Loss Energy: 16.768509861901276, Test Loss Force: 9.990253480919897, time: 9.37955904006958


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6501432825684839, Training Loss Force: 2.348576108746339, time: 0.5486433506011963
Validation Loss Energy: 1.1725776151434713, Validation Loss Force: 2.4426041553107796, time: 0.051479339599609375
Test Loss Energy: 15.121742165152149, Test Loss Force: 10.137663463306275, time: 9.25997018814087


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1857369407416725, Training Loss Force: 2.35460535832215, time: 0.6130492687225342
Validation Loss Energy: 2.7238971886401435, Validation Loss Force: 2.4880674055114396, time: 0.05463218688964844
Test Loss Energy: 12.737346698560673, Test Loss Force: 10.089659502191841, time: 9.22618293762207


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8734755526759794, Training Loss Force: 2.3388833764913888, time: 0.5985579490661621
Validation Loss Energy: 3.7023047478394053, Validation Loss Force: 2.4488019283185336, time: 0.0537409782409668
Test Loss Energy: 12.589074555230948, Test Loss Force: 10.028829154746477, time: 9.436410427093506


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.951594705217415, Training Loss Force: 2.3437212286166593, time: 0.5797238349914551
Validation Loss Energy: 1.5031199421617054, Validation Loss Force: 2.4940282585479263, time: 0.049915313720703125
Test Loss Energy: 14.845089587134904, Test Loss Force: 10.054242344733776, time: 9.66762375831604


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8369675143148052, Training Loss Force: 2.334451821334388, time: 0.5798954963684082
Validation Loss Energy: 2.247331107752217, Validation Loss Force: 2.4471884676871407, time: 0.05020642280578613
Test Loss Energy: 15.572318787137311, Test Loss Force: 10.094039789008564, time: 9.266084909439087


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.244833814520723, Training Loss Force: 2.3356401168800205, time: 0.6600968837738037
Validation Loss Energy: 1.7623783048174932, Validation Loss Force: 2.4517868082196954, time: 0.05054354667663574
Test Loss Energy: 13.30154654994515, Test Loss Force: 9.9529757233946, time: 9.467382907867432


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5756117428336534, Training Loss Force: 2.3366264267692807, time: 0.549933671951294
Validation Loss Energy: 1.1334536441928023, Validation Loss Force: 2.545820879221584, time: 0.05082345008850098
Test Loss Energy: 14.2160938350136, Test Loss Force: 10.01946688478006, time: 9.267524719238281


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.813486508245508, Training Loss Force: 2.3632524610088392, time: 0.5697751045227051
Validation Loss Energy: 4.1046478543077844, Validation Loss Force: 2.5628299072715697, time: 0.05149698257446289
Test Loss Energy: 17.7547392787393, Test Loss Force: 10.272040786126098, time: 9.30055856704712


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.683499554813708, Training Loss Force: 2.375498404284554, time: 0.5457839965820312
Validation Loss Energy: 1.9268627782340475, Validation Loss Force: 2.5101076429136637, time: 0.05346107482910156
Test Loss Energy: 15.374290973667312, Test Loss Force: 10.129549133824659, time: 9.460938930511475


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5919480425506993, Training Loss Force: 2.325267603556197, time: 0.6190800666809082
Validation Loss Energy: 1.20165030084696, Validation Loss Force: 2.566961978612552, time: 0.050551652908325195
Test Loss Energy: 14.272181534832741, Test Loss Force: 10.44604683296168, time: 9.303163528442383


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1684546605381083, Training Loss Force: 2.3458269674329197, time: 0.6486444473266602
Validation Loss Energy: 1.0679909193123458, Validation Loss Force: 2.461643480633335, time: 0.05001473426818848
Test Loss Energy: 14.13102871865992, Test Loss Force: 10.202924031415792, time: 9.296340703964233


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9446374448644252, Training Loss Force: 2.323293548798736, time: 0.5728468894958496
Validation Loss Energy: 3.2405314689920455, Validation Loss Force: 2.601894759563995, time: 0.05006718635559082
Test Loss Energy: 12.972466593799245, Test Loss Force: 9.854617352293602, time: 9.390426635742188


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9514875982655961, Training Loss Force: 2.326613743692649, time: 0.6664333343505859
Validation Loss Energy: 1.4578511934600131, Validation Loss Force: 2.527106205513791, time: 0.05173444747924805
Test Loss Energy: 14.853620133048349, Test Loss Force: 10.110843974268175, time: 9.29595398902893


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8574882141684401, Training Loss Force: 2.32280592811017, time: 0.5806808471679688
Validation Loss Energy: 1.2214265497079633, Validation Loss Force: 2.4715460228910353, time: 0.057062387466430664
Test Loss Energy: 13.677262924244154, Test Loss Force: 10.145309903124522, time: 9.322444200515747

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–ƒâ–„â–…â–‡â–„â–â–â–„â–…â–‚â–ƒâ–ˆâ–…â–ƒâ–ƒâ–‚â–„â–ƒ
wandb:   test_error_force â–‚â–â–…â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–„â–‚â–ƒâ–†â–„â–ˆâ–…â–â–„â–…
wandb:          test_loss â–‚â–â–„â–‚â–ƒâ–ƒâ–…â–…â–„â–„â–…â–ƒâ–„â–…â–…â–ˆâ–†â–ƒâ–…â–†
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–„â–ƒâ–â–ƒâ–‚â–‚â–‚â–ƒâ–â–†â–…â–â–ƒâ–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–â–â–‚â–‚â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–ƒâ–â–‚â–â–â–
wandb: valid_error_energy â–ˆâ–…â–â–â–‚â–ƒâ–â–„â–†â–‚â–ƒâ–‚â–â–‡â–ƒâ–â–â–…â–‚â–
wandb:  valid_error_force â–ˆâ–„â–‡â–‚â–‚â–ƒâ–â–ƒâ–â–ƒâ–â–â–…â–†â–„â–†â–‚â–ˆâ–…â–‚
wandb:         valid_loss â–‡â–„â–…â–â–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–†â–ƒâ–„â–‚â–ˆâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1130
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.67726
wandb:   test_error_force 10.14531
wandb:          test_loss 71.43934
wandb: train_error_energy 1.85749
wandb:  train_error_force 2.32281
wandb:         train_loss -4.66316
wandb: valid_error_energy 1.22143
wandb:  valid_error_force 2.47155
wandb:         valid_loss -4.15092
wandb: 
wandb: ğŸš€ View run al_82_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/s6fkpffg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_054531-s6fkpffg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 9.352180480957031, Uncertainty Bias: -2.012805461883545
0.00011253357 0.0023827553
1.1768403 4.4530764
(48745, 22, 3)
Found uncertainty sample 0 after 3484 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3678 steps.
Found uncertainty sample 4 after 1356 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3287 steps.
Found uncertainty sample 21 after 1954 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 970 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3751 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1676 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3907 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3026 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1244 steps.
Found uncertainty sample 50 after 2678 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 537 steps.
Found uncertainty sample 53 after 2777 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1907 steps.
Found uncertainty sample 58 after 2195 steps.
Found uncertainty sample 59 after 3994 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1054 steps.
Found uncertainty sample 62 after 2845 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1496 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1897 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2779 steps.
Found uncertainty sample 87 after 2596 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1705 steps.
Found uncertainty sample 97 after 3357 steps.
Found uncertainty sample 98 after 1210 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_062455-rrx74hpa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rrx74hpa
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)
Training model 12. Added 26 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.89574351317275, Training Loss Force: 2.5858424445447, time: 0.5940296649932861
Validation Loss Energy: 1.5598346643060967, Validation Loss Force: 2.5855285773383025, time: 0.05400824546813965
Test Loss Energy: 15.056703552714646, Test Loss Force: 10.15301310841949, time: 9.503444194793701


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1597218329885255, Training Loss Force: 2.3638439961387023, time: 0.5755629539489746
Validation Loss Energy: 1.253058149236454, Validation Loss Force: 2.572545630115837, time: 0.058860063552856445
Test Loss Energy: 13.43232214453666, Test Loss Force: 9.929353105776851, time: 9.52188754081726


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4318998146361626, Training Loss Force: 2.3694600580388894, time: 0.5953176021575928
Validation Loss Energy: 2.5481782774695216, Validation Loss Force: 2.5474403519199167, time: 0.05222797393798828
Test Loss Energy: 15.745674397578918, Test Loss Force: 10.042250974694916, time: 9.711485862731934


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7286563294736275, Training Loss Force: 2.3927729910350894, time: 0.5880541801452637
Validation Loss Energy: 1.0998383965778136, Validation Loss Force: 2.5198894984942717, time: 0.05362677574157715
Test Loss Energy: 13.677866611775553, Test Loss Force: 10.322304370417267, time: 9.536153078079224


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8936772038355945, Training Loss Force: 2.399239760407294, time: 0.5832114219665527
Validation Loss Energy: 2.0219848106829392, Validation Loss Force: 2.501084866451524, time: 0.05751681327819824
Test Loss Energy: 12.894337674968343, Test Loss Force: 9.67400338987315, time: 9.547458171844482


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6137924385106082, Training Loss Force: 2.450268962923181, time: 0.6105835437774658
Validation Loss Energy: 3.5649998270476617, Validation Loss Force: 2.4907441113146374, time: 0.05180931091308594
Test Loss Energy: 16.79941642795739, Test Loss Force: 10.133610348579145, time: 9.747478723526001


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.032893123895934, Training Loss Force: 2.3599675610134154, time: 0.5948588848114014
Validation Loss Energy: 1.8438584007065462, Validation Loss Force: 2.5262389091904023, time: 0.05263113975524902
Test Loss Energy: 12.572732659097653, Test Loss Force: 9.905125037927444, time: 9.606365203857422


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8009704184769435, Training Loss Force: 2.3602262122897075, time: 0.5928609371185303
Validation Loss Energy: 1.0909542316590137, Validation Loss Force: 2.6367890187531926, time: 0.05399179458618164
Test Loss Energy: 13.78552940549731, Test Loss Force: 10.323718587629529, time: 9.588308572769165


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.845878626713826, Training Loss Force: 2.469586107122834, time: 0.6467146873474121
Validation Loss Energy: 2.683739030841213, Validation Loss Force: 2.510079363932131, time: 0.05338859558105469
Test Loss Energy: 12.732842826870534, Test Loss Force: 9.972471593912152, time: 9.767520427703857


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0481496299193322, Training Loss Force: 2.3623798622510366, time: 0.6034817695617676
Validation Loss Energy: 2.363087667285091, Validation Loss Force: 2.5835646354712196, time: 0.052639007568359375
Test Loss Energy: 13.200843745536378, Test Loss Force: 10.061492284248967, time: 9.545634984970093


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7375947007887695, Training Loss Force: 2.3665548696196295, time: 0.5926384925842285
Validation Loss Energy: 1.003168479561005, Validation Loss Force: 2.5240580875751855, time: 0.053338050842285156
Test Loss Energy: 13.885192137480944, Test Loss Force: 10.06645059685238, time: 10.044623613357544


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0080138894871187, Training Loss Force: 2.394562582960911, time: 0.6349549293518066
Validation Loss Energy: 4.7989734491249365, Validation Loss Force: 2.523224859631124, time: 0.053734779357910156
Test Loss Energy: 12.13877594558384, Test Loss Force: 10.074266400455151, time: 9.819039821624756


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.2338650797395587, Training Loss Force: 2.370485915857477, time: 0.5736775398254395
Validation Loss Energy: 2.1224399918459476, Validation Loss Force: 2.4565474745596316, time: 0.052102088928222656
Test Loss Energy: 13.315344338002932, Test Loss Force: 10.001299432739359, time: 9.583414316177368


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.564056982850115, Training Loss Force: 2.3545760910373206, time: 0.5792946815490723
Validation Loss Energy: 1.4336364805132311, Validation Loss Force: 2.602955555375195, time: 0.053493499755859375
Test Loss Energy: 15.212968758276986, Test Loss Force: 9.992772104453366, time: 9.55328106880188


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.486287948040801, Training Loss Force: 2.413594415767611, time: 0.6059324741363525
Validation Loss Energy: 3.902467832511688, Validation Loss Force: 2.4867850539000416, time: 0.05961108207702637
Test Loss Energy: 17.53464619332656, Test Loss Force: 10.088080118100423, time: 9.836902141571045


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.199370421474128, Training Loss Force: 2.3347580315306056, time: 0.6201567649841309
Validation Loss Energy: 4.3514449835500155, Validation Loss Force: 2.562495458214386, time: 0.05227804183959961
Test Loss Energy: 12.56186674985526, Test Loss Force: 9.987082569690868, time: 9.57024097442627


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6951941097246568, Training Loss Force: 2.357089402823046, time: 0.6200909614562988
Validation Loss Energy: 1.1525592135862712, Validation Loss Force: 2.4807789990269313, time: 0.0518190860748291
Test Loss Energy: 13.574486032518521, Test Loss Force: 10.010508044673784, time: 9.543903350830078


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7253755373227402, Training Loss Force: 2.339874456966798, time: 0.5931119918823242
Validation Loss Energy: 2.502385699602034, Validation Loss Force: 2.496215537568375, time: 0.05209159851074219
Test Loss Energy: 13.003495830736043, Test Loss Force: 10.012662763869224, time: 9.805408477783203


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7923836176708816, Training Loss Force: 2.390857639186499, time: 0.5928909778594971
Validation Loss Energy: 2.060745496922027, Validation Loss Force: 2.520104151550946, time: 0.05390620231628418
Test Loss Energy: 13.714453194945433, Test Loss Force: 9.78440901980283, time: 9.546713590621948


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4424316800811057, Training Loss Force: 2.3460848739711913, time: 0.5741884708404541
Validation Loss Energy: 1.0216524680336165, Validation Loss Force: 2.528337343221626, time: 0.05381894111633301
Test Loss Energy: 14.292707162714681, Test Loss Force: 10.147502221928832, time: 9.58204960823059

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–†â–ƒâ–‚â–‡â–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–…â–ˆâ–‚â–ƒâ–‚â–ƒâ–„
wandb:   test_error_force â–†â–„â–…â–ˆâ–â–†â–ƒâ–ˆâ–„â–…â–…â–…â–…â–„â–…â–„â–…â–…â–‚â–†
wandb:          test_loss â–…â–„â–…â–ˆâ–â–†â–ƒâ–ˆâ–…â–†â–…â–†â–…â–…â–†â–†â–†â–†â–„â–‡
wandb: train_error_energy â–ˆâ–ƒâ–â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–†â–â–„â–ƒâ–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–ƒâ–„â–‚â–‚â–…â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–ƒâ–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–†â–‚â–‚â–„â–‚â–‚â–‚â–ƒâ–â–ƒâ–â–â–â–‚â–
wandb: valid_error_energy â–‚â–â–„â–â–ƒâ–†â–ƒâ–â–„â–„â–â–ˆâ–ƒâ–‚â–†â–‡â–â–„â–ƒâ–
wandb:  valid_error_force â–†â–†â–…â–ƒâ–ƒâ–‚â–„â–ˆâ–ƒâ–†â–„â–„â–â–‡â–‚â–…â–‚â–ƒâ–ƒâ–„
wandb:         valid_loss â–…â–…â–…â–‚â–ƒâ–„â–„â–†â–„â–‡â–‚â–ˆâ–â–†â–„â–‡â–â–ƒâ–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1153
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.29271
wandb:   test_error_force 10.1475
wandb:          test_loss 66.96704
wandb: train_error_energy 1.44243
wandb:  train_error_force 2.34608
wandb:         train_loss -4.6215
wandb: valid_error_energy 1.02165
wandb:  valid_error_force 2.52834
wandb:         valid_loss -4.09281
wandb: 
wandb: ğŸš€ View run al_82_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rrx74hpa
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_062455-rrx74hpa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 9.757092475891113, Uncertainty Bias: -2.1462175846099854
0.00016212463 0.0026187897
1.2432241 4.6698384
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2992 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2610 steps.
Found uncertainty sample 19 after 3115 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1591 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2546 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1845 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 978 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3194 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1443 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1915 steps.
Found uncertainty sample 54 after 2697 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1916 steps.
Found uncertainty sample 58 after 2614 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2825 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3058 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1567 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1954 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3857 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2662 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1122 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_070540-fjl4is0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/fjl4is0k
Training model 13. Added 20 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.237922078556998, Training Loss Force: 2.573379459868401, time: 0.6684415340423584
Validation Loss Energy: 1.7730101998626804, Validation Loss Force: 2.5152891539394036, time: 0.06208610534667969
Test Loss Energy: 15.16916584814068, Test Loss Force: 9.842417540618014, time: 9.15225625038147


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6712935062121945, Training Loss Force: 2.3707434658242095, time: 0.6826565265655518
Validation Loss Energy: 1.6494621129100744, Validation Loss Force: 2.4714752141026306, time: 0.05579376220703125
Test Loss Energy: 15.54301391871949, Test Loss Force: 10.082160005356991, time: 9.543788194656372


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5682270373347322, Training Loss Force: 2.3864996970783556, time: 0.578453540802002
Validation Loss Energy: 1.8004410346186706, Validation Loss Force: 2.4761274405685, time: 0.05100679397583008
Test Loss Energy: 13.516700600539803, Test Loss Force: 10.007553721741125, time: 9.088513374328613


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.037088962865842, Training Loss Force: 2.3715604148482785, time: 0.6539044380187988
Validation Loss Energy: 3.165315835519952, Validation Loss Force: 2.4598129175846624, time: 0.05008506774902344
Test Loss Energy: 17.05790852079684, Test Loss Force: 10.145621392777727, time: 8.944510221481323


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0170510311182146, Training Loss Force: 2.3636474815902933, time: 0.6381077766418457
Validation Loss Energy: 1.9624036686230195, Validation Loss Force: 2.5095200190375606, time: 0.059308767318725586
Test Loss Energy: 13.265910924909752, Test Loss Force: 9.937990495574512, time: 9.132793188095093


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9968175642655157, Training Loss Force: 2.385170807615459, time: 0.6016590595245361
Validation Loss Energy: 1.0701886637826532, Validation Loss Force: 2.4962974798140767, time: 0.05376124382019043
Test Loss Energy: 14.327897300234921, Test Loss Force: 9.92623131699354, time: 9.157039165496826


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8823010883238667, Training Loss Force: 2.3689141304648826, time: 0.5624377727508545
Validation Loss Energy: 1.7427605963883903, Validation Loss Force: 2.512467045183915, time: 0.05763745307922363
Test Loss Energy: 13.873797530079626, Test Loss Force: 9.796993580446442, time: 9.04766035079956


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4522100286226647, Training Loss Force: 2.360070783207765, time: 0.5729362964630127
Validation Loss Energy: 1.074046518070425, Validation Loss Force: 2.449622464121277, time: 0.05273008346557617
Test Loss Energy: 15.20976200081288, Test Loss Force: 10.066061105381293, time: 9.18433952331543


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.516498056405694, Training Loss Force: 2.384948120415275, time: 0.6012799739837646
Validation Loss Energy: 1.646739982601107, Validation Loss Force: 2.46706035294632, time: 0.05156755447387695
Test Loss Energy: 15.801460876173323, Test Loss Force: 10.14847346976916, time: 9.123183012008667


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1136701705426235, Training Loss Force: 2.354238500539755, time: 0.6485190391540527
Validation Loss Energy: 3.6227606488396216, Validation Loss Force: 2.5306755919230137, time: 0.05011343955993652
Test Loss Energy: 12.59045756612018, Test Loss Force: 9.90373726588223, time: 8.954456329345703


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1022110656384, Training Loss Force: 2.357150808353599, time: 0.6137933731079102
Validation Loss Energy: 6.339330463894719, Validation Loss Force: 2.510744922009309, time: 0.05100822448730469
Test Loss Energy: 12.066884117769147, Test Loss Force: 9.604965257190075, time: 8.95725131034851


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8053120906922213, Training Loss Force: 2.3733514210240814, time: 0.5861482620239258
Validation Loss Energy: 1.0209980434137347, Validation Loss Force: 2.4537999599680287, time: 0.05197644233703613
Test Loss Energy: 14.541093886186443, Test Loss Force: 9.947674640203305, time: 8.943908452987671


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8285937176101208, Training Loss Force: 2.3514899147290165, time: 0.6269032955169678
Validation Loss Energy: 2.2708915074136904, Validation Loss Force: 2.479148392871302, time: 0.05097818374633789
Test Loss Energy: 13.20390138228952, Test Loss Force: 9.886581244719142, time: 10.400772333145142


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.4194579744234974, Training Loss Force: 2.3355768461610324, time: 0.6166157722473145
Validation Loss Energy: 2.974903432747847, Validation Loss Force: 2.505999619840442, time: 0.06132245063781738
Test Loss Energy: 17.388393185832737, Test Loss Force: 9.885186286639291, time: 10.931215763092041


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8946823218286635, Training Loss Force: 2.363132201114276, time: 0.5976212024688721
Validation Loss Energy: 1.8235447398618458, Validation Loss Force: 2.4831150210368595, time: 0.05072617530822754
Test Loss Energy: 13.815893619462363, Test Loss Force: 9.933297441380061, time: 9.206699132919312


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.201461101202797, Training Loss Force: 2.3612602637310562, time: 0.6016819477081299
Validation Loss Energy: 3.244481174302513, Validation Loss Force: 2.492098830398462, time: 0.052919864654541016
Test Loss Energy: 13.04077168566424, Test Loss Force: 9.727891892626406, time: 9.053254127502441


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0035150459542845, Training Loss Force: 2.348977460520408, time: 0.623723030090332
Validation Loss Energy: 1.9626207710402992, Validation Loss Force: 2.4355110296672495, time: 0.05515408515930176
Test Loss Energy: 13.72541132418845, Test Loss Force: 9.730099077802178, time: 9.089939594268799


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5951365103397876, Training Loss Force: 2.353754285418637, time: 0.5730786323547363
Validation Loss Energy: 1.4308348573191676, Validation Loss Force: 2.4764115663987036, time: 0.0519099235534668
Test Loss Energy: 14.918612887299858, Test Loss Force: 10.047652182058613, time: 8.989517450332642


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5983809261757411, Training Loss Force: 2.351620777987887, time: 0.6501801013946533
Validation Loss Energy: 2.2172536275277293, Validation Loss Force: 2.4601035008200984, time: 0.07413077354431152
Test Loss Energy: 16.594141402960688, Test Loss Force: 10.03349800212341, time: 9.02958345413208


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8192234900181008, Training Loss Force: 2.3233082275767885, time: 0.6218314170837402
Validation Loss Energy: 1.9832000761760913, Validation Loss Force: 2.4695375471947667, time: 0.04954361915588379
Test Loss Energy: 13.134319288701661, Test Loss Force: 9.941885718058458, time: 9.030954599380493

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–†â–ƒâ–ˆâ–ƒâ–„â–ƒâ–…â–†â–‚â–â–„â–‚â–ˆâ–ƒâ–‚â–ƒâ–…â–‡â–‚
wandb:   test_error_force â–„â–‡â–†â–ˆâ–…â–…â–ƒâ–‡â–ˆâ–…â–â–…â–…â–…â–…â–ƒâ–ƒâ–‡â–‡â–…
wandb:          test_loss â–ƒâ–†â–†â–‡â–„â–„â–„â–†â–ˆâ–…â–â–…â–…â–…â–†â–ƒâ–„â–‡â–‡â–†
wandb: train_error_energy â–‡â–ƒâ–‚â–…â–…â–…â–„â–â–â–†â–†â–„â–„â–ˆâ–„â–†â–…â–‚â–‚â–„
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–‚â–‚â–‚â–„â–‚â–â–‚â–â–‚â–„â–ˆâ–â–ƒâ–„â–‚â–„â–‚â–‚â–ƒâ–‚
wandb:  valid_error_force â–‡â–„â–„â–ƒâ–†â–…â–‡â–‚â–ƒâ–ˆâ–‡â–‚â–„â–†â–…â–…â–â–„â–ƒâ–„
wandb:         valid_loss â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–â–‚â–…â–ˆâ–â–ƒâ–„â–ƒâ–„â–‚â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1171
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.13432
wandb:   test_error_force 9.94189
wandb:          test_loss 64.60847
wandb: train_error_energy 1.81922
wandb:  train_error_force 2.32331
wandb:         train_loss -4.65865
wandb: valid_error_energy 1.9832
wandb:  valid_error_force 2.46954
wandb:         valid_loss -4.13702
wandb: 
wandb: ğŸš€ View run al_82_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/fjl4is0k
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_070540-fjl4is0k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 9.274410247802734, Uncertainty Bias: -2.018122911453247
6.1035156e-05 0.039260626
1.3801711 4.3737564
(48745, 22, 3)
Found uncertainty sample 0 after 2487 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 633 steps.
Found uncertainty sample 11 after 3536 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2106 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 679 steps.
Found uncertainty sample 20 after 1303 steps.
Found uncertainty sample 21 after 2592 steps.
Found uncertainty sample 22 after 1150 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1730 steps.
Found uncertainty sample 32 after 1496 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2552 steps.
Found uncertainty sample 36 after 2373 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2838 steps.
Found uncertainty sample 40 after 1254 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3054 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1946 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2335 steps.
Found uncertainty sample 51 after 3110 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2150 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 938 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3746 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1179 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3145 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1388 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2820 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3255 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_074428-r7ibgtf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/r7ibgtf7
Training model 14. Added 26 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.465948077092915, Training Loss Force: 2.5740228172299218, time: 0.600548505783081
Validation Loss Energy: 1.6939295866901454, Validation Loss Force: 2.5471241617326994, time: 0.05504155158996582
Test Loss Energy: 13.86865313601864, Test Loss Force: 9.93349553997667, time: 9.848842144012451


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9220948897961547, Training Loss Force: 2.3929626826587866, time: 0.6155030727386475
Validation Loss Energy: 2.151387203485706, Validation Loss Force: 2.447430954387056, time: 0.05239391326904297
Test Loss Energy: 13.348735425404783, Test Loss Force: 9.964361787761879, time: 9.792569160461426


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.916528917051113, Training Loss Force: 2.378698913210372, time: 0.6637732982635498
Validation Loss Energy: 3.1089633960759855, Validation Loss Force: 2.5391298940555997, time: 0.0543971061706543
Test Loss Energy: 17.48532953814072, Test Loss Force: 10.02028663366305, time: 9.966899394989014


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.8513710820581726, Training Loss Force: 2.3836770042518785, time: 0.6302053928375244
Validation Loss Energy: 2.389078055336074, Validation Loss Force: 2.476052401066322, time: 0.054143428802490234
Test Loss Energy: 16.368717221820038, Test Loss Force: 9.849429095908288, time: 9.813902854919434


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5729081529050966, Training Loss Force: 2.378818328329448, time: 0.5973784923553467
Validation Loss Energy: 2.167318512869401, Validation Loss Force: 2.4797202072380444, time: 0.055021047592163086
Test Loss Energy: 16.437717255928828, Test Loss Force: 10.404156000268562, time: 10.218616962432861


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8598507258310115, Training Loss Force: 2.3706683153042007, time: 0.6438827514648438
Validation Loss Energy: 2.9836654636401057, Validation Loss Force: 2.5043149050823525, time: 0.05282878875732422
Test Loss Energy: 16.949828134990945, Test Loss Force: 9.890559314115055, time: 9.909613370895386


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8487315882116058, Training Loss Force: 2.4062557083863854, time: 0.649259090423584
Validation Loss Energy: 1.7869997229593126, Validation Loss Force: 2.5681205261788143, time: 0.05792427062988281
Test Loss Energy: 14.012388168167712, Test Loss Force: 9.765647402542685, time: 9.778271913528442


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1399504400490623, Training Loss Force: 2.3916351116316217, time: 0.6510441303253174
Validation Loss Energy: 2.0058009944877617, Validation Loss Force: 2.489942725058443, time: 0.054075002670288086
Test Loss Energy: 16.01358376782448, Test Loss Force: 10.009703096877063, time: 9.858367681503296


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.545383177443023, Training Loss Force: 2.373625021698688, time: 0.601142406463623
Validation Loss Energy: 1.0662075621226101, Validation Loss Force: 2.5127945914975744, time: 0.05305671691894531
Test Loss Energy: 15.11834762881541, Test Loss Force: 9.844839518747303, time: 9.96493911743164


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4804120811329888, Training Loss Force: 2.3724268331647367, time: 0.6168558597564697
Validation Loss Energy: 2.1296375493189172, Validation Loss Force: 2.4851562290975795, time: 0.05860710144042969
Test Loss Energy: 14.07386707738932, Test Loss Force: 10.132916478877839, time: 9.783011674880981


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6482671267100237, Training Loss Force: 2.3601154853849606, time: 0.5980057716369629
Validation Loss Energy: 2.3164774483137567, Validation Loss Force: 2.4497489401961645, time: 0.056937217712402344
Test Loss Energy: 16.196231704472922, Test Loss Force: 10.057119062222947, time: 9.823016881942749


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1472574511266846, Training Loss Force: 2.384780001725946, time: 0.5891678333282471
Validation Loss Energy: 5.258658759390932, Validation Loss Force: 2.6660684527586755, time: 0.05601167678833008
Test Loss Energy: 12.83021703298913, Test Loss Force: 9.787480776810922, time: 9.9737389087677


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.040939449948541, Training Loss Force: 2.3931330890122795, time: 0.5728785991668701
Validation Loss Energy: 2.8292873860843493, Validation Loss Force: 2.5806044718452554, time: 0.057405948638916016
Test Loss Energy: 13.43993269148755, Test Loss Force: 9.972471645207664, time: 9.867682456970215


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4997834706089808, Training Loss Force: 2.3883916718340372, time: 0.6276252269744873
Validation Loss Energy: 1.5825355610642888, Validation Loss Force: 2.5475378810058333, time: 0.061040639877319336
Test Loss Energy: 14.208899765635312, Test Loss Force: 10.039998649470293, time: 9.815720796585083


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.56852544986123, Training Loss Force: 2.3604196514382987, time: 0.5790069103240967
Validation Loss Energy: 1.687884119378206, Validation Loss Force: 2.4893938456137312, time: 0.053781747817993164
Test Loss Energy: 15.356707110644523, Test Loss Force: 10.05055787218451, time: 9.97328495979309


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5388864608523602, Training Loss Force: 2.361240017309326, time: 0.5878434181213379
Validation Loss Energy: 1.2819611610507458, Validation Loss Force: 2.44761064838782, time: 0.056819915771484375
Test Loss Energy: 14.4266423322275, Test Loss Force: 9.920624908936702, time: 9.799636125564575


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.729946353272394, Training Loss Force: 2.3561222541161793, time: 0.631859540939331
Validation Loss Energy: 1.2211138108925077, Validation Loss Force: 2.5374999559074083, time: 0.06718730926513672
Test Loss Energy: 15.32008226102414, Test Loss Force: 10.018515539597638, time: 10.38112187385559


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7313052620519904, Training Loss Force: 2.3763043760927793, time: 0.6524012088775635
Validation Loss Energy: 1.896491820075227, Validation Loss Force: 2.5475712813777225, time: 0.05413961410522461
Test Loss Energy: 15.631638155385533, Test Loss Force: 10.176524144313182, time: 9.783019542694092


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.148965761489599, Training Loss Force: 2.348800939475789, time: 0.5821552276611328
Validation Loss Energy: 2.857205420931629, Validation Loss Force: 2.4971634401225895, time: 0.05409431457519531
Test Loss Energy: 16.708795756050254, Test Loss Force: 10.283007579647085, time: 9.862287998199463


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8300155228216506, Training Loss Force: 2.3505898633941724, time: 0.6122050285339355
Validation Loss Energy: 1.001752860465769, Validation Loss Force: 2.437999580042139, time: 0.05466127395629883
Test Loss Energy: 14.557528366052162, Test Loss Force: 9.859459970205695, time: 9.972558736801147

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–ˆâ–†â–†â–‡â–ƒâ–†â–„â–ƒâ–†â–â–‚â–ƒâ–…â–ƒâ–…â–…â–‡â–„
wandb:   test_error_force â–ƒâ–ƒâ–„â–‚â–ˆâ–‚â–â–„â–‚â–…â–„â–â–ƒâ–„â–„â–ƒâ–„â–†â–‡â–‚
wandb:          test_loss â–‚â–‚â–„â–ƒâ–ˆâ–ƒâ–â–ƒâ–‚â–†â–…â–ƒâ–„â–„â–…â–ƒâ–„â–†â–‡â–„
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–â–ƒâ–ƒâ–ˆâ–„â–‚â–‚â–â–â–‚â–„â–
wandb:  valid_error_force â–„â–â–„â–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–‚â–â–ˆâ–…â–„â–ƒâ–â–„â–„â–ƒâ–
wandb:         valid_loss â–„â–‚â–†â–ƒâ–ƒâ–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–ˆâ–„â–ƒâ–â–„â–…â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1194
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.55753
wandb:   test_error_force 9.85946
wandb:          test_loss 66.44892
wandb: train_error_energy 1.83002
wandb:  train_error_force 2.35059
wandb:         train_loss -4.6241
wandb: valid_error_energy 1.00175
wandb:  valid_error_force 2.438
wandb:         valid_loss -4.24755
wandb: 
wandb: ğŸš€ View run al_82_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/r7ibgtf7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_074428-r7ibgtf7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 9.876884460449219, Uncertainty Bias: -2.1405556201934814
5.9604645e-05 0.002667904
1.2515075 4.3284564
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2822 steps.
Found uncertainty sample 7 after 1046 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2625 steps.
Found uncertainty sample 11 after 3495 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3531 steps.
Found uncertainty sample 17 after 3412 steps.
Found uncertainty sample 18 after 1975 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2099 steps.
Found uncertainty sample 25 after 587 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 936 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2567 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2472 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2037 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2013 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1750 steps.
Found uncertainty sample 45 after 1583 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3616 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 853 steps.
Found uncertainty sample 59 after 293 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1349 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2474 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1041 steps.
Found uncertainty sample 66 after 1363 steps.
Found uncertainty sample 67 after 1907 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1764 steps.
Found uncertainty sample 71 after 889 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3261 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2627 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 620 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 304 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 754 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3559 steps.
Found uncertainty sample 88 after 1304 steps.
Found uncertainty sample 89 after 1177 steps.
Found uncertainty sample 90 after 2771 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3209 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1182 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_082058-eyi82ngb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/eyi82ngb
Training model 15. Added 37 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.534509223804334, Training Loss Force: 2.601478099916242, time: 0.6469597816467285
Validation Loss Energy: 1.5846168495712758, Validation Loss Force: 3.1363514783559574, time: 0.05993175506591797
Test Loss Energy: 14.867144264223207, Test Loss Force: 9.724251921263733, time: 10.023383378982544


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1864128203426048, Training Loss Force: 2.46881659588544, time: 0.6428415775299072
Validation Loss Energy: 1.8960729794117368, Validation Loss Force: 3.0884998788960756, time: 0.056911468505859375
Test Loss Energy: 14.336681418507492, Test Loss Force: 9.500323997508836, time: 9.97979187965393


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7625337963949346, Training Loss Force: 2.4098598866242855, time: 0.6292035579681396
Validation Loss Energy: 3.952158233778641, Validation Loss Force: 3.0465532425170534, time: 0.05678415298461914
Test Loss Energy: 17.752803125048985, Test Loss Force: 9.901995279687162, time: 10.120192766189575


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0132323588460546, Training Loss Force: 2.4112727337741275, time: 0.6931521892547607
Validation Loss Energy: 2.9575946920274427, Validation Loss Force: 3.111003045452684, time: 0.055858612060546875
Test Loss Energy: 13.595379481850161, Test Loss Force: 9.440797479338094, time: 9.955847263336182


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.872552498904136, Training Loss Force: 2.414074556799476, time: 0.6081736087799072
Validation Loss Energy: 1.5321781543707087, Validation Loss Force: 3.1464733497223967, time: 0.05550980567932129
Test Loss Energy: 14.353004741002914, Test Loss Force: 9.705100840511868, time: 9.957767248153687


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4356253698888564, Training Loss Force: 2.4287954195775123, time: 0.6500675678253174
Validation Loss Energy: 1.7442440182385612, Validation Loss Force: 3.0534326057804924, time: 0.05627846717834473
Test Loss Energy: 15.586285705818208, Test Loss Force: 9.999585132130038, time: 10.079683542251587


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5726294760833817, Training Loss Force: 2.4093228486105644, time: 0.6458864212036133
Validation Loss Energy: 3.237989032683842, Validation Loss Force: 3.097788076980162, time: 0.05798983573913574
Test Loss Energy: 13.272089678941349, Test Loss Force: 9.681625347743417, time: 9.919797897338867


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5867220193441636, Training Loss Force: 2.4481605897930736, time: 0.5930347442626953
Validation Loss Energy: 2.351740670277757, Validation Loss Force: 3.071446985024342, time: 0.05582380294799805
Test Loss Energy: 15.935705208388482, Test Loss Force: 9.588939579223368, time: 9.87166714668274


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8327987667962298, Training Loss Force: 2.4180640456640154, time: 0.621107816696167
Validation Loss Energy: 3.444466123658053, Validation Loss Force: 3.1394839879008694, time: 0.05501890182495117
Test Loss Energy: 16.703404835767934, Test Loss Force: 9.768937407956386, time: 10.552814245223999


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9657855162261835, Training Loss Force: 2.4338229520341095, time: 0.6826763153076172
Validation Loss Energy: 2.5207153783565177, Validation Loss Force: 3.0781613504506486, time: 0.05614805221557617
Test Loss Energy: 13.718009484678293, Test Loss Force: 9.434070138479356, time: 9.86809778213501


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8790712980162003, Training Loss Force: 2.3988943389923216, time: 0.6519961357116699
Validation Loss Energy: 3.0406302432353742, Validation Loss Force: 3.0851801045994383, time: 0.055243730545043945
Test Loss Energy: 17.275962115382647, Test Loss Force: 9.73658923288564, time: 9.88871145248413


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1761155599122235, Training Loss Force: 2.418975795884076, time: 0.7220072746276855
Validation Loss Energy: 1.686616575265012, Validation Loss Force: 3.061055015983892, time: 0.08054256439208984
Test Loss Energy: 15.02494465113698, Test Loss Force: 9.734120300711735, time: 10.036375045776367


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1014567334773835, Training Loss Force: 2.400980389193352, time: 0.6046488285064697
Validation Loss Energy: 2.5828594422860665, Validation Loss Force: 3.0408310908050007, time: 0.05504250526428223
Test Loss Energy: 15.75754193559327, Test Loss Force: 9.714826441239241, time: 9.897568941116333


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4027896855263946, Training Loss Force: 2.3958020640492395, time: 0.6648945808410645
Validation Loss Energy: 2.3406092170036805, Validation Loss Force: 3.061281247836155, time: 0.05718827247619629
Test Loss Energy: 16.429043866009557, Test Loss Force: 9.707340463102907, time: 10.083921670913696


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.414376248842153, Training Loss Force: 2.396135314118714, time: 0.6355211734771729
Validation Loss Energy: 1.7067813817856596, Validation Loss Force: 3.0331478919247625, time: 0.058145761489868164
Test Loss Energy: 14.899265326091564, Test Loss Force: 9.592788449219134, time: 9.939367771148682


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9941110812862342, Training Loss Force: 2.41550639363084, time: 0.6598846912384033
Validation Loss Energy: 1.7648780999842517, Validation Loss Force: 3.0052142702372677, time: 0.05992531776428223
Test Loss Energy: 15.262921766907674, Test Loss Force: 9.73753665162993, time: 9.919387102127075


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.489220381682127, Training Loss Force: 2.3865238175631367, time: 0.6187748908996582
Validation Loss Energy: 1.6189839395574894, Validation Loss Force: 2.9792374650041857, time: 0.05796647071838379
Test Loss Energy: 15.18537560704007, Test Loss Force: 9.747491114270264, time: 10.103399753570557


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.177512686049416, Training Loss Force: 2.4031052409204263, time: 0.6117188930511475
Validation Loss Energy: 3.037919914391141, Validation Loss Force: 3.0438821034425034, time: 0.06085085868835449
Test Loss Energy: 16.556927774149415, Test Loss Force: 9.749780195059456, time: 9.9253671169281


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.308019095315554, Training Loss Force: 2.3707662186605916, time: 0.6395795345306396
Validation Loss Energy: 2.145978124592828, Validation Loss Force: 3.028317307473005, time: 0.05934286117553711
Test Loss Energy: 14.033633630605507, Test Loss Force: 9.515875523096721, time: 9.880873918533325


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.812596885862785, Training Loss Force: 2.360228915181434, time: 0.6316308975219727
Validation Loss Energy: 1.6371003012701744, Validation Loss Force: 2.9946383764822815, time: 0.05579733848571777
Test Loss Energy: 14.558651084870458, Test Loss Force: 9.580011637667058, time: 10.22708511352539

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.055 MB of 0.058 MB uploadedwandb: / 0.055 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ˆâ–‚â–ƒâ–…â–â–…â–†â–‚â–‡â–„â–…â–†â–„â–„â–„â–†â–‚â–ƒ
wandb:   test_error_force â–…â–‚â–‡â–â–„â–ˆâ–„â–ƒâ–…â–â–…â–…â–„â–„â–ƒâ–…â–…â–…â–‚â–ƒ
wandb:          test_loss â–„â–‚â–‡â–‚â–„â–ˆâ–„â–ƒâ–†â–â–‡â–†â–†â–†â–…â–‡â–‡â–‡â–„â–…
wandb: train_error_energy â–ˆâ–†â–ƒâ–…â–„â–â–‚â–‚â–„â–„â–„â–†â–…â–â–â–…â–‚â–†â–‡â–„
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–â–
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–
wandb: valid_error_energy â–â–‚â–ˆâ–…â–â–‚â–†â–ƒâ–‡â–„â–…â–â–„â–ƒâ–‚â–‚â–â–…â–ƒâ–
wandb:  valid_error_force â–ˆâ–†â–„â–‡â–ˆâ–„â–†â–…â–ˆâ–…â–…â–„â–„â–„â–ƒâ–‚â–â–„â–ƒâ–‚
wandb:         valid_loss â–…â–…â–†â–‡â–ˆâ–„â–‡â–ƒâ–‡â–ƒâ–‚â–„â–…â–„â–â–ƒâ–â–„â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1227
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.55865
wandb:   test_error_force 9.58001
wandb:          test_loss 58.18796
wandb: train_error_energy 1.8126
wandb:  train_error_force 2.36023
wandb:         train_loss -4.57263
wandb: valid_error_energy 1.6371
wandb:  valid_error_force 2.99464
wandb:         valid_loss 22.90226
wandb: 
wandb: ğŸš€ View run al_82_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/eyi82ngb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_082058-eyi82ngb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 32.08382797241211, Uncertainty Bias: -7.4450602531433105
6.1035156e-05 0.0027179718
-1.2243596 133.38849
(48745, 22, 3)
Found uncertainty sample 0 after 544 steps.
Found uncertainty sample 1 after 121 steps.
Found uncertainty sample 2 after 177 steps.
Found uncertainty sample 3 after 19 steps.
Found uncertainty sample 4 after 110 steps.
Found uncertainty sample 5 after 1038 steps.
Found uncertainty sample 6 after 165 steps.
Found uncertainty sample 7 after 1377 steps.
Found uncertainty sample 8 after 634 steps.
Found uncertainty sample 9 after 838 steps.
Found uncertainty sample 10 after 359 steps.
Found uncertainty sample 11 after 1447 steps.
Found uncertainty sample 12 after 624 steps.
Found uncertainty sample 13 after 1048 steps.
Found uncertainty sample 14 after 105 steps.
Found uncertainty sample 15 after 121 steps.
Found uncertainty sample 16 after 2284 steps.
Found uncertainty sample 17 after 36 steps.
Found uncertainty sample 18 after 292 steps.
Found uncertainty sample 19 after 425 steps.
Found uncertainty sample 20 after 775 steps.
Found uncertainty sample 21 after 805 steps.
Found uncertainty sample 22 after 45 steps.
Found uncertainty sample 23 after 1451 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 784 steps.
Found uncertainty sample 26 after 1008 steps.
Found uncertainty sample 27 after 28 steps.
Found uncertainty sample 28 after 359 steps.
Found uncertainty sample 29 after 15 steps.
Found uncertainty sample 30 after 627 steps.
Found uncertainty sample 31 after 341 steps.
Found uncertainty sample 32 after 172 steps.
Found uncertainty sample 33 after 585 steps.
Found uncertainty sample 34 after 817 steps.
Found uncertainty sample 35 after 309 steps.
Found uncertainty sample 36 after 313 steps.
Found uncertainty sample 37 after 785 steps.
Found uncertainty sample 38 after 183 steps.
Found uncertainty sample 39 after 449 steps.
Found uncertainty sample 40 after 386 steps.
Found uncertainty sample 41 after 543 steps.
Found uncertainty sample 42 after 797 steps.
Found uncertainty sample 43 after 123 steps.
Found uncertainty sample 44 after 445 steps.
Found uncertainty sample 45 after 590 steps.
Found uncertainty sample 46 after 518 steps.
Found uncertainty sample 47 after 1664 steps.
Found uncertainty sample 48 after 390 steps.
Found uncertainty sample 49 after 653 steps.
Found uncertainty sample 50 after 717 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 114 steps.
Found uncertainty sample 53 after 67 steps.
Found uncertainty sample 54 after 13 steps.
Found uncertainty sample 55 after 607 steps.
Found uncertainty sample 56 after 384 steps.
Found uncertainty sample 57 after 723 steps.
Found uncertainty sample 58 after 479 steps.
Found uncertainty sample 59 after 570 steps.
Found uncertainty sample 60 after 97 steps.
Found uncertainty sample 61 after 467 steps.
Found uncertainty sample 62 after 1830 steps.
Found uncertainty sample 63 after 7 steps.
Found uncertainty sample 64 after 1454 steps.
Found uncertainty sample 65 after 1253 steps.
Found uncertainty sample 66 after 168 steps.
Found uncertainty sample 67 after 155 steps.
Found uncertainty sample 68 after 1562 steps.
Found uncertainty sample 69 after 1060 steps.
Found uncertainty sample 70 after 781 steps.
Found uncertainty sample 71 after 73 steps.
Found uncertainty sample 72 after 256 steps.
Found uncertainty sample 73 after 1044 steps.
Found uncertainty sample 74 after 481 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1485 steps.
Found uncertainty sample 77 after 293 steps.
Found uncertainty sample 78 after 855 steps.
Found uncertainty sample 79 after 338 steps.
Found uncertainty sample 80 after 543 steps.
Found uncertainty sample 81 after 37 steps.
Found uncertainty sample 82 after 295 steps.
Found uncertainty sample 83 after 673 steps.
Found uncertainty sample 84 after 1029 steps.
Found uncertainty sample 85 after 134 steps.
Found uncertainty sample 86 after 1071 steps.
Found uncertainty sample 87 after 313 steps.
Found uncertainty sample 88 after 136 steps.
Found uncertainty sample 89 after 455 steps.
Found uncertainty sample 90 after 2382 steps.
Found uncertainty sample 91 after 1123 steps.
Found uncertainty sample 92 after 643 steps.
Found uncertainty sample 93 after 779 steps.
Found uncertainty sample 94 after 458 steps.
Found uncertainty sample 95 after 320 steps.
Found uncertainty sample 96 after 35 steps.
Found uncertainty sample 97 after 117 steps.
Found uncertainty sample 98 after 164 steps.
Found uncertainty sample 99 after 23 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_083423-ctq4vr88
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ctq4vr88
Training model 16. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.7572582769842615, Training Loss Force: 2.576593293945573, time: 0.7249231338500977
Validation Loss Energy: 1.3509110517582905, Validation Loss Force: 2.9869505015499787, time: 0.07622146606445312
Test Loss Energy: 14.456513778206812, Test Loss Force: 9.493331244354613, time: 10.053373575210571


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7841008702223502, Training Loss Force: 2.3894208544862297, time: 0.6754558086395264
Validation Loss Energy: 1.3427684864300033, Validation Loss Force: 2.779351937422302, time: 0.06136631965637207
Test Loss Energy: 15.162782686164741, Test Loss Force: 9.545811676030356, time: 10.00096607208252


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.028316222289775, Training Loss Force: 2.3768570289145097, time: 0.6953461170196533
Validation Loss Energy: 2.2405641924074713, Validation Loss Force: 2.6808956571822877, time: 0.06241941452026367
Test Loss Energy: 14.087038486647348, Test Loss Force: 9.484750983765467, time: 10.190378665924072


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6525249256868995, Training Loss Force: 2.392693730419418, time: 0.677954912185669
Validation Loss Energy: 1.2242989816904317, Validation Loss Force: 2.745699615394517, time: 0.06258296966552734
Test Loss Energy: 14.667197868106705, Test Loss Force: 9.615136233515129, time: 10.016151666641235


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5604644932632346, Training Loss Force: 2.3830722496403416, time: 0.7198657989501953
Validation Loss Energy: 2.949881878150796, Validation Loss Force: 2.421741336684935, time: 0.06266164779663086
Test Loss Energy: 13.677750371486537, Test Loss Force: 9.41493884380469, time: 10.078906536102295


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8731988155735468, Training Loss Force: 2.385413393040626, time: 0.7098824977874756
Validation Loss Energy: 2.6435275437818326, Validation Loss Force: 2.8469482780590383, time: 0.061902761459350586
Test Loss Energy: 13.791657750032202, Test Loss Force: 9.437568081901142, time: 10.262361526489258


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1713284846445426, Training Loss Force: 2.3530555686959844, time: 0.6862015724182129
Validation Loss Energy: 1.600336177928048, Validation Loss Force: 2.554392416659501, time: 0.06255483627319336
Test Loss Energy: 15.743883941790074, Test Loss Force: 9.718321362889162, time: 10.096063375473022


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8618766713588035, Training Loss Force: 2.38531164384423, time: 0.656390905380249
Validation Loss Energy: 1.2912857655401908, Validation Loss Force: 2.6518493577725915, time: 0.06915974617004395
Test Loss Energy: 14.9235060546055, Test Loss Force: 9.622904546802044, time: 10.059375047683716


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5191028007780947, Training Loss Force: 2.382560810422023, time: 0.729362964630127
Validation Loss Energy: 1.484116800575363, Validation Loss Force: 2.720498255462129, time: 0.06987929344177246
Test Loss Energy: 14.256232870079543, Test Loss Force: 9.569222937493759, time: 10.251489400863647


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4696948473702816, Training Loss Force: 2.3855202053092692, time: 0.7140467166900635
Validation Loss Energy: 1.4753979674974147, Validation Loss Force: 2.9194976711777922, time: 0.06217694282531738
Test Loss Energy: 15.038333819161654, Test Loss Force: 9.812167216674968, time: 10.056065082550049


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2490564453787667, Training Loss Force: 2.3762880933417256, time: 0.6790728569030762
Validation Loss Energy: 2.783761343184537, Validation Loss Force: 2.763975074211967, time: 0.06427502632141113
Test Loss Energy: 16.73334160424769, Test Loss Force: 9.550911415018223, time: 10.28158187866211


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4811409308221417, Training Loss Force: 2.3493820685561015, time: 0.6833574771881104
Validation Loss Energy: 4.3844592471401445, Validation Loss Force: 2.622841580125141, time: 0.0641183853149414
Test Loss Energy: 18.676683907965934, Test Loss Force: 9.968677815294186, time: 10.484221696853638


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0682121036684458, Training Loss Force: 2.339941882874981, time: 0.6927225589752197
Validation Loss Energy: 2.468599219413827, Validation Loss Force: 2.963678681101628, time: 0.06423640251159668
Test Loss Energy: 13.87399124990497, Test Loss Force: 9.389149499178917, time: 10.049569606781006


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4643421183508505, Training Loss Force: 2.394053835975915, time: 0.6588637828826904
Validation Loss Energy: 1.0783280004083244, Validation Loss Force: 2.9397632354869723, time: 0.06696176528930664
Test Loss Energy: 15.019853977464706, Test Loss Force: 9.652050996031898, time: 10.347450017929077


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5935503131739017, Training Loss Force: 2.358660601738925, time: 0.6953918933868408
Validation Loss Energy: 4.1182703073173546, Validation Loss Force: 2.573654967800849, time: 0.06261110305786133
Test Loss Energy: 18.859132169846642, Test Loss Force: 10.053054639167467, time: 10.10287070274353


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.4709800734705474, Training Loss Force: 2.353088751700374, time: 0.6668791770935059
Validation Loss Energy: 1.3941684300648172, Validation Loss Force: 2.3854103604989243, time: 0.06245303153991699
Test Loss Energy: 15.427856655122868, Test Loss Force: 9.827467375610663, time: 10.032937288284302


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3900180398814928, Training Loss Force: 2.375514291551395, time: 0.6906912326812744
Validation Loss Energy: 1.2828415113528147, Validation Loss Force: 2.8625984676460003, time: 0.06885051727294922
Test Loss Energy: 14.430317025987256, Test Loss Force: 9.57707863035044, time: 10.15587568283081


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7176483770120103, Training Loss Force: 2.3470461260708686, time: 0.6798534393310547
Validation Loss Energy: 1.5781531539359976, Validation Loss Force: 2.728711518244248, time: 0.06398534774780273
Test Loss Energy: 14.252836990733087, Test Loss Force: 9.487105965295395, time: 10.006365060806274


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4997678583069116, Training Loss Force: 2.3567291377572697, time: 0.6684932708740234
Validation Loss Energy: 8.719552076620662, Validation Loss Force: 10.496711159344843, time: 0.06712007522583008
Test Loss Energy: 15.183785548819335, Test Loss Force: 9.636818910901276, time: 10.030563354492188


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.353687565029916, Training Loss Force: 2.353772102102641, time: 0.6596345901489258
Validation Loss Energy: 1.3084875137359773, Validation Loss Force: 2.859187844337824, time: 0.06224656105041504
Test Loss Energy: 14.72173216734189, Test Loss Force: 9.543619100748494, time: 10.18453311920166

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‚â–‚â–â–â–„â–ƒâ–‚â–ƒâ–…â–ˆâ–â–ƒâ–ˆâ–ƒâ–‚â–‚â–ƒâ–‚
wandb:   test_error_force â–‚â–ƒâ–‚â–ƒâ–â–‚â–„â–ƒâ–ƒâ–…â–ƒâ–‡â–â–„â–ˆâ–†â–ƒâ–‚â–„â–ƒ
wandb:          test_loss â–â–‚â–‚â–„â–‚â–‚â–…â–„â–ƒâ–…â–ƒâ–ˆâ–‚â–…â–ˆâ–‡â–„â–„â–…â–„
wandb: train_error_energy â–„â–„â–…â–ƒâ–ƒâ–…â–†â–…â–ƒâ–‚â–â–‚â–†â–‚â–ƒâ–ˆâ–ˆâ–„â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–
wandb: valid_error_energy â–â–â–‚â–â–ƒâ–‚â–â–â–â–â–ƒâ–„â–‚â–â–„â–â–â–â–ˆâ–
wandb:  valid_error_force â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb:         valid_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1316
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.72173
wandb:   test_error_force 9.54362
wandb:          test_loss 60.5303
wandb: train_error_energy 1.35369
wandb:  train_error_force 2.35377
wandb:         train_loss -4.6498
wandb: valid_error_energy 1.30849
wandb:  valid_error_force 2.85919
wandb:         valid_loss 10.24796
wandb: 
wandb: ğŸš€ View run al_82_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ctq4vr88
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_083423-ctq4vr88/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 32.03556442260742, Uncertainty Bias: -7.318385601043701
0.00011444092 0.0007492304
-1.7447927 132.38744
(48745, 22, 3)
Found uncertainty sample 0 after 760 steps.
Found uncertainty sample 1 after 353 steps.
Found uncertainty sample 2 after 483 steps.
Found uncertainty sample 3 after 269 steps.
Found uncertainty sample 4 after 1585 steps.
Found uncertainty sample 5 after 202 steps.
Found uncertainty sample 6 after 771 steps.
Found uncertainty sample 7 after 24 steps.
Found uncertainty sample 8 after 481 steps.
Found uncertainty sample 9 after 1307 steps.
Found uncertainty sample 10 after 1067 steps.
Found uncertainty sample 11 after 1893 steps.
Found uncertainty sample 12 after 6 steps.
Found uncertainty sample 13 after 241 steps.
Found uncertainty sample 14 after 947 steps.
Found uncertainty sample 15 after 560 steps.
Found uncertainty sample 16 after 83 steps.
Found uncertainty sample 17 after 28 steps.
Found uncertainty sample 18 after 786 steps.
Found uncertainty sample 19 after 2156 steps.
Found uncertainty sample 20 after 1793 steps.
Found uncertainty sample 21 after 310 steps.
Found uncertainty sample 22 after 663 steps.
Found uncertainty sample 23 after 890 steps.
Found uncertainty sample 24 after 263 steps.
Found uncertainty sample 25 after 1970 steps.
Found uncertainty sample 26 after 60 steps.
Found uncertainty sample 27 after 36 steps.
Found uncertainty sample 28 after 374 steps.
Found uncertainty sample 29 after 182 steps.
Found uncertainty sample 30 after 85 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 102 steps.
Found uncertainty sample 33 after 3431 steps.
Found uncertainty sample 34 after 1254 steps.
Found uncertainty sample 35 after 138 steps.
Found uncertainty sample 36 after 2254 steps.
Found uncertainty sample 37 after 1105 steps.
Found uncertainty sample 38 after 1118 steps.
Found uncertainty sample 39 after 50 steps.
Found uncertainty sample 40 after 116 steps.
Found uncertainty sample 41 after 1169 steps.
Found uncertainty sample 42 after 137 steps.
Found uncertainty sample 43 after 539 steps.
Found uncertainty sample 44 after 697 steps.
Found uncertainty sample 45 after 66 steps.
Found uncertainty sample 46 after 39 steps.
Found uncertainty sample 47 after 606 steps.
Found uncertainty sample 48 after 10 steps.
Found uncertainty sample 49 after 1422 steps.
Found uncertainty sample 50 after 1581 steps.
Found uncertainty sample 51 after 452 steps.
Found uncertainty sample 52 after 2311 steps.
Found uncertainty sample 53 after 13 steps.
Found uncertainty sample 54 after 116 steps.
Found uncertainty sample 55 after 742 steps.
Found uncertainty sample 56 after 1249 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 361 steps.
Found uncertainty sample 59 after 571 steps.
Found uncertainty sample 60 after 197 steps.
Found uncertainty sample 61 after 227 steps.
Found uncertainty sample 62 after 549 steps.
Found uncertainty sample 63 after 40 steps.
Found uncertainty sample 64 after 54 steps.
Found uncertainty sample 65 after 571 steps.
Found uncertainty sample 66 after 1479 steps.
Found uncertainty sample 67 after 2870 steps.
Found uncertainty sample 68 after 11 steps.
Found uncertainty sample 69 after 335 steps.
Found uncertainty sample 70 after 930 steps.
Found uncertainty sample 71 after 14 steps.
Found uncertainty sample 72 after 1545 steps.
Found uncertainty sample 73 after 321 steps.
Found uncertainty sample 74 after 1205 steps.
Found uncertainty sample 75 after 51 steps.
Found uncertainty sample 76 after 252 steps.
Found uncertainty sample 77 after 775 steps.
Found uncertainty sample 78 after 611 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 217 steps.
Found uncertainty sample 81 after 569 steps.
Found uncertainty sample 82 after 30 steps.
Found uncertainty sample 83 after 988 steps.
Found uncertainty sample 84 after 112 steps.
Found uncertainty sample 85 after 388 steps.
Found uncertainty sample 86 after 196 steps.
Found uncertainty sample 87 after 485 steps.
Found uncertainty sample 88 after 504 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 250 steps.
Found uncertainty sample 91 after 196 steps.
Found uncertainty sample 92 after 1470 steps.
Found uncertainty sample 93 after 231 steps.
Found uncertainty sample 94 after 182 steps.
Found uncertainty sample 95 after 180 steps.
Found uncertainty sample 96 after 118 steps.
Found uncertainty sample 97 after 242 steps.
Found uncertainty sample 98 after 483 steps.
Found uncertainty sample 99 after 393 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_084759-dnikayp4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/dnikayp4
Training model 17. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.097021081813389, Training Loss Force: 2.557644641234324, time: 0.7043571472167969
Validation Loss Energy: 5.124776931379536, Validation Loss Force: 6.072291818611069, time: 0.06643462181091309
Test Loss Energy: 16.564787155619594, Test Loss Force: 9.680386360656735, time: 10.070637702941895


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.195391011785013, Training Loss Force: 2.353353518568998, time: 0.7508056163787842
Validation Loss Energy: 1.662775779481529, Validation Loss Force: 2.729826311323335, time: 0.07287335395812988
Test Loss Energy: 15.983001445350665, Test Loss Force: 9.40337222856847, time: 10.0555260181427


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.795386723342542, Training Loss Force: 2.328270552833632, time: 0.7112014293670654
Validation Loss Energy: 1.5072466694431852, Validation Loss Force: 2.6989384267422434, time: 0.06374573707580566
Test Loss Energy: 15.861643897597911, Test Loss Force: 9.447907834443967, time: 10.270816087722778


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.051604696956386, Training Loss Force: 2.3356147075752207, time: 0.6867082118988037
Validation Loss Energy: 1.4466582278343747, Validation Loss Force: 2.7132672976172696, time: 0.06305885314941406
Test Loss Energy: 14.577379569894331, Test Loss Force: 9.863448326682988, time: 10.076430797576904


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5953774929287705, Training Loss Force: 2.3344265146485763, time: 0.688739538192749
Validation Loss Energy: 1.3957678625400165, Validation Loss Force: 2.8368893107263236, time: 0.06346631050109863
Test Loss Energy: 14.08851285017677, Test Loss Force: 9.678674055909077, time: 10.472220182418823


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6273703959195105, Training Loss Force: 2.348633803109263, time: 0.7071268558502197
Validation Loss Energy: 1.2106858251177042, Validation Loss Force: 2.7421785481899605, time: 0.06444096565246582
Test Loss Energy: 15.55462332840078, Test Loss Force: 9.427790700687979, time: 10.25495171546936


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5007371710176225, Training Loss Force: 2.3177136213806873, time: 0.7198724746704102
Validation Loss Energy: 2.2776371578549996, Validation Loss Force: 2.5539437383304566, time: 0.06327056884765625
Test Loss Energy: 16.49724587721548, Test Loss Force: 9.759382262208929, time: 10.153947114944458


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4427098661297766, Training Loss Force: 2.3364210178559373, time: 0.7359180450439453
Validation Loss Energy: 1.780134944524932, Validation Loss Force: 2.799879694650812, time: 0.06470012664794922
Test Loss Energy: 14.099330541639702, Test Loss Force: 10.052598379595196, time: 10.081115484237671


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.966650119790569, Training Loss Force: 2.355100464292712, time: 0.8846476078033447
Validation Loss Energy: 1.941885319165925, Validation Loss Force: 2.7363358211353885, time: 0.09107804298400879
Test Loss Energy: 15.691697358775302, Test Loss Force: 9.812140020728181, time: 10.160619735717773


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6208892435292575, Training Loss Force: 2.3248285939038293, time: 0.7068440914154053
Validation Loss Energy: 1.690016788790616, Validation Loss Force: 2.6157262989015915, time: 0.06481242179870605
Test Loss Energy: 15.059284197183002, Test Loss Force: 9.643109092770397, time: 10.199061393737793


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9307217332158932, Training Loss Force: 2.32513133791103, time: 0.6889896392822266
Validation Loss Energy: 1.5088291233960074, Validation Loss Force: 2.8050437261485963, time: 0.06271052360534668
Test Loss Energy: 15.533846935423087, Test Loss Force: 9.712007752961629, time: 10.330724477767944


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9630868833513375, Training Loss Force: 2.3377428375734515, time: 0.7412149906158447
Validation Loss Energy: 1.719807025816857, Validation Loss Force: 2.6588204607241526, time: 0.0658879280090332
Test Loss Energy: 14.138442412096131, Test Loss Force: 9.723663263316777, time: 10.082050085067749


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7852337896302457, Training Loss Force: 2.309766544380537, time: 0.7318625450134277
Validation Loss Energy: 1.2977402204059132, Validation Loss Force: 2.6081231495793142, time: 0.06285786628723145
Test Loss Energy: 14.335373023932473, Test Loss Force: 9.676297115237617, time: 10.066209316253662


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.565158391331976, Training Loss Force: 2.304876557873441, time: 0.68269944190979
Validation Loss Energy: 1.0927184949694861, Validation Loss Force: 2.54897532167737, time: 0.06518840789794922
Test Loss Energy: 14.845940435086668, Test Loss Force: 9.617523904274652, time: 10.251646041870117


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7448617176313521, Training Loss Force: 2.3104083881936734, time: 0.6796371936798096
Validation Loss Energy: 1.257479105960634, Validation Loss Force: 2.67303855369908, time: 0.06344842910766602
Test Loss Energy: 14.861189018718616, Test Loss Force: 9.714887296367083, time: 10.045165777206421


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.90562203060478, Training Loss Force: 2.298585759769313, time: 0.716017484664917
Validation Loss Energy: 1.951714547607329, Validation Loss Force: 2.8152497664521965, time: 0.06392145156860352
Test Loss Energy: 16.248469685588773, Test Loss Force: 9.86717560300378, time: 10.142808198928833


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9747794654034825, Training Loss Force: 2.2984512827871595, time: 0.7535059452056885
Validation Loss Energy: 2.591720672282835, Validation Loss Force: 2.676252003478537, time: 0.0656280517578125
Test Loss Energy: 16.76152749375622, Test Loss Force: 9.806538243256933, time: 10.364400625228882


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1382768717994507, Training Loss Force: 2.318234206661879, time: 0.7892298698425293
Validation Loss Energy: 1.9526125166055694, Validation Loss Force: 2.666426393410754, time: 0.06643891334533691
Test Loss Energy: 14.349736144469821, Test Loss Force: 10.088425500096092, time: 10.578570127487183


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7490758121886345, Training Loss Force: 2.3241953835807596, time: 0.7063629627227783
Validation Loss Energy: 2.236713352197796, Validation Loss Force: 2.5721159899987693, time: 0.06365656852722168
Test Loss Energy: 16.963784995088645, Test Loss Force: 10.028886750277813, time: 10.181477546691895


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2823700614009685, Training Loss Force: 2.300717103288172, time: 0.7700355052947998
Validation Loss Energy: 1.2544840111124027, Validation Loss Force: 2.751816448167726, time: 0.06347513198852539
Test Loss Energy: 15.331286403533388, Test Loss Force: 9.744782445535266, time: 10.274992942810059

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–†â–…â–‚â–â–…â–‡â–â–…â–ƒâ–…â–â–‚â–ƒâ–ƒâ–†â–ˆâ–‚â–ˆâ–„
wandb:   test_error_force â–„â–â–â–†â–„â–â–…â–ˆâ–…â–ƒâ–„â–„â–„â–ƒâ–„â–†â–…â–ˆâ–‡â–„
wandb:          test_loss â–‚â–â–‚â–…â–„â–‚â–„â–†â–…â–„â–…â–„â–…â–„â–…â–‡â–†â–ˆâ–ˆâ–†
wandb: train_error_energy â–ˆâ–ƒâ–‚â–ƒâ–â–â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–‚â–â–
wandb: valid_error_energy â–ˆâ–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–„â–‚â–ƒâ–
wandb:  valid_error_force â–ˆâ–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–
wandb:         valid_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1406
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 15.33129
wandb:   test_error_force 9.74478
wandb:          test_loss 70.21184
wandb: train_error_energy 2.28237
wandb:  train_error_force 2.30072
wandb:         train_loss -4.74798
wandb: valid_error_energy 1.25448
wandb:  valid_error_force 2.75182
wandb:         valid_loss 8.34371
wandb: 
wandb: ğŸš€ View run al_82_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/dnikayp4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_084759-dnikayp4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 30.861186981201172, Uncertainty Bias: -6.840329170227051
6.866455e-05 0.00955677
-1.4721957 122.10223
(48745, 22, 3)
Found uncertainty sample 0 after 12 steps.
Found uncertainty sample 1 after 1920 steps.
Found uncertainty sample 2 after 1025 steps.
Found uncertainty sample 3 after 2186 steps.
Found uncertainty sample 4 after 170 steps.
Found uncertainty sample 5 after 1557 steps.
Found uncertainty sample 6 after 263 steps.
Found uncertainty sample 7 after 2837 steps.
Found uncertainty sample 8 after 98 steps.
Found uncertainty sample 9 after 1082 steps.
Found uncertainty sample 10 after 1221 steps.
Found uncertainty sample 11 after 653 steps.
Found uncertainty sample 12 after 494 steps.
Found uncertainty sample 13 after 1451 steps.
Found uncertainty sample 14 after 637 steps.
Found uncertainty sample 15 after 66 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 555 steps.
Found uncertainty sample 18 after 131 steps.
Found uncertainty sample 19 after 108 steps.
Found uncertainty sample 20 after 1202 steps.
Found uncertainty sample 21 after 1736 steps.
Found uncertainty sample 22 after 6 steps.
Found uncertainty sample 23 after 839 steps.
Found uncertainty sample 24 after 59 steps.
Found uncertainty sample 25 after 1830 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 2 steps.
Found uncertainty sample 28 after 787 steps.
Found uncertainty sample 29 after 1571 steps.
Found uncertainty sample 30 after 722 steps.
Found uncertainty sample 31 after 973 steps.
Found uncertainty sample 32 after 1236 steps.
Found uncertainty sample 33 after 63 steps.
Found uncertainty sample 34 after 431 steps.
Found uncertainty sample 35 after 1334 steps.
Found uncertainty sample 36 after 1636 steps.
Found uncertainty sample 37 after 12 steps.
Found uncertainty sample 38 after 192 steps.
Found uncertainty sample 39 after 172 steps.
Found uncertainty sample 40 after 2873 steps.
Found uncertainty sample 41 after 892 steps.
Found uncertainty sample 42 after 1679 steps.
Found uncertainty sample 43 after 931 steps.
Found uncertainty sample 44 after 1228 steps.
Found uncertainty sample 45 after 466 steps.
Found uncertainty sample 46 after 174 steps.
Found uncertainty sample 47 after 814 steps.
Found uncertainty sample 48 after 438 steps.
Found uncertainty sample 49 after 158 steps.
Found uncertainty sample 50 after 14 steps.
Found uncertainty sample 51 after 430 steps.
Found uncertainty sample 52 after 252 steps.
Found uncertainty sample 53 after 2385 steps.
Found uncertainty sample 54 after 714 steps.
Found uncertainty sample 55 after 3447 steps.
Found uncertainty sample 56 after 244 steps.
Found uncertainty sample 57 after 348 steps.
Found uncertainty sample 58 after 1021 steps.
Found uncertainty sample 59 after 327 steps.
Found uncertainty sample 60 after 940 steps.
Found uncertainty sample 61 after 1775 steps.
Found uncertainty sample 62 after 3123 steps.
Found uncertainty sample 63 after 1083 steps.
Found uncertainty sample 64 after 1048 steps.
Found uncertainty sample 65 after 365 steps.
Found uncertainty sample 66 after 95 steps.
Found uncertainty sample 67 after 510 steps.
Found uncertainty sample 68 after 16 steps.
Found uncertainty sample 69 after 326 steps.
Found uncertainty sample 70 after 220 steps.
Found uncertainty sample 71 after 473 steps.
Found uncertainty sample 72 after 1290 steps.
Found uncertainty sample 73 after 824 steps.
Found uncertainty sample 74 after 1698 steps.
Found uncertainty sample 75 after 2153 steps.
Found uncertainty sample 76 after 180 steps.
Found uncertainty sample 77 after 264 steps.
Found uncertainty sample 78 after 944 steps.
Found uncertainty sample 79 after 3822 steps.
Found uncertainty sample 80 after 565 steps.
Found uncertainty sample 81 after 244 steps.
Found uncertainty sample 82 after 1831 steps.
Found uncertainty sample 83 after 1057 steps.
Found uncertainty sample 84 after 754 steps.
Found uncertainty sample 85 after 151 steps.
Found uncertainty sample 86 after 1201 steps.
Found uncertainty sample 87 after 156 steps.
Found uncertainty sample 88 after 1075 steps.
Found uncertainty sample 89 after 840 steps.
Found uncertainty sample 90 after 956 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 372 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 750 steps.
Found uncertainty sample 95 after 64 steps.
Found uncertainty sample 96 after 120 steps.
Found uncertainty sample 97 after 3915 steps.
Found uncertainty sample 98 after 303 steps.
Found uncertainty sample 99 after 830 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_090355-5f5zv4rg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/5f5zv4rg
Training model 18. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.3595838261446747, Training Loss Force: 2.569918063129268, time: 0.7727348804473877
Validation Loss Energy: 3.1756932753986304, Validation Loss Force: 4.792948244705277, time: 0.06578350067138672
Test Loss Energy: 14.733868251341075, Test Loss Force: 9.831693468124158, time: 10.0657479763031


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.3638601752481145, Training Loss Force: 2.34101981417113, time: 0.7437431812286377
Validation Loss Energy: 4.953505502395103, Validation Loss Force: 4.5120919769056504, time: 0.06854081153869629
Test Loss Energy: 17.423952478485944, Test Loss Force: 9.886713563818947, time: 10.060871601104736


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6644102314175675, Training Loss Force: 2.306649386516548, time: 0.7508342266082764
Validation Loss Energy: 1.299709561999785, Validation Loss Force: 2.7280764658400622, time: 0.06468701362609863
Test Loss Energy: 15.636402328473064, Test Loss Force: 9.63950305105601, time: 10.31041145324707


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4867728135453246, Training Loss Force: 2.3257349085804213, time: 0.8048930168151855
Validation Loss Energy: 2.1238186478629593, Validation Loss Force: 2.5588442408940355, time: 0.06435513496398926
Test Loss Energy: 16.614450647728294, Test Loss Force: 9.713512231618678, time: 10.119831323623657


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7416124064906446, Training Loss Force: 2.318262402088645, time: 0.7583820819854736
Validation Loss Energy: 1.127226868528791, Validation Loss Force: 2.554529135515101, time: 0.06758975982666016
Test Loss Energy: 15.890464130699945, Test Loss Force: 9.628504846029957, time: 10.122604131698608


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4501429833863995, Training Loss Force: 2.314144704751679, time: 0.8037323951721191
Validation Loss Energy: 1.595163963339151, Validation Loss Force: 2.718037093392189, time: 0.0701746940612793
Test Loss Energy: 14.114378074851595, Test Loss Force: 9.663273245856196, time: 10.25059986114502


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5572280365101177, Training Loss Force: 2.2996329206485555, time: 0.8461434841156006
Validation Loss Energy: 1.1843297586618209, Validation Loss Force: 2.579986119627014, time: 0.06408858299255371
Test Loss Energy: 14.736240043808616, Test Loss Force: 9.956992488258011, time: 10.135697364807129


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0137030191023397, Training Loss Force: 2.3120151207282325, time: 0.7302770614624023
Validation Loss Energy: 4.5583881210466535, Validation Loss Force: 4.708165965382115, time: 0.06530070304870605
Test Loss Energy: 17.233265546807246, Test Loss Force: 10.159231411289337, time: 10.072080612182617


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5147529221546736, Training Loss Force: 2.3021762760591913, time: 0.9548237323760986
Validation Loss Energy: 2.9203815563525533, Validation Loss Force: 2.7764743840494774, time: 0.06561851501464844
Test Loss Energy: 17.413470758624193, Test Loss Force: 9.948937265193665, time: 10.09022569656372


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7473802124840745, Training Loss Force: 2.3180575843755222, time: 0.7542951107025146
Validation Loss Energy: 1.3535688863513713, Validation Loss Force: 2.704460398892107, time: 0.06457805633544922
Test Loss Energy: 16.1799075052906, Test Loss Force: 9.849678088977331, time: 10.091991662979126


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.797119495550611, Training Loss Force: 2.2881563538864986, time: 0.7711877822875977
Validation Loss Energy: 1.1555870964662405, Validation Loss Force: 2.6377302412330295, time: 0.06443452835083008
Test Loss Energy: 15.16144462879523, Test Loss Force: 9.680109854541389, time: 10.735214948654175


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7147200887732086, Training Loss Force: 2.295480505875391, time: 0.7487025260925293
Validation Loss Energy: 1.2741380702795784, Validation Loss Force: 2.5739231727871195, time: 0.06407380104064941
Test Loss Energy: 15.865918203227634, Test Loss Force: 9.940322198269333, time: 10.10948920249939


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3040628942227876, Training Loss Force: 2.2896085452045427, time: 0.7670671939849854
Validation Loss Energy: 3.3443257966673867, Validation Loss Force: 2.504495601094273, time: 0.07336258888244629
Test Loss Energy: 13.814494175356998, Test Loss Force: 9.96736317665663, time: 10.078556537628174


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.4074839532654444, Training Loss Force: 2.299280506455174, time: 0.7669281959533691
Validation Loss Energy: 2.945937405565258, Validation Loss Force: 2.624879448148672, time: 0.06568622589111328
Test Loss Energy: 17.618960231495528, Test Loss Force: 10.117380118108018, time: 10.191995859146118


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0022269107070887, Training Loss Force: 2.270866440553028, time: 0.7612795829772949
Validation Loss Energy: 1.4474741989196271, Validation Loss Force: 2.5543383080570408, time: 0.06545615196228027
Test Loss Energy: 16.556560409696072, Test Loss Force: 9.682767899271191, time: 10.081672430038452


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5209335804328599, Training Loss Force: 2.3051357953659246, time: 0.7687370777130127
Validation Loss Energy: 1.1517739986768, Validation Loss Force: 2.5680686442678127, time: 0.06471538543701172
Test Loss Energy: 15.367561632283687, Test Loss Force: 10.07162351121696, time: 10.065795421600342


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8238381076460164, Training Loss Force: 2.311208622556965, time: 0.7786800861358643
Validation Loss Energy: 3.0081039312449023, Validation Loss Force: 4.638293389401132, time: 0.06595373153686523
Test Loss Energy: 15.109285931885015, Test Loss Force: 10.127593758307755, time: 10.327981233596802


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2375547525732777, Training Loss Force: 2.3093545939704248, time: 0.7379140853881836
Validation Loss Energy: 2.559717437949791, Validation Loss Force: 2.641688296636469, time: 0.06507039070129395
Test Loss Energy: 14.31314741621497, Test Loss Force: 9.805051746007774, time: 10.1552152633667


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.388850714875723, Training Loss Force: 2.2725451858829504, time: 0.7790348529815674
Validation Loss Energy: 3.523450543759547, Validation Loss Force: 2.5525815598302435, time: 0.06687164306640625
Test Loss Energy: 13.795028294059916, Test Loss Force: 9.832050004561648, time: 10.156424522399902


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6941230080068734, Training Loss Force: 2.2896032011450407, time: 0.7622945308685303
Validation Loss Energy: 1.711382450015252, Validation Loss Force: 2.5754974436488287, time: 0.06516456604003906
Test Loss Energy: 16.41624319271885, Test Loss Force: 9.699313606455625, time: 10.30354619026184

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–„â–†â–…â–‚â–ƒâ–‡â–ˆâ–…â–„â–…â–â–ˆâ–†â–„â–ƒâ–‚â–â–†
wandb:   test_error_force â–„â–„â–â–‚â–â–â–…â–ˆâ–…â–„â–‚â–…â–…â–‡â–‚â–‡â–ˆâ–ƒâ–„â–‚
wandb:          test_loss â–‚â–ƒâ–â–ƒâ–â–â–…â–‡â–†â–„â–ƒâ–†â–†â–ˆâ–„â–‡â–‡â–„â–…â–„
wandb: train_error_energy â–ˆâ–ˆâ–ƒâ–‚â–„â–‚â–ƒâ–†â–‚â–„â–„â–„â–â–ˆâ–…â–‚â–„â–‡â–ˆâ–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–‚â–‚â–â–
wandb: valid_error_energy â–…â–ˆâ–â–ƒâ–â–‚â–â–‡â–„â–â–â–â–…â–„â–‚â–â–„â–„â–…â–‚
wandb:  valid_error_force â–ˆâ–‡â–‚â–â–â–‚â–â–ˆâ–‚â–‚â–â–â–â–â–â–â–ˆâ–â–â–
wandb:         valid_loss â–ˆâ–‡â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–ˆâ–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1496
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 16.41624
wandb:   test_error_force 9.69931
wandb:          test_loss 72.17589
wandb: train_error_energy 1.69412
wandb:  train_error_force 2.2896
wandb:         train_loss -4.82681
wandb: valid_error_energy 1.71138
wandb:  valid_error_force 2.5755
wandb:         valid_loss 6.30528
wandb: 
wandb: ğŸš€ View run al_82_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/5f5zv4rg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_090355-5f5zv4rg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 27.16849708557129, Uncertainty Bias: -5.906808853149414
6.1035156e-05 0.038749695
-1.117963 112.864456
(48745, 22, 3)
Found uncertainty sample 0 after 23 steps.
Found uncertainty sample 1 after 235 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 232 steps.
Found uncertainty sample 5 after 2229 steps.
Found uncertainty sample 6 after 1154 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 115 steps.
Found uncertainty sample 9 after 214 steps.
Found uncertainty sample 10 after 2429 steps.
Found uncertainty sample 11 after 3107 steps.
Found uncertainty sample 12 after 461 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 40 steps.
Found uncertainty sample 15 after 974 steps.
Found uncertainty sample 16 after 1517 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1347 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 414 steps.
Found uncertainty sample 21 after 2677 steps.
Found uncertainty sample 22 after 120 steps.
Found uncertainty sample 23 after 2869 steps.
Found uncertainty sample 24 after 215 steps.
Found uncertainty sample 25 after 3240 steps.
Found uncertainty sample 26 after 77 steps.
Found uncertainty sample 27 after 504 steps.
Found uncertainty sample 28 after 354 steps.
Found uncertainty sample 29 after 1396 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3250 steps.
Found uncertainty sample 32 after 732 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 250 steps.
Found uncertainty sample 35 after 3222 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 238 steps.
Found uncertainty sample 40 after 1757 steps.
Found uncertainty sample 41 after 1656 steps.
Found uncertainty sample 42 after 3521 steps.
Found uncertainty sample 43 after 168 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 54 steps.
Found uncertainty sample 46 after 2741 steps.
Found uncertainty sample 47 after 966 steps.
Found uncertainty sample 48 after 100 steps.
Found uncertainty sample 49 after 139 steps.
Found uncertainty sample 50 after 1479 steps.
Found uncertainty sample 51 after 767 steps.
Found uncertainty sample 52 after 1462 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 198 steps.
Found uncertainty sample 55 after 266 steps.
Found uncertainty sample 56 after 1014 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 18 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1580 steps.
Found uncertainty sample 63 after 1079 steps.
Found uncertainty sample 64 after 534 steps.
Found uncertainty sample 65 after 1245 steps.
Found uncertainty sample 66 after 1336 steps.
Found uncertainty sample 67 after 1932 steps.
Found uncertainty sample 68 after 3945 steps.
Found uncertainty sample 69 after 1553 steps.
Found uncertainty sample 70 after 52 steps.
Found uncertainty sample 71 after 389 steps.
Found uncertainty sample 72 after 1624 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1495 steps.
Found uncertainty sample 75 after 1865 steps.
Found uncertainty sample 76 after 107 steps.
Found uncertainty sample 77 after 437 steps.
Found uncertainty sample 78 after 39 steps.
Found uncertainty sample 79 after 260 steps.
Found uncertainty sample 80 after 1379 steps.
Found uncertainty sample 81 after 23 steps.
Found uncertainty sample 82 after 785 steps.
Found uncertainty sample 83 after 912 steps.
Found uncertainty sample 84 after 2394 steps.
Found uncertainty sample 85 after 2251 steps.
Found uncertainty sample 86 after 796 steps.
Found uncertainty sample 87 after 1218 steps.
Found uncertainty sample 88 after 810 steps.
Found uncertainty sample 89 after 3738 steps.
Found uncertainty sample 90 after 3971 steps.
Found uncertainty sample 91 after 1263 steps.
Found uncertainty sample 92 after 3333 steps.
Found uncertainty sample 93 after 500 steps.
Found uncertainty sample 94 after 1201 steps.
Found uncertainty sample 95 after 3343 steps.
Found uncertainty sample 96 after 795 steps.
Found uncertainty sample 97 after 230 steps.
Found uncertainty sample 98 after 719 steps.
Found uncertainty sample 99 after 435 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_092723-73ci7ci6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/73ci7ci6
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)
Training model 19. Added 82 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.215198769932884, Training Loss Force: 2.4568910886788613, time: 0.8134260177612305
Validation Loss Energy: 1.597835380750133, Validation Loss Force: 2.71242850294456, time: 0.0688784122467041
Test Loss Energy: 15.076992372542799, Test Loss Force: 10.166692921467373, time: 10.289869785308838


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.3723449945610446, Training Loss Force: 2.3263689862622656, time: 0.8211410045623779
Validation Loss Energy: 4.070222313670765, Validation Loss Force: 2.793733246881194, time: 0.06631851196289062
Test Loss Energy: 18.038110747845806, Test Loss Force: 10.502285560752114, time: 10.243311405181885


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8325452171223668, Training Loss Force: 2.3229090105645858, time: 0.8240692615509033
Validation Loss Energy: 2.4751318868170564, Validation Loss Force: 2.618767180092954, time: 0.07547163963317871
Test Loss Energy: 14.199455973113732, Test Loss Force: 9.860229416846229, time: 10.428531646728516


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6305932085317003, Training Loss Force: 2.3315659082195945, time: 0.7883749008178711
Validation Loss Energy: 1.6677501525342695, Validation Loss Force: 2.7210714058437464, time: 0.06859278678894043
Test Loss Energy: 16.518248203598834, Test Loss Force: 10.371686273491896, time: 10.828914880752563


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4944581969993902, Training Loss Force: 2.2653103943386683, time: 0.79152512550354
Validation Loss Energy: 3.3637570196867754, Validation Loss Force: 2.5762164423210296, time: 0.06906533241271973
Test Loss Energy: 17.193110586817042, Test Loss Force: 10.174423187475508, time: 10.311239242553711


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5941371067591732, Training Loss Force: 2.280287940516229, time: 0.8499124050140381
Validation Loss Energy: 1.3231438752573768, Validation Loss Force: 2.931325856209477, time: 0.06742739677429199
Test Loss Energy: 16.517413126684794, Test Loss Force: 10.146581364932297, time: 10.4709153175354


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.347765003929306, Training Loss Force: 2.352712919476387, time: 0.7946860790252686
Validation Loss Energy: 1.4883740119763567, Validation Loss Force: 2.7387307391344144, time: 0.07576584815979004
Test Loss Energy: 16.38486343490892, Test Loss Force: 10.273345944420752, time: 10.33839201927185


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5612545753491205, Training Loss Force: 2.2830473144665437, time: 0.8331952095031738
Validation Loss Energy: 1.2119951753630458, Validation Loss Force: 2.572533828651103, time: 0.06812667846679688
Test Loss Energy: 15.806339760011024, Test Loss Force: 10.483185738204483, time: 10.537896871566772


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7050651682501872, Training Loss Force: 2.2676969132575104, time: 0.7959082126617432
Validation Loss Energy: 2.1923466362062576, Validation Loss Force: 2.608198634419784, time: 0.0675048828125
Test Loss Energy: 17.087181637293938, Test Loss Force: 9.883159698964743, time: 10.326058626174927


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9703178600218605, Training Loss Force: 2.317537077338632, time: 0.8627634048461914
Validation Loss Energy: 1.3808235341456458, Validation Loss Force: 2.7873466504376934, time: 0.08208966255187988
Test Loss Energy: 15.826016601088059, Test Loss Force: 10.175821740904293, time: 10.314168930053711


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.565225474308897, Training Loss Force: 2.2980020771370926, time: 0.8332748413085938
Validation Loss Energy: 2.6767916421536926, Validation Loss Force: 2.6975980698183313, time: 0.07723879814147949
Test Loss Energy: 17.543421232293845, Test Loss Force: 10.412049092215305, time: 10.500511169433594


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7405781559684825, Training Loss Force: 2.2990409155438125, time: 0.774247407913208
Validation Loss Energy: 2.2612239924395166, Validation Loss Force: 2.6030459590484414, time: 0.07013583183288574
Test Loss Energy: 17.217277100054375, Test Loss Force: 10.258515083443337, time: 10.26567554473877


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2358115421567883, Training Loss Force: 2.273494220259696, time: 0.8278849124908447
Validation Loss Energy: 4.945181127709166, Validation Loss Force: 2.5459375578540504, time: 0.06676006317138672
Test Loss Energy: 13.758728923777298, Test Loss Force: 9.762823626683122, time: 10.313910007476807


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9379257763325912, Training Loss Force: 2.2980046333788877, time: 0.7761716842651367
Validation Loss Energy: 2.8262773445696974, Validation Loss Force: 2.760108313158358, time: 0.0679931640625
Test Loss Energy: 14.828028215514326, Test Loss Force: 10.337010368796747, time: 10.511257648468018


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5994566759954254, Training Loss Force: 2.2844635703955367, time: 0.8659770488739014
Validation Loss Energy: 3.421237501024012, Validation Loss Force: 2.637482410473612, time: 0.07948517799377441
Test Loss Energy: 18.790177397030636, Test Loss Force: 10.299011928008067, time: 10.332480669021606


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.128771069077948, Training Loss Force: 2.260456226997666, time: 0.8398590087890625
Validation Loss Energy: 2.090424956048169, Validation Loss Force: 2.660088784179358, time: 0.06601452827453613
Test Loss Energy: 17.07385379538315, Test Loss Force: 10.18702256319507, time: 10.480066061019897


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7191304233500406, Training Loss Force: 2.3085347419040882, time: 0.843207597732544
Validation Loss Energy: 5.307388565962352, Validation Loss Force: 2.5909991129154566, time: 0.06685352325439453
Test Loss Energy: 13.548201588292914, Test Loss Force: 9.870499729258121, time: 10.799794912338257


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5179152737237698, Training Loss Force: 2.283446132720432, time: 0.8394985198974609
Validation Loss Energy: 1.3092007786776705, Validation Loss Force: 2.6236437457233457, time: 0.06813693046569824
Test Loss Energy: 15.313652448113416, Test Loss Force: 10.447059933274986, time: 10.315871000289917


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5996082068026118, Training Loss Force: 2.2846436607473803, time: 0.777324914932251
Validation Loss Energy: 1.1464774512035456, Validation Loss Force: 2.5492515427528932, time: 0.07384133338928223
Test Loss Energy: 16.007724160466775, Test Loss Force: 9.868600610926068, time: 10.426851034164429


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.92110002168989, Training Loss Force: 2.245892727416884, time: 0.8068289756774902
Validation Loss Energy: 3.33751000544511, Validation Loss Force: 3.769160713565932, time: 0.06574773788452148
Test Loss Energy: 17.08042137870743, Test Loss Force: 10.265823392585746, time: 10.330077648162842

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‡â–‚â–…â–†â–…â–…â–„â–†â–„â–†â–†â–â–ƒâ–ˆâ–†â–â–ƒâ–„â–†
wandb:   test_error_force â–…â–ˆâ–‚â–‡â–…â–…â–†â–ˆâ–‚â–…â–‡â–†â–â–†â–†â–…â–‚â–‡â–‚â–†
wandb:          test_loss â–‚â–…â–â–…â–…â–ƒâ–„â–ˆâ–â–…â–‡â–…â–â–†â–†â–†â–‚â–ˆâ–ƒâ–‡
wandb: train_error_energy â–ˆâ–†â–‚â–‚â–â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–„â–„â–„â–‚â–‚â–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–‚â–
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–
wandb: valid_error_energy â–‚â–†â–ƒâ–‚â–…â–â–‚â–â–ƒâ–â–„â–ƒâ–‡â–„â–…â–ƒâ–ˆâ–â–â–…
wandb:  valid_error_force â–‚â–‚â–â–‚â–â–ƒâ–‚â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–ˆ
wandb:         valid_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1569
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 17.08042
wandb:   test_error_force 10.26582
wandb:          test_loss 87.3324
wandb: train_error_energy 1.9211
wandb:  train_error_force 2.24589
wandb:         train_loss -4.91283
wandb: valid_error_energy 3.33751
wandb:  valid_error_force 3.76916
wandb:         valid_loss 65.41023
wandb: 
wandb: ğŸš€ View run al_82_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/73ci7ci6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_092723-73ci7ci6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 25.22751808166504, Uncertainty Bias: -5.391053676605225
8.392334e-05 0.10787964
-1.1009831 107.379005
(48745, 22, 3)
Found uncertainty sample 0 after 1649 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 5 steps.
Found uncertainty sample 3 after 314 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3028 steps.
Found uncertainty sample 6 after 503 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1207 steps.
Found uncertainty sample 9 after 109 steps.
Found uncertainty sample 10 after 2105 steps.
Found uncertainty sample 11 after 3668 steps.
Found uncertainty sample 12 after 2351 steps.
Found uncertainty sample 13 after 558 steps.
Found uncertainty sample 14 after 2707 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 261 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1439 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2700 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2846 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3157 steps.
Found uncertainty sample 27 after 3365 steps.
Found uncertainty sample 28 after 2145 steps.
Found uncertainty sample 29 after 92 steps.
Found uncertainty sample 30 after 3202 steps.
Found uncertainty sample 31 after 1627 steps.
Found uncertainty sample 32 after 129 steps.
Found uncertainty sample 33 after 3259 steps.
Found uncertainty sample 34 after 1046 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 713 steps.
Found uncertainty sample 37 after 3127 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1883 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1543 steps.
Found uncertainty sample 43 after 2447 steps.
Found uncertainty sample 44 after 1693 steps.
Found uncertainty sample 45 after 170 steps.
Found uncertainty sample 46 after 1679 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1205 steps.
Found uncertainty sample 49 after 2062 steps.
Found uncertainty sample 50 after 2251 steps.
Found uncertainty sample 51 after 2153 steps.
Found uncertainty sample 52 after 3874 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1811 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1036 steps.
Found uncertainty sample 57 after 448 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1499 steps.
Found uncertainty sample 60 after 2137 steps.
Found uncertainty sample 61 after 1395 steps.
Found uncertainty sample 62 after 1565 steps.
Found uncertainty sample 63 after 2595 steps.
Found uncertainty sample 64 after 1243 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3996 steps.
Found uncertainty sample 67 after 742 steps.
Found uncertainty sample 68 after 1301 steps.
Found uncertainty sample 69 after 1745 steps.
Found uncertainty sample 70 after 33 steps.
Found uncertainty sample 71 after 886 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3384 steps.
Found uncertainty sample 74 after 448 steps.
Found uncertainty sample 75 after 2789 steps.
Found uncertainty sample 76 after 2908 steps.
Found uncertainty sample 77 after 2076 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3452 steps.
Found uncertainty sample 80 after 2227 steps.
Found uncertainty sample 81 after 871 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1666 steps.
Found uncertainty sample 85 after 1402 steps.
Found uncertainty sample 86 after 283 steps.
Found uncertainty sample 87 after 3125 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1685 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1025 steps.
Found uncertainty sample 92 after 2254 steps.
Found uncertainty sample 93 after 1138 steps.
Found uncertainty sample 94 after 395 steps.
Found uncertainty sample 95 after 2603 steps.
Found uncertainty sample 96 after 402 steps.
Found uncertainty sample 97 after 2686 steps.
Found uncertainty sample 98 after 763 steps.
Found uncertainty sample 99 after 3367 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_095615-591oolns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_82_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/591oolns
Training model 20. Added 75 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8609632200799258, Training Loss Force: 2.435359235682261, time: 0.8363633155822754
Validation Loss Energy: 3.082430919989241, Validation Loss Force: 2.6038909884572377, time: 0.07836461067199707
Test Loss Energy: 14.119552905802957, Test Loss Force: 9.814657464464917, time: 10.229228258132935


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1142371891610625, Training Loss Force: 2.296057771263001, time: 0.8248920440673828
Validation Loss Energy: 1.3372224103450936, Validation Loss Force: 2.5827476623748105, time: 0.06954121589660645
Test Loss Energy: 15.340485446523573, Test Loss Force: 10.112462114449054, time: 10.168227910995483


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7394727526331741, Training Loss Force: 2.2897514256361124, time: 0.8398511409759521
Validation Loss Energy: 3.976500647480613, Validation Loss Force: 3.5355915789412595, time: 0.06718730926513672
Test Loss Energy: 17.956377396114245, Test Loss Force: 10.261178630782398, time: 10.351508378982544


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0266893429876065, Training Loss Force: 2.298813130659899, time: 0.8687376976013184
Validation Loss Energy: 2.0089342833746846, Validation Loss Force: 2.7452534977606504, time: 0.07033634185791016
Test Loss Energy: 14.636638595969817, Test Loss Force: 9.894840549301861, time: 10.207494974136353


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4999407737959989, Training Loss Force: 2.300586146580646, time: 0.8498456478118896
Validation Loss Energy: 2.020610496714273, Validation Loss Force: 2.5397864340323677, time: 0.07043862342834473
Test Loss Energy: 17.176346458687558, Test Loss Force: 9.653984267847196, time: 10.258440971374512


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3535854559332976, Training Loss Force: 2.282707497027536, time: 0.8167693614959717
Validation Loss Energy: 1.6152494439765617, Validation Loss Force: 2.5540952646842605, time: 0.06801867485046387
Test Loss Energy: 16.802364478848137, Test Loss Force: 10.307782480949836, time: 10.47462248802185


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3287546153186836, Training Loss Force: 2.276345103007358, time: 0.8184163570404053
Validation Loss Energy: 2.74067297075977, Validation Loss Force: 2.6709609392330007, time: 0.06896400451660156
Test Loss Energy: 17.294852372455555, Test Loss Force: 10.775021596006145, time: 10.232219457626343


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9210220477081152, Training Loss Force: 2.2726662789950107, time: 0.8451752662658691
Validation Loss Energy: 1.6919651438174839, Validation Loss Force: 2.646738878204403, time: 0.06756377220153809
Test Loss Energy: 15.017519565434311, Test Loss Force: 10.131176483881209, time: 10.496569633483887


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3199376825651326, Training Loss Force: 2.278712307261914, time: 0.8486087322235107
Validation Loss Energy: 2.26501916536271, Validation Loss Force: 3.5871103165654263, time: 0.06695914268493652
Test Loss Energy: 16.43798377807262, Test Loss Force: 10.203655234921964, time: 10.305039882659912


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4320179852039858, Training Loss Force: 2.2748105700239987, time: 0.8497741222381592
Validation Loss Energy: 1.7680508569772901, Validation Loss Force: 2.653667451349092, time: 0.07778525352478027
Test Loss Energy: 16.82844403948012, Test Loss Force: 10.375801124696991, time: 10.318043947219849


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.017876963175775, Training Loss Force: 2.2748938654129716, time: 0.8444738388061523
Validation Loss Energy: 4.038337650657927, Validation Loss Force: 3.5059470788710287, time: 0.06782221794128418
Test Loss Energy: 17.98649554551756, Test Loss Force: 10.619316975757075, time: 10.880716800689697


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6721220342633165, Training Loss Force: 2.237566179308799, time: 0.842498779296875
Validation Loss Energy: 3.743384310564185, Validation Loss Force: 2.543087392786174, time: 0.06939530372619629
Test Loss Energy: 14.275489722173141, Test Loss Force: 9.923263857747077, time: 10.274760246276855


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5945656417093206, Training Loss Force: 2.241504299400529, time: 0.8892052173614502
Validation Loss Energy: 2.546187503970354, Validation Loss Force: 2.5484001672734387, time: 0.06790900230407715
Test Loss Energy: 14.952907712987566, Test Loss Force: 10.000209193305388, time: 10.305559635162354


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7276678954061002, Training Loss Force: 2.242316307403194, time: 0.8406271934509277
Validation Loss Energy: 2.0920671409993865, Validation Loss Force: 2.5597749979240136, time: 0.06905174255371094
Test Loss Energy: 17.425700601489304, Test Loss Force: 10.345570176467064, time: 10.480387449264526


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6612469952160238, Training Loss Force: 2.2494085958963765, time: 0.883033037185669
Validation Loss Energy: 1.2177591888745327, Validation Loss Force: 2.655295608144116, time: 0.06955170631408691
Test Loss Energy: 15.709163633836125, Test Loss Force: 10.19350757940107, time: 10.307251930236816


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.620865718650775, Training Loss Force: 2.257255779897344, time: 0.8700635433197021
Validation Loss Energy: 1.1470804949180045, Validation Loss Force: 2.5201513574098824, time: 0.06678390502929688
Test Loss Energy: 16.35133113096789, Test Loss Force: 9.992275988269782, time: 10.410912275314331


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3428163121227645, Training Loss Force: 2.253855887529162, time: 0.8812246322631836
Validation Loss Energy: 1.0784579556886167, Validation Loss Force: 2.4435388090508114, time: 0.06840085983276367
Test Loss Energy: 16.047701516748248, Test Loss Force: 10.383991222310188, time: 10.25369119644165


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2827930765314761, Training Loss Force: 2.2710870537448047, time: 0.8883543014526367
Validation Loss Energy: 1.9935551934728901, Validation Loss Force: 2.615005184872504, time: 0.07638144493103027
Test Loss Energy: 17.453442178616182, Test Loss Force: 10.451992761336355, time: 10.29433298110962


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5592751352812706, Training Loss Force: 2.2560632624400303, time: 0.8279166221618652
Validation Loss Energy: 3.27818727092904, Validation Loss Force: 2.4822117636464034, time: 0.07064366340637207
Test Loss Energy: 18.327708465962996, Test Loss Force: 10.068875177063, time: 10.421584606170654


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2455381522376623, Training Loss Force: 2.223867564887123, time: 0.8557796478271484
Validation Loss Energy: 4.651944344061381, Validation Loss Force: 2.4903704724877707, time: 0.06914281845092773
Test Loss Energy: 19.702136627761142, Test Loss Force: 10.498774835421871, time: 10.266340494155884

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–†â–‚â–…â–„â–…â–‚â–„â–„â–†â–â–‚â–…â–ƒâ–„â–ƒâ–…â–†â–ˆ
wandb:   test_error_force â–‚â–„â–…â–ƒâ–â–…â–ˆâ–„â–„â–†â–‡â–ƒâ–ƒâ–…â–„â–ƒâ–†â–†â–„â–†
wandb:          test_loss â–â–„â–…â–‚â–â–…â–ˆâ–„â–…â–†â–‡â–ƒâ–„â–†â–…â–„â–‡â–†â–„â–ˆ
wandb: train_error_energy â–ˆâ–ƒâ–‚â–ƒâ–‚â–â–â–ƒâ–â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–„
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–…â–‚â–‡â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–‚â–‡â–†â–„â–ƒâ–â–â–â–ƒâ–…â–ˆ
wandb:  valid_error_force â–‚â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–ˆâ–‚â–ˆâ–‚â–‚â–‚â–‚â–â–â–‚â–â–
wandb:         valid_loss â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1636
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 19.70214
wandb:   test_error_force 10.49877
wandb:          test_loss 95.98381
wandb: train_error_energy 2.24554
wandb:  train_error_force 2.22387
wandb:         train_loss -4.94915
wandb: valid_error_energy 4.65194
wandb:  valid_error_force 2.49037
wandb:         valid_loss 4.22774
wandb: 
wandb: ğŸš€ View run al_82_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/591oolns
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_095615-591oolns/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 20.278522491455078, Uncertainty Bias: -4.27678108215332
1.5258789e-05 0.0058460236
-0.30403423 98.69406
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2611 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2249 steps.
Found uncertainty sample 5 after 890 steps.
Found uncertainty sample 6 after 3054 steps.
Found uncertainty sample 7 after 696 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2924 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2536 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1977 steps.
Found uncertainty sample 17 after 2927 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3055 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1036 steps.
Found uncertainty sample 23 after 2771 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 177 steps.
Found uncertainty sample 26 after 1091 steps.
Did not find any uncertainty samples for sample 27.
