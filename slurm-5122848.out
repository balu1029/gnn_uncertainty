wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_164835-fl9zr4hd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/fl9zr4hd
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
54
Uncertainty Slope: 0.6569392085075378, Uncertainty Bias: 0.02670060098171234
0.0004043579 0.0067281723
0.4407349 2.8812606

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 12.431827418372507, Test Loss Force: 10.721727356400123, time: 14.565014839172363

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.047 MB uploadedwandb: | 0.039 MB of 0.050 MB uploadedwandb: / 0.039 MB of 0.050 MB uploadedwandb: - 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.43183
wandb:   test_error_force 10.72173
wandb:          test_loss 6.0442
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_55 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/fl9zr4hd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_164835-fl9zr4hd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 520 steps.
Found uncertainty sample 1 after 251 steps.
Found uncertainty sample 2 after 268 steps.
Found uncertainty sample 6 after 69 steps.
Found uncertainty sample 7 after 3085 steps.
Found uncertainty sample 8 after 3286 steps.
Found uncertainty sample 9 after 846 steps.
Found uncertainty sample 10 after 3583 steps.
Found uncertainty sample 11 after 1274 steps.
Found uncertainty sample 12 after 1155 steps.
Found uncertainty sample 13 after 1457 steps.
Found uncertainty sample 14 after 3351 steps.
Found uncertainty sample 15 after 1272 steps.
Found uncertainty sample 16 after 1093 steps.
Found uncertainty sample 17 after 658 steps.
Found uncertainty sample 21 after 134 steps.
Found uncertainty sample 23 after 460 steps.
Found uncertainty sample 24 after 45 steps.
Found uncertainty sample 25 after 226 steps.
Found uncertainty sample 26 after 3470 steps.
Found uncertainty sample 28 after 3094 steps.
Found uncertainty sample 29 after 2080 steps.
Found uncertainty sample 30 after 2503 steps.
Found uncertainty sample 31 after 1879 steps.
Found uncertainty sample 35 after 3618 steps.
Found uncertainty sample 37 after 2586 steps.
Found uncertainty sample 39 after 50 steps.
Found uncertainty sample 40 after 1893 steps.
Found uncertainty sample 41 after 1318 steps.
Found uncertainty sample 42 after 569 steps.
Found uncertainty sample 43 after 884 steps.
Found uncertainty sample 44 after 1218 steps.
Found uncertainty sample 46 after 2203 steps.
Found uncertainty sample 47 after 2959 steps.
Found uncertainty sample 49 after 1326 steps.
Found uncertainty sample 50 after 2173 steps.
Found uncertainty sample 51 after 1005 steps.
Found uncertainty sample 52 after 919 steps.
Found uncertainty sample 53 after 908 steps.
Found uncertainty sample 56 after 3103 steps.
Found uncertainty sample 57 after 1178 steps.
Found uncertainty sample 59 after 852 steps.
Found uncertainty sample 61 after 633 steps.
Found uncertainty sample 63 after 451 steps.
Found uncertainty sample 64 after 969 steps.
Found uncertainty sample 65 after 120 steps.
Found uncertainty sample 66 after 3652 steps.
Found uncertainty sample 67 after 313 steps.
Found uncertainty sample 68 after 559 steps.
Found uncertainty sample 70 after 2428 steps.
Found uncertainty sample 71 after 1263 steps.
Found uncertainty sample 72 after 3949 steps.
Found uncertainty sample 73 after 13 steps.
Found uncertainty sample 74 after 840 steps.
Found uncertainty sample 76 after 918 steps.
Found uncertainty sample 79 after 84 steps.
Found uncertainty sample 81 after 976 steps.
Found uncertainty sample 83 after 3850 steps.
Found uncertainty sample 84 after 841 steps.
Found uncertainty sample 86 after 68 steps.
Found uncertainty sample 87 after 2893 steps.
Found uncertainty sample 88 after 3292 steps.
Found uncertainty sample 91 after 978 steps.
Found uncertainty sample 92 after 1436 steps.
Found uncertainty sample 93 after 1574 steps.
Found uncertainty sample 94 after 894 steps.
Found uncertainty sample 95 after 726 steps.
Found uncertainty sample 96 after 3859 steps.
Found uncertainty sample 99 after 2399 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_183550-qgol9mdl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qgol9mdl
Training model 0. Added 69 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.384761372059645, Training Loss Force: 3.035181306565375, time: 1.0143578052520752
Validation Loss Energy: 1.23124592503966, Validation Loss Force: 2.776435750952659, time: 0.07066679000854492
Test Loss Energy: 11.938175937414961, Test Loss Force: 10.360448131385938, time: 15.990667819976807


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.408830849011686, Training Loss Force: 2.630320529546023, time: 0.9684827327728271
Validation Loss Energy: 1.8398712869795633, Validation Loss Force: 2.6912329609474126, time: 0.06943774223327637
Test Loss Energy: 11.549434164195695, Test Loss Force: 10.370537874275977, time: 16.124412298202515


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4683700055670903, Training Loss Force: 2.5440805796470665, time: 0.9457859992980957
Validation Loss Energy: 1.1201001755115128, Validation Loss Force: 2.660498384073292, time: 0.07200145721435547
Test Loss Energy: 11.874220313091604, Test Loss Force: 10.18820005629165, time: 16.02809190750122


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3513870730337545, Training Loss Force: 2.534016363095412, time: 0.975085973739624
Validation Loss Energy: 1.1878970297141571, Validation Loss Force: 2.655480312200663, time: 0.06613516807556152
Test Loss Energy: 11.69157352359729, Test Loss Force: 10.26547744633947, time: 16.214299201965332


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4907043456143072, Training Loss Force: 2.516585797611168, time: 0.9612009525299072
Validation Loss Energy: 1.420920958935025, Validation Loss Force: 2.6584587346965933, time: 0.07127046585083008
Test Loss Energy: 11.470890898887468, Test Loss Force: 10.189008888557453, time: 16.117172718048096


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3720119964799429, Training Loss Force: 2.488577606500803, time: 0.9681093692779541
Validation Loss Energy: 1.1251696839568506, Validation Loss Force: 2.636795030820133, time: 0.07240176200866699
Test Loss Energy: 11.823122519246837, Test Loss Force: 10.166487133207484, time: 16.289467334747314


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4264660763055563, Training Loss Force: 2.4894016885158714, time: 0.9687294960021973
Validation Loss Energy: 1.830544233129513, Validation Loss Force: 2.6306259821322033, time: 0.06982016563415527
Test Loss Energy: 12.363232749363558, Test Loss Force: 10.20959926069954, time: 16.28991389274597


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5525817364388392, Training Loss Force: 2.4956354926902384, time: 0.9885938167572021
Validation Loss Energy: 1.1241348291011513, Validation Loss Force: 2.630725737909579, time: 0.07001948356628418
Test Loss Energy: 11.6209272533578, Test Loss Force: 10.186498989923923, time: 16.29477596282959


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3325915498084766, Training Loss Force: 2.5142683643514223, time: 0.9870195388793945
Validation Loss Energy: 1.3514064349406936, Validation Loss Force: 2.6477913239226307, time: 0.07340407371520996
Test Loss Energy: 11.422407753770997, Test Loss Force: 10.186573009344933, time: 16.4256374835968


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4927432218342491, Training Loss Force: 2.5268648486536165, time: 0.9593238830566406
Validation Loss Energy: 1.1297556663518065, Validation Loss Force: 2.6272055613816065, time: 0.06815958023071289
Test Loss Energy: 11.556505879792812, Test Loss Force: 10.113127006850407, time: 16.37386655807495


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.19493788377568, Training Loss Force: 2.4800906627208255, time: 0.9686410427093506
Validation Loss Energy: 1.3417948099221475, Validation Loss Force: 2.6476615078105548, time: 0.0684194564819336
Test Loss Energy: 11.35192139961572, Test Loss Force: 10.18818443914045, time: 16.50856113433838


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.636143265157474, Training Loss Force: 2.4701622743481866, time: 0.983985185623169
Validation Loss Energy: 1.2714954885229939, Validation Loss Force: 2.707210362844315, time: 0.07079243659973145
Test Loss Energy: 11.393385374390284, Test Loss Force: 10.091116462553664, time: 16.569475650787354


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6951746535901084, Training Loss Force: 2.5387485772667016, time: 0.9829151630401611
Validation Loss Energy: 1.1525549828724986, Validation Loss Force: 2.6067182186030826, time: 0.0775139331817627
Test Loss Energy: 11.647920545573657, Test Loss Force: 10.059459307951803, time: 17.218719244003296


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.403195756812189, Training Loss Force: 2.4968713064501378, time: 0.9435489177703857
Validation Loss Energy: 2.590349587016785, Validation Loss Force: 2.6290439178503866, time: 0.0749976634979248
Test Loss Energy: 10.944148325323798, Test Loss Force: 10.199874634586854, time: 16.936707973480225


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5188402354181099, Training Loss Force: 2.501972310209116, time: 0.9847970008850098
Validation Loss Energy: 1.299055137379903, Validation Loss Force: 2.6208830936521332, time: 0.07159709930419922
Test Loss Energy: 11.674081544822702, Test Loss Force: 10.00309157195358, time: 16.808595180511475


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2161258612071197, Training Loss Force: 2.4745492688732345, time: 0.9664373397827148
Validation Loss Energy: 1.2181379490917559, Validation Loss Force: 2.6342708533818953, time: 0.06904792785644531
Test Loss Energy: 11.613059193619966, Test Loss Force: 10.130868645535672, time: 17.007864713668823


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.159925634680157, Training Loss Force: 2.476292677568789, time: 0.9657096862792969
Validation Loss Energy: 1.1164990587489956, Validation Loss Force: 2.623014260047808, time: 0.07314133644104004
Test Loss Energy: 11.546414849851793, Test Loss Force: 9.977235543164731, time: 16.832149028778076


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4638421006459463, Training Loss Force: 2.4521272528498086, time: 0.9978258609771729
Validation Loss Energy: 1.1928982900662681, Validation Loss Force: 2.614040916136064, time: 0.07172369956970215
Test Loss Energy: 11.536346585790783, Test Loss Force: 10.04971202787659, time: 17.09766411781311


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3875452311597574, Training Loss Force: 2.4652446716189007, time: 0.9824037551879883
Validation Loss Energy: 1.1194770359066337, Validation Loss Force: 2.640970077306279, time: 0.0737605094909668
Test Loss Energy: 11.318794875801833, Test Loss Force: 10.019996613512417, time: 16.962181568145752


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3446203947904143, Training Loss Force: 2.4591652720032235, time: 0.9775345325469971
Validation Loss Energy: 1.6618331653195304, Validation Loss Force: 2.609844493411909, time: 0.07019400596618652
Test Loss Energy: 11.029138121215802, Test Loss Force: 10.050450939698957, time: 17.00000500679016

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–„â–†â–…â–„â–…â–ˆâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–â–…â–„â–„â–„â–ƒâ–
wandb:   test_error_force â–ˆâ–ˆâ–…â–†â–…â–„â–…â–…â–…â–ƒâ–…â–ƒâ–‚â–…â–â–„â–â–‚â–‚â–‚
wandb:          test_loss â–ˆâ–‡â–…â–…â–„â–„â–†â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–â–‚â–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–
wandb: valid_error_energy â–‚â–„â–â–â–‚â–â–„â–â–‚â–â–‚â–‚â–â–ˆâ–‚â–â–â–â–â–„
wandb:  valid_error_force â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–…â–â–‚â–‚â–‚â–‚â–â–‚â–
wandb:         valid_loss â–ˆâ–…â–‚â–‚â–ƒâ–‚â–„â–â–‚â–â–ƒâ–„â–ƒâ–…â–‚â–ƒâ–â–„â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 862
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.02914
wandb:   test_error_force 10.05045
wandb:          test_loss 5.59375
wandb: train_error_energy 1.34462
wandb:  train_error_force 2.45917
wandb:         train_loss 1.10551
wandb: valid_error_energy 1.66183
wandb:  valid_error_force 2.60984
wandb:         valid_loss 1.30574
wandb: 
wandb: ğŸš€ View run al_55_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qgol9mdl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_183550-qgol9mdl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.734303891658783, Uncertainty Bias: 0.014710575342178345
9.536743e-06 0.026553392
0.26015446 3.3277085
Found uncertainty sample 0 after 1723 steps.
Found uncertainty sample 1 after 1377 steps.
Found uncertainty sample 2 after 2881 steps.
Found uncertainty sample 3 after 2169 steps.
Found uncertainty sample 5 after 536 steps.
Found uncertainty sample 14 after 1021 steps.
Found uncertainty sample 15 after 2023 steps.
Found uncertainty sample 16 after 1147 steps.
Found uncertainty sample 19 after 31 steps.
Found uncertainty sample 20 after 38 steps.
Found uncertainty sample 21 after 1316 steps.
Found uncertainty sample 22 after 1359 steps.
Found uncertainty sample 23 after 2058 steps.
Found uncertainty sample 27 after 3092 steps.
Found uncertainty sample 28 after 1605 steps.
Found uncertainty sample 29 after 142 steps.
Found uncertainty sample 30 after 119 steps.
Found uncertainty sample 31 after 1270 steps.
Found uncertainty sample 32 after 1077 steps.
Found uncertainty sample 33 after 41 steps.
Found uncertainty sample 35 after 1580 steps.
Found uncertainty sample 36 after 1392 steps.
Found uncertainty sample 39 after 187 steps.
Found uncertainty sample 40 after 2683 steps.
Found uncertainty sample 41 after 642 steps.
Found uncertainty sample 42 after 248 steps.
Found uncertainty sample 43 after 1053 steps.
Found uncertainty sample 44 after 1791 steps.
Found uncertainty sample 47 after 1646 steps.
Found uncertainty sample 49 after 917 steps.
Found uncertainty sample 50 after 177 steps.
Found uncertainty sample 51 after 3208 steps.
Found uncertainty sample 52 after 1538 steps.
Found uncertainty sample 53 after 2201 steps.
Found uncertainty sample 54 after 656 steps.
Found uncertainty sample 55 after 2438 steps.
Found uncertainty sample 57 after 1950 steps.
Found uncertainty sample 58 after 2661 steps.
Found uncertainty sample 61 after 697 steps.
Found uncertainty sample 62 after 405 steps.
Found uncertainty sample 63 after 86 steps.
Found uncertainty sample 64 after 1103 steps.
Found uncertainty sample 66 after 94 steps.
Found uncertainty sample 68 after 79 steps.
Found uncertainty sample 70 after 3365 steps.
Found uncertainty sample 71 after 3852 steps.
Found uncertainty sample 73 after 37 steps.
Found uncertainty sample 74 after 3337 steps.
Found uncertainty sample 78 after 364 steps.
Found uncertainty sample 79 after 1078 steps.
Found uncertainty sample 81 after 2327 steps.
Found uncertainty sample 82 after 2886 steps.
Found uncertainty sample 83 after 3981 steps.
Found uncertainty sample 84 after 948 steps.
Found uncertainty sample 85 after 370 steps.
Found uncertainty sample 86 after 3060 steps.
Found uncertainty sample 87 after 571 steps.
Found uncertainty sample 89 after 624 steps.
Found uncertainty sample 90 after 3578 steps.
Found uncertainty sample 92 after 181 steps.
Found uncertainty sample 94 after 1268 steps.
Found uncertainty sample 95 after 3862 steps.
Found uncertainty sample 99 after 7 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_203319-afxxun9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/afxxun9s
Training model 1. Added 63 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.1617748509174195, Training Loss Force: 3.157047984244972, time: 1.0437922477722168
Validation Loss Energy: 1.58618265900544, Validation Loss Force: 2.8828653679700555, time: 0.07887816429138184
Test Loss Energy: 10.94842160970655, Test Loss Force: 9.768370172879722, time: 16.235610485076904


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.875188988021413, Training Loss Force: 2.7624023581951556, time: 1.0567450523376465
Validation Loss Energy: 2.584766603520938, Validation Loss Force: 2.7106937989632094, time: 0.07277655601501465
Test Loss Energy: 12.297342085861414, Test Loss Force: 9.771189280847873, time: 16.33895754814148


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7266163270013544, Training Loss Force: 2.676794387126785, time: 1.0218281745910645
Validation Loss Energy: 1.443553384930844, Validation Loss Force: 2.6861997475728607, time: 0.07135725021362305
Test Loss Energy: 11.541231830271736, Test Loss Force: 9.77622425692268, time: 16.211690187454224


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5026454860398966, Training Loss Force: 2.670908581270722, time: 1.0536072254180908
Validation Loss Energy: 1.261581256135132, Validation Loss Force: 2.686286143201481, time: 0.07363343238830566
Test Loss Energy: 10.999834232075898, Test Loss Force: 9.808460770994488, time: 16.33811593055725


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.339796644191248, Training Loss Force: 2.655376617482878, time: 1.0120429992675781
Validation Loss Energy: 2.2685855457384623, Validation Loss Force: 2.6803419903509385, time: 0.07648444175720215
Test Loss Energy: 12.002296849861409, Test Loss Force: 9.719064121874782, time: 16.28484869003296


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6285299846734365, Training Loss Force: 2.6514505842060974, time: 1.0818908214569092
Validation Loss Energy: 1.1714670527781563, Validation Loss Force: 2.7040295340947367, time: 0.07486724853515625
Test Loss Energy: 11.247994905561299, Test Loss Force: 9.75358753434499, time: 16.569846153259277


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6990836998131278, Training Loss Force: 2.681029239474229, time: 1.0745525360107422
Validation Loss Energy: 1.5431095394171688, Validation Loss Force: 2.6746127132262165, time: 0.07333827018737793
Test Loss Energy: 10.862998180225441, Test Loss Force: 9.703626929315584, time: 16.47455334663391


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3277487902884213, Training Loss Force: 2.648004740781633, time: 1.0515751838684082
Validation Loss Energy: 1.6069139358333278, Validation Loss Force: 2.6668678349925563, time: 0.07212305068969727
Test Loss Energy: 11.553817584701761, Test Loss Force: 9.705313395115857, time: 16.657240867614746


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.451560114401869, Training Loss Force: 2.6600616530956636, time: 1.05928635597229
Validation Loss Energy: 1.1535622267541028, Validation Loss Force: 2.6699622681135144, time: 0.07344222068786621
Test Loss Energy: 11.146958629041647, Test Loss Force: 9.711858259192411, time: 16.43461847305298


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6709928276391297, Training Loss Force: 2.650577260459276, time: 1.0608186721801758
Validation Loss Energy: 1.1609568464212188, Validation Loss Force: 2.672243068175253, time: 0.0764927864074707
Test Loss Energy: 10.977697146419072, Test Loss Force: 9.685623884047844, time: 16.30374312400818


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7742601588720306, Training Loss Force: 2.6687412964039283, time: 1.0687003135681152
Validation Loss Energy: 1.371827422313731, Validation Loss Force: 2.696720864717949, time: 0.07450127601623535
Test Loss Energy: 11.368397876514491, Test Loss Force: 9.696691393971212, time: 16.600988149642944


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7119483425344493, Training Loss Force: 2.6395058280373975, time: 1.0591349601745605
Validation Loss Energy: 1.6382557314683937, Validation Loss Force: 2.6747106876504247, time: 0.07994604110717773
Test Loss Energy: 10.770766791996705, Test Loss Force: 9.718809071272323, time: 16.644575119018555


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3918779131822452, Training Loss Force: 2.673663720361011, time: 1.1151492595672607
Validation Loss Energy: 1.353011322809968, Validation Loss Force: 2.6709616072404385, time: 0.0747992992401123
Test Loss Energy: 10.792344994418547, Test Loss Force: 9.702451604620114, time: 16.802378177642822


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3836116321086562, Training Loss Force: 2.650885948999749, time: 1.0657289028167725
Validation Loss Energy: 1.596046790835468, Validation Loss Force: 2.6834655931300135, time: 0.07274937629699707
Test Loss Energy: 10.677351480079714, Test Loss Force: 9.65018017883171, time: 16.87101435661316


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4305107930902559, Training Loss Force: 2.6459325817096286, time: 1.089782476425171
Validation Loss Energy: 1.2569639887251733, Validation Loss Force: 2.6613316120173534, time: 0.07447600364685059
Test Loss Energy: 11.290856641015854, Test Loss Force: 9.62970856512186, time: 16.944418907165527


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5006747239704388, Training Loss Force: 2.6119000905064036, time: 1.0732877254486084
Validation Loss Energy: 1.5877299869004922, Validation Loss Force: 2.655043880674645, time: 0.07546448707580566
Test Loss Energy: 11.450919402410987, Test Loss Force: 9.665656155459736, time: 17.231143951416016


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5362044962586077, Training Loss Force: 2.6310162827537824, time: 1.0546760559082031
Validation Loss Energy: 1.1538691761717643, Validation Loss Force: 2.6753922779061097, time: 0.0793619155883789
Test Loss Energy: 10.979961176346444, Test Loss Force: 9.644999476876059, time: 16.777384996414185


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3982177836572105, Training Loss Force: 2.6408216951943806, time: 1.1461429595947266
Validation Loss Energy: 1.137126571754881, Validation Loss Force: 2.6688055019004198, time: 0.09805130958557129
Test Loss Energy: 11.019458900955975, Test Loss Force: 9.582291643814196, time: 16.996574640274048


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4207250542365253, Training Loss Force: 2.6480240285366183, time: 1.1001029014587402
Validation Loss Energy: 1.1989666923002382, Validation Loss Force: 2.690420886572214, time: 0.07393527030944824
Test Loss Energy: 11.22696941692354, Test Loss Force: 9.626217210841505, time: 17.08795738220215


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.584503426515288, Training Loss Force: 2.6270003756027576, time: 1.044532060623169
Validation Loss Energy: 1.217412493014323, Validation Loss Force: 2.6627595892501885, time: 0.07345318794250488
Test Loss Energy: 11.180429560236512, Test Loss Force: 9.656248834045806, time: 16.939852237701416

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–…â–‚â–‡â–ƒâ–‚â–…â–ƒâ–‚â–„â–â–â–â–„â–„â–‚â–‚â–ƒâ–ƒ
wandb:   test_error_force â–‡â–‡â–‡â–ˆâ–…â–†â–…â–…â–…â–„â–…â–…â–…â–ƒâ–‚â–„â–ƒâ–â–‚â–ƒ
wandb:          test_loss â–…â–ˆâ–‡â–†â–†â–…â–ƒâ–„â–…â–‚â–…â–‚â–‚â–â–ƒâ–ƒâ–‚â–â–â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–ˆâ–‚â–‚â–†â–â–ƒâ–ƒâ–â–â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–â–â–
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–‚â–
wandb:         valid_loss â–ˆâ–…â–ƒâ–‚â–„â–„â–ƒâ–‚â–„â–‚â–„â–ƒâ–‚â–‚â–â–‚â–â–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 918
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.18043
wandb:   test_error_force 9.65625
wandb:          test_loss 5.39924
wandb: train_error_energy 1.5845
wandb:  train_error_force 2.627
wandb:         train_loss 1.20472
wandb: valid_error_energy 1.21741
wandb:  valid_error_force 2.66276
wandb:         valid_loss 1.3676
wandb: 
wandb: ğŸš€ View run al_55_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/afxxun9s
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_203319-afxxun9s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6627286672592163, Uncertainty Bias: 0.03025926649570465
6.389618e-05 0.013895988
1.0295689 5.5197115
Found uncertainty sample 2 after 91 steps.
Found uncertainty sample 6 after 84 steps.
Found uncertainty sample 7 after 498 steps.
Found uncertainty sample 9 after 1403 steps.
Found uncertainty sample 12 after 1734 steps.
Found uncertainty sample 14 after 2521 steps.
Found uncertainty sample 19 after 1397 steps.
Found uncertainty sample 20 after 1112 steps.
Found uncertainty sample 21 after 3278 steps.
Found uncertainty sample 23 after 3672 steps.
Found uncertainty sample 24 after 2126 steps.
Found uncertainty sample 26 after 2777 steps.
Found uncertainty sample 27 after 3532 steps.
Found uncertainty sample 28 after 1519 steps.
Found uncertainty sample 30 after 3023 steps.
Found uncertainty sample 33 after 1074 steps.
Found uncertainty sample 34 after 272 steps.
Found uncertainty sample 37 after 2069 steps.
Found uncertainty sample 39 after 271 steps.
Found uncertainty sample 40 after 3730 steps.
Found uncertainty sample 41 after 1046 steps.
Found uncertainty sample 45 after 741 steps.
Found uncertainty sample 47 after 39 steps.
Found uncertainty sample 48 after 1715 steps.
Found uncertainty sample 55 after 781 steps.
Found uncertainty sample 62 after 1418 steps.
Found uncertainty sample 64 after 2353 steps.
Found uncertainty sample 67 after 906 steps.
Found uncertainty sample 70 after 3961 steps.
Found uncertainty sample 72 after 1398 steps.
Found uncertainty sample 73 after 3180 steps.
Found uncertainty sample 74 after 1004 steps.
Found uncertainty sample 75 after 1992 steps.
Found uncertainty sample 79 after 1300 steps.
Found uncertainty sample 85 after 3442 steps.
Found uncertainty sample 91 after 3064 steps.
Found uncertainty sample 93 after 1721 steps.
Found uncertainty sample 95 after 1441 steps.
Found uncertainty sample 96 after 746 steps.
Found uncertainty sample 98 after 1479 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_230331-4m22u2wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4m22u2wh
Training model 2. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.108862662081089, Training Loss Force: 3.049117841827581, time: 1.0607233047485352
Validation Loss Energy: 1.9796389285252682, Validation Loss Force: 2.798964079122757, time: 0.07607054710388184
Test Loss Energy: 10.55717490419177, Test Loss Force: 9.569179704705236, time: 16.47830295562744


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.754302568066628, Training Loss Force: 2.8412105320844665, time: 1.0830836296081543
Validation Loss Energy: 1.2871673883516834, Validation Loss Force: 2.715899580925855, time: 0.0790410041809082
Test Loss Energy: 10.666536759093132, Test Loss Force: 9.441373546568942, time: 16.62801766395569


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6706390843004513, Training Loss Force: 2.7935470954751986, time: 1.1046695709228516
Validation Loss Energy: 1.214107637550463, Validation Loss Force: 2.713287894513268, time: 0.0749349594116211
Test Loss Energy: 10.750645988280128, Test Loss Force: 9.489744741566328, time: 16.55025577545166


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4663948694210462, Training Loss Force: 2.7786358111820832, time: 1.0929434299468994
Validation Loss Energy: 1.3278581707476733, Validation Loss Force: 2.711310369828283, time: 0.07599663734436035
Test Loss Energy: 10.669454275165714, Test Loss Force: 9.478511868908221, time: 16.68919062614441


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3521869904982864, Training Loss Force: 2.7812383607373827, time: 1.0706181526184082
Validation Loss Energy: 1.6484810326531165, Validation Loss Force: 2.7072854023464927, time: 0.07523584365844727
Test Loss Energy: 11.183833637538122, Test Loss Force: 9.413530227129481, time: 16.63750696182251


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5383073044588402, Training Loss Force: 2.777397214057861, time: 1.0648999214172363
Validation Loss Energy: 1.5431203388707462, Validation Loss Force: 2.725815928670603, time: 0.0754537582397461
Test Loss Energy: 11.178970781215694, Test Loss Force: 9.423285887025747, time: 16.55730628967285


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4091389517730535, Training Loss Force: 2.7658899175323723, time: 1.1002135276794434
Validation Loss Energy: 1.2010950753315888, Validation Loss Force: 2.6994432176960617, time: 0.07905983924865723
Test Loss Energy: 10.606103821280316, Test Loss Force: 9.403895046396652, time: 16.628926038742065


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3108794498240244, Training Loss Force: 2.7525900156252887, time: 1.109224557876587
Validation Loss Energy: 1.3619637358219947, Validation Loss Force: 2.6959161384245656, time: 0.07782244682312012
Test Loss Energy: 11.070279955523983, Test Loss Force: 9.418001983167093, time: 16.534295320510864


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5582424073441246, Training Loss Force: 2.7455410601180064, time: 1.0982439517974854
Validation Loss Energy: 1.2545494758413054, Validation Loss Force: 2.6974465434645274, time: 0.07464933395385742
Test Loss Energy: 10.596338895549643, Test Loss Force: 9.3925246038438, time: 16.988696098327637


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5567297379016367, Training Loss Force: 2.7610830621892664, time: 1.0956311225891113
Validation Loss Energy: 1.1716977380133375, Validation Loss Force: 2.687615032664378, time: 0.07360124588012695
Test Loss Energy: 10.606055123188362, Test Loss Force: 9.411624081312548, time: 16.58610510826111


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4793359678331113, Training Loss Force: 2.7655681531942027, time: 1.076812744140625
Validation Loss Energy: 1.852930387049936, Validation Loss Force: 2.6982100759659136, time: 0.0775444507598877
Test Loss Energy: 11.295251369850273, Test Loss Force: 9.364981558993753, time: 16.686506032943726


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4571148080386676, Training Loss Force: 2.7582439118218094, time: 1.1076858043670654
Validation Loss Energy: 1.916615098800159, Validation Loss Force: 2.6875876443594287, time: 0.0759432315826416
Test Loss Energy: 10.319666629382992, Test Loss Force: 9.376229148800022, time: 16.864549160003662


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8379815644499706, Training Loss Force: 2.774088068501789, time: 1.0939664840698242
Validation Loss Energy: 1.1564308733610906, Validation Loss Force: 2.6853335645952017, time: 0.0773916244506836
Test Loss Energy: 10.596523144358539, Test Loss Force: 9.399307521056068, time: 17.10445737838745


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6906249390508215, Training Loss Force: 2.7614685544370015, time: 1.1346302032470703
Validation Loss Energy: 1.5322996203898125, Validation Loss Force: 2.700709759798099, time: 0.07488870620727539
Test Loss Energy: 11.031554839223697, Test Loss Force: 9.368841308300881, time: 17.180537939071655


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4004562634642181, Training Loss Force: 2.7653402810125645, time: 1.10341477394104
Validation Loss Energy: 1.5784741871771388, Validation Loss Force: 2.6796673028387774, time: 0.0812840461730957
Test Loss Energy: 10.995151427657001, Test Loss Force: 9.31178452437929, time: 17.089200973510742


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4450613523432012, Training Loss Force: 2.739037228369175, time: 1.1187491416931152
Validation Loss Energy: 1.2054563845583035, Validation Loss Force: 2.680715629177805, time: 0.07497501373291016
Test Loss Energy: 10.780886356230997, Test Loss Force: 9.362527008215576, time: 17.239914655685425


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3929759588541728, Training Loss Force: 2.744289310669564, time: 1.0900726318359375
Validation Loss Energy: 1.4050350740570987, Validation Loss Force: 2.68382832116873, time: 0.07762622833251953
Test Loss Energy: 10.413601103157264, Test Loss Force: 9.342965801207898, time: 17.52904224395752


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4462750327899947, Training Loss Force: 2.7358746510672574, time: 1.1361477375030518
Validation Loss Energy: 1.1538561500267275, Validation Loss Force: 2.683875081689375, time: 0.08203554153442383
Test Loss Energy: 10.646210265044463, Test Loss Force: 9.318630320560432, time: 17.230084896087646


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.2984486014710055, Training Loss Force: 2.742756471113606, time: 1.0720350742340088
Validation Loss Energy: 1.1767449795440827, Validation Loss Force: 2.675501163118468, time: 0.07706451416015625
Test Loss Energy: 10.67922544495893, Test Loss Force: 9.320290756220967, time: 17.22734522819519


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3938291732096582, Training Loss Force: 2.7456198107726166, time: 1.079038143157959
Validation Loss Energy: 1.1388548183309994, Validation Loss Force: 2.6738781277138006, time: 0.07835626602172852
Test Loss Energy: 10.639621655224285, Test Loss Force: 9.315789169512641, time: 17.175182819366455

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–„â–„â–‡â–‡â–ƒâ–†â–ƒâ–ƒâ–ˆâ–â–ƒâ–†â–†â–„â–‚â–ƒâ–„â–ƒ
wandb:   test_error_force â–ˆâ–…â–†â–†â–„â–„â–„â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–â–â–
wandb:          test_loss â–ˆâ–…â–ˆâ–‡â–…â–†â–ƒâ–…â–‚â–ƒâ–…â–â–„â–ƒâ–ƒâ–ƒâ–â–â–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–‚â–ƒâ–…â–„â–‚â–ƒâ–‚â–â–‡â–‡â–â–„â–…â–‚â–ƒâ–â–â–
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–‚â–â–
wandb:         valid_loss â–ˆâ–ƒâ–…â–‚â–ƒâ–ƒâ–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–†â–‚â–„â–â–‚â–…â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 954
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.63962
wandb:   test_error_force 9.31579
wandb:          test_loss 5.15501
wandb: train_error_energy 1.39383
wandb:  train_error_force 2.74562
wandb:         train_loss 1.23224
wandb: valid_error_energy 1.13885
wandb:  valid_error_force 2.67388
wandb:         valid_loss 1.33425
wandb: 
wandb: ğŸš€ View run al_55_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4m22u2wh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_230331-4m22u2wh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6801798939704895, Uncertainty Bias: 0.027707546949386597
0.00019073486 0.0008176565
0.50942403 5.327008
Found uncertainty sample 1 after 2204 steps.
Found uncertainty sample 2 after 1460 steps.
Found uncertainty sample 3 after 45 steps.
Found uncertainty sample 5 after 3690 steps.
Found uncertainty sample 8 after 399 steps.
Found uncertainty sample 9 after 1357 steps.
Found uncertainty sample 10 after 2574 steps.
Found uncertainty sample 13 after 880 steps.
Found uncertainty sample 14 after 1456 steps.
Found uncertainty sample 15 after 3047 steps.
Found uncertainty sample 16 after 2864 steps.
Found uncertainty sample 22 after 1141 steps.
Found uncertainty sample 25 after 994 steps.
Found uncertainty sample 26 after 236 steps.
Found uncertainty sample 27 after 1890 steps.
Found uncertainty sample 28 after 813 steps.
Found uncertainty sample 29 after 1299 steps.
Found uncertainty sample 31 after 1368 steps.
Found uncertainty sample 32 after 225 steps.
Found uncertainty sample 34 after 3580 steps.
Found uncertainty sample 36 after 3791 steps.
Found uncertainty sample 43 after 17 steps.
Found uncertainty sample 44 after 1457 steps.
Found uncertainty sample 47 after 2337 steps.
Found uncertainty sample 48 after 2149 steps.
Found uncertainty sample 49 after 1906 steps.
Found uncertainty sample 53 after 659 steps.
Found uncertainty sample 57 after 1858 steps.
Found uncertainty sample 59 after 2206 steps.
Found uncertainty sample 61 after 2000 steps.
Found uncertainty sample 62 after 2187 steps.
Found uncertainty sample 64 after 1249 steps.
Found uncertainty sample 65 after 2230 steps.
Found uncertainty sample 68 after 596 steps.
Found uncertainty sample 69 after 732 steps.
Found uncertainty sample 70 after 1389 steps.
Found uncertainty sample 72 after 3349 steps.
Found uncertainty sample 73 after 1360 steps.
Found uncertainty sample 74 after 3756 steps.
Found uncertainty sample 77 after 2235 steps.
Found uncertainty sample 79 after 1113 steps.
Found uncertainty sample 83 after 1107 steps.
Found uncertainty sample 85 after 3722 steps.
Found uncertainty sample 86 after 3748 steps.
Found uncertainty sample 90 after 2191 steps.
Found uncertainty sample 97 after 1065 steps.
Found uncertainty sample 98 after 1184 steps.
Found uncertainty sample 99 after 478 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_012545-nyysy38s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nyysy38s
Training model 3. Added 48 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.689346306651223, Training Loss Force: 3.2106886542137225, time: 1.1687016487121582
Validation Loss Energy: 1.516457601333634, Validation Loss Force: 2.878809004138689, time: 0.07903242111206055
Test Loss Energy: 10.710576146194027, Test Loss Force: 9.412506555277876, time: 16.60508942604065


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2479131301076185, Training Loss Force: 3.0333354280545093, time: 1.1699035167694092
Validation Loss Energy: 2.6722878246735844, Validation Loss Force: 2.773919144265383, time: 0.07724642753601074
Test Loss Energy: 10.210417741184457, Test Loss Force: 9.217192488798375, time: 16.804198265075684


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1230891106775864, Training Loss Force: 2.9077890664358828, time: 1.155165195465088
Validation Loss Energy: 3.2489038288789303, Validation Loss Force: 2.777893788520194, time: 0.0766298770904541
Test Loss Energy: 10.163661939726548, Test Loss Force: 9.229836426326491, time: 16.659226417541504


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1667639936327276, Training Loss Force: 2.9084649786283467, time: 1.1619155406951904
Validation Loss Energy: 1.2576429069511073, Validation Loss Force: 2.7389019717076333, time: 0.08240032196044922
Test Loss Energy: 10.364835441024313, Test Loss Force: 9.177634459321931, time: 16.7433180809021


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8697433375209056, Training Loss Force: 2.8754288795450944, time: 1.146892786026001
Validation Loss Energy: 1.2537454175553602, Validation Loss Force: 2.7334957875136525, time: 0.08170437812805176
Test Loss Energy: 10.318383831267496, Test Loss Force: 9.1678475371439, time: 16.733916997909546


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7323329533153191, Training Loss Force: 2.901252662366048, time: 1.144270658493042
Validation Loss Energy: 1.3654274657214744, Validation Loss Force: 2.7260524033035782, time: 0.08226561546325684
Test Loss Energy: 10.223142128725257, Test Loss Force: 9.144497004901172, time: 16.957878589630127


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.484636701718256, Training Loss Force: 2.9062597747416508, time: 1.1755871772766113
Validation Loss Energy: 1.3100971889918893, Validation Loss Force: 2.750695197683407, time: 0.0785055160522461
Test Loss Energy: 10.426472069949662, Test Loss Force: 9.167252597828575, time: 16.770692348480225


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4904312974452538, Training Loss Force: 2.9034707184375104, time: 1.1681561470031738
Validation Loss Energy: 1.4157188510132868, Validation Loss Force: 2.756281966554735, time: 0.07693886756896973
Test Loss Energy: 10.519872217048587, Test Loss Force: 9.116234824979502, time: 16.684993505477905


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.625211134465752, Training Loss Force: 2.853992444324107, time: 1.1672136783599854
Validation Loss Energy: 1.372172002817054, Validation Loss Force: 2.744600965828509, time: 0.07585382461547852
Test Loss Energy: 10.4602240445809, Test Loss Force: 9.117359427741983, time: 16.7909255027771


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6047102784534344, Training Loss Force: 2.8707553325085025, time: 1.1534950733184814
Validation Loss Energy: 1.330899608611901, Validation Loss Force: 2.7457552826809986, time: 0.07843589782714844
Test Loss Energy: 10.177591300767629, Test Loss Force: 9.070921476580525, time: 16.77046227455139


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6046393165799917, Training Loss Force: 2.8903075692502918, time: 1.2622478008270264
Validation Loss Energy: 1.920259302042413, Validation Loss Force: 2.7341197064605423, time: 0.07914590835571289
Test Loss Energy: 9.916680797168445, Test Loss Force: 9.083207082328297, time: 16.649051904678345


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9248663162340427, Training Loss Force: 2.868766695241454, time: 1.1387171745300293
Validation Loss Energy: 2.027974388039251, Validation Loss Force: 2.763534077968457, time: 0.0814361572265625
Test Loss Energy: 9.886333086367944, Test Loss Force: 9.094951455159775, time: 17.044336557388306


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8664188175880956, Training Loss Force: 2.922169874889196, time: 1.1725358963012695
Validation Loss Energy: 3.6581545775922812, Validation Loss Force: 2.8185086407374227, time: 0.07884788513183594
Test Loss Energy: 9.984605570132196, Test Loss Force: 9.096451154007934, time: 16.986225605010986


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.332294563217645, Training Loss Force: 2.9311664251009923, time: 1.1572351455688477
Validation Loss Energy: 1.390263536919968, Validation Loss Force: 2.7298043784124615, time: 0.07910680770874023
Test Loss Energy: 9.953950240157885, Test Loss Force: 9.003238981637228, time: 17.579962968826294


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.62952581712123, Training Loss Force: 2.8637391738469447, time: 1.1390409469604492
Validation Loss Energy: 1.2643142972322496, Validation Loss Force: 2.755297546260588, time: 0.07752275466918945
Test Loss Energy: 10.013157252586172, Test Loss Force: 9.006154380604212, time: 17.239928483963013


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4193729839077673, Training Loss Force: 2.879952396286207, time: 1.2228772640228271
Validation Loss Energy: 1.445415901001957, Validation Loss Force: 2.75375600776333, time: 0.07868075370788574
Test Loss Energy: 9.947331431271973, Test Loss Force: 8.985029318054979, time: 17.20814871788025


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6235468861334579, Training Loss Force: 2.918678805393643, time: 1.1915764808654785
Validation Loss Energy: 1.473488690905657, Validation Loss Force: 2.721233842985701, time: 0.08037543296813965
Test Loss Energy: 9.954273863530833, Test Loss Force: 9.03174056703079, time: 17.218148946762085


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8732076867189473, Training Loss Force: 2.8505390685399132, time: 1.1687369346618652
Validation Loss Energy: 1.265398695972918, Validation Loss Force: 2.723481688013842, time: 0.08029866218566895
Test Loss Energy: 9.997536841791508, Test Loss Force: 8.944005514715437, time: 17.336868047714233


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8436365596115047, Training Loss Force: 2.8493964766096394, time: 1.1498494148254395
Validation Loss Energy: 1.4217647636635182, Validation Loss Force: 2.737212803566625, time: 0.07879781723022461
Test Loss Energy: 9.920418374560303, Test Loss Force: 8.967678835613265, time: 17.35649871826172


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7526615764828641, Training Loss Force: 2.865235461798704, time: 1.1604595184326172
Validation Loss Energy: 2.8258137474078757, Validation Loss Force: 2.7408095782807966, time: 0.08035063743591309
Test Loss Energy: 9.835522608001463, Test Loss Force: 9.021007816269279, time: 17.356937646865845

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–„â–…â–…â–„â–†â–†â–†â–„â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:   test_error_force â–ˆâ–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚
wandb:          test_loss â–ˆâ–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–‚â–‚â–ƒâ–â–â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–…â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–ƒâ–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–ƒâ–â–â–‚â–â–â–
wandb: valid_error_energy â–‚â–…â–‡â–â–â–â–â–â–â–â–ƒâ–ƒâ–ˆâ–â–â–‚â–‚â–â–â–†
wandb:  valid_error_force â–ˆâ–ƒâ–„â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–…â–â–ƒâ–‚â–â–â–‚â–‚
wandb:         valid_loss â–‡â–†â–†â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ˆâ–‚â–â–ƒâ–â–â–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 997
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.83552
wandb:   test_error_force 9.02101
wandb:          test_loss 4.89948
wandb: train_error_energy 1.75266
wandb:  train_error_force 2.86524
wandb:         train_loss 1.30558
wandb: valid_error_energy 2.82581
wandb:  valid_error_force 2.74081
wandb:         valid_loss 1.44637
wandb: 
wandb: ğŸš€ View run al_55_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nyysy38s
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_012545-nyysy38s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6743947863578796, Uncertainty Bias: 0.03226761519908905
5.722046e-06 0.02125454
0.9220463 4.588394
Found uncertainty sample 5 after 2962 steps.
Found uncertainty sample 6 after 3491 steps.
Found uncertainty sample 11 after 455 steps.
Found uncertainty sample 12 after 1364 steps.
Found uncertainty sample 13 after 1887 steps.
Found uncertainty sample 14 after 1594 steps.
Found uncertainty sample 21 after 1514 steps.
Found uncertainty sample 25 after 2874 steps.
Found uncertainty sample 26 after 2986 steps.
Found uncertainty sample 27 after 3764 steps.
Found uncertainty sample 30 after 1890 steps.
Found uncertainty sample 31 after 592 steps.
Found uncertainty sample 33 after 927 steps.
Found uncertainty sample 35 after 763 steps.
Found uncertainty sample 36 after 1942 steps.
Found uncertainty sample 37 after 3161 steps.
Found uncertainty sample 41 after 3365 steps.
Found uncertainty sample 44 after 17 steps.
Found uncertainty sample 45 after 3823 steps.
Found uncertainty sample 46 after 3722 steps.
Found uncertainty sample 48 after 603 steps.
Found uncertainty sample 49 after 3442 steps.
Found uncertainty sample 51 after 1064 steps.
Found uncertainty sample 52 after 391 steps.
Found uncertainty sample 53 after 3871 steps.
Found uncertainty sample 56 after 1725 steps.
Found uncertainty sample 58 after 3111 steps.
Found uncertainty sample 59 after 3868 steps.
Found uncertainty sample 68 after 1952 steps.
Found uncertainty sample 69 after 1905 steps.
Found uncertainty sample 72 after 2797 steps.
Found uncertainty sample 73 after 978 steps.
Found uncertainty sample 74 after 1717 steps.
Found uncertainty sample 77 after 2692 steps.
Found uncertainty sample 78 after 2852 steps.
Found uncertainty sample 82 after 1494 steps.
Found uncertainty sample 83 after 2242 steps.
Found uncertainty sample 86 after 1178 steps.
Found uncertainty sample 88 after 379 steps.
Found uncertainty sample 90 after 2004 steps.
Found uncertainty sample 92 after 650 steps.
Found uncertainty sample 93 after 3328 steps.
Found uncertainty sample 98 after 3550 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_035944-2boaekla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2boaekla
Training model 4. Added 43 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.668087543380077, Training Loss Force: 3.304896009887436, time: 1.208698034286499
Validation Loss Energy: 2.1831554105352233, Validation Loss Force: 2.904255411466171, time: 0.08023619651794434
Test Loss Energy: 9.67760476835935, Test Loss Force: 8.92576201941269, time: 16.760206699371338


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7963758433051777, Training Loss Force: 3.051261986460689, time: 1.2080409526824951
Validation Loss Energy: 1.3500609566264248, Validation Loss Force: 2.7751017400994056, time: 0.07841253280639648
Test Loss Energy: 9.998681225967958, Test Loss Force: 8.89068968436291, time: 16.839357376098633


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6111929536286347, Training Loss Force: 3.041065217290619, time: 1.1777691841125488
Validation Loss Energy: 1.3215142154456176, Validation Loss Force: 2.78633116779769, time: 0.07790589332580566
Test Loss Energy: 10.012535415770667, Test Loss Force: 8.907666180567256, time: 17.185216426849365


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6655776843858, Training Loss Force: 3.0118826915964645, time: 1.1718659400939941
Validation Loss Energy: 2.101324722075907, Validation Loss Force: 2.77219635308334, time: 0.0800318717956543
Test Loss Energy: 9.62730393886465, Test Loss Force: 8.904048415497208, time: 16.8670973777771


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7450045413327027, Training Loss Force: 3.003054926073308, time: 1.1936390399932861
Validation Loss Energy: 1.434081150797649, Validation Loss Force: 2.8044793711982425, time: 0.07950353622436523
Test Loss Energy: 9.820657915303553, Test Loss Force: 8.892963521059158, time: 16.910732984542847


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7704864222167733, Training Loss Force: 3.0199115337191316, time: 1.213770866394043
Validation Loss Energy: 1.3707959074952205, Validation Loss Force: 2.807051199833708, time: 0.08036303520202637
Test Loss Energy: 9.876029002857521, Test Loss Force: 8.888797504914397, time: 16.800141096115112


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9469784356013942, Training Loss Force: 3.0039615133796285, time: 1.219970703125
Validation Loss Energy: 1.7413563334195967, Validation Loss Force: 2.7814600575613735, time: 0.08018922805786133
Test Loss Energy: 9.622197456848825, Test Loss Force: 8.874845387319763, time: 16.835575103759766


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7683093168146509, Training Loss Force: 3.000063096195773, time: 1.2175569534301758
Validation Loss Energy: 1.317310333305074, Validation Loss Force: 2.804578904306472, time: 0.07977414131164551
Test Loss Energy: 9.773782627949808, Test Loss Force: 8.824279723769871, time: 16.727147102355957


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5871918765453834, Training Loss Force: 2.9893006934146475, time: 1.2281157970428467
Validation Loss Energy: 1.3516378995178855, Validation Loss Force: 2.7815584773238737, time: 0.08006072044372559
Test Loss Energy: 9.7661610104952, Test Loss Force: 8.812461228926358, time: 16.86644434928894


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6892073375254317, Training Loss Force: 3.005148724537767, time: 1.2593967914581299
Validation Loss Energy: 2.434797375054551, Validation Loss Force: 2.7701072711562453, time: 0.07830619812011719
Test Loss Energy: 10.530498874705614, Test Loss Force: 8.816226412629081, time: 16.90912938117981


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8501215844628038, Training Loss Force: 2.9946957104135823, time: 1.2072198390960693
Validation Loss Energy: 1.888191159653331, Validation Loss Force: 2.7809018260125327, time: 0.07944178581237793
Test Loss Energy: 10.278514083639664, Test Loss Force: 8.786575453404907, time: 17.12247633934021


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9855243186508227, Training Loss Force: 2.9755022170714467, time: 1.194756031036377
Validation Loss Energy: 2.525090159066561, Validation Loss Force: 2.7720157684059923, time: 0.08457708358764648
Test Loss Energy: 9.55232049801625, Test Loss Force: 8.816840583097445, time: 17.21944808959961


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.51122674261646, Training Loss Force: 2.987330833946323, time: 1.216064214706421
Validation Loss Energy: 1.4107586731185995, Validation Loss Force: 2.764902379870183, time: 0.0882570743560791
Test Loss Energy: 9.660576841411329, Test Loss Force: 8.806082552975933, time: 17.223122596740723


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.716956504815725, Training Loss Force: 2.988021405190894, time: 1.2202653884887695
Validation Loss Energy: 1.6940104155901172, Validation Loss Force: 2.764804850784267, time: 0.08141922950744629
Test Loss Energy: 9.511465097836226, Test Loss Force: 8.762718942250983, time: 17.508665323257446


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7192217585225475, Training Loss Force: 2.965187790874179, time: 1.2508811950683594
Validation Loss Energy: 1.330813546987, Validation Loss Force: 2.77920196975252, time: 0.07982325553894043
Test Loss Energy: 9.62631210287188, Test Loss Force: 8.755553281258813, time: 17.52270221710205


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6928585784622072, Training Loss Force: 2.990965685084448, time: 1.1831300258636475
Validation Loss Energy: 1.9585902368298602, Validation Loss Force: 2.7721783168825196, time: 0.08138561248779297
Test Loss Energy: 10.229300956782806, Test Loss Force: 8.781353057526038, time: 17.305357217788696


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7574308679838604, Training Loss Force: 2.9681780958054413, time: 1.2287521362304688
Validation Loss Energy: 1.605947997078293, Validation Loss Force: 2.7684352485394736, time: 0.08046817779541016
Test Loss Energy: 9.484379140281453, Test Loss Force: 8.7558954736064, time: 17.52184224128723


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.491056931100692, Training Loss Force: 2.9901412491978756, time: 1.2338409423828125
Validation Loss Energy: 1.3457509726378467, Validation Loss Force: 2.7766931564853516, time: 0.08290386199951172
Test Loss Energy: 9.693766066991419, Test Loss Force: 8.769632975450186, time: 17.411518812179565


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2710372612385745, Training Loss Force: 2.998087393349255, time: 1.1840779781341553
Validation Loss Energy: 1.43593420343006, Validation Loss Force: 2.7673875902078833, time: 0.08064770698547363
Test Loss Energy: 9.581163249847199, Test Loss Force: 8.729865865474748, time: 17.40601086616516


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8136871025485741, Training Loss Force: 2.9496249381990447, time: 1.2121226787567139
Validation Loss Energy: 1.3101341520701133, Validation Loss Force: 2.7556665090353905, time: 0.07985997200012207
Test Loss Energy: 9.67761379636912, Test Loss Force: 8.719494943914722, time: 17.399455785751343

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–…â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–ˆâ–†â–â–‚â–â–‚â–†â–â–‚â–‚â–‚
wandb:   test_error_force â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–…â–„â–„â–ƒâ–„â–„â–‚â–‚â–ƒâ–‚â–ƒâ–â–
wandb:          test_loss â–‡â–‡â–‡â–†â–‡â–ˆâ–…â–…â–„â–‡â–…â–ƒâ–„â–ƒâ–‚â–„â–â–…â–ƒâ–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–â–â–â–‚â–‚â–ƒâ–â–â–â–â–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–‚â–‚â–
wandb: valid_error_energy â–†â–â–â–†â–‚â–â–ƒâ–â–â–‡â–„â–ˆâ–‚â–ƒâ–â–…â–ƒâ–â–‚â–
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–
wandb:         valid_loss â–ˆâ–ƒâ–‚â–„â–„â–…â–„â–ƒâ–ƒâ–…â–„â–…â–„â–ƒâ–‚â–…â–†â–…â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1035
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.67761
wandb:   test_error_force 8.71949
wandb:          test_loss 4.76557
wandb: train_error_energy 1.81369
wandb:  train_error_force 2.94962
wandb:         train_loss 1.35403
wandb: valid_error_energy 1.31013
wandb:  valid_error_force 2.75567
wandb:         valid_loss 1.35305
wandb: 
wandb: ğŸš€ View run al_55_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2boaekla
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_035944-2boaekla/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.693762481212616, Uncertainty Bias: 0.02676767110824585
0.00018310547 0.008595467
0.4106724 5.933535
Found uncertainty sample 4 after 470 steps.
Found uncertainty sample 5 after 20 steps.
Found uncertainty sample 6 after 1781 steps.
Found uncertainty sample 9 after 1145 steps.
Found uncertainty sample 11 after 1977 steps.
Found uncertainty sample 15 after 1412 steps.
Found uncertainty sample 16 after 1196 steps.
Found uncertainty sample 20 after 3963 steps.
Found uncertainty sample 30 after 473 steps.
Found uncertainty sample 31 after 1398 steps.
Found uncertainty sample 33 after 591 steps.
Found uncertainty sample 35 after 387 steps.
Found uncertainty sample 38 after 1102 steps.
Found uncertainty sample 40 after 235 steps.
Found uncertainty sample 41 after 391 steps.
Found uncertainty sample 42 after 2306 steps.
Found uncertainty sample 45 after 3588 steps.
Found uncertainty sample 46 after 1191 steps.
Found uncertainty sample 48 after 2685 steps.
Found uncertainty sample 52 after 801 steps.
Found uncertainty sample 54 after 359 steps.
Found uncertainty sample 56 after 3354 steps.
Found uncertainty sample 63 after 719 steps.
Found uncertainty sample 68 after 1360 steps.
Found uncertainty sample 69 after 1396 steps.
Found uncertainty sample 75 after 675 steps.
Found uncertainty sample 76 after 529 steps.
Found uncertainty sample 78 after 2408 steps.
Found uncertainty sample 82 after 3491 steps.
Found uncertainty sample 85 after 1633 steps.
Found uncertainty sample 88 after 2684 steps.
Found uncertainty sample 89 after 3510 steps.
Found uncertainty sample 90 after 727 steps.
Found uncertainty sample 91 after 200 steps.
Found uncertainty sample 92 after 1246 steps.
Found uncertainty sample 94 after 631 steps.
Found uncertainty sample 97 after 3317 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_062857-5xv2vy7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/5xv2vy7x
Training model 5. Added 37 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2379244946515326, Training Loss Force: 3.26963376314285, time: 1.2067523002624512
Validation Loss Energy: 2.188565157435539, Validation Loss Force: 2.8651838790993676, time: 0.08972430229187012
Test Loss Energy: 9.441670165187457, Test Loss Force: 8.738438590287144, time: 16.90186357498169


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1090001602815005, Training Loss Force: 3.1220981774596037, time: 1.204756498336792
Validation Loss Energy: 1.572325401381489, Validation Loss Force: 2.8144691997611466, time: 0.08193349838256836
Test Loss Energy: 9.711081938953528, Test Loss Force: 8.696169910203723, time: 16.77688455581665


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8339991708722745, Training Loss Force: 3.046928420380664, time: 1.2390780448913574
Validation Loss Energy: 1.4316403629545615, Validation Loss Force: 2.8097644233768384, time: 0.07900500297546387
Test Loss Energy: 9.390158379270712, Test Loss Force: 8.670993248476522, time: 16.69223189353943


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6730023020720084, Training Loss Force: 3.040214591979945, time: 1.196638822555542
Validation Loss Energy: 1.4610616372060001, Validation Loss Force: 2.814450050214597, time: 0.07698535919189453
Test Loss Energy: 9.53659308478761, Test Loss Force: 8.632715941979033, time: 16.78432583808899


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8965314879286648, Training Loss Force: 3.047443192151494, time: 1.2295136451721191
Validation Loss Energy: 1.4782135075130987, Validation Loss Force: 2.814885591064032, time: 0.08174395561218262
Test Loss Energy: 9.630336534082428, Test Loss Force: 8.631955117647417, time: 16.832950115203857


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.793401552592032, Training Loss Force: 3.0535643735221414, time: 1.213280439376831
Validation Loss Energy: 1.5840718668366176, Validation Loss Force: 2.8294583959884214, time: 0.08265209197998047
Test Loss Energy: 9.333687893702614, Test Loss Force: 8.645534382169133, time: 16.671433210372925


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8646392410666806, Training Loss Force: 3.0441821239202707, time: 1.2130582332611084
Validation Loss Energy: 1.504986466277445, Validation Loss Force: 2.7956509849004973, time: 0.0833280086517334
Test Loss Energy: 9.290025575232917, Test Loss Force: 8.58300253001259, time: 16.814658880233765


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8334618342031421, Training Loss Force: 3.053135185292458, time: 1.252533197402954
Validation Loss Energy: 1.6816415898721204, Validation Loss Force: 2.7893409866431957, time: 0.08263874053955078
Test Loss Energy: 9.302438617680584, Test Loss Force: 8.572200730831314, time: 16.72480034828186


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.031046370871026, Training Loss Force: 3.0582992953793524, time: 1.2330737113952637
Validation Loss Energy: 1.401241014479635, Validation Loss Force: 2.8151485633253723, time: 0.08175516128540039
Test Loss Energy: 9.428853814123586, Test Loss Force: 8.573355929033934, time: 17.177000284194946


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8173830654521022, Training Loss Force: 3.050552557203414, time: 1.2004072666168213
Validation Loss Energy: 1.386766740652318, Validation Loss Force: 2.797542113956862, time: 0.07874202728271484
Test Loss Energy: 9.45181682277752, Test Loss Force: 8.561394058576584, time: 16.822192192077637


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.673504827039812, Training Loss Force: 3.033619983259592, time: 1.2337706089019775
Validation Loss Energy: 1.3368094704139704, Validation Loss Force: 2.819047500070568, time: 0.08060169219970703
Test Loss Energy: 9.448206304364072, Test Loss Force: 8.5862180729986, time: 16.69240713119507


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7935758403169142, Training Loss Force: 3.0763231118655345, time: 1.2516276836395264
Validation Loss Energy: 1.469603114309217, Validation Loss Force: 2.832251112416648, time: 0.08274388313293457
Test Loss Energy: 9.259614267326402, Test Loss Force: 8.58982634373606, time: 16.971100330352783


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.933388759013807, Training Loss Force: 3.05271927862242, time: 1.2546062469482422
Validation Loss Energy: 1.491588909105262, Validation Loss Force: 2.8041827758958666, time: 0.08702397346496582
Test Loss Energy: 9.191117526109378, Test Loss Force: 8.554431569773293, time: 17.139833211898804


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7323982488934415, Training Loss Force: 3.0454953479538425, time: 1.2567105293273926
Validation Loss Energy: 1.5340489092002212, Validation Loss Force: 2.818587688284227, time: 0.0892336368560791
Test Loss Energy: 9.253531240043031, Test Loss Force: 8.53444559397329, time: 17.32358455657959


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9482053473584329, Training Loss Force: 3.0333360342548863, time: 1.2551696300506592
Validation Loss Energy: 1.5236456953679018, Validation Loss Force: 2.799379802418204, time: 0.08489537239074707
Test Loss Energy: 9.590414824102913, Test Loss Force: 8.50909375341602, time: 17.453214406967163


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8363807156243603, Training Loss Force: 3.0224148985382318, time: 1.2454619407653809
Validation Loss Energy: 1.514521493109792, Validation Loss Force: 2.81617885346358, time: 0.08180975914001465
Test Loss Energy: 9.212769654687671, Test Loss Force: 8.526639424599953, time: 17.237600326538086


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8768645172255716, Training Loss Force: 3.0245628371598685, time: 1.2433750629425049
Validation Loss Energy: 1.4117462107807892, Validation Loss Force: 2.793955582023403, time: 0.08230352401733398
Test Loss Energy: 9.402099447067119, Test Loss Force: 8.463755265553887, time: 17.435400009155273


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.807600938084155, Training Loss Force: 3.0390963016854475, time: 1.2391550540924072
Validation Loss Energy: 1.3387573801025467, Validation Loss Force: 2.7925035565228082, time: 0.0834665298461914
Test Loss Energy: 9.322445564017743, Test Loss Force: 8.479726374424349, time: 17.496631622314453


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5969716487703522, Training Loss Force: 3.020716247311244, time: 1.240842580795288
Validation Loss Energy: 1.6153149087054643, Validation Loss Force: 2.810286582524039, time: 0.08396649360656738
Test Loss Energy: 9.611103702277221, Test Loss Force: 8.466287860119001, time: 17.33651638031006


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9731793751910132, Training Loss Force: 3.010817274308971, time: 1.2398219108581543
Validation Loss Energy: 1.407484991335169, Validation Loss Force: 2.788954878344157, time: 0.0827186107635498
Test Loss Energy: 9.372092310474024, Test Loss Force: 8.45127442909484, time: 17.49536681175232

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–„â–†â–‡â–ƒâ–‚â–‚â–„â–…â–„â–‚â–â–‚â–†â–â–„â–ƒâ–‡â–ƒ
wandb:   test_error_force â–ˆâ–‡â–†â–…â–…â–†â–„â–„â–„â–„â–„â–„â–„â–ƒâ–‚â–ƒâ–â–‚â–â–
wandb:          test_loss â–†â–‡â–‡â–†â–ˆâ–…â–ƒâ–…â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–â–â–‚
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒ
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–‚â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–â–ƒâ–‚â–„â–…â–‚â–„â–‚â–ƒâ–â–â–ƒâ–
wandb:         valid_loss â–ˆâ–ƒâ–‚â–„â–†â–‚â–„â–…â–…â–‚â–â–‚â–ƒâ–„â–‡â–„â–â–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1068
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.37209
wandb:   test_error_force 8.45127
wandb:          test_loss 4.60501
wandb: train_error_energy 1.97318
wandb:  train_error_force 3.01082
wandb:         train_loss 1.37981
wandb: valid_error_energy 1.40748
wandb:  valid_error_force 2.78895
wandb:         valid_loss 1.38693
wandb: 
wandb: ğŸš€ View run al_55_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/5xv2vy7x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_062857-5xv2vy7x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7013411521911621, Uncertainty Bias: 0.026312917470932007
0.00023627281 0.0066337585
0.61287206 5.9209566
Found uncertainty sample 4 after 902 steps.
Found uncertainty sample 6 after 3730 steps.
Found uncertainty sample 7 after 2545 steps.
Found uncertainty sample 9 after 3882 steps.
Found uncertainty sample 11 after 989 steps.
Found uncertainty sample 12 after 1796 steps.
Found uncertainty sample 14 after 1932 steps.
Found uncertainty sample 16 after 2766 steps.
Found uncertainty sample 17 after 532 steps.
Found uncertainty sample 19 after 882 steps.
Found uncertainty sample 26 after 175 steps.
Found uncertainty sample 34 after 2642 steps.
Found uncertainty sample 35 after 875 steps.
Found uncertainty sample 37 after 1655 steps.
Found uncertainty sample 39 after 1942 steps.
Found uncertainty sample 41 after 1492 steps.
Found uncertainty sample 54 after 1075 steps.
Found uncertainty sample 63 after 761 steps.
Found uncertainty sample 64 after 2871 steps.
Found uncertainty sample 65 after 1142 steps.
Found uncertainty sample 66 after 2395 steps.
Found uncertainty sample 67 after 3502 steps.
Found uncertainty sample 71 after 875 steps.
Found uncertainty sample 81 after 3650 steps.
Found uncertainty sample 83 after 531 steps.
Found uncertainty sample 91 after 551 steps.
Found uncertainty sample 94 after 473 steps.
Found uncertainty sample 96 after 1384 steps.
Found uncertainty sample 97 after 2609 steps.
Found uncertainty sample 99 after 982 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_090846-gg1k1x9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gg1k1x9v
Training model 6. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2404736036429944, Training Loss Force: 3.3417968541094267, time: 1.2586638927459717
Validation Loss Energy: 1.374969395297345, Validation Loss Force: 2.8969454060745075, time: 0.08450913429260254
Test Loss Energy: 9.177162661873343, Test Loss Force: 8.533548883172305, time: 16.867761373519897


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.942192483300263, Training Loss Force: 3.1279739970787164, time: 1.2731573581695557
Validation Loss Energy: 1.4812297837638364, Validation Loss Force: 2.8348567867622947, time: 0.0818624496459961
Test Loss Energy: 9.033563712049224, Test Loss Force: 8.43183032507339, time: 16.973822355270386


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.866075386514832, Training Loss Force: 3.068088434486436, time: 1.2513148784637451
Validation Loss Energy: 1.4207856874288736, Validation Loss Force: 2.822381302523399, time: 0.0798943042755127
Test Loss Energy: 9.263335131708438, Test Loss Force: 8.432020892556478, time: 16.89547848701477


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.010409068842981, Training Loss Force: 3.1230238711054734, time: 1.2551145553588867
Validation Loss Energy: 1.8288348020962253, Validation Loss Force: 2.848190215220451, time: 0.08014035224914551
Test Loss Energy: 9.50986811472163, Test Loss Force: 8.422313958731538, time: 16.937979221343994


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8464503999856452, Training Loss Force: 3.0837655638590666, time: 1.2758383750915527
Validation Loss Energy: 1.576669787753113, Validation Loss Force: 2.829842945603439, time: 0.08106637001037598
Test Loss Energy: 8.997076642168851, Test Loss Force: 8.410536253144977, time: 16.96798849105835


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7895513682271942, Training Loss Force: 3.1223353208484848, time: 1.2940032482147217
Validation Loss Energy: 1.5585396205533808, Validation Loss Force: 2.8263503800495617, time: 0.08333826065063477
Test Loss Energy: 9.351647440377828, Test Loss Force: 8.412093580167069, time: 16.84211301803589


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2566724951332895, Training Loss Force: 3.073882788259548, time: 1.2833666801452637
Validation Loss Energy: 2.39568910227867, Validation Loss Force: 2.831606485239187, time: 0.08345746994018555
Test Loss Energy: 10.139921832074627, Test Loss Force: 8.42858746955989, time: 16.876213312149048


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9198929985734108, Training Loss Force: 3.0908657131236557, time: 1.243494987487793
Validation Loss Energy: 1.568097916311477, Validation Loss Force: 2.8608453934601106, time: 0.08191156387329102
Test Loss Energy: 9.494990159802757, Test Loss Force: 8.396391422982289, time: 16.808918714523315


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8382746521831328, Training Loss Force: 3.084798774144074, time: 1.2493467330932617
Validation Loss Energy: 1.6693419029239343, Validation Loss Force: 2.868686464764812, time: 0.08089184761047363
Test Loss Energy: 9.50804863966378, Test Loss Force: 8.399468992704316, time: 16.924083471298218


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8474056378977244, Training Loss Force: 3.126349549315466, time: 1.2786953449249268
Validation Loss Energy: 2.597922119331497, Validation Loss Force: 2.879287742802434, time: 0.08480381965637207
Test Loss Energy: 9.067185125617682, Test Loss Force: 8.395187204924971, time: 17.272210597991943


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9926385441238008, Training Loss Force: 3.092515882354249, time: 1.2826342582702637
Validation Loss Energy: 1.725404538474476, Validation Loss Force: 2.851338088936432, time: 0.08982014656066895
Test Loss Energy: 9.478102614676077, Test Loss Force: 8.357615001845492, time: 16.882765531539917


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3147052945630486, Training Loss Force: 3.1268773388110707, time: 1.2346618175506592
Validation Loss Energy: 3.2189258817626722, Validation Loss Force: 3.0125509959264423, time: 0.08943843841552734
Test Loss Energy: 9.001657200646523, Test Loss Force: 8.407428262853871, time: 17.036727905273438


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3166880837828407, Training Loss Force: 3.0994296511817216, time: 1.2744276523590088
Validation Loss Energy: 1.8686530554438971, Validation Loss Force: 2.8305136250709735, time: 0.08427929878234863
Test Loss Energy: 8.875576595489164, Test Loss Force: 8.345996853274576, time: 17.17044186592102


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1787896670115168, Training Loss Force: 3.1103297003173735, time: 1.2980921268463135
Validation Loss Energy: 1.4428791427569747, Validation Loss Force: 2.826117468122921, time: 0.08621025085449219
Test Loss Energy: 8.99533307513943, Test Loss Force: 8.345711580290239, time: 17.422032594680786


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.168455464709496, Training Loss Force: 3.081996572010231, time: 1.283959150314331
Validation Loss Energy: 1.4913251575019106, Validation Loss Force: 2.813277474492141, time: 0.08265852928161621
Test Loss Energy: 9.361202380943242, Test Loss Force: 8.343358389439933, time: 17.45618510246277


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2442418055645783, Training Loss Force: 3.0907132738263536, time: 1.3111722469329834
Validation Loss Energy: 1.669842685833126, Validation Loss Force: 2.8364731420925846, time: 0.082733154296875
Test Loss Energy: 9.00679515945261, Test Loss Force: 8.325042614100289, time: 17.486942768096924


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7642250050172699, Training Loss Force: 3.0478312552610936, time: 1.2814998626708984
Validation Loss Energy: 1.6218650556366492, Validation Loss Force: 2.8246816974699787, time: 0.08736848831176758
Test Loss Energy: 9.2876747812819, Test Loss Force: 8.306572737721979, time: 17.492707014083862


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7860583636970004, Training Loss Force: 3.0632483834149884, time: 1.2718815803527832
Validation Loss Energy: 2.3927906180061282, Validation Loss Force: 2.806213518506728, time: 0.09007072448730469
Test Loss Energy: 8.937268432373017, Test Loss Force: 8.314408094240536, time: 17.814218759536743


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.329954517456963, Training Loss Force: 3.084385869203816, time: 1.489088773727417
Validation Loss Energy: 3.3829887311514124, Validation Loss Force: 2.8487533454905023, time: 0.08579826354980469
Test Loss Energy: 9.034170258139504, Test Loss Force: 8.37165614979267, time: 17.470380306243896


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.207767069406475, Training Loss Force: 3.0804993510349887, time: 1.2819762229919434
Validation Loss Energy: 1.550059154796148, Validation Loss Force: 2.842654660252686, time: 0.08360505104064941
Test Loss Energy: 9.23702027857182, Test Loss Force: 8.312931585626153, time: 17.620190858840942

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–ƒâ–…â–‚â–„â–ˆâ–„â–…â–‚â–„â–‚â–â–‚â–„â–‚â–ƒâ–â–‚â–ƒ
wandb:   test_error_force â–ˆâ–…â–…â–…â–„â–„â–…â–„â–„â–„â–ƒâ–„â–‚â–‚â–‚â–‚â–â–â–ƒâ–
wandb:          test_loss â–‡â–…â–…â–†â–„â–†â–ˆâ–„â–„â–ƒâ–„â–„â–‚â–‚â–…â–â–‚â–â–â–‚
wandb: train_error_energy â–ˆâ–‚â–â–‚â–â–â–ƒâ–‚â–â–â–‚â–„â–„â–ƒâ–ƒâ–ƒâ–â–â–„â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚
wandb: valid_error_energy â–â–â–â–ƒâ–‚â–‚â–…â–‚â–‚â–…â–‚â–‡â–ƒâ–â–â–‚â–‚â–…â–ˆâ–‚
wandb:  valid_error_force â–„â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–‚â–‚â–â–‚â–‚â–â–‚â–‚
wandb:         valid_loss â–ƒâ–‚â–â–ƒâ–â–‚â–„â–â–‚â–„â–‚â–ˆâ–‚â–ƒâ–„â–‚â–‚â–ƒâ–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1095
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.23702
wandb:   test_error_force 8.31293
wandb:          test_loss 4.49051
wandb: train_error_energy 2.20777
wandb:  train_error_force 3.0805
wandb:         train_loss 1.45817
wandb: valid_error_energy 1.55006
wandb:  valid_error_force 2.84265
wandb:         valid_loss 1.41783
wandb: 
wandb: ğŸš€ View run al_55_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gg1k1x9v
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_090846-gg1k1x9v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7349976301193237, Uncertainty Bias: 0.0207635760307312
0.00017547607 0.008922577
0.5351896 5.4854546
Found uncertainty sample 4 after 994 steps.
Found uncertainty sample 8 after 3547 steps.
Found uncertainty sample 9 after 3853 steps.
Found uncertainty sample 10 after 1268 steps.
Found uncertainty sample 14 after 1900 steps.
Found uncertainty sample 15 after 1044 steps.
Found uncertainty sample 18 after 1425 steps.
Found uncertainty sample 19 after 1739 steps.
Found uncertainty sample 21 after 1171 steps.
Found uncertainty sample 25 after 1272 steps.
Found uncertainty sample 29 after 10 steps.
Found uncertainty sample 31 after 279 steps.
Found uncertainty sample 32 after 1322 steps.
Found uncertainty sample 34 after 3561 steps.
Found uncertainty sample 35 after 696 steps.
Found uncertainty sample 36 after 708 steps.
Found uncertainty sample 39 after 3739 steps.
Found uncertainty sample 40 after 1705 steps.
Found uncertainty sample 41 after 392 steps.
Found uncertainty sample 42 after 3670 steps.
Found uncertainty sample 45 after 2738 steps.
Found uncertainty sample 47 after 3620 steps.
Found uncertainty sample 52 after 501 steps.
Found uncertainty sample 53 after 2026 steps.
Found uncertainty sample 54 after 749 steps.
Found uncertainty sample 55 after 3465 steps.
Found uncertainty sample 60 after 2687 steps.
Found uncertainty sample 63 after 749 steps.
Found uncertainty sample 65 after 3369 steps.
Found uncertainty sample 68 after 2277 steps.
Found uncertainty sample 69 after 662 steps.
Found uncertainty sample 71 after 206 steps.
Found uncertainty sample 72 after 1275 steps.
Found uncertainty sample 73 after 903 steps.
Found uncertainty sample 74 after 1312 steps.
Found uncertainty sample 75 after 336 steps.
Found uncertainty sample 80 after 1197 steps.
Found uncertainty sample 81 after 1769 steps.
Found uncertainty sample 85 after 1893 steps.
Found uncertainty sample 88 after 2119 steps.
Found uncertainty sample 89 after 3745 steps.
Found uncertainty sample 91 after 940 steps.
Found uncertainty sample 92 after 575 steps.
Found uncertainty sample 93 after 326 steps.
Found uncertainty sample 94 after 1599 steps.
Found uncertainty sample 96 after 683 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_113054-rvivxedx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/rvivxedx
Training model 7. Added 46 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.837874939251071, Training Loss Force: 3.6075253660945723, time: 1.2949409484863281
Validation Loss Energy: 2.4844822095928563, Validation Loss Force: 2.9149749268202805, time: 0.09065890312194824
Test Loss Energy: 9.619704028737255, Test Loss Force: 8.273145211855075, time: 17.149376153945923


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.3410654970099567, Training Loss Force: 3.2406080733634983, time: 1.3341064453125
Validation Loss Energy: 1.9124556391542278, Validation Loss Force: 2.8864672640745836, time: 0.08963823318481445
Test Loss Energy: 8.89316081291729, Test Loss Force: 8.277900713669796, time: 17.278129816055298


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.031808797121533, Training Loss Force: 3.1843614821721506, time: 1.375830888748169
Validation Loss Energy: 1.6426305121784368, Validation Loss Force: 2.8626492362112717, time: 0.0848684310913086
Test Loss Energy: 8.924510287723374, Test Loss Force: 8.209741177477815, time: 17.158632516860962


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8784283701183435, Training Loss Force: 3.1752830384235278, time: 1.3105254173278809
Validation Loss Energy: 1.481644059709835, Validation Loss Force: 2.8690200231454117, time: 0.08692693710327148
Test Loss Energy: 8.963898668958377, Test Loss Force: 8.256088536105285, time: 17.24276900291443


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0578926598244003, Training Loss Force: 3.1760551746133037, time: 1.337193250656128
Validation Loss Energy: 1.790837203020232, Validation Loss Force: 2.865781300417892, time: 0.08536171913146973
Test Loss Energy: 9.391006350010686, Test Loss Force: 8.224243010400814, time: 17.304837942123413


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2000255177791668, Training Loss Force: 3.1934525871358197, time: 1.3662402629852295
Validation Loss Energy: 1.9400167353605857, Validation Loss Force: 2.8621206196588393, time: 0.08865475654602051
Test Loss Energy: 9.403424843772104, Test Loss Force: 8.207426593493668, time: 17.179970502853394


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.173455500292944, Training Loss Force: 3.174843303971845, time: 1.3114535808563232
Validation Loss Energy: 1.5469675050395135, Validation Loss Force: 2.8571139039126527, time: 0.08695507049560547
Test Loss Energy: 9.202817838429333, Test Loss Force: 8.2114844903613, time: 17.261626482009888


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9952674109631288, Training Loss Force: 3.1567421456136247, time: 1.3180365562438965
Validation Loss Energy: 1.5060555008470444, Validation Loss Force: 2.874277019011621, time: 0.0870053768157959
Test Loss Energy: 8.9451774632337, Test Loss Force: 8.197659830451089, time: 17.11960220336914


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0912887700735254, Training Loss Force: 3.1599912348269377, time: 1.5463104248046875
Validation Loss Energy: 1.3922113352739713, Validation Loss Force: 2.8533336498222366, time: 0.08535027503967285
Test Loss Energy: 8.988658591972191, Test Loss Force: 8.193814791297278, time: 17.142930269241333


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9525863034988906, Training Loss Force: 3.156341693710436, time: 1.3834497928619385
Validation Loss Energy: 2.446996081545059, Validation Loss Force: 2.860045120549646, time: 0.08372735977172852
Test Loss Energy: 8.802224258596, Test Loss Force: 8.206893073556797, time: 17.712308645248413


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.013121381828354, Training Loss Force: 3.1547511803715818, time: 1.3430914878845215
Validation Loss Energy: 1.384451092869242, Validation Loss Force: 2.8547320120586632, time: 0.08817458152770996
Test Loss Energy: 8.953306106494235, Test Loss Force: 8.163538350944771, time: 17.190807104110718


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0700318425225235, Training Loss Force: 3.1762863113720305, time: 1.3219213485717773
Validation Loss Energy: 1.3635434620777795, Validation Loss Force: 2.8445671655470597, time: 0.09075784683227539
Test Loss Energy: 8.989596600322, Test Loss Force: 8.160757430152243, time: 17.303595542907715


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9385781596949303, Training Loss Force: 3.1461779914708314, time: 1.3468363285064697
Validation Loss Energy: 1.4453152545479977, Validation Loss Force: 2.849940840045735, time: 0.09181046485900879
Test Loss Energy: 8.923280300667095, Test Loss Force: 8.165374366473, time: 17.55783176422119


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9631739770702221, Training Loss Force: 3.162897871264322, time: 1.369873046875
Validation Loss Energy: 1.4196079903160617, Validation Loss Force: 2.881025898155546, time: 0.08781743049621582
Test Loss Energy: 8.880562955078506, Test Loss Force: 8.198416707360046, time: 17.53501534461975


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.584640374856213, Training Loss Force: 3.15648472152517, time: 1.3329360485076904
Validation Loss Energy: 1.983882334439214, Validation Loss Force: 2.8695383969171315, time: 0.08673381805419922
Test Loss Energy: 9.518652825224176, Test Loss Force: 8.112091327941085, time: 17.7060284614563


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9312444060203282, Training Loss Force: 3.1550711311932633, time: 1.4172227382659912
Validation Loss Energy: 1.6162055852891755, Validation Loss Force: 2.853650730686038, time: 0.08689713478088379
Test Loss Energy: 9.225204106015944, Test Loss Force: 8.112271172330958, time: 17.837932348251343


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0366801887869084, Training Loss Force: 3.1509236709401964, time: 1.3709845542907715
Validation Loss Energy: 2.427498948458476, Validation Loss Force: 2.8724132782602054, time: 0.08730769157409668
Test Loss Energy: 9.706378131354876, Test Loss Force: 8.188421914790734, time: 17.907349348068237


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3421403549962476, Training Loss Force: 3.142706066109731, time: 1.3464205265045166
Validation Loss Energy: 2.5603676318559003, Validation Loss Force: 2.8559718338631894, time: 0.09385466575622559
Test Loss Energy: 9.83627280949927, Test Loss Force: 8.134568973815632, time: 17.800292491912842


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1878401559742797, Training Loss Force: 3.156307464514503, time: 1.393665075302124
Validation Loss Energy: 1.4097935137055755, Validation Loss Force: 2.8924951405239945, time: 0.08845186233520508
Test Loss Energy: 8.800041490083016, Test Loss Force: 8.156719139827523, time: 17.836645126342773


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0550957312381635, Training Loss Force: 3.136200156115537, time: 1.4094023704528809
Validation Loss Energy: 1.4060727122771222, Validation Loss Force: 2.8504670072375626, time: 0.08643937110900879
Test Loss Energy: 8.992770048347166, Test Loss Force: 8.106712007438881, time: 17.642178297042847

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–‚â–‚â–‚â–…â–…â–„â–‚â–‚â–â–‚â–‚â–‚â–‚â–†â–„â–‡â–ˆâ–â–‚
wandb:   test_error_force â–ˆâ–ˆâ–…â–‡â–†â–…â–…â–…â–…â–…â–ƒâ–ƒâ–ƒâ–…â–â–â–„â–‚â–ƒâ–
wandb:          test_loss â–ˆâ–„â–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–„â–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–
wandb: valid_error_energy â–ˆâ–„â–ƒâ–‚â–ƒâ–„â–‚â–‚â–â–‡â–â–â–â–â–…â–‚â–‡â–ˆâ–â–
wandb:  valid_error_force â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–‚â–â–‚â–…â–ƒâ–‚â–„â–‚â–†â–‚
wandb:         valid_loss â–ˆâ–‚â–â–‚â–ƒâ–ƒâ–â–â–â–ƒâ–‚â–â–â–‚â–‚â–â–ƒâ–ƒâ–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1136
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.99277
wandb:   test_error_force 8.10671
wandb:          test_loss 4.36528
wandb: train_error_energy 2.0551
wandb:  train_error_force 3.1362
wandb:         train_loss 1.45704
wandb: valid_error_energy 1.40607
wandb:  valid_error_force 2.85047
wandb:         valid_loss 1.41241
wandb: 
wandb: ğŸš€ View run al_55_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/rvivxedx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_113054-rvivxedx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7228235006332397, Uncertainty Bias: 0.02268126606941223
0.00028800964 6.888062e-05
0.40040186 5.002351
Found uncertainty sample 5 after 2929 steps.
Found uncertainty sample 6 after 3834 steps.
Found uncertainty sample 10 after 1645 steps.
Found uncertainty sample 12 after 1312 steps.
Found uncertainty sample 13 after 938 steps.
Found uncertainty sample 17 after 2171 steps.
Found uncertainty sample 22 after 3210 steps.
Found uncertainty sample 26 after 3370 steps.
Found uncertainty sample 27 after 69 steps.
Found uncertainty sample 33 after 435 steps.
Found uncertainty sample 35 after 142 steps.
Found uncertainty sample 40 after 3110 steps.
Found uncertainty sample 45 after 2010 steps.
Found uncertainty sample 47 after 2902 steps.
Found uncertainty sample 50 after 629 steps.
Found uncertainty sample 52 after 3439 steps.
Found uncertainty sample 53 after 104 steps.
Found uncertainty sample 58 after 4 steps.
Found uncertainty sample 60 after 1298 steps.
Found uncertainty sample 61 after 2373 steps.
Found uncertainty sample 63 after 1613 steps.
Found uncertainty sample 65 after 2292 steps.
Found uncertainty sample 66 after 2981 steps.
Found uncertainty sample 69 after 1962 steps.
Found uncertainty sample 77 after 3158 steps.
Found uncertainty sample 80 after 838 steps.
Found uncertainty sample 82 after 2560 steps.
Found uncertainty sample 83 after 670 steps.
Found uncertainty sample 84 after 1526 steps.
Found uncertainty sample 88 after 1682 steps.
Found uncertainty sample 91 after 1145 steps.
Found uncertainty sample 96 after 3725 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_141146-wjafaucq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/wjafaucq
Training model 8. Added 32 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.850399655760903, Training Loss Force: 3.3932439572639224, time: 1.3668975830078125
Validation Loss Energy: 2.8099018102398756, Validation Loss Force: 2.9162978042162373, time: 0.09058785438537598
Test Loss Energy: 8.77243856938305, Test Loss Force: 8.08734350833603, time: 17.319905281066895


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9582425600217916, Training Loss Force: 3.224060541996492, time: 1.3038625717163086
Validation Loss Energy: 1.4740658493319019, Validation Loss Force: 2.8966142970545126, time: 0.09952759742736816
Test Loss Energy: 8.739861308564391, Test Loss Force: 8.054000305292817, time: 17.146854877471924


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.13421460689378, Training Loss Force: 3.2076586364180906, time: 1.3120524883270264
Validation Loss Energy: 1.6383294349556956, Validation Loss Force: 2.9117025810517254, time: 0.08710932731628418
Test Loss Energy: 8.712763172989206, Test Loss Force: 8.098314030107952, time: 17.06348443031311


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.03897150862844, Training Loss Force: 3.2009618618543128, time: 1.333343267440796
Validation Loss Energy: 1.9276683952040143, Validation Loss Force: 2.9125603026018396, time: 0.0848841667175293
Test Loss Energy: 8.572431490678147, Test Loss Force: 8.046809089810184, time: 17.175369262695312


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.433843565749885, Training Loss Force: 3.2311630859430855, time: 1.3509585857391357
Validation Loss Energy: 2.212857247910531, Validation Loss Force: 2.8839600094914366, time: 0.09075784683227539
Test Loss Energy: 8.668624048763851, Test Loss Force: 8.069862275970797, time: 17.170491456985474


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.138816642530541, Training Loss Force: 3.2043548341191097, time: 1.371927261352539
Validation Loss Energy: 1.7177770068807197, Validation Loss Force: 2.8938948387752967, time: 0.08896017074584961
Test Loss Energy: 8.68403895342393, Test Loss Force: 8.070336864361455, time: 17.143784284591675


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8811364293922612, Training Loss Force: 3.1935725621743587, time: 1.3470401763916016
Validation Loss Energy: 1.723384929320911, Validation Loss Force: 2.8840379436925114, time: 0.09184670448303223
Test Loss Energy: 9.034500848375362, Test Loss Force: 8.031062335842638, time: 17.179425716400146


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.877093194013377, Training Loss Force: 3.199383757472442, time: 1.335073709487915
Validation Loss Energy: 2.395696005022194, Validation Loss Force: 2.879669397718554, time: 0.08921146392822266
Test Loss Energy: 8.619704929117724, Test Loss Force: 8.009579496437215, time: 17.09114980697632


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0398080585554355, Training Loss Force: 3.201212791927518, time: 1.5736029148101807
Validation Loss Energy: 1.4162033790748256, Validation Loss Force: 2.8733489340113936, time: 0.08961677551269531
Test Loss Energy: 8.763266708349965, Test Loss Force: 8.03379677590821, time: 17.454695224761963


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.343994645598899, Training Loss Force: 3.1851469663073417, time: 1.3751025199890137
Validation Loss Energy: 1.7539384761793924, Validation Loss Force: 2.878171279704752, time: 0.08467602729797363
Test Loss Energy: 9.1269640503405, Test Loss Force: 8.026645022994106, time: 17.31222701072693


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.211725929169964, Training Loss Force: 3.212306451627636, time: 1.3506131172180176
Validation Loss Energy: 1.5274878514808858, Validation Loss Force: 2.8871212433561735, time: 0.08524417877197266
Test Loss Energy: 8.67925737017396, Test Loss Force: 8.021059193763259, time: 17.164071798324585


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3401101281854237, Training Loss Force: 3.1964031564297324, time: 1.3323228359222412
Validation Loss Energy: 1.8240568788974798, Validation Loss Force: 2.893143998415228, time: 0.08844280242919922
Test Loss Energy: 8.64620940310211, Test Loss Force: 7.978833823411623, time: 17.254358291625977


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0757988609808815, Training Loss Force: 3.2028349246194314, time: 1.3454911708831787
Validation Loss Energy: 2.5403303034212965, Validation Loss Force: 2.9085965691351787, time: 0.09878015518188477
Test Loss Energy: 8.588042787193318, Test Loss Force: 8.02247216822521, time: 17.344789266586304


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.099141583497956, Training Loss Force: 3.196255382351942, time: 1.326221227645874
Validation Loss Energy: 2.126364535542925, Validation Loss Force: 2.881758256976503, time: 0.08833718299865723
Test Loss Energy: 9.36370436141531, Test Loss Force: 7.977836044134529, time: 17.53235936164856


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.310748451029988, Training Loss Force: 3.189313731908493, time: 1.308469533920288
Validation Loss Energy: 1.6694923159320085, Validation Loss Force: 2.8662382175053356, time: 0.08616423606872559
Test Loss Energy: 8.99804986721793, Test Loss Force: 7.977300920047162, time: 17.544330596923828


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.780752421111802, Training Loss Force: 3.1521687751188523, time: 1.4281537532806396
Validation Loss Energy: 1.4132110397572752, Validation Loss Force: 2.875575402801526, time: 0.08564162254333496
Test Loss Energy: 8.665982073518382, Test Loss Force: 7.963661439259866, time: 17.686551332473755


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.215830952227801, Training Loss Force: 3.181072800980472, time: 1.3743116855621338
Validation Loss Energy: 1.9817756616495912, Validation Loss Force: 2.891476206512229, time: 0.08793377876281738
Test Loss Energy: 9.145371667959289, Test Loss Force: 7.998623118236384, time: 18.0356867313385


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.049511823464757, Training Loss Force: 3.1676588023999996, time: 1.348681926727295
Validation Loss Energy: 1.5430599955321997, Validation Loss Force: 2.8961484732012317, time: 0.08812260627746582
Test Loss Energy: 8.471921338215465, Test Loss Force: 7.9936966508182605, time: 17.716877222061157


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8689094499383057, Training Loss Force: 3.1690361073569235, time: 1.2997379302978516
Validation Loss Energy: 1.4332708577756177, Validation Loss Force: 2.8956748559278433, time: 0.09047603607177734
Test Loss Energy: 8.618872486927613, Test Loss Force: 7.9460170078977725, time: 17.61336922645569


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0896735409609803, Training Loss Force: 3.18046288009935, time: 1.3629145622253418
Validation Loss Energy: 1.5680247694970397, Validation Loss Force: 2.865790207183729, time: 0.0926668643951416
Test Loss Energy: 8.573664895880688, Test Loss Force: 7.950375449822055, time: 17.707309246063232

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–†â–ƒâ–‚â–‚â–ˆâ–…â–ƒâ–†â–â–‚â–‚
wandb:   test_error_force â–‡â–†â–ˆâ–†â–‡â–‡â–…â–„â–…â–…â–„â–ƒâ–…â–‚â–‚â–‚â–ƒâ–ƒâ–â–
wandb:          test_loss â–†â–…â–†â–„â–‡â–‡â–†â–„â–…â–ˆâ–‚â–ƒâ–†â–†â–ƒâ–‚â–ˆâ–‚â–‚â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–
wandb: valid_error_energy â–ˆâ–â–‚â–„â–…â–ƒâ–ƒâ–†â–â–ƒâ–‚â–ƒâ–‡â–…â–‚â–â–„â–‚â–â–‚
wandb:  valid_error_force â–ˆâ–…â–‡â–‡â–„â–…â–„â–ƒâ–‚â–ƒâ–„â–…â–‡â–ƒâ–â–‚â–…â–…â–…â–
wandb:         valid_loss â–ˆâ–ƒâ–„â–…â–…â–„â–‚â–…â–â–ƒâ–‡â–„â–†â–†â–â–â–ˆâ–ƒâ–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1164
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.57366
wandb:   test_error_force 7.95038
wandb:          test_loss 4.28101
wandb: train_error_energy 2.08967
wandb:  train_error_force 3.18046
wandb:         train_loss 1.45303
wandb: valid_error_energy 1.56802
wandb:  valid_error_force 2.86579
wandb:         valid_loss 1.45683
wandb: 
wandb: ğŸš€ View run al_55_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/wjafaucq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_141146-wjafaucq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7066308259963989, Uncertainty Bias: 0.027644142508506775
3.8146973e-06 0.010543346
0.8193185 5.896148
Found uncertainty sample 0 after 703 steps.
Found uncertainty sample 2 after 1403 steps.
Found uncertainty sample 8 after 1513 steps.
Found uncertainty sample 17 after 1355 steps.
Found uncertainty sample 19 after 2183 steps.
Found uncertainty sample 30 after 668 steps.
Found uncertainty sample 33 after 2667 steps.
Found uncertainty sample 34 after 1278 steps.
Found uncertainty sample 37 after 1256 steps.
Found uncertainty sample 39 after 408 steps.
Found uncertainty sample 46 after 664 steps.
Found uncertainty sample 47 after 2967 steps.
Found uncertainty sample 51 after 1996 steps.
Found uncertainty sample 52 after 1070 steps.
Found uncertainty sample 59 after 577 steps.
Found uncertainty sample 60 after 2270 steps.
Found uncertainty sample 61 after 291 steps.
Found uncertainty sample 63 after 3967 steps.
Found uncertainty sample 67 after 2530 steps.
Found uncertainty sample 68 after 1939 steps.
Found uncertainty sample 69 after 1902 steps.
Found uncertainty sample 70 after 1677 steps.
Found uncertainty sample 71 after 519 steps.
Found uncertainty sample 75 after 1283 steps.
Found uncertainty sample 80 after 2019 steps.
Found uncertainty sample 85 after 2849 steps.
Found uncertainty sample 89 after 3371 steps.
Found uncertainty sample 95 after 1311 steps.
Found uncertainty sample 97 after 3776 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_165241-m31rlafz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/m31rlafz
Training model 9. Added 29 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.298919810684827, Training Loss Force: 3.3761418717235645, time: 1.3524844646453857
Validation Loss Energy: 1.5748695077082868, Validation Loss Force: 2.9753899648316997, time: 0.08774423599243164
Test Loss Energy: 8.77619696808876, Test Loss Force: 8.006312191618331, time: 16.896591901779175


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.06386553406491, Training Loss Force: 3.266338828864791, time: 1.3734922409057617
Validation Loss Energy: 1.480349238626265, Validation Loss Force: 2.91844767482017, time: 0.08783769607543945
Test Loss Energy: 8.680450501406265, Test Loss Force: 7.949181416255098, time: 17.09204649925232


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8963242000159155, Training Loss Force: 3.29312845851651, time: 1.3643543720245361
Validation Loss Energy: 1.6128736755240851, Validation Loss Force: 2.907668261465806, time: 0.0853126049041748
Test Loss Energy: 8.78044322673255, Test Loss Force: 7.929969065348086, time: 17.096622228622437


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.917270440465339, Training Loss Force: 3.2296850732427576, time: 1.3355107307434082
Validation Loss Energy: 1.4446799794746656, Validation Loss Force: 2.9076731601870165, time: 0.09110212326049805
Test Loss Energy: 8.567486897292062, Test Loss Force: 7.922964446609739, time: 17.13961887359619


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0060056904247987, Training Loss Force: 3.257986204495893, time: 1.365955114364624
Validation Loss Energy: 1.8252938060031088, Validation Loss Force: 2.9123959727721447, time: 0.0888373851776123
Test Loss Energy: 8.937089369073867, Test Loss Force: 7.947676958582576, time: 17.08279800415039


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.063196228700395, Training Loss Force: 3.2146910310317014, time: 1.3546011447906494
Validation Loss Energy: 1.5038504082949216, Validation Loss Force: 2.8912619987938464, time: 0.08823728561401367
Test Loss Energy: 8.739596313627825, Test Loss Force: 7.927381869044131, time: 17.36110806465149


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.029798602087407, Training Loss Force: 3.240126586168176, time: 1.3368501663208008
Validation Loss Energy: 1.4818245330526096, Validation Loss Force: 2.8930547080877114, time: 0.08796930313110352
Test Loss Energy: 8.733637449458158, Test Loss Force: 7.917820215761738, time: 17.131927013397217


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9000899747521316, Training Loss Force: 3.250306761692563, time: 1.4039487838745117
Validation Loss Energy: 1.4621458132775225, Validation Loss Force: 2.898768175703072, time: 0.09000468254089355
Test Loss Energy: 8.64450670693613, Test Loss Force: 7.906793548722446, time: 17.03885245323181


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8859210565001687, Training Loss Force: 3.217684214148121, time: 1.5887172222137451
Validation Loss Energy: 1.4533047348384596, Validation Loss Force: 2.9099007423228778, time: 0.08582258224487305
Test Loss Energy: 8.605720782140288, Test Loss Force: 7.936957470042028, time: 17.022624492645264


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0046038636322536, Training Loss Force: 3.2317370573181976, time: 1.3576459884643555
Validation Loss Energy: 1.4345483106658055, Validation Loss Force: 2.90362882048953, time: 0.08797001838684082
Test Loss Energy: 8.631426717935096, Test Loss Force: 7.921123637282931, time: 17.139811754226685


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0905728552387797, Training Loss Force: 3.231911360381744, time: 1.377748727798462
Validation Loss Energy: 1.5166215971596098, Validation Loss Force: 2.877767803212331, time: 0.08641934394836426
Test Loss Energy: 8.436814446313203, Test Loss Force: 7.889550187627029, time: 17.10577082633972


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3100650632673285, Training Loss Force: 3.238734300455548, time: 1.3780229091644287
Validation Loss Energy: 1.8533044712150948, Validation Loss Force: 2.927745002339239, time: 0.08936643600463867
Test Loss Energy: 8.323742268257124, Test Loss Force: 7.832547984459754, time: 17.184097290039062


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0455384570236053, Training Loss Force: 3.222792888924285, time: 1.389714002609253
Validation Loss Energy: 1.943025663529508, Validation Loss Force: 2.9185752642407867, time: 0.09141373634338379
Test Loss Energy: 8.34227977543383, Test Loss Force: 7.871559012606639, time: 17.312607288360596


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.14753401353057, Training Loss Force: 3.224777908183944, time: 1.4110524654388428
Validation Loss Energy: 1.6422896057160215, Validation Loss Force: 2.8843516845191237, time: 0.09242010116577148
Test Loss Energy: 8.378230574072703, Test Loss Force: 7.857385067578764, time: 17.35990047454834


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9105763760194552, Training Loss Force: 3.22143548609128, time: 1.3820011615753174
Validation Loss Energy: 1.608103323076301, Validation Loss Force: 2.8969022082601974, time: 0.08779144287109375
Test Loss Energy: 8.388317530683898, Test Loss Force: 7.860149874586291, time: 17.589815616607666


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9457646434471358, Training Loss Force: 3.2225441733479974, time: 1.4063096046447754
Validation Loss Energy: 3.1485408327423365, Validation Loss Force: 2.895508744744981, time: 0.08700847625732422
Test Loss Energy: 8.50185416160417, Test Loss Force: 7.905987029417824, time: 17.725289821624756


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2106295925282393, Training Loss Force: 3.239158760585116, time: 1.3632540702819824
Validation Loss Energy: 1.9817204397014012, Validation Loss Force: 2.9181081043726302, time: 0.09270119667053223
Test Loss Energy: 8.354471820502875, Test Loss Force: 7.889423557665612, time: 17.938647270202637


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8211919356299717, Training Loss Force: 3.213696309359699, time: 1.3658418655395508
Validation Loss Energy: 2.149790220371112, Validation Loss Force: 2.872050550221489, time: 0.0957174301147461
Test Loss Energy: 8.990653963997254, Test Loss Force: 7.833654493896872, time: 17.70850110054016


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.873469403719601, Training Loss Force: 3.200167723114566, time: 1.4058406352996826
Validation Loss Energy: 2.0101058570859838, Validation Loss Force: 2.9047675505018047, time: 0.0904085636138916
Test Loss Energy: 8.774983819949464, Test Loss Force: 7.85420514466126, time: 17.59657597541809


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.3066263455586227, Training Loss Force: 3.2070788577492997, time: 1.378448486328125
Validation Loss Energy: 3.5297243582806357, Validation Loss Force: 2.926532791508808, time: 0.09392356872558594
Test Loss Energy: 8.512502176846297, Test Loss Force: 7.835631450833824, time: 17.72642469406128

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–†â–„â–‡â–…â–…â–„â–„â–„â–‚â–â–â–‚â–‚â–ƒâ–â–ˆâ–†â–ƒ
wandb:   test_error_force â–ˆâ–†â–…â–…â–†â–…â–„â–„â–…â–…â–ƒâ–â–ƒâ–‚â–‚â–„â–ƒâ–â–‚â–
wandb:          test_loss â–ˆâ–†â–‡â–†â–†â–…â–ˆâ–…â–„â–„â–„â–ƒâ–â–â–‚â–‡â–„â–‚â–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–„â–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–‚â–â–‚â–â–â–‚â–‚â–â–‚â–â–â–‚â–â–â–‚
wandb: valid_error_energy â–â–â–‚â–â–‚â–â–â–â–â–â–â–‚â–ƒâ–‚â–‚â–‡â–ƒâ–ƒâ–ƒâ–ˆ
wandb:  valid_error_force â–ˆâ–„â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–„â–ƒâ–â–…â–„â–‚â–ƒâ–ƒâ–„â–â–ƒâ–…
wandb:         valid_loss â–ƒâ–â–‚â–â–ƒâ–‚â–…â–‚â–â–ƒâ–â–„â–„â–ƒâ–â–‡â–ƒâ–ƒâ–ƒâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1190
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.5125
wandb:   test_error_force 7.83563
wandb:          test_loss 4.22684
wandb: train_error_energy 2.30663
wandb:  train_error_force 3.20708
wandb:         train_loss 1.49769
wandb: valid_error_energy 3.52972
wandb:  valid_error_force 2.92653
wandb:         valid_loss 1.57083
wandb: 
wandb: ğŸš€ View run al_55_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/m31rlafz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_165241-m31rlafz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6967669129371643, Uncertainty Bias: 0.030797362327575684
0.00012207031 0.099824905
0.60038584 6.974499
Found uncertainty sample 0 after 2593 steps.
Found uncertainty sample 6 after 2455 steps.
Found uncertainty sample 7 after 1817 steps.
Found uncertainty sample 9 after 467 steps.
Found uncertainty sample 10 after 622 steps.
Found uncertainty sample 11 after 1453 steps.
Found uncertainty sample 13 after 536 steps.
Found uncertainty sample 15 after 2051 steps.
Found uncertainty sample 30 after 3654 steps.
Found uncertainty sample 33 after 2540 steps.
Found uncertainty sample 35 after 2278 steps.
Found uncertainty sample 39 after 734 steps.
Found uncertainty sample 40 after 1505 steps.
Found uncertainty sample 54 after 419 steps.
Found uncertainty sample 56 after 2141 steps.
Found uncertainty sample 60 after 1588 steps.
Found uncertainty sample 61 after 1564 steps.
Found uncertainty sample 62 after 2190 steps.
Found uncertainty sample 73 after 109 steps.
Found uncertainty sample 75 after 3604 steps.
Found uncertainty sample 79 after 1922 steps.
Found uncertainty sample 81 after 675 steps.
Found uncertainty sample 83 after 10 steps.
Found uncertainty sample 84 after 1024 steps.
Found uncertainty sample 86 after 213 steps.
Found uncertainty sample 97 after 90 steps.
Found uncertainty sample 98 after 842 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_193332-9hfblxen
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9hfblxen
Training model 10. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.7872844088706, Training Loss Force: 3.45617754802127, time: 1.3848252296447754
Validation Loss Energy: 1.612485229199014, Validation Loss Force: 2.9468954395656124, time: 0.08851432800292969
Test Loss Energy: 8.33091471657792, Test Loss Force: 7.9047594858931145, time: 16.975186824798584


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.029409317823182, Training Loss Force: 3.304637646557795, time: 1.388270616531372
Validation Loss Energy: 1.6983288610062408, Validation Loss Force: 2.89897280864818, time: 0.08791542053222656
Test Loss Energy: 8.68871224718894, Test Loss Force: 7.827813984790204, time: 17.00164818763733


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.882052317792961, Training Loss Force: 3.275436357703104, time: 1.4141349792480469
Validation Loss Energy: 1.8766263922212794, Validation Loss Force: 2.9138669251501437, time: 0.09196662902832031
Test Loss Energy: 8.297503586621326, Test Loss Force: 7.781045147277899, time: 17.318180561065674


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1101280756738783, Training Loss Force: 3.255565304523364, time: 1.41953444480896
Validation Loss Energy: 1.8955991394692024, Validation Loss Force: 2.963891107466843, time: 0.0846867561340332
Test Loss Energy: 8.306988571769095, Test Loss Force: 7.8282303994092315, time: 17.099120140075684


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.241916465060548, Training Loss Force: 3.288251687796116, time: 1.3643929958343506
Validation Loss Energy: 2.5150181655888093, Validation Loss Force: 2.9238794659659324, time: 0.08703160285949707
Test Loss Energy: 8.327579195725503, Test Loss Force: 7.789880861838739, time: 17.074275493621826


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0297995367118484, Training Loss Force: 3.2648986517066447, time: 1.416541337966919
Validation Loss Energy: 1.508905888584066, Validation Loss Force: 2.9155108914545287, time: 0.09089112281799316
Test Loss Energy: 8.388721368576501, Test Loss Force: 7.79556736783453, time: 16.901188135147095


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9222814308731553, Training Loss Force: 3.2626112829051017, time: 1.4208111763000488
Validation Loss Energy: 1.501058471208706, Validation Loss Force: 2.9002507068766596, time: 0.08895730972290039
Test Loss Energy: 8.3572775403429, Test Loss Force: 7.790225343831366, time: 17.059775352478027


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.115253951641565, Training Loss Force: 3.2534671693375734, time: 1.3763296604156494
Validation Loss Energy: 1.5905362861466201, Validation Loss Force: 2.9113667959796663, time: 0.08793759346008301
Test Loss Energy: 8.60328979465414, Test Loss Force: 7.825446305289923, time: 16.863240242004395


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.323043070750583, Training Loss Force: 3.2661341021642536, time: 1.5937304496765137
Validation Loss Energy: 1.459224171413804, Validation Loss Force: 2.9062692312219416, time: 0.08565807342529297
Test Loss Energy: 8.383477085836137, Test Loss Force: 7.757195943402541, time: 17.00751495361328


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.268416560365703, Training Loss Force: 3.2426465153134982, time: 1.3537161350250244
Validation Loss Energy: 1.4534407856866216, Validation Loss Force: 2.8929803365929714, time: 0.08619856834411621
Test Loss Energy: 8.465387882726672, Test Loss Force: 7.766448440977435, time: 17.062624216079712


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9485313603227183, Training Loss Force: 3.237526572306608, time: 1.3608744144439697
Validation Loss Energy: 1.863263460101288, Validation Loss Force: 2.9007973596299124, time: 0.08503937721252441
Test Loss Energy: 8.243435654505504, Test Loss Force: 7.7900634598648555, time: 16.94657063484192


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1341077115295617, Training Loss Force: 3.242219090168461, time: 1.3650751113891602
Validation Loss Energy: 1.8561823585916384, Validation Loss Force: 2.895849873876543, time: 0.0903475284576416
Test Loss Energy: 8.188646798970051, Test Loss Force: 7.751686017536892, time: 17.555971384048462


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.981614903315803, Training Loss Force: 3.2581735805821905, time: 1.421252727508545
Validation Loss Energy: 1.4546502131527284, Validation Loss Force: 2.905356065054492, time: 0.08949518203735352
Test Loss Energy: 8.435995324634407, Test Loss Force: 7.786670474051489, time: 17.429370164871216


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.04541656617521, Training Loss Force: 3.2468944332075065, time: 1.4446773529052734
Validation Loss Energy: 1.4698292348269066, Validation Loss Force: 2.8907903855427715, time: 0.0891561508178711
Test Loss Energy: 8.260555433059126, Test Loss Force: 7.76287863720929, time: 17.446479082107544


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0751036927376005, Training Loss Force: 3.24769106723535, time: 1.3977899551391602
Validation Loss Energy: 1.9696588974047846, Validation Loss Force: 2.890815547156261, time: 0.08802103996276855
Test Loss Energy: 8.193629376681335, Test Loss Force: 7.761662686469853, time: 17.619057178497314


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9473018897036203, Training Loss Force: 3.2459805052771884, time: 1.4026942253112793
Validation Loss Energy: 1.5198397229911311, Validation Loss Force: 2.882164405498675, time: 0.08816146850585938
Test Loss Energy: 8.28365029215843, Test Loss Force: 7.726215728652058, time: 17.49991273880005


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8372462316286489, Training Loss Force: 3.23897247440569, time: 1.3606796264648438
Validation Loss Energy: 1.5631964117367414, Validation Loss Force: 2.8979503119300793, time: 0.08687210083007812
Test Loss Energy: 8.214304682530006, Test Loss Force: 7.726535241389359, time: 17.574824333190918


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.949499666402357, Training Loss Force: 3.235351053732893, time: 1.3730394840240479
Validation Loss Energy: 1.9275501578875267, Validation Loss Force: 2.8889257541147724, time: 0.0912470817565918
Test Loss Energy: 8.13723691624726, Test Loss Force: 7.727372202247586, time: 17.58546805381775


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1231131001650865, Training Loss Force: 3.2371754289231935, time: 1.364311933517456
Validation Loss Energy: 2.076385109724557, Validation Loss Force: 2.8837333323008822, time: 0.08986043930053711
Test Loss Energy: 8.17507056787827, Test Loss Force: 7.710379391739427, time: 17.572818756103516


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.3495462687744957, Training Loss Force: 3.2521318576277314, time: 1.3742263317108154
Validation Loss Energy: 1.5849654381192257, Validation Loss Force: 2.8869482294297875, time: 0.09090495109558105
Test Loss Energy: 8.1748471969165, Test Loss Force: 7.725079129735065, time: 17.828248262405396

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–„â–„â–‡â–„â–…â–‚â–‚â–…â–ƒâ–‚â–ƒâ–‚â–â–â–
wandb:   test_error_force â–ˆâ–…â–„â–…â–„â–„â–„â–…â–ƒâ–ƒâ–„â–‚â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚
wandb:          test_loss â–‡â–…â–ƒâ–…â–…â–„â–„â–ˆâ–‚â–‚â–„â–…â–ƒâ–â–â–â–â–â–‚â–ƒ
wandb: train_error_energy â–ˆâ–â–â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–‚â–ƒâ–„â–„â–ˆâ–â–â–‚â–â–â–„â–„â–â–â–„â–â–‚â–„â–…â–‚
wandb:  valid_error_force â–‡â–‚â–„â–ˆâ–…â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–
wandb:         valid_loss â–…â–ƒâ–ƒâ–†â–†â–‚â–ƒâ–ˆâ–ˆâ–‚â–„â–‡â–‚â–ƒâ–…â–â–‚â–ƒâ–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1214
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.17485
wandb:   test_error_force 7.72508
wandb:          test_loss 4.17668
wandb: train_error_energy 2.34955
wandb:  train_error_force 3.25213
wandb:         train_loss 1.51135
wandb: valid_error_energy 1.58497
wandb:  valid_error_force 2.88695
wandb:         valid_loss 1.47543
wandb: 
wandb: ğŸš€ View run al_55_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9hfblxen
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_193332-9hfblxen/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6945311427116394, Uncertainty Bias: 0.030136778950691223
6.1035156e-05 0.044727325
0.6725656 7.1867685
Found uncertainty sample 0 after 1714 steps.
Found uncertainty sample 4 after 2405 steps.
Found uncertainty sample 11 after 714 steps.
Found uncertainty sample 12 after 3558 steps.
Found uncertainty sample 14 after 3011 steps.
Found uncertainty sample 15 after 2345 steps.
Found uncertainty sample 20 after 2543 steps.
Found uncertainty sample 22 after 3632 steps.
Found uncertainty sample 23 after 476 steps.
Found uncertainty sample 28 after 1334 steps.
Found uncertainty sample 32 after 1183 steps.
Found uncertainty sample 33 after 2964 steps.
Found uncertainty sample 37 after 366 steps.
Found uncertainty sample 43 after 2717 steps.
Found uncertainty sample 44 after 236 steps.
Found uncertainty sample 47 after 2641 steps.
Found uncertainty sample 48 after 2565 steps.
Found uncertainty sample 50 after 2720 steps.
Found uncertainty sample 55 after 1417 steps.
Found uncertainty sample 58 after 2020 steps.
Found uncertainty sample 62 after 829 steps.
Found uncertainty sample 64 after 656 steps.
Found uncertainty sample 72 after 522 steps.
Found uncertainty sample 80 after 2252 steps.
Found uncertainty sample 81 after 3373 steps.
Found uncertainty sample 82 after 866 steps.
Found uncertainty sample 88 after 1808 steps.
Found uncertainty sample 90 after 481 steps.
Found uncertainty sample 91 after 1750 steps.
Found uncertainty sample 92 after 2713 steps.
Found uncertainty sample 93 after 3671 steps.
Found uncertainty sample 94 after 1362 steps.
Found uncertainty sample 96 after 198 steps.
Found uncertainty sample 99 after 1967 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_221131-3yj02wru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3yj02wru
Training model 11. Added 34 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4404789813837433, Training Loss Force: 3.494898287235279, time: 1.4436283111572266
Validation Loss Energy: 2.1357449186534248, Validation Loss Force: 3.016986119975032, time: 0.09117770195007324
Test Loss Energy: 8.141233214202158, Test Loss Force: 7.79789149511516, time: 17.109164237976074


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0082248708946895, Training Loss Force: 3.344689369706965, time: 1.4090750217437744
Validation Loss Energy: 1.6210504205662724, Validation Loss Force: 2.9653803187148076, time: 0.08888888359069824
Test Loss Energy: 8.510783998762738, Test Loss Force: 7.699250450779536, time: 17.209733724594116


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.019441680674704, Training Loss Force: 3.3106823614223098, time: 1.3995602130889893
Validation Loss Energy: 1.9794340729110147, Validation Loss Force: 2.9426052731310217, time: 0.08754467964172363
Test Loss Energy: 8.750815012403857, Test Loss Force: 7.691756428574578, time: 17.110152006149292


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9368948311474317, Training Loss Force: 3.3114455456463143, time: 1.4086928367614746
Validation Loss Energy: 1.5705099798347397, Validation Loss Force: 2.946743133869798, time: 0.0917959213256836
Test Loss Energy: 8.220603454065447, Test Loss Force: 7.668091286978991, time: 17.226264715194702


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9684443885145788, Training Loss Force: 3.3024188696193884, time: 1.387847661972046
Validation Loss Energy: 1.5061557019627119, Validation Loss Force: 2.9422819575311348, time: 0.08954715728759766
Test Loss Energy: 8.140439542091192, Test Loss Force: 7.6573361550537955, time: 17.25306510925293


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2656085677372477, Training Loss Force: 3.300720572043396, time: 1.4232850074768066
Validation Loss Energy: 3.0507672561037364, Validation Loss Force: 2.981943785803792, time: 0.09181857109069824
Test Loss Energy: 8.166445482008177, Test Loss Force: 7.701962381442651, time: 17.070513010025024


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.268973672333477, Training Loss Force: 3.3002542971423585, time: 1.3702824115753174
Validation Loss Energy: 1.4625763440711739, Validation Loss Force: 2.926880378045601, time: 0.09135150909423828
Test Loss Energy: 8.299518304048522, Test Loss Force: 7.655781973379117, time: 17.233105421066284


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.862837097217291, Training Loss Force: 3.2873557301072687, time: 1.451629877090454
Validation Loss Energy: 1.5272838865432161, Validation Loss Force: 2.9569910359728326, time: 0.09169650077819824
Test Loss Energy: 8.347573854456389, Test Loss Force: 7.648955949285488, time: 17.224767208099365


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1133973378804347, Training Loss Force: 3.291834468761134, time: 1.5256712436676025
Validation Loss Energy: 1.463587595997405, Validation Loss Force: 2.9444594391091625, time: 0.09049391746520996
Test Loss Energy: 8.189514870555126, Test Loss Force: 7.641554263661862, time: 17.07161283493042


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9559580163253925, Training Loss Force: 3.2760984801846744, time: 1.397711992263794
Validation Loss Energy: 1.891915746457265, Validation Loss Force: 2.9432380988437488, time: 0.08884429931640625
Test Loss Energy: 8.149075327738359, Test Loss Force: 7.64993771503699, time: 17.267152070999146


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0626138594855874, Training Loss Force: 3.303630047036603, time: 1.4058971405029297
Validation Loss Energy: 1.8205899202953841, Validation Loss Force: 2.9808106225201656, time: 0.08906412124633789
Test Loss Energy: 8.08723565719452, Test Loss Force: 7.6222222892937825, time: 17.188493251800537


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9985267018014259, Training Loss Force: 3.286993435987914, time: 1.3994617462158203
Validation Loss Energy: 2.7404853720043256, Validation Loss Force: 2.938083530784666, time: 0.09065556526184082
Test Loss Energy: 8.201596851780886, Test Loss Force: 7.608676462449782, time: 17.99122452735901


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.915971536437973, Training Loss Force: 3.2893227665045344, time: 1.4094021320343018
Validation Loss Energy: 2.433120008378277, Validation Loss Force: 2.9361788189104, time: 0.09174418449401855
Test Loss Energy: 8.019982424063905, Test Loss Force: 7.625055890575138, time: 17.6797297000885


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0466823388516753, Training Loss Force: 3.2932997801874366, time: 1.4549305438995361
Validation Loss Energy: 1.8437318132970861, Validation Loss Force: 2.9370670461335058, time: 0.09137606620788574
Test Loss Energy: 8.572219292811113, Test Loss Force: 7.64024149731042, time: 17.588143587112427


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1108149895551898, Training Loss Force: 3.2727139377138985, time: 1.4069373607635498
Validation Loss Energy: 1.4558696607304018, Validation Loss Force: 2.9623161685976953, time: 0.0908362865447998
Test Loss Energy: 8.22554320935229, Test Loss Force: 7.625608347881676, time: 17.70403742790222


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2228063765501855, Training Loss Force: 3.3033999612952765, time: 1.421445608139038
Validation Loss Energy: 1.926423897347424, Validation Loss Force: 2.9406110482600925, time: 0.0927436351776123
Test Loss Energy: 8.128818765791193, Test Loss Force: 7.576633215870182, time: 17.737497806549072


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9664276512220498, Training Loss Force: 3.280162506118447, time: 1.666935920715332
Validation Loss Energy: 1.787223728120116, Validation Loss Force: 2.9432962154908355, time: 0.08933019638061523
Test Loss Energy: 8.549446853971885, Test Loss Force: 7.588990854503758, time: 17.624290466308594


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.922936810025483, Training Loss Force: 3.266614241900728, time: 1.4080150127410889
Validation Loss Energy: 1.6699893134657193, Validation Loss Force: 2.9361394064715705, time: 0.09120798110961914
Test Loss Energy: 8.109045692005681, Test Loss Force: 7.61496061709647, time: 17.768954038619995


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.064293498529042, Training Loss Force: 3.2848841882294506, time: 1.4100782871246338
Validation Loss Energy: 1.512128579133079, Validation Loss Force: 2.9429143379055693, time: 0.0924997329711914
Test Loss Energy: 8.033526809970397, Test Loss Force: 7.594539233349038, time: 17.635295152664185


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9898591054649024, Training Loss Force: 3.2666039934105493, time: 1.4787702560424805
Validation Loss Energy: 1.4685903036989645, Validation Loss Force: 2.9297352191655417, time: 0.09344649314880371
Test Loss Energy: 8.157921735081432, Test Loss Force: 7.61631411907774, time: 17.734976291656494

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–ˆâ–ƒâ–‚â–‚â–„â–„â–ƒâ–‚â–‚â–ƒâ–â–†â–ƒâ–‚â–†â–‚â–â–‚
wandb:   test_error_force â–ˆâ–…â–…â–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–â–â–‚â–‚â–‚
wandb:          test_loss â–†â–ˆâ–†â–ƒâ–‚â–‚â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–…â–ƒâ–„â–â–â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–ƒâ–ƒâ–â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–â–
wandb: valid_error_energy â–„â–‚â–ƒâ–‚â–â–ˆâ–â–â–â–ƒâ–ƒâ–‡â–…â–ƒâ–â–ƒâ–‚â–‚â–â–
wandb:  valid_error_force â–ˆâ–„â–‚â–ƒâ–‚â–…â–â–ƒâ–‚â–‚â–…â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–
wandb:         valid_loss â–†â–†â–ƒâ–‚â–‚â–ˆâ–â–…â–â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–ƒâ–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1244
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.15792
wandb:   test_error_force 7.61631
wandb:          test_loss 4.07834
wandb: train_error_energy 1.98986
wandb:  train_error_force 3.2666
wandb:         train_loss 1.48722
wandb: valid_error_energy 1.46859
wandb:  valid_error_force 2.92974
wandb:         valid_loss 1.43782
wandb: 
wandb: ğŸš€ View run al_55_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3yj02wru
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_221131-3yj02wru/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7291700839996338, Uncertainty Bias: 0.02417983114719391
0.00037384033 0.0047664642
0.43821144 7.097926
Found uncertainty sample 0 after 1027 steps.
Found uncertainty sample 2 after 905 steps.
Found uncertainty sample 10 after 3105 steps.
Found uncertainty sample 13 after 2237 steps.
Found uncertainty sample 16 after 995 steps.
Found uncertainty sample 21 after 503 steps.
Found uncertainty sample 22 after 3999 steps.
Found uncertainty sample 28 after 2080 steps.
Found uncertainty sample 31 after 2971 steps.
Found uncertainty sample 33 after 345 steps.
Found uncertainty sample 35 after 865 steps.
Found uncertainty sample 37 after 1655 steps.
Found uncertainty sample 44 after 1429 steps.
Found uncertainty sample 47 after 3258 steps.
Found uncertainty sample 49 after 2035 steps.
Found uncertainty sample 51 after 2196 steps.
Found uncertainty sample 59 after 646 steps.
Found uncertainty sample 60 after 3949 steps.
Found uncertainty sample 62 after 2711 steps.
Found uncertainty sample 74 after 2036 steps.
Found uncertainty sample 78 after 477 steps.
Found uncertainty sample 79 after 1649 steps.
Found uncertainty sample 81 after 875 steps.
Found uncertainty sample 84 after 398 steps.
Found uncertainty sample 87 after 775 steps.
Found uncertainty sample 88 after 1187 steps.
Found uncertainty sample 91 after 1891 steps.
Found uncertainty sample 92 after 1644 steps.
Found uncertainty sample 93 after 1209 steps.
Found uncertainty sample 97 after 1529 steps.
Found uncertainty sample 99 after 2824 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_005049-o0taf200
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/o0taf200
Training model 12. Added 31 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.976452018723574, Training Loss Force: 3.6043158724036077, time: 1.427475929260254
Validation Loss Energy: 1.215964726061144, Validation Loss Force: 2.609887579891646, time: 0.11854982376098633
Test Loss Energy: 8.06849834001646, Test Loss Force: 7.667935689044077, time: 17.072226524353027


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.094737024776626, Training Loss Force: 3.3332125298958046, time: 1.4343864917755127
Validation Loss Energy: 1.3407929657673319, Validation Loss Force: 2.755828278169907, time: 0.1244814395904541
Test Loss Energy: 8.430453161872302, Test Loss Force: 7.578712327815414, time: 17.21040916442871


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8308180521616246, Training Loss Force: 3.3084530234831377, time: 1.4808769226074219
Validation Loss Energy: 2.714619010667624, Validation Loss Force: 3.47584777707024, time: 0.11766481399536133
Test Loss Energy: 8.451840619608387, Test Loss Force: 7.560200545337, time: 17.194530963897705


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.958902599891132, Training Loss Force: 3.3148281969994526, time: 1.4466040134429932
Validation Loss Energy: 1.1460522644693962, Validation Loss Force: 2.5956824017271827, time: 0.14661216735839844
Test Loss Energy: 8.234194050231656, Test Loss Force: 7.577985799195497, time: 17.295031309127808


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0560577769942965, Training Loss Force: 3.3160596408773637, time: 1.4606468677520752
Validation Loss Energy: 1.8642743780238002, Validation Loss Force: 3.5236773322846746, time: 0.11700010299682617
Test Loss Energy: 8.12090668284766, Test Loss Force: 7.574595914428875, time: 17.697012186050415


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8631561892402373, Training Loss Force: 3.3065491187845253, time: 1.441502332687378
Validation Loss Energy: 1.6200162337180108, Validation Loss Force: 3.110217023367559, time: 0.11728429794311523
Test Loss Energy: 7.947071624931627, Test Loss Force: 7.570110313266776, time: 17.118408679962158


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0519783140224046, Training Loss Force: 3.3264468559315477, time: 1.4331202507019043
Validation Loss Energy: 1.8382207519353733, Validation Loss Force: 2.590847252557934, time: 0.12032938003540039
Test Loss Energy: 8.594652582059148, Test Loss Force: 7.521378942182299, time: 17.288960218429565


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.250047657415714, Training Loss Force: 3.3222594179074307, time: 1.495973825454712
Validation Loss Energy: 2.1720495642129287, Validation Loss Force: 2.642486231520901, time: 0.1253657341003418
Test Loss Energy: 8.039436710244098, Test Loss Force: 7.536881911906687, time: 17.253774166107178


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.372636070966379, Training Loss Force: 3.3227523851295997, time: 1.4655535221099854
Validation Loss Energy: 3.6956928102202258, Validation Loss Force: 3.7689267996281344, time: 0.11919760704040527
Test Loss Energy: 8.294335606231208, Test Loss Force: 7.537618995743604, time: 17.117713451385498


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9806660901619757, Training Loss Force: 3.2980057100264673, time: 1.4716589450836182
Validation Loss Energy: 2.1338554596156545, Validation Loss Force: 3.6400510193554876, time: 0.11767911911010742
Test Loss Energy: 7.90781422444994, Test Loss Force: 7.550596477662635, time: 17.24785852432251


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2331682979594953, Training Loss Force: 3.319566913728329, time: 1.441502571105957
Validation Loss Energy: 1.6934378218813637, Validation Loss Force: 2.498183153476366, time: 0.11962366104125977
Test Loss Energy: 8.51024256999086, Test Loss Force: 7.514867219668471, time: 17.201420068740845


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0219179626219677, Training Loss Force: 3.2854071955177178, time: 1.508378267288208
Validation Loss Energy: 2.406087194720633, Validation Loss Force: 2.4471827896239198, time: 0.1347954273223877
Test Loss Energy: 7.986411904967878, Test Loss Force: 7.51434739330117, time: 17.31596851348877


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9244676152989606, Training Loss Force: 3.2893305869018645, time: 1.443941593170166
Validation Loss Energy: 1.8355428771191593, Validation Loss Force: 3.9099590905881367, time: 0.1288135051727295
Test Loss Energy: 8.056979807326075, Test Loss Force: 7.497231524864387, time: 17.59939479827881


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9497596989914925, Training Loss Force: 3.294255260201234, time: 1.4765937328338623
Validation Loss Energy: 3.364208592714717, Validation Loss Force: 3.381244897735079, time: 0.11851811408996582
Test Loss Energy: 8.041805343374547, Test Loss Force: 7.52028564133902, time: 17.643874883651733


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9345595571488232, Training Loss Force: 3.3037211037299414, time: 1.4474513530731201
Validation Loss Energy: 1.9953946632873996, Validation Loss Force: 2.5563898702330463, time: 0.12551569938659668
Test Loss Energy: 8.057789492962636, Test Loss Force: 7.486310333051841, time: 18.039623498916626


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2019691427876285, Training Loss Force: 3.2883920698521516, time: 1.4177088737487793
Validation Loss Energy: 2.4170492524419442, Validation Loss Force: 3.028588741161891, time: 0.12063026428222656
Test Loss Energy: 8.017695730847544, Test Loss Force: 7.465374359742361, time: 17.68119764328003


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1140492074789194, Training Loss Force: 3.310366296986065, time: 1.4902617931365967
Validation Loss Energy: 1.6746631388387434, Validation Loss Force: 3.170299616344108, time: 0.11618924140930176
Test Loss Energy: 8.038552282386158, Test Loss Force: 7.484362490980071, time: 17.71561622619629


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8709091503638953, Training Loss Force: 3.306087503378103, time: 1.4553523063659668
Validation Loss Energy: 2.460277294088495, Validation Loss Force: 3.3268054089237777, time: 0.11768054962158203
Test Loss Energy: 8.054944070397825, Test Loss Force: 7.489717600001527, time: 17.768181562423706


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.885036021356464, Training Loss Force: 3.2889744832702403, time: 1.4497671127319336
Validation Loss Energy: 1.609246562138781, Validation Loss Force: 2.550700005547154, time: 0.12365078926086426
Test Loss Energy: 8.472832770827836, Test Loss Force: 7.50171584130712, time: 17.777833700180054


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.023875488834283, Training Loss Force: 3.298598588894415, time: 1.486227035522461
Validation Loss Energy: 1.1215479146310487, Validation Loss Force: 3.242265504965958, time: 0.12797856330871582
Test Loss Energy: 8.29021894103035, Test Loss Force: 7.473619686298591, time: 17.841459274291992

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–‡â–„â–ƒâ–â–ˆâ–‚â–…â–â–‡â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‡â–…
wandb:   test_error_force â–ˆâ–…â–„â–…â–…â–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–
wandb:          test_loss â–ˆâ–†â–„â–„â–„â–ƒâ–…â–…â–…â–‚â–„â–‚â–ƒâ–‚â–„â–‚â–â–‚â–ƒâ–‚
wandb: train_error_energy â–ˆâ–ƒâ–â–‚â–‚â–â–‚â–„â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–‚â–‚â–â–â–
wandb: valid_error_energy â–â–‚â–…â–â–ƒâ–‚â–ƒâ–„â–ˆâ–„â–ƒâ–„â–ƒâ–‡â–ƒâ–…â–ƒâ–…â–‚â–
wandb:  valid_error_force â–‚â–‚â–†â–‚â–†â–„â–‚â–‚â–‡â–‡â–â–â–ˆâ–…â–‚â–„â–„â–…â–â–…
wandb:         valid_loss â–â–‚â–†â–â–…â–„â–‚â–‚â–ˆâ–†â–â–â–ˆâ–‡â–‚â–„â–†â–†â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1271
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.29022
wandb:   test_error_force 7.47362
wandb:          test_loss 4.00459
wandb: train_error_energy 2.02388
wandb:  train_error_force 3.2986
wandb:         train_loss 1.49575
wandb: valid_error_energy 1.12155
wandb:  valid_error_force 3.24227
wandb:         valid_loss 1.48002
wandb: 
wandb: ğŸš€ View run al_55_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/o0taf200
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_005049-o0taf200/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7097359299659729, Uncertainty Bias: 0.02840001881122589
0.00013542175 0.0036239624
0.5393374 5.8714423
Found uncertainty sample 1 after 3553 steps.
Found uncertainty sample 2 after 838 steps.
Found uncertainty sample 4 after 3986 steps.
Found uncertainty sample 6 after 1380 steps.
Found uncertainty sample 8 after 1792 steps.
Found uncertainty sample 17 after 2558 steps.
Found uncertainty sample 18 after 221 steps.
Found uncertainty sample 19 after 590 steps.
Found uncertainty sample 20 after 1047 steps.
Found uncertainty sample 22 after 1607 steps.
Found uncertainty sample 26 after 2825 steps.
Found uncertainty sample 36 after 389 steps.
Found uncertainty sample 39 after 1569 steps.
Found uncertainty sample 40 after 3013 steps.
Found uncertainty sample 42 after 1342 steps.
Found uncertainty sample 49 after 3560 steps.
Found uncertainty sample 50 after 2010 steps.
Found uncertainty sample 51 after 2289 steps.
Found uncertainty sample 66 after 3584 steps.
Found uncertainty sample 67 after 448 steps.
Found uncertainty sample 69 after 1048 steps.
Found uncertainty sample 79 after 1039 steps.
Found uncertainty sample 83 after 1064 steps.
Found uncertainty sample 88 after 1415 steps.
Found uncertainty sample 91 after 1784 steps.
Found uncertainty sample 92 after 210 steps.
Found uncertainty sample 93 after 1847 steps.
Found uncertainty sample 95 after 2129 steps.
Found uncertainty sample 96 after 2103 steps.
Found uncertainty sample 98 after 492 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_033207-7u3rvixy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7u3rvixy
Training model 13. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.434859984706427, Training Loss Force: 3.6210189036254, time: 1.4845235347747803
Validation Loss Energy: 3.0276775790167547, Validation Loss Force: 3.318031353897639, time: 0.12394404411315918
Test Loss Energy: 8.930883885418304, Test Loss Force: 7.472560028315067, time: 17.56012272834778


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1981210309878034, Training Loss Force: 3.3780029571668524, time: 1.458512306213379
Validation Loss Energy: 1.3946925375670447, Validation Loss Force: 2.7972841517513047, time: 0.1215662956237793
Test Loss Energy: 8.01445045745023, Test Loss Force: 7.421518759790772, time: 17.297654390335083


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1334871458399483, Training Loss Force: 3.326508447031954, time: 1.4883270263671875
Validation Loss Energy: 1.913918408441114, Validation Loss Force: 3.2960699413730734, time: 0.12392258644104004
Test Loss Energy: 7.891763691476995, Test Loss Force: 7.442393106208146, time: 17.225019216537476


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.059781176591516, Training Loss Force: 3.3443846736481433, time: 1.691908597946167
Validation Loss Energy: 1.393701659867666, Validation Loss Force: 3.0789104094575497, time: 0.11706233024597168
Test Loss Energy: 8.172946845160588, Test Loss Force: 7.471158506741543, time: 17.183001041412354


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8885743433832216, Training Loss Force: 3.3458648695111752, time: 1.5180518627166748
Validation Loss Energy: 2.692476902131138, Validation Loss Force: 3.0516923350704936, time: 0.1295926570892334
Test Loss Energy: 8.952759016563341, Test Loss Force: 7.397321984534115, time: 17.348424196243286


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.469694433900937, Training Loss Force: 3.355374275814354, time: 1.498166799545288
Validation Loss Energy: 1.1508391222676222, Validation Loss Force: 2.6456181843929487, time: 0.1198275089263916
Test Loss Energy: 8.127810585183626, Test Loss Force: 7.433908350863885, time: 17.22165822982788


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0755639222072397, Training Loss Force: 3.3575803568002454, time: 1.5073299407958984
Validation Loss Energy: 1.9329224963713265, Validation Loss Force: 2.6174644542547036, time: 0.1276257038116455
Test Loss Energy: 7.749646731891993, Test Loss Force: 7.42602422164172, time: 17.339527368545532


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0945891623485764, Training Loss Force: 3.3349377776344675, time: 1.4708921909332275
Validation Loss Energy: 1.3113341717648046, Validation Loss Force: 2.7015379776863777, time: 0.12524938583374023
Test Loss Energy: 8.059734436838085, Test Loss Force: 7.406797127938795, time: 17.322150945663452


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1025555312109776, Training Loss Force: 3.3544278667727028, time: 1.4800043106079102
Validation Loss Energy: 2.884334984333179, Validation Loss Force: 2.901898792560244, time: 0.12588214874267578
Test Loss Energy: 7.759202292666756, Test Loss Force: 7.452404227070953, time: 17.18337368965149


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0533637893498975, Training Loss Force: 3.3575395105893557, time: 1.5433387756347656
Validation Loss Energy: 1.885948881353838, Validation Loss Force: 3.402554446334941, time: 0.12251424789428711
Test Loss Energy: 7.980784323523459, Test Loss Force: 7.41741218581571, time: 17.68227481842041


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9255865228693887, Training Loss Force: 3.340835327462054, time: 1.496213436126709
Validation Loss Energy: 2.039168968016197, Validation Loss Force: 3.209318710127045, time: 0.12950873374938965
Test Loss Energy: 7.7296646685404395, Test Loss Force: 7.42060929739231, time: 17.263039350509644


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8887439738247802, Training Loss Force: 3.315744191472378, time: 1.5195395946502686
Validation Loss Energy: 1.1082768613673957, Validation Loss Force: 2.9342471640694763, time: 0.1350407600402832
Test Loss Energy: 7.885180696183555, Test Loss Force: 7.371310775169276, time: 17.696170806884766


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9123086367857545, Training Loss Force: 3.3393618496900834, time: 1.4909827709197998
Validation Loss Energy: 1.7211254498298953, Validation Loss Force: 3.2618542664060906, time: 0.12772130966186523
Test Loss Energy: 7.8946536385445345, Test Loss Force: 7.380197421508375, time: 17.800406455993652


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.880920124077682, Training Loss Force: 3.3378220925459923, time: 1.4679198265075684
Validation Loss Energy: 1.5572245365775312, Validation Loss Force: 2.529789925395086, time: 0.12465071678161621
Test Loss Energy: 7.827753374481845, Test Loss Force: 7.420866586344297, time: 17.672964096069336


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9621990519707764, Training Loss Force: 3.3185261546101423, time: 1.5262806415557861
Validation Loss Energy: 2.454412411453903, Validation Loss Force: 2.9182795596149944, time: 0.12310624122619629
Test Loss Energy: 8.211985405006686, Test Loss Force: 7.405182869895382, time: 17.86974549293518


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1497797766450724, Training Loss Force: 3.3477261663329405, time: 1.5439393520355225
Validation Loss Energy: 1.5809293371801387, Validation Loss Force: 2.947738353617522, time: 0.12787365913391113
Test Loss Energy: 8.388237239220974, Test Loss Force: 7.435687281484263, time: 17.971173763275146


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.129885317622355, Training Loss Force: 3.353539791616331, time: 1.5242550373077393
Validation Loss Energy: 1.692574756271748, Validation Loss Force: 3.180751149381093, time: 0.12804651260375977
Test Loss Energy: 7.928933124543123, Test Loss Force: 7.366872960438021, time: 17.848848819732666


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3243641559314634, Training Loss Force: 3.324945499710959, time: 1.4921989440917969
Validation Loss Energy: 2.3403722970324132, Validation Loss Force: 3.1122865104098114, time: 0.12007355690002441
Test Loss Energy: 8.649487855367974, Test Loss Force: 7.387569500296243, time: 18.035012006759644


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.450493211816428, Training Loss Force: 3.333633924873101, time: 1.531010627746582
Validation Loss Energy: 2.3487623591163995, Validation Loss Force: 2.9622721914413748, time: 0.1253974437713623
Test Loss Energy: 7.79194443590765, Test Loss Force: 7.379631981774565, time: 17.919437170028687


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.524233909305192, Training Loss Force: 3.328886759886745, time: 1.453352689743042
Validation Loss Energy: 1.218503989334018, Validation Loss Force: 2.5753509273508084, time: 0.125962495803833
Test Loss Energy: 7.7384821172364715, Test Loss Force: 7.332444295438116, time: 17.896960020065308

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–ƒâ–‚â–„â–ˆâ–ƒâ–â–ƒâ–â–‚â–â–‚â–‚â–‚â–„â–…â–‚â–†â–â–
wandb:   test_error_force â–ˆâ–…â–†â–ˆâ–„â–†â–†â–…â–‡â–…â–…â–ƒâ–ƒâ–…â–…â–†â–ƒâ–„â–ƒâ–
wandb:          test_loss â–ˆâ–„â–ƒâ–…â–…â–…â–‚â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–ƒâ–‚â–…â–‚â–…â–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–ˆâ–‚â–„â–‚â–‡â–â–„â–‚â–‡â–„â–„â–â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–†â–
wandb:  valid_error_force â–‡â–ƒâ–‡â–…â–…â–‚â–‚â–‚â–„â–ˆâ–†â–„â–‡â–â–„â–„â–†â–†â–„â–
wandb:         valid_loss â–ˆâ–„â–ˆâ–…â–†â–ƒâ–‚â–‚â–…â–ˆâ–†â–„â–†â–â–…â–…â–†â–…â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1298
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.73848
wandb:   test_error_force 7.33244
wandb:          test_loss 3.91751
wandb: train_error_energy 2.52423
wandb:  train_error_force 3.32889
wandb:         train_loss 1.54785
wandb: valid_error_energy 1.2185
wandb:  valid_error_force 2.57535
wandb:         valid_loss 1.25285
wandb: 
wandb: ğŸš€ View run al_55_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7u3rvixy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_033207-7u3rvixy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.708260715007782, Uncertainty Bias: 0.028825029730796814
0.00011253357 0.013093233
0.4434499 5.057127
Found uncertainty sample 9 after 3468 steps.
Found uncertainty sample 11 after 939 steps.
Found uncertainty sample 19 after 3189 steps.
Found uncertainty sample 21 after 511 steps.
Found uncertainty sample 23 after 3495 steps.
Found uncertainty sample 24 after 2277 steps.
Found uncertainty sample 28 after 684 steps.
Found uncertainty sample 29 after 1356 steps.
Found uncertainty sample 39 after 2122 steps.
Found uncertainty sample 54 after 1538 steps.
Found uncertainty sample 55 after 77 steps.
Found uncertainty sample 60 after 2388 steps.
Found uncertainty sample 63 after 3494 steps.
Found uncertainty sample 73 after 1736 steps.
Found uncertainty sample 74 after 2405 steps.
Found uncertainty sample 77 after 3970 steps.
Found uncertainty sample 79 after 1844 steps.
Found uncertainty sample 82 after 3333 steps.
Found uncertainty sample 83 after 3163 steps.
Found uncertainty sample 85 after 1138 steps.
Found uncertainty sample 87 after 274 steps.
Found uncertainty sample 88 after 3439 steps.
Found uncertainty sample 89 after 1360 steps.
Found uncertainty sample 91 after 2749 steps.
Found uncertainty sample 93 after 2153 steps.
Found uncertainty sample 96 after 3786 steps.
Found uncertainty sample 97 after 1906 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_062054-asgskj77
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/asgskj77
Training model 14. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.916293688484417, Training Loss Force: 3.7080092927839896, time: 1.5020215511322021
Validation Loss Energy: 2.2123992174773575, Validation Loss Force: 3.1358324365767993, time: 0.12520217895507812
Test Loss Energy: 7.669782301758362, Test Loss Force: 7.381231580960171, time: 17.246744394302368


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.026354594591315, Training Loss Force: 3.381013571000692, time: 1.5047283172607422
Validation Loss Energy: 1.950829771755985, Validation Loss Force: 3.134330310518371, time: 0.11827826499938965
Test Loss Energy: 8.193274096983838, Test Loss Force: 7.3303712596792145, time: 17.32146978378296


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3793157575287833, Training Loss Force: 3.3737308266744654, time: 1.502830982208252
Validation Loss Energy: 2.506983817465443, Validation Loss Force: 3.206394507568148, time: 0.12089252471923828
Test Loss Energy: 7.7075748820071155, Test Loss Force: 7.344247749039111, time: 17.276413202285767


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.91176090876811, Training Loss Force: 3.364501572294294, time: 1.7370221614837646
Validation Loss Energy: 1.2982501327500877, Validation Loss Force: 2.6516281359761122, time: 0.12497591972351074
Test Loss Energy: 7.7386269174665205, Test Loss Force: 7.319891433088108, time: 17.294986486434937


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8907903580379841, Training Loss Force: 3.365654664466482, time: 1.5182898044586182
Validation Loss Energy: 1.8411219082376666, Validation Loss Force: 2.7549210127348243, time: 0.12456679344177246
Test Loss Energy: 7.823446365632851, Test Loss Force: 7.329815559097471, time: 17.355161905288696


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2333472839253914, Training Loss Force: 3.3585208274807714, time: 1.5071995258331299
Validation Loss Energy: 1.9808195203369774, Validation Loss Force: 3.130754132700198, time: 0.1255354881286621
Test Loss Energy: 8.402369210531937, Test Loss Force: 7.2985943044136175, time: 17.21858835220337


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1651848228900725, Training Loss Force: 3.365059072215942, time: 1.5193495750427246
Validation Loss Energy: 2.1446379903380617, Validation Loss Force: 2.8560301731794224, time: 0.12872052192687988
Test Loss Energy: 8.4951071605754, Test Loss Force: 7.305148837693817, time: 17.39068579673767


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.090163812854813, Training Loss Force: 3.3684370638909464, time: 1.5882606506347656
Validation Loss Energy: 1.5947956129044998, Validation Loss Force: 2.9390845399301844, time: 0.12620091438293457
Test Loss Energy: 7.845763263036949, Test Loss Force: 7.335287568254731, time: 17.761173009872437


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0586244990840163, Training Loss Force: 3.379314865197932, time: 1.5162479877471924
Validation Loss Energy: 1.7283393734850907, Validation Loss Force: 3.1158025675585845, time: 0.12327051162719727
Test Loss Energy: 8.128640534878274, Test Loss Force: 7.391003177438768, time: 17.206804275512695


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.98454327743326, Training Loss Force: 3.3853381398183275, time: 1.5363218784332275
Validation Loss Energy: 1.2063434706020364, Validation Loss Force: 2.8567604166434926, time: 0.1273031234741211
Test Loss Energy: 7.710738140878692, Test Loss Force: 7.33204226221482, time: 17.36840534210205


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.301608869842172, Training Loss Force: 3.35314372281692, time: 1.5556166172027588
Validation Loss Energy: 2.3660206652752516, Validation Loss Force: 2.8045620927859547, time: 0.13045144081115723
Test Loss Energy: 7.743858616485621, Test Loss Force: 7.305383920353178, time: 17.406752586364746


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.187045708247721, Training Loss Force: 3.349953828252114, time: 1.7254157066345215
Validation Loss Energy: 2.154270212252606, Validation Loss Force: 3.144826266049969, time: 0.1240699291229248
Test Loss Energy: 7.680928366092154, Test Loss Force: 7.273050108025249, time: 17.762781858444214


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.24870246340223, Training Loss Force: 3.3555201115620172, time: 1.5835635662078857
Validation Loss Energy: 1.4111490677986973, Validation Loss Force: 2.9395694019954424, time: 0.12519216537475586
Test Loss Energy: 7.757265180683048, Test Loss Force: 7.354687586116902, time: 17.883718013763428


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9204867665274477, Training Loss Force: 3.358480826559199, time: 1.554199457168579
Validation Loss Energy: 1.368690069714895, Validation Loss Force: 2.8149913589083475, time: 0.13126492500305176
Test Loss Energy: 7.729586832267157, Test Loss Force: 7.291186689495352, time: 17.79479217529297


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.4904920392381547, Training Loss Force: 3.3682076457492385, time: 1.5205883979797363
Validation Loss Energy: 1.7490299575265602, Validation Loss Force: 2.859296284211891, time: 0.12492513656616211
Test Loss Energy: 7.763302573615381, Test Loss Force: 7.324567883858602, time: 18.062706232070923


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.4555901032650684, Training Loss Force: 3.3868714501604793, time: 1.5316905975341797
Validation Loss Energy: 1.3107134815205308, Validation Loss Force: 3.1552029822539227, time: 0.12934017181396484
Test Loss Energy: 7.759254157090654, Test Loss Force: 7.2846688301732305, time: 17.95539951324463


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.15496769419317, Training Loss Force: 3.3515253104478533, time: 1.5680303573608398
Validation Loss Energy: 1.1787332480153583, Validation Loss Force: 2.756015876925351, time: 0.1307365894317627
Test Loss Energy: 7.772849759232322, Test Loss Force: 7.271141509350288, time: 18.160919427871704


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2005706215680823, Training Loss Force: 3.3529993801938955, time: 1.532958745956421
Validation Loss Energy: 1.4875861528707777, Validation Loss Force: 3.0099506656402975, time: 0.12399673461914062
Test Loss Energy: 7.720646826939528, Test Loss Force: 7.235202622927822, time: 18.211552381515503


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.093276730165706, Training Loss Force: 3.322643977065411, time: 1.5284533500671387
Validation Loss Energy: 1.822419258663754, Validation Loss Force: 3.315206907116118, time: 0.12925338745117188
Test Loss Energy: 7.989570568228078, Test Loss Force: 7.238760283649768, time: 17.94649624824524


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0494856536787385, Training Loss Force: 3.351293262689565, time: 1.507781982421875
Validation Loss Energy: 1.4377226820101519, Validation Loss Force: 2.9827147777215672, time: 0.12953734397888184
Test Loss Energy: 7.92379537325069, Test Loss Force: 7.2396000284552215, time: 18.06213927268982

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–â–‚â–‚â–‡â–ˆâ–‚â–…â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–„â–ƒ
wandb:   test_error_force â–ˆâ–…â–†â–…â–…â–„â–„â–…â–ˆâ–…â–„â–ƒâ–†â–„â–…â–ƒâ–ƒâ–â–â–
wandb:          test_loss â–…â–„â–„â–„â–†â–ˆâ–…â–…â–‡â–…â–…â–‚â–„â–‚â–ƒâ–‚â–â–ƒâ–‡â–
wandb: train_error_energy â–ˆâ–â–ƒâ–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–ƒâ–ƒâ–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–†â–…â–ˆâ–‚â–„â–…â–†â–ƒâ–„â–â–‡â–†â–‚â–‚â–„â–‚â–â–ƒâ–„â–‚
wandb:  valid_error_force â–†â–†â–‡â–â–‚â–†â–ƒâ–„â–†â–ƒâ–ƒâ–†â–„â–ƒâ–ƒâ–†â–‚â–…â–ˆâ–„
wandb:         valid_loss â–†â–†â–‡â–â–„â–†â–ƒâ–„â–…â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–†â–ƒâ–„â–ˆâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1322
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.9238
wandb:   test_error_force 7.2396
wandb:          test_loss 3.85702
wandb: train_error_energy 2.04949
wandb:  train_error_force 3.35129
wandb:         train_loss 1.5278
wandb: valid_error_energy 1.43772
wandb:  valid_error_force 2.98271
wandb:         valid_loss 1.47184
wandb: 
wandb: ğŸš€ View run al_55_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/asgskj77
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_062054-asgskj77/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7393958568572998, Uncertainty Bias: 0.02165307104587555
0.00019073486 0.0030751228
0.47563514 5.2920804
Found uncertainty sample 1 after 1879 steps.
Found uncertainty sample 7 after 2850 steps.
Found uncertainty sample 9 after 2857 steps.
Found uncertainty sample 10 after 2761 steps.
Found uncertainty sample 11 after 264 steps.
Found uncertainty sample 13 after 2153 steps.
Found uncertainty sample 15 after 2726 steps.
Found uncertainty sample 16 after 418 steps.
Found uncertainty sample 19 after 1030 steps.
Found uncertainty sample 22 after 1559 steps.
Found uncertainty sample 32 after 2481 steps.
Found uncertainty sample 38 after 2241 steps.
Found uncertainty sample 47 after 2320 steps.
Found uncertainty sample 49 after 932 steps.
Found uncertainty sample 60 after 2796 steps.
Found uncertainty sample 61 after 1134 steps.
Found uncertainty sample 67 after 2010 steps.
Found uncertainty sample 71 after 3772 steps.
Found uncertainty sample 73 after 1327 steps.
Found uncertainty sample 75 after 1255 steps.
Found uncertainty sample 76 after 996 steps.
Found uncertainty sample 79 after 486 steps.
Found uncertainty sample 80 after 1391 steps.
Found uncertainty sample 87 after 1432 steps.
Found uncertainty sample 88 after 1370 steps.
Found uncertainty sample 89 after 1617 steps.
Found uncertainty sample 90 after 2062 steps.
Found uncertainty sample 91 after 3370 steps.
Found uncertainty sample 92 after 833 steps.
Found uncertainty sample 93 after 240 steps.
Found uncertainty sample 96 after 1567 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_090112-9t2i0xdj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9t2i0xdj
Training model 15. Added 31 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5279318871909733, Training Loss Force: 3.584648033382228, time: 1.5449676513671875
Validation Loss Energy: 2.1010686525580904, Validation Loss Force: 2.9219708573816128, time: 0.1335735321044922
Test Loss Energy: 7.644914718795396, Test Loss Force: 7.192573549917198, time: 17.136078596115112


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1823226072160447, Training Loss Force: 3.3955411708828125, time: 1.664151906967163
Validation Loss Energy: 1.6168619025967979, Validation Loss Force: 3.0764418993057943, time: 0.127730131149292
Test Loss Energy: 8.280692800562218, Test Loss Force: 7.241362089847634, time: 17.730200052261353


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8751135379116164, Training Loss Force: 3.3682817499423683, time: 1.5368738174438477
Validation Loss Energy: 1.6216106561374266, Validation Loss Force: 2.8961993531010766, time: 0.12647223472595215
Test Loss Energy: 7.638747000293306, Test Loss Force: 7.229201621828259, time: 16.703452348709106


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1245540411983233, Training Loss Force: 3.389745900837259, time: 1.7329730987548828
Validation Loss Energy: 1.3949923615720365, Validation Loss Force: 2.6750413513321276, time: 0.12463974952697754
Test Loss Energy: 7.662888185206745, Test Loss Force: 7.2433849492712445, time: 16.718695878982544


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9694241031471087, Training Loss Force: 3.369406938563559, time: 1.5382235050201416
Validation Loss Energy: 2.081076080621818, Validation Loss Force: 2.9121346705293982, time: 0.12612271308898926
Test Loss Energy: 7.597550226162239, Test Loss Force: 7.227192954939634, time: 16.851991176605225


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9112152438471925, Training Loss Force: 3.3962168474602485, time: 1.5277090072631836
Validation Loss Energy: 1.7963377989320861, Validation Loss Force: 2.959083346602543, time: 0.12498736381530762
Test Loss Energy: 7.585795841379842, Test Loss Force: 7.230737089968226, time: 17.04685401916504


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9978160038286834, Training Loss Force: 3.3873713518867326, time: 1.563349723815918
Validation Loss Energy: 1.400316046847451, Validation Loss Force: 3.1186232289646245, time: 0.12095928192138672
Test Loss Energy: 7.900588123357237, Test Loss Force: 7.226826614064881, time: 17.435047149658203


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2173271109350616, Training Loss Force: 3.399545953147607, time: 1.583000659942627
Validation Loss Energy: 2.2538690078803754, Validation Loss Force: 3.283045132351173, time: 0.12713003158569336
Test Loss Energy: 8.41321614743045, Test Loss Force: 7.214045055346512, time: 17.432557582855225


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.39474260953085, Training Loss Force: 3.4119108174261465, time: 1.582047939300537
Validation Loss Energy: 3.1227870306589014, Validation Loss Force: 3.00156917631843, time: 0.13187932968139648
Test Loss Energy: 8.766757500711325, Test Loss Force: 7.21631160108549, time: 17.352760314941406


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.066975020996485, Training Loss Force: 3.389077996966521, time: 1.5283482074737549
Validation Loss Energy: 1.479711068854036, Validation Loss Force: 3.3148525291703743, time: 0.12224054336547852
Test Loss Energy: 7.546651419259056, Test Loss Force: 7.199006090816413, time: 17.478399753570557


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2640447496450733, Training Loss Force: 3.3839672274106074, time: 1.574833631515503
Validation Loss Energy: 1.9199699991545665, Validation Loss Force: 2.9542496447827427, time: 0.12053656578063965
Test Loss Energy: 7.473940038416963, Test Loss Force: 7.206762414943657, time: 17.694963455200195


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1287049358496644, Training Loss Force: 3.400839774809195, time: 1.5788969993591309
Validation Loss Energy: 2.505925693683994, Validation Loss Force: 3.2253197149534154, time: 0.13487982749938965
Test Loss Energy: 7.419711875449026, Test Loss Force: 7.186274465945469, time: 18.02801203727722


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.079890054129443, Training Loss Force: 3.3593338472751353, time: 1.613922119140625
Validation Loss Energy: 1.6135485300381056, Validation Loss Force: 2.810117131303988, time: 0.13406848907470703
Test Loss Energy: 7.629305504411609, Test Loss Force: 7.1886203868230325, time: 17.874050855636597


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1422060341747042, Training Loss Force: 3.3794815626442447, time: 1.5803942680358887
Validation Loss Energy: 1.6646888414487677, Validation Loss Force: 3.1887775927497795, time: 0.12833142280578613
Test Loss Energy: 7.993048501737712, Test Loss Force: 7.165691575953007, time: 17.804161548614502


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0736792705117084, Training Loss Force: 3.3662317490395597, time: 1.5662267208099365
Validation Loss Energy: 1.4946638586759518, Validation Loss Force: 3.042436646681713, time: 0.13389372825622559
Test Loss Energy: 7.596649768457406, Test Loss Force: 7.210626354161308, time: 17.87499237060547


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.066371849117808, Training Loss Force: 3.3867250262097404, time: 1.5804429054260254
Validation Loss Energy: 1.8697071711807194, Validation Loss Force: 2.9709191023851886, time: 0.1243295669555664
Test Loss Energy: 7.528802330469908, Test Loss Force: 7.167800658465796, time: 18.2634060382843


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.918397464335442, Training Loss Force: 3.3510375314907592, time: 1.5802185535430908
Validation Loss Energy: 1.549065939070737, Validation Loss Force: 2.890056690706939, time: 0.12186646461486816
Test Loss Energy: 7.892083542298338, Test Loss Force: 7.2073556335277775, time: 18.02380084991455


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1163969376461473, Training Loss Force: 3.3489891876606666, time: 1.5827152729034424
Validation Loss Energy: 1.9177081816375185, Validation Loss Force: 3.0381209846299138, time: 0.12304997444152832
Test Loss Energy: 8.028228590001207, Test Loss Force: 7.136839800775518, time: 17.897294998168945


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.937806513650578, Training Loss Force: 3.3546553406716932, time: 1.6352829933166504
Validation Loss Energy: 3.1451739639213354, Validation Loss Force: 3.5974733386169055, time: 0.13068795204162598
Test Loss Energy: 8.647708222931755, Test Loss Force: 7.141820375630294, time: 17.90469241142273


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1063988573789634, Training Loss Force: 3.3867486757443785, time: 1.5659301280975342
Validation Loss Energy: 1.169147341283167, Validation Loss Force: 2.730419501928087, time: 0.12231206893920898
Test Loss Energy: 7.577653551182018, Test Loss Force: 7.139919627499987, time: 17.874508142471313

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–‚â–‚â–‚â–‚â–ƒâ–†â–ˆâ–‚â–â–â–‚â–„â–‚â–‚â–ƒâ–„â–‡â–‚
wandb:   test_error_force â–…â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–†â–…â–†â–„â–„â–ƒâ–†â–ƒâ–†â–â–â–
wandb:          test_loss â–‡â–…â–…â–‡â–„â–„â–†â–ˆâ–‡â–‚â–„â–…â–‚â–ƒâ–ƒâ–„â–…â–„â–„â–
wandb: train_error_energy â–ˆâ–‚â–â–‚â–â–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–…â–ˆâ–‚â–„â–†â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–ˆâ–
wandb:  valid_error_force â–ƒâ–„â–ƒâ–â–ƒâ–ƒâ–„â–†â–ƒâ–†â–ƒâ–…â–‚â–…â–„â–ƒâ–ƒâ–„â–ˆâ–
wandb:         valid_loss â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–ƒâ–…â–„â–…â–‚â–†â–â–†â–ƒâ–„â–‚â–ƒâ–ˆâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1349
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.57765
wandb:   test_error_force 7.13992
wandb:          test_loss 3.79186
wandb: train_error_energy 2.1064
wandb:  train_error_force 3.38675
wandb:         train_loss 1.53857
wandb: valid_error_energy 1.16915
wandb:  valid_error_force 2.73042
wandb:         valid_loss 1.36186
wandb: 
wandb: ğŸš€ View run al_55_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9t2i0xdj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_090112-9t2i0xdj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7191523313522339, Uncertainty Bias: 0.02645242214202881
0.00010728836 0.0010108948
0.56201524 5.6404934
Found uncertainty sample 2 after 1135 steps.
Found uncertainty sample 3 after 906 steps.
Found uncertainty sample 5 after 3697 steps.
Found uncertainty sample 7 after 1053 steps.
Found uncertainty sample 10 after 2267 steps.
Found uncertainty sample 13 after 2796 steps.
Found uncertainty sample 16 after 2401 steps.
Found uncertainty sample 19 after 2233 steps.
Found uncertainty sample 24 after 2480 steps.
Found uncertainty sample 27 after 3146 steps.
Found uncertainty sample 33 after 2118 steps.
Found uncertainty sample 34 after 2623 steps.
Found uncertainty sample 39 after 678 steps.
Found uncertainty sample 40 after 1957 steps.
Found uncertainty sample 43 after 2648 steps.
Found uncertainty sample 45 after 1052 steps.
Found uncertainty sample 50 after 2697 steps.
Found uncertainty sample 55 after 303 steps.
Found uncertainty sample 57 after 2373 steps.
Found uncertainty sample 59 after 1556 steps.
Found uncertainty sample 60 after 809 steps.
Found uncertainty sample 61 after 3017 steps.
Found uncertainty sample 63 after 3221 steps.
Found uncertainty sample 71 after 2696 steps.
Found uncertainty sample 72 after 2142 steps.
Found uncertainty sample 74 after 2921 steps.
Found uncertainty sample 84 after 2477 steps.
Found uncertainty sample 89 after 3947 steps.
Found uncertainty sample 92 after 270 steps.
Found uncertainty sample 95 after 3282 steps.
Found uncertainty sample 97 after 3504 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_114731-jb6qmiaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jb6qmiaj
Training model 16. Added 31 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.681100418178522, Training Loss Force: 3.6428239104621967, time: 1.5598642826080322
Validation Loss Energy: 1.474403972429993, Validation Loss Force: 3.1123261455177866, time: 0.1268930435180664
Test Loss Energy: 7.829122036617947, Test Loss Force: 7.190654029961825, time: 17.315163373947144


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0741118545220196, Training Loss Force: 3.4334651959303084, time: 1.5491337776184082
Validation Loss Energy: 1.4347194875717375, Validation Loss Force: 3.0288847797914022, time: 0.13123226165771484
Test Loss Energy: 7.716886280817238, Test Loss Force: 7.132570671329085, time: 17.468233823776245


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9840427779155592, Training Loss Force: 3.407105109778506, time: 1.5937864780426025
Validation Loss Energy: 1.5891670935683102, Validation Loss Force: 3.2444237256628634, time: 0.12345242500305176
Test Loss Energy: 7.628856239681619, Test Loss Force: 7.154348492559929, time: 17.678942918777466


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0709620907074737, Training Loss Force: 3.4041533972233835, time: 1.8182718753814697
Validation Loss Energy: 2.045019154487158, Validation Loss Force: 3.2973306940773166, time: 0.12158846855163574
Test Loss Energy: 7.593424006006825, Test Loss Force: 7.18199003411574, time: 17.347286462783813


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.283338298402875, Training Loss Force: 3.408311712453471, time: 1.5837397575378418
Validation Loss Energy: 2.6652784226289237, Validation Loss Force: 3.3714433359350564, time: 0.1358957290649414
Test Loss Energy: 7.522831199678495, Test Loss Force: 7.148689434325248, time: 17.444498300552368


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0240185179004526, Training Loss Force: 3.4210360683005834, time: 1.5550720691680908
Validation Loss Energy: 1.770678352899238, Validation Loss Force: 2.89059799940069, time: 0.12059569358825684
Test Loss Energy: 7.895560972179328, Test Loss Force: 7.113531976708142, time: 17.361395597457886


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1369673178918696, Training Loss Force: 3.4127162531537856, time: 1.5405771732330322
Validation Loss Energy: 2.65329436919509, Validation Loss Force: 2.9764508719774727, time: 0.1273658275604248
Test Loss Energy: 8.449089356947129, Test Loss Force: 7.127922869100957, time: 17.458534955978394


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2071556335434264, Training Loss Force: 3.4057440006080286, time: 1.5503840446472168
Validation Loss Energy: 1.9139930582722864, Validation Loss Force: 3.0169856746367403, time: 0.13263773918151855
Test Loss Energy: 7.881197760709031, Test Loss Force: 7.162663522719484, time: 17.5124409198761


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.4541317059253474, Training Loss Force: 3.4060705060728895, time: 1.5822429656982422
Validation Loss Energy: 1.777740527531484, Validation Loss Force: 3.1130855586399737, time: 0.1365976333618164
Test Loss Energy: 7.775957395118086, Test Loss Force: 7.0653022687171765, time: 17.357321739196777


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.3086058609793594, Training Loss Force: 3.4016628583612376, time: 1.6033694744110107
Validation Loss Energy: 2.228938413629436, Validation Loss Force: 2.789312818996236, time: 0.12563610076904297
Test Loss Energy: 7.473411522123937, Test Loss Force: 7.138216110605847, time: 17.46169924736023


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0737607415273573, Training Loss Force: 3.3879105840612387, time: 1.5967998504638672
Validation Loss Energy: 1.3373710976672868, Validation Loss Force: 2.8059106884682663, time: 0.1346123218536377
Test Loss Energy: 7.378253664424499, Test Loss Force: 7.077594549876098, time: 17.441807508468628


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.079005765043208, Training Loss Force: 3.402886601382086, time: 1.6010768413543701
Validation Loss Energy: 1.6658435479722629, Validation Loss Force: 3.234329242601373, time: 0.13357043266296387
Test Loss Energy: 7.730370448126537, Test Loss Force: 7.078704486785931, time: 17.724609375


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9548873058949559, Training Loss Force: 3.3903766344956847, time: 1.6254329681396484
Validation Loss Energy: 1.8503738112509662, Validation Loss Force: 2.9468423329743088, time: 0.1248323917388916
Test Loss Energy: 7.3412800659576956, Test Loss Force: 7.045272066861049, time: 17.868085861206055


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0642046336230777, Training Loss Force: 3.3889690081871175, time: 1.576845645904541
Validation Loss Energy: 1.7024915493547876, Validation Loss Force: 3.1509643637266143, time: 0.13273286819458008
Test Loss Energy: 7.481539062531004, Test Loss Force: 7.087334424744953, time: 17.99846887588501


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9647936438848412, Training Loss Force: 3.398716210234596, time: 1.5719141960144043
Validation Loss Energy: 1.7474660407801363, Validation Loss Force: 3.0707422371774804, time: 0.12280964851379395
Test Loss Energy: 7.477667501266882, Test Loss Force: 7.076149035407858, time: 18.336196899414062


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.263577659684672, Training Loss Force: 3.394103722443746, time: 1.581063985824585
Validation Loss Energy: 2.3814022045376513, Validation Loss Force: 3.1419601801381596, time: 0.13098764419555664
Test Loss Energy: 7.459368156811755, Test Loss Force: 7.095590073356774, time: 17.981584548950195


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1622836450113114, Training Loss Force: 3.385518206043982, time: 1.5872101783752441
Validation Loss Energy: 1.5616524238788783, Validation Loss Force: 2.8066060842109986, time: 0.1242372989654541
Test Loss Energy: 7.717710685933571, Test Loss Force: 7.055681453058777, time: 18.286530256271362


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1308640368664484, Training Loss Force: 3.3870595011586855, time: 1.5850639343261719
Validation Loss Energy: 2.331927347003956, Validation Loss Force: 2.931833541862192, time: 0.12373065948486328
Test Loss Energy: 7.346416812324455, Test Loss Force: 7.081172500303885, time: 18.10761284828186


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.4721019578406622, Training Loss Force: 3.399941672468385, time: 1.5945146083831787
Validation Loss Energy: 2.2542098030082185, Validation Loss Force: 2.9907857549194388, time: 0.12427377700805664
Test Loss Energy: 8.193407432667389, Test Loss Force: 7.032571522405973, time: 18.093706846237183


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9813880050232355, Training Loss Force: 3.3816467404573713, time: 1.6229774951934814
Validation Loss Energy: 1.558583653376988, Validation Loss Force: 3.015848057970195, time: 0.13614988327026367
Test Loss Energy: 7.76630849516793, Test Loss Force: 7.070497247145918, time: 17.98232913017273

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.045 MB of 0.047 MB uploaded (0.003 MB deduped)wandb: / 0.045 MB of 0.047 MB uploaded (0.003 MB deduped)wandb: - 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.7%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–ƒâ–ƒâ–‚â–…â–ˆâ–„â–„â–‚â–â–ƒâ–â–‚â–‚â–‚â–ƒâ–â–†â–„
wandb:   test_error_force â–ˆâ–…â–†â–ˆâ–†â–…â–…â–‡â–‚â–†â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–â–ƒ
wandb:          test_loss â–…â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–â–‚â–â–‚â–ƒ
wandb: train_error_energy â–ˆâ–â–â–â–‚â–â–‚â–‚â–ƒâ–‚â–â–‚â–â–â–â–‚â–‚â–‚â–ƒâ–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–â–â–‚â–
wandb: valid_error_energy â–‚â–‚â–‚â–…â–ˆâ–ƒâ–ˆâ–„â–ƒâ–†â–â–ƒâ–„â–ƒâ–ƒâ–‡â–‚â–†â–†â–‚
wandb:  valid_error_force â–…â–„â–†â–‡â–ˆâ–‚â–ƒâ–„â–…â–â–â–†â–ƒâ–…â–„â–…â–â–ƒâ–ƒâ–„
wandb:         valid_loss â–„â–ƒâ–…â–‡â–ˆâ–‚â–„â–†â–…â–â–â–†â–ƒâ–…â–…â–†â–‚â–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1376
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.76631
wandb:   test_error_force 7.0705
wandb:          test_loss 3.78536
wandb: train_error_energy 1.98139
wandb:  train_error_force 3.38165
wandb:         train_loss 1.53348
wandb: valid_error_energy 1.55858
wandb:  valid_error_force 3.01585
wandb:         valid_loss 1.49512
wandb: 
wandb: ğŸš€ View run al_55_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jb6qmiaj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_114731-jb6qmiaj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7271142601966858, Uncertainty Bias: 0.02829912304878235
0.0002603531 0.011012495
0.7023644 7.5909586
Found uncertainty sample 1 after 3528 steps.
Found uncertainty sample 3 after 2607 steps.
Found uncertainty sample 4 after 1297 steps.
Found uncertainty sample 12 after 1196 steps.
Found uncertainty sample 13 after 2327 steps.
Found uncertainty sample 14 after 633 steps.
Found uncertainty sample 21 after 1879 steps.
Found uncertainty sample 27 after 2318 steps.
Found uncertainty sample 30 after 1328 steps.
Found uncertainty sample 32 after 3398 steps.
Found uncertainty sample 39 after 1123 steps.
Found uncertainty sample 43 after 1980 steps.
Found uncertainty sample 44 after 1543 steps.
Found uncertainty sample 46 after 3125 steps.
Found uncertainty sample 47 after 2258 steps.
Found uncertainty sample 49 after 1606 steps.
Found uncertainty sample 51 after 861 steps.
Found uncertainty sample 55 after 1597 steps.
Found uncertainty sample 60 after 2847 steps.
Found uncertainty sample 62 after 454 steps.
Found uncertainty sample 70 after 3088 steps.
Found uncertainty sample 75 after 150 steps.
Found uncertainty sample 77 after 1079 steps.
Found uncertainty sample 78 after 3773 steps.
Found uncertainty sample 81 after 3598 steps.
Found uncertainty sample 88 after 2488 steps.
Found uncertainty sample 93 after 616 steps.
Found uncertainty sample 94 after 2324 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_143320-nt4y2bhm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nt4y2bhm
Training model 17. Added 28 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.79647901943263, Training Loss Force: 3.6456334056931707, time: 1.6288933753967285
Validation Loss Energy: 1.579526911231799, Validation Loss Force: 3.291688814592371, time: 0.12702727317810059
Test Loss Energy: 7.575891154037176, Test Loss Force: 7.039449096155595, time: 17.383253812789917


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2954112745600623, Training Loss Force: 3.455373369344829, time: 1.5916807651519775
Validation Loss Energy: 1.4928570098913208, Validation Loss Force: 2.9221065742260555, time: 0.12491655349731445
Test Loss Energy: 7.387959507054045, Test Loss Force: 7.024049106830873, time: 17.47404456138611


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.00363931229777, Training Loss Force: 3.454011944883314, time: 1.6305139064788818
Validation Loss Energy: 1.7843707240206297, Validation Loss Force: 3.115273394333287, time: 0.13284659385681152
Test Loss Energy: 7.613616331985713, Test Loss Force: 7.0573335741834535, time: 17.47616744041443


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.064762782318283, Training Loss Force: 3.440540982802912, time: 1.6826837062835693
Validation Loss Energy: 2.0207884093618693, Validation Loss Force: 3.3239792921236626, time: 0.12152242660522461
Test Loss Energy: 7.865185659731186, Test Loss Force: 7.023644357277156, time: 17.648714065551758


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.6360063620085685, Training Loss Force: 3.4464729141537402, time: 1.5958311557769775
Validation Loss Energy: 2.0556249972422718, Validation Loss Force: 3.0506502434675515, time: 0.12444543838500977
Test Loss Energy: 7.700144825303198, Test Loss Force: 7.010685707805158, time: 17.496562957763672


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.069127274701652, Training Loss Force: 3.437011413685511, time: 1.591486930847168
Validation Loss Energy: 1.9509892028644695, Validation Loss Force: 3.1968628207729903, time: 0.11928415298461914
Test Loss Energy: 7.626201067500382, Test Loss Force: 7.034908932892093, time: 17.347711086273193


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0896370159719915, Training Loss Force: 3.432500561884656, time: 1.5854790210723877
Validation Loss Energy: 1.4535591900049685, Validation Loss Force: 2.9218768910020314, time: 0.13763928413391113
Test Loss Energy: 7.519265718722881, Test Loss Force: 7.023966544375823, time: 17.44941258430481


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.333197277219475, Training Loss Force: 3.423182202252622, time: 1.6189274787902832
Validation Loss Energy: 1.762465813791843, Validation Loss Force: 2.876509722537839, time: 0.12763500213623047
Test Loss Energy: 7.819612646465462, Test Loss Force: 7.021142327841193, time: 17.501091718673706


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1512446496863507, Training Loss Force: 3.453565538791692, time: 1.600832462310791
Validation Loss Energy: 1.5447722655970981, Validation Loss Force: 2.913932835217338, time: 0.12227916717529297
Test Loss Energy: 7.381950725358252, Test Loss Force: 7.030852689138853, time: 17.424519777297974


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.104189795855235, Training Loss Force: 3.4327681089848143, time: 1.5972325801849365
Validation Loss Energy: 1.6948910720622616, Validation Loss Force: 2.964063676054937, time: 0.125457763671875
Test Loss Energy: 7.765361134713993, Test Loss Force: 7.004629079056555, time: 17.525743007659912


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.641424274287679, Training Loss Force: 3.4389278915998744, time: 1.5794775485992432
Validation Loss Energy: 2.072770521478711, Validation Loss Force: 3.0597161064094287, time: 0.12107372283935547
Test Loss Energy: 7.210749339809898, Test Loss Force: 7.030147541420173, time: 17.676831245422363


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.5082731300179826, Training Loss Force: 3.4209487598696926, time: 1.6630933284759521
Validation Loss Energy: 2.2223295933782987, Validation Loss Force: 3.0052418812113624, time: 0.12780141830444336
Test Loss Energy: 7.1752075529153085, Test Loss Force: 6.992532268765158, time: 18.107181787490845


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2831635757967876, Training Loss Force: 3.432944270643217, time: 1.6152653694152832
Validation Loss Energy: 1.4731768984340716, Validation Loss Force: 2.9906707463055673, time: 0.13105463981628418
Test Loss Energy: 7.535845306591707, Test Loss Force: 6.969131040237201, time: 18.128924131393433


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2705766583020104, Training Loss Force: 3.4194354851719804, time: 1.6115362644195557
Validation Loss Energy: 1.3148287413409951, Validation Loss Force: 2.773296338664223, time: 0.1269071102142334
Test Loss Energy: 7.483628282023332, Test Loss Force: 7.005797942849372, time: 17.955357789993286


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.143972270319687, Training Loss Force: 3.4184730585166565, time: 1.8276677131652832
Validation Loss Energy: 1.7113356338273205, Validation Loss Force: 2.890785486821561, time: 0.12438583374023438
Test Loss Energy: 7.314045262822424, Test Loss Force: 7.000279210477292, time: 17.942731618881226


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0192476147819853, Training Loss Force: 3.415639112871797, time: 1.6484911441802979
Validation Loss Energy: 1.4183803039799887, Validation Loss Force: 2.8782957517573253, time: 0.1281909942626953
Test Loss Energy: 7.536756258891575, Test Loss Force: 6.926046665947698, time: 18.1965548992157


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.055806783826941, Training Loss Force: 3.4041939592564074, time: 1.6223177909851074
Validation Loss Energy: 1.3525879174289863, Validation Loss Force: 2.8942632448772345, time: 0.12749099731445312
Test Loss Energy: 7.329341339101839, Test Loss Force: 6.991079344427331, time: 18.033336639404297


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1408847677758946, Training Loss Force: 3.410687224342132, time: 1.604306936264038
Validation Loss Energy: 1.8355233935688906, Validation Loss Force: 3.0607626513952892, time: 0.14780402183532715
Test Loss Energy: 7.244836064276538, Test Loss Force: 7.000195316670596, time: 18.14889407157898


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0649055436047976, Training Loss Force: 3.41429821951767, time: 1.6004369258880615
Validation Loss Energy: 1.6067239433845648, Validation Loss Force: 3.1177109534737584, time: 0.12562799453735352
Test Loss Energy: 7.488585820530866, Test Loss Force: 6.966676668993307, time: 18.12386965751648


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.4446930955393267, Training Loss Force: 3.4194707023216733, time: 1.6022191047668457
Validation Loss Energy: 1.6586170991776088, Validation Loss Force: 3.221921004444547, time: 0.128265380859375
Test Loss Energy: 7.275030958757736, Test Loss Force: 6.980221516559389, time: 18.04862928390503

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–…â–ˆâ–†â–†â–„â–ˆâ–ƒâ–‡â–â–â–…â–„â–‚â–…â–ƒâ–‚â–„â–‚
wandb:   test_error_force â–‡â–†â–ˆâ–†â–†â–‡â–†â–†â–‡â–…â–‡â–…â–ƒâ–…â–…â–â–„â–…â–ƒâ–„
wandb:          test_loss â–…â–„â–†â–ˆâ–„â–‡â–…â–…â–ƒâ–†â–‚â–…â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–
wandb: train_error_energy â–ˆâ–‚â–â–â–ƒâ–â–â–‚â–‚â–â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–
wandb: valid_error_energy â–ƒâ–‚â–…â–†â–‡â–†â–‚â–„â–ƒâ–„â–‡â–ˆâ–‚â–â–„â–‚â–â–…â–ƒâ–„
wandb:  valid_error_force â–ˆâ–ƒâ–…â–ˆâ–…â–†â–ƒâ–‚â–ƒâ–ƒâ–…â–„â–„â–â–‚â–‚â–ƒâ–…â–…â–‡
wandb:         valid_loss â–†â–„â–…â–ˆâ–…â–…â–ƒâ–„â–ƒâ–„â–‡â–…â–ƒâ–â–‚â–‚â–‚â–„â–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1401
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.27503
wandb:   test_error_force 6.98022
wandb:          test_loss 3.68696
wandb: train_error_energy 2.44469
wandb:  train_error_force 3.41947
wandb:         train_loss 1.55972
wandb: valid_error_energy 1.65862
wandb:  valid_error_force 3.22192
wandb:         valid_loss 1.55686
wandb: 
wandb: ğŸš€ View run al_55_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nt4y2bhm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_143320-nt4y2bhm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7375754714012146, Uncertainty Bias: 0.023163527250289917
0.00014781952 0.032975197
0.40191412 5.2269883
Found uncertainty sample 2 after 2814 steps.
Found uncertainty sample 4 after 1283 steps.
Found uncertainty sample 5 after 1924 steps.
Found uncertainty sample 8 after 1713 steps.
Found uncertainty sample 15 after 858 steps.
Found uncertainty sample 16 after 1604 steps.
Found uncertainty sample 18 after 690 steps.
Found uncertainty sample 21 after 2952 steps.
Found uncertainty sample 27 after 410 steps.
Found uncertainty sample 35 after 672 steps.
Found uncertainty sample 36 after 1853 steps.
Found uncertainty sample 39 after 2217 steps.
Found uncertainty sample 40 after 2165 steps.
Found uncertainty sample 42 after 3638 steps.
Found uncertainty sample 44 after 2681 steps.
Found uncertainty sample 46 after 3979 steps.
Found uncertainty sample 47 after 1850 steps.
Found uncertainty sample 50 after 1419 steps.
Found uncertainty sample 54 after 2624 steps.
Found uncertainty sample 55 after 1228 steps.
Found uncertainty sample 57 after 968 steps.
Found uncertainty sample 58 after 3473 steps.
Found uncertainty sample 59 after 2975 steps.
Found uncertainty sample 64 after 2342 steps.
Found uncertainty sample 65 after 1134 steps.
Found uncertainty sample 66 after 3251 steps.
Found uncertainty sample 67 after 2055 steps.
Found uncertainty sample 69 after 2776 steps.
Found uncertainty sample 72 after 1625 steps.
Found uncertainty sample 87 after 2726 steps.
Found uncertainty sample 88 after 2586 steps.
Found uncertainty sample 89 after 2183 steps.
Found uncertainty sample 93 after 850 steps.
Found uncertainty sample 96 after 813 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_171422-r7qsav92
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/r7qsav92
Training model 18. Added 34 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.019528688937343, Training Loss Force: 3.6673775830986433, time: 1.6454651355743408
Validation Loss Energy: 1.6839384777796522, Validation Loss Force: 3.101147597719347, time: 0.12387728691101074
Test Loss Energy: 7.5941524815245085, Test Loss Force: 6.990716449678208, time: 17.392795085906982


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.398542444093027, Training Loss Force: 3.4799544146465533, time: 1.614642858505249
Validation Loss Energy: 2.271001617306352, Validation Loss Force: 3.06903681418882, time: 0.12378692626953125
Test Loss Energy: 7.940166426218223, Test Loss Force: 6.968482639342329, time: 17.523830890655518


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1028441643715845, Training Loss Force: 3.464201166356552, time: 1.650622844696045
Validation Loss Energy: 1.5329042784555793, Validation Loss Force: 3.014969071516645, time: 0.12562322616577148
Test Loss Energy: 7.25155351442829, Test Loss Force: 6.966286032699698, time: 17.501229763031006


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.993874402064086, Training Loss Force: 3.462445207368172, time: 1.698885202407837
Validation Loss Energy: 1.6612582335847448, Validation Loss Force: 3.1596198474325465, time: 0.13103866577148438
Test Loss Energy: 7.235523688520109, Test Loss Force: 6.931652887475408, time: 17.448519468307495


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.177075362704921, Training Loss Force: 3.465541228862371, time: 1.664473056793213
Validation Loss Energy: 2.9613631446531246, Validation Loss Force: 3.08863225570333, time: 0.12977075576782227
Test Loss Energy: 7.083061937774224, Test Loss Force: 6.947049831712125, time: 17.828717708587646


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.127740559115811, Training Loss Force: 3.4499877642782986, time: 1.5993475914001465
Validation Loss Energy: 1.3871269079958564, Validation Loss Force: 2.9529020511115878, time: 0.12372159957885742
Test Loss Energy: 7.362247245590203, Test Loss Force: 6.888454373681192, time: 17.479055166244507


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.088968343563168, Training Loss Force: 3.460594025156587, time: 1.6828527450561523
Validation Loss Energy: 2.3053367542701246, Validation Loss Force: 3.1587212660941546, time: 0.12919068336486816
Test Loss Energy: 7.155761495001249, Test Loss Force: 6.917831794934759, time: 17.49912118911743


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0839777762782643, Training Loss Force: 3.4523060519278044, time: 1.6421635150909424
Validation Loss Energy: 1.3245684011184498, Validation Loss Force: 2.968519174330379, time: 0.12681102752685547
Test Loss Energy: 7.488792173041367, Test Loss Force: 6.926568541803787, time: 17.56620192527771


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.057112226734838, Training Loss Force: 3.464328345076299, time: 1.6427462100982666
Validation Loss Energy: 2.4183597160330157, Validation Loss Force: 2.957941721891371, time: 0.12809324264526367
Test Loss Energy: 7.142520431103793, Test Loss Force: 6.93242175121242, time: 17.44678831100464


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.315230788092349, Training Loss Force: 3.4523084171689553, time: 1.6359193325042725
Validation Loss Energy: 1.432721532992614, Validation Loss Force: 2.9909896085225354, time: 0.1327047348022461
Test Loss Energy: 7.293766044581113, Test Loss Force: 6.9167839932089015, time: 17.50094223022461


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.117545498875207, Training Loss Force: 3.481190851880062, time: 1.623255968093872
Validation Loss Energy: 1.3898865580559123, Validation Loss Force: 3.1200081197177223, time: 0.1278836727142334
Test Loss Energy: 7.214557387906115, Test Loss Force: 6.9351405065099865, time: 17.880953073501587


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.172139183595961, Training Loss Force: 3.444429249647487, time: 1.652818202972412
Validation Loss Energy: 1.6950322999680663, Validation Loss Force: 2.923534996797182, time: 0.13475775718688965
Test Loss Energy: 7.056347627847883, Test Loss Force: 6.862574667351224, time: 17.832059383392334


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.008338220337951, Training Loss Force: 3.446946984525102, time: 1.6452207565307617
Validation Loss Energy: 1.3641520725208867, Validation Loss Force: 2.935868195451831, time: 0.1270616054534912
Test Loss Energy: 7.321339955338527, Test Loss Force: 6.875492023937627, time: 18.421202421188354


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1870081162175206, Training Loss Force: 3.4400821145489613, time: 1.6399166584014893
Validation Loss Energy: 2.1543180304516936, Validation Loss Force: 2.9251492367705856, time: 0.13049697875976562
Test Loss Energy: 7.964061506932482, Test Loss Force: 6.884515487060117, time: 18.102132558822632


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.200376832787103, Training Loss Force: 3.44092230956319, time: 1.6309702396392822
Validation Loss Energy: 1.7045932677559137, Validation Loss Force: 3.1111920915575766, time: 0.12976861000061035
Test Loss Energy: 7.168948521410476, Test Loss Force: 6.880781831443167, time: 17.964573621749878


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.958703664492796, Training Loss Force: 3.4502400731616514, time: 1.6353912353515625
Validation Loss Energy: 1.3292851459693515, Validation Loss Force: 2.84517382763514, time: 0.13277387619018555
Test Loss Energy: 7.359591989470859, Test Loss Force: 6.856384143331686, time: 18.003875255584717


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.284131672137125, Training Loss Force: 3.441750594252211, time: 1.6379008293151855
Validation Loss Energy: 1.9201274262407373, Validation Loss Force: 3.095841057968169, time: 0.12987661361694336
Test Loss Energy: 7.006317673620495, Test Loss Force: 6.8932922444269895, time: 18.147701740264893


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3372037769384013, Training Loss Force: 3.4542243416717704, time: 1.8905575275421143
Validation Loss Energy: 1.9635354958917706, Validation Loss Force: 3.106751178111193, time: 0.12748932838439941
Test Loss Energy: 7.716717178173495, Test Loss Force: 6.842804062745039, time: 17.98013424873352


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.336113655600683, Training Loss Force: 3.439312480912977, time: 1.6246795654296875
Validation Loss Energy: 2.160788740165069, Validation Loss Force: 3.157404066761419, time: 0.12697052955627441
Test Loss Energy: 7.054665503513052, Test Loss Force: 6.876748934141842, time: 18.150582313537598


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1812378481771355, Training Loss Force: 3.4331225903929887, time: 1.6584804058074951
Validation Loss Energy: 1.9151848392085784, Validation Loss Force: 3.000950044758177, time: 0.12383437156677246
Test Loss Energy: 7.694741841249561, Test Loss Force: 6.879265016215949, time: 18.004828214645386

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ˆâ–ƒâ–ƒâ–‚â–„â–‚â–…â–‚â–ƒâ–ƒâ–â–ƒâ–ˆâ–‚â–„â–â–†â–â–†
wandb:   test_error_force â–ˆâ–‡â–‡â–…â–†â–ƒâ–…â–…â–…â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒ
wandb:          test_loss â–‡â–†â–†â–…â–…â–…â–ˆâ–ˆâ–…â–…â–ƒâ–‚â–ƒâ–‡â–‚â–â–â–‡â–ƒâ–„
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–
wandb: valid_error_energy â–ƒâ–…â–‚â–‚â–ˆâ–â–…â–â–†â–â–â–ƒâ–â–…â–ƒâ–â–„â–„â–…â–„
wandb:  valid_error_force â–‡â–†â–…â–ˆâ–†â–ƒâ–ˆâ–„â–„â–„â–‡â–ƒâ–ƒâ–ƒâ–‡â–â–‡â–‡â–ˆâ–„
wandb:         valid_loss â–…â–†â–ƒâ–†â–†â–‚â–ˆâ–ƒâ–„â–„â–„â–‚â–‚â–ƒâ–„â–â–†â–†â–†â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1431
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.69474
wandb:   test_error_force 6.87927
wandb:          test_loss 3.6669
wandb: train_error_energy 2.18124
wandb:  train_error_force 3.43312
wandb:         train_loss 1.55303
wandb: valid_error_energy 1.91518
wandb:  valid_error_force 3.00095
wandb:         valid_loss 1.49718
wandb: 
wandb: ğŸš€ View run al_55_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/r7qsav92
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_171422-r7qsav92/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7505691051483154, Uncertainty Bias: 0.017882630228996277
7.6293945e-05 0.00029468536
0.372717 5.4974413
Found uncertainty sample 0 after 2608 steps.
Found uncertainty sample 1 after 2314 steps.
Found uncertainty sample 4 after 395 steps.
Found uncertainty sample 5 after 1155 steps.
Found uncertainty sample 6 after 1792 steps.
Found uncertainty sample 13 after 2105 steps.
Found uncertainty sample 14 after 2084 steps.
Found uncertainty sample 16 after 2075 steps.
Found uncertainty sample 19 after 3582 steps.
Found uncertainty sample 22 after 2903 steps.
Found uncertainty sample 39 after 3177 steps.
Found uncertainty sample 41 after 1247 steps.
Found uncertainty sample 44 after 3513 steps.
Found uncertainty sample 48 after 1075 steps.
Found uncertainty sample 50 after 1833 steps.
Found uncertainty sample 55 after 2059 steps.
Found uncertainty sample 59 after 2944 steps.
Found uncertainty sample 62 after 8 steps.
Found uncertainty sample 67 after 3365 steps.
Found uncertainty sample 69 after 2475 steps.
Found uncertainty sample 75 after 1879 steps.
Found uncertainty sample 84 after 2538 steps.
Found uncertainty sample 87 after 2126 steps.
Found uncertainty sample 90 after 1484 steps.
Found uncertainty sample 91 after 3745 steps.
Found uncertainty sample 93 after 1922 steps.
Found uncertainty sample 94 after 1944 steps.
Found uncertainty sample 98 after 1605 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_200243-jo7h0fjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jo7h0fjp
Training model 19. Added 28 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.6400203854057054, Training Loss Force: 3.6584265001851612, time: 1.7149434089660645
Validation Loss Energy: 2.1568351381445483, Validation Loss Force: 3.0292479531684102, time: 0.13220500946044922
Test Loss Energy: 7.863408578080784, Test Loss Force: 6.895521619574089, time: 17.465341567993164


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1613780994083203, Training Loss Force: 3.480658200283023, time: 1.6812877655029297
Validation Loss Energy: 2.4391944226791873, Validation Loss Force: 3.0673772610442196, time: 0.12188339233398438
Test Loss Energy: 6.972665485077616, Test Loss Force: 6.8686894978508315, time: 17.6463725566864


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.103352428399339, Training Loss Force: 3.4514972504663426, time: 1.7162656784057617
Validation Loss Energy: 1.8243907156145123, Validation Loss Force: 3.2814159735449926, time: 0.12433147430419922
Test Loss Energy: 7.348019948568642, Test Loss Force: 6.825670299170087, time: 17.595739603042603


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0299259620874675, Training Loss Force: 3.4886292813251454, time: 1.7078912258148193
Validation Loss Energy: 2.1311099490463645, Validation Loss Force: 3.043364620347367, time: 0.12539148330688477
Test Loss Energy: 7.0248978096976735, Test Loss Force: 6.855861509701018, time: 17.537075996398926


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9836817531044353, Training Loss Force: 3.4661727639546087, time: 1.67769193649292
Validation Loss Energy: 2.683358266601676, Validation Loss Force: 3.091878103843519, time: 0.13193821907043457
Test Loss Energy: 7.768823227237475, Test Loss Force: 6.8220789909251565, time: 17.64408540725708


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1742568398908086, Training Loss Force: 3.484065425466407, time: 1.6530394554138184
Validation Loss Energy: 1.701295537704723, Validation Loss Force: 3.221254667025358, time: 0.1281745433807373
Test Loss Energy: 7.1258079598845505, Test Loss Force: 6.824829143738105, time: 17.47675347328186


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.133421024850999, Training Loss Force: 3.461827511109569, time: 1.665937900543213
Validation Loss Energy: 2.103540057408743, Validation Loss Force: 3.0914329882208094, time: 0.1285865306854248
Test Loss Energy: 7.046091736469157, Test Loss Force: 6.864357923115747, time: 17.61421036720276


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.064810319760622, Training Loss Force: 3.440396757884817, time: 1.6424365043640137
Validation Loss Energy: 1.6329162366836183, Validation Loss Force: 3.0762879235913854, time: 0.1294724941253662
Test Loss Energy: 7.187453672778407, Test Loss Force: 6.8136871737186615, time: 17.569921255111694


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1368423169156445, Training Loss Force: 3.462504551169663, time: 1.6591172218322754
Validation Loss Energy: 3.0349855803861043, Validation Loss Force: 2.9764848290222266, time: 0.12229776382446289
Test Loss Energy: 8.228021598552958, Test Loss Force: 6.824305815286438, time: 17.824039220809937


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0893597310572183, Training Loss Force: 3.4721461832759406, time: 1.695035696029663
Validation Loss Energy: 1.6263089194492166, Validation Loss Force: 2.8695545404302116, time: 0.12015271186828613
Test Loss Energy: 7.482372215863416, Test Loss Force: 6.838515527274505, time: 17.61575937271118


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.129130701095816, Training Loss Force: 3.447051205948335, time: 1.6519348621368408
Validation Loss Energy: 1.759678330088546, Validation Loss Force: 3.0858939818812825, time: 0.12609505653381348
Test Loss Energy: 7.3894074440693265, Test Loss Force: 6.79164041012859, time: 17.674379348754883


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.22209575689064, Training Loss Force: 3.4494460658597577, time: 1.6884512901306152
Validation Loss Energy: 2.0002009768022506, Validation Loss Force: 3.0703415440493833, time: 0.1243748664855957
Test Loss Energy: 6.920042083488889, Test Loss Force: 6.818507230932784, time: 17.917904376983643


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0737449918504787, Training Loss Force: 3.4673737299931697, time: 1.6648433208465576
Validation Loss Energy: 1.801207239149808, Validation Loss Force: 3.2033296894435983, time: 0.13891077041625977
Test Loss Energy: 7.1438964984462565, Test Loss Force: 6.83915139341201, time: 17.97521662712097


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.087288039106358, Training Loss Force: 3.438768087982631, time: 1.719834804534912
Validation Loss Energy: 1.9171747776984485, Validation Loss Force: 3.113186761766798, time: 0.12354922294616699
Test Loss Energy: 6.8840670360634455, Test Loss Force: 6.789080719876095, time: 18.230769157409668


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.986571637991375, Training Loss Force: 3.4462405498787847, time: 1.686509609222412
Validation Loss Energy: 1.6607307860453284, Validation Loss Force: 3.1559282156622093, time: 0.13354229927062988
Test Loss Energy: 7.141030699905885, Test Loss Force: 6.796750503814645, time: 18.070062398910522


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.299476925257018, Training Loss Force: 3.4576896213269905, time: 1.6560993194580078
Validation Loss Energy: 1.7980574727460863, Validation Loss Force: 3.071836099356851, time: 0.12500333786010742
Test Loss Energy: 7.488885526206443, Test Loss Force: 6.794883839219158, time: 18.168823957443237


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.5756049226571247, Training Loss Force: 3.471241904511793, time: 1.6621758937835693
Validation Loss Energy: 1.7670323683038165, Validation Loss Force: 3.123938786816213, time: 0.12747406959533691
Test Loss Energy: 7.114095497523553, Test Loss Force: 6.756781270876675, time: 18.15188431739807


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.49707045639163, Training Loss Force: 3.465234997687167, time: 1.6194677352905273
Validation Loss Energy: 2.2032039837616963, Validation Loss Force: 3.065333492288322, time: 0.13044095039367676
Test Loss Energy: 6.901342944159993, Test Loss Force: 6.796494096212784, time: 18.290388822555542


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.110410235569912, Training Loss Force: 3.4365659821014445, time: 1.7130773067474365
Validation Loss Energy: 2.8098143012655266, Validation Loss Force: 2.9209838763922877, time: 0.12633848190307617
Test Loss Energy: 8.0848351812104, Test Loss Force: 6.794392833933666, time: 18.16996741294861


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.286156731091144, Training Loss Force: 3.4482750149368884, time: 1.7098498344421387
Validation Loss Energy: 2.258336307620552, Validation Loss Force: 3.0090279246995726, time: 0.12931609153747559
Test Loss Energy: 6.87362810598354, Test Loss Force: 6.7812133945966995, time: 18.1887264251709

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‚â–ƒâ–‚â–†â–‚â–‚â–ƒâ–ˆâ–„â–„â–â–‚â–â–‚â–„â–‚â–â–‡â–
wandb:   test_error_force â–ˆâ–‡â–„â–†â–„â–„â–†â–„â–„â–…â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–‚
wandb:          test_loss â–†â–…â–„â–†â–…â–„â–„â–ƒâ–†â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–ˆâ–â–…â–†â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–‚â–„â–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–ƒâ–‚â–â–
wandb: valid_error_energy â–„â–…â–‚â–„â–†â–â–ƒâ–â–ˆâ–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–„â–‡â–„
wandb:  valid_error_force â–„â–„â–ˆâ–„â–…â–‡â–…â–…â–ƒâ–â–…â–„â–‡â–…â–†â–„â–…â–„â–‚â–ƒ
wandb:         valid_loss â–„â–…â–ˆâ–…â–…â–†â–„â–…â–„â–â–…â–ƒâ–†â–„â–„â–†â–†â–…â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1456
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.87363
wandb:   test_error_force 6.78121
wandb:          test_loss 3.60248
wandb: train_error_energy 2.28616
wandb:  train_error_force 3.44828
wandb:         train_loss 1.55809
wandb: valid_error_energy 2.25834
wandb:  valid_error_force 3.00903
wandb:         valid_loss 1.48986
wandb: 
wandb: ğŸš€ View run al_55_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jo7h0fjp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_200243-jo7h0fjp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.739158570766449, Uncertainty Bias: 0.028968781232833862
3.8146973e-05 0.021415234
0.49715808 6.3271885
Found uncertainty sample 2 after 2342 steps.
Found uncertainty sample 5 after 401 steps.
Found uncertainty sample 8 after 569 steps.
Found uncertainty sample 9 after 488 steps.
Found uncertainty sample 16 after 492 steps.
Found uncertainty sample 17 after 2902 steps.
Found uncertainty sample 18 after 3493 steps.
Found uncertainty sample 19 after 469 steps.
Found uncertainty sample 27 after 1838 steps.
Found uncertainty sample 31 after 1835 steps.
Found uncertainty sample 32 after 885 steps.
Found uncertainty sample 34 after 456 steps.
Found uncertainty sample 35 after 1918 steps.
Found uncertainty sample 37 after 1052 steps.
Found uncertainty sample 40 after 516 steps.
Found uncertainty sample 47 after 3555 steps.
Found uncertainty sample 49 after 2588 steps.
Found uncertainty sample 60 after 3149 steps.
Found uncertainty sample 65 after 3846 steps.
Found uncertainty sample 66 after 260 steps.
Found uncertainty sample 68 after 3071 steps.
Found uncertainty sample 69 after 1989 steps.
Found uncertainty sample 73 after 2824 steps.
Found uncertainty sample 75 after 2687 steps.
Found uncertainty sample 78 after 2418 steps.
Found uncertainty sample 79 after 3516 steps.
Found uncertainty sample 87 after 415 steps.
Found uncertainty sample 89 after 3482 steps.
Found uncertainty sample 92 after 850 steps.
Found uncertainty sample 96 after 2226 steps.
Found uncertainty sample 98 after 1195 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_224454-daqp06o4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/daqp06o4
Training model 20. Added 31 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.093431433803972, Training Loss Force: 3.733139104179108, time: 1.7082371711730957
Validation Loss Energy: 2.0335099430070156, Validation Loss Force: 3.071530819957784, time: 0.13170289993286133
Test Loss Energy: 7.769073101656645, Test Loss Force: 6.741627171242638, time: 17.561824798583984


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9263803915864228, Training Loss Force: 3.5139725581296894, time: 1.690310001373291
Validation Loss Energy: 1.8688517319893512, Validation Loss Force: 3.052629326836558, time: 0.1326134204864502
Test Loss Energy: 6.989579431070678, Test Loss Force: 6.762436353709328, time: 17.566009283065796


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.154202376334181, Training Loss Force: 3.484614630881446, time: 1.7159693241119385
Validation Loss Energy: 1.7374934690760415, Validation Loss Force: 3.044026393049065, time: 0.12650728225708008
Test Loss Energy: 7.182723657837343, Test Loss Force: 6.756576818631659, time: 17.56172204017639


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1810814203648174, Training Loss Force: 3.48669482973091, time: 1.6973648071289062
Validation Loss Energy: 2.919140955206016, Validation Loss Force: 2.9676345098136077, time: 0.12197375297546387
Test Loss Energy: 6.941021914459467, Test Loss Force: 6.779182157683651, time: 17.411426544189453


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.548664321576309, Training Loss Force: 3.4887500564725413, time: 1.6985182762145996
Validation Loss Energy: 1.5782801866837493, Validation Loss Force: 3.000148881171129, time: 0.12972593307495117
Test Loss Energy: 7.056127185393415, Test Loss Force: 6.720707680113184, time: 17.544130563735962


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1345166638003836, Training Loss Force: 3.477615703761927, time: 1.6912214756011963
Validation Loss Energy: 1.8271663421857884, Validation Loss Force: 3.1177306596931733, time: 0.13145232200622559
Test Loss Energy: 6.9444003346795915, Test Loss Force: 6.759295109938021, time: 17.487857580184937


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.59601649072362, Training Loss Force: 3.492249960632951, time: 1.700963020324707
Validation Loss Energy: 3.0291244831269935, Validation Loss Force: 3.1404021641241027, time: 0.13711094856262207
Test Loss Energy: 6.920445410758009, Test Loss Force: 6.719844054916188, time: 17.977771759033203


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.195282353602584, Training Loss Force: 3.491372307825456, time: 1.7363786697387695
Validation Loss Energy: 1.8599406241038943, Validation Loss Force: 3.301518766708499, time: 0.12514615058898926
Test Loss Energy: 7.4503668463547665, Test Loss Force: 6.699472945431838, time: 17.57326054573059


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2314827047242485, Training Loss Force: 3.4928715723484784, time: 1.7430579662322998
Validation Loss Energy: 2.195259482638712, Validation Loss Force: 2.9864814489940814, time: 0.12621426582336426
Test Loss Energy: 6.959105260516586, Test Loss Force: 6.7038050611013915, time: 17.51228618621826


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0684402722290334, Training Loss Force: 3.4880002441806583, time: 1.727626085281372
Validation Loss Energy: 2.097773316200218, Validation Loss Force: 3.2682005597341783, time: 0.12273716926574707
Test Loss Energy: 7.226498087307495, Test Loss Force: 6.789745901397596, time: 17.622604608535767


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.340070376621101, Training Loss Force: 3.495797876051337, time: 1.7205471992492676
Validation Loss Energy: 1.7565784415735122, Validation Loss Force: 3.216746507496904, time: 0.12735772132873535
Test Loss Energy: 7.287140280490358, Test Loss Force: 6.746767060625196, time: 17.623004913330078


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.484160883802358, Training Loss Force: 3.4997715206638116, time: 1.7018883228302002
Validation Loss Energy: 2.6740165165879946, Validation Loss Force: 3.05314892528858, time: 0.12576508522033691
Test Loss Energy: 6.812395650703228, Test Loss Force: 6.691876779876673, time: 17.831949472427368


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.320723578371509, Training Loss Force: 3.4613535175026664, time: 1.7318651676177979
Validation Loss Energy: 2.3277975023544335, Validation Loss Force: 3.044534190036353, time: 0.12761640548706055
Test Loss Energy: 7.756410445930589, Test Loss Force: 6.764881044091505, time: 18.06948161125183


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0920443103054667, Training Loss Force: 3.471526654886724, time: 1.7395200729370117
Validation Loss Energy: 1.628682739546666, Validation Loss Force: 3.0165440103857923, time: 0.12892436981201172
Test Loss Energy: 7.081972050413981, Test Loss Force: 6.70260926017095, time: 18.196332693099976


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0656767988923646, Training Loss Force: 3.4825577554406064, time: 1.7048068046569824
Validation Loss Energy: 2.0439244016312044, Validation Loss Force: 2.9012537200444912, time: 0.13258028030395508
Test Loss Energy: 7.476771809381255, Test Loss Force: 6.6730117671895535, time: 18.06115412712097


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3490996839219145, Training Loss Force: 3.4644070031889806, time: 1.7303886413574219
Validation Loss Energy: 1.9931768785939588, Validation Loss Force: 3.118305702762532, time: 0.13718128204345703
Test Loss Energy: 6.911492369375982, Test Loss Force: 6.726255783828002, time: 18.52354145050049


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.145429614684146, Training Loss Force: 3.4813739088692546, time: 1.7404704093933105
Validation Loss Energy: 1.9657819492377495, Validation Loss Force: 3.146339302896548, time: 0.1277017593383789
Test Loss Energy: 6.841768042665195, Test Loss Force: 6.698690502374347, time: 18.140397787094116


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1972165691386847, Training Loss Force: 3.4593430946357806, time: 1.6812596321105957
Validation Loss Energy: 1.7200047003511543, Validation Loss Force: 3.036196677870806, time: 0.12479639053344727
Test Loss Energy: 7.420395157290736, Test Loss Force: 6.672058139356932, time: 18.26796007156372


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9907475676871689, Training Loss Force: 3.455658967289425, time: 1.7193419933319092
Validation Loss Energy: 1.6430583152750506, Validation Loss Force: 3.030834582167719, time: 0.12463808059692383
Test Loss Energy: 6.984507442953751, Test Loss Force: 6.694827020153055, time: 18.124213218688965


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0506277473036083, Training Loss Force: 3.4682300808200353, time: 1.7148668766021729
Validation Loss Energy: 1.6388890581866988, Validation Loss Force: 2.9203865664083364, time: 0.12710785865783691
Test Loss Energy: 6.876432359238301, Test Loss Force: 6.675767051885125, time: 18.28706645965576

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–„â–‚â–ƒâ–‚â–‚â–†â–‚â–„â–„â–â–ˆâ–ƒâ–†â–‚â–â–…â–‚â–
wandb:   test_error_force â–…â–†â–†â–‡â–„â–†â–„â–ƒâ–ƒâ–ˆâ–…â–‚â–‡â–ƒâ–â–„â–ƒâ–â–‚â–
wandb:          test_loss â–†â–ƒâ–„â–ˆâ–‚â–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–†â–†â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–
wandb: train_error_energy â–ˆâ–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–
wandb: valid_error_energy â–ƒâ–‚â–‚â–‡â–â–‚â–ˆâ–‚â–„â–„â–‚â–†â–…â–â–ƒâ–ƒâ–ƒâ–‚â–â–
wandb:  valid_error_force â–„â–„â–ƒâ–‚â–ƒâ–…â–…â–ˆâ–‚â–‡â–‡â–„â–„â–ƒâ–â–…â–…â–ƒâ–ƒâ–
wandb:         valid_loss â–„â–‚â–‚â–†â–‚â–„â–†â–†â–ƒâ–ˆâ–†â–…â–ƒâ–â–‚â–„â–„â–‚â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1483
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.87643
wandb:   test_error_force 6.67577
wandb:          test_loss 3.53548
wandb: train_error_energy 2.05063
wandb:  train_error_force 3.46823
wandb:         train_loss 1.56268
wandb: valid_error_energy 1.63889
wandb:  valid_error_force 2.92039
wandb:         valid_loss 1.46194
wandb: 
wandb: ğŸš€ View run al_55_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/daqp06o4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_224454-daqp06o4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7550286650657654, Uncertainty Bias: 0.02255457639694214
1.5258789e-05 0.00044822693
0.7005928 6.54104
Found uncertainty sample 0 after 1018 steps.
Found uncertainty sample 5 after 1413 steps.
Found uncertainty sample 10 after 2321 steps.
Found uncertainty sample 11 after 3485 steps.
Found uncertainty sample 25 after 172 steps.
Found uncertainty sample 30 after 3103 steps.
Found uncertainty sample 42 after 1750 steps.
Found uncertainty sample 44 after 3778 steps.
Found uncertainty sample 47 after 3966 steps.
Found uncertainty sample 53 after 1924 steps.
Found uncertainty sample 54 after 1297 steps.
Found uncertainty sample 68 after 946 steps.
Found uncertainty sample 69 after 2603 steps.
Found uncertainty sample 70 after 372 steps.
Found uncertainty sample 71 after 531 steps.
Found uncertainty sample 72 after 3960 steps.
Found uncertainty sample 74 after 1410 steps.
Found uncertainty sample 82 after 3662 steps.
Found uncertainty sample 88 after 1061 steps.
Found uncertainty sample 89 after 2192 steps.
Found uncertainty sample 90 after 2344 steps.
Found uncertainty sample 97 after 2569 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_013732-4mayk4wz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4mayk4wz
Training model 21. Added 22 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.778488984989822, Training Loss Force: 3.6512017192977617, time: 1.7959527969360352
Validation Loss Energy: 2.356935764121398, Validation Loss Force: 3.1880785229661392, time: 0.12683391571044922
Test Loss Energy: 7.7207223036193495, Test Loss Force: 6.6736824280041755, time: 17.750336170196533


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.134191294432948, Training Loss Force: 3.4994159985776703, time: 1.7446460723876953
Validation Loss Energy: 2.1159736798482047, Validation Loss Force: 3.152106099772359, time: 0.13712739944458008
Test Loss Energy: 7.460358493576663, Test Loss Force: 6.692419094661905, time: 17.84936285018921


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.069055796075357, Training Loss Force: 3.4728641100052773, time: 1.7788012027740479
Validation Loss Energy: 1.9739305823002635, Validation Loss Force: 3.062884911025127, time: 0.12780261039733887
Test Loss Energy: 6.804315271854427, Test Loss Force: 6.688294543942182, time: 17.781036853790283


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.011882370752714, Training Loss Force: 3.4780267367923856, time: 1.7776644229888916
Validation Loss Energy: 2.053483588065884, Validation Loss Force: 3.03525512138725, time: 0.13312745094299316
Test Loss Energy: 6.7438620489989995, Test Loss Force: 6.666748993444102, time: 17.85005259513855


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2981677387177855, Training Loss Force: 3.4939126074573874, time: 1.7500226497650146
Validation Loss Energy: 1.793438702319393, Validation Loss Force: 3.013879662720193, time: 0.1333756446838379
Test Loss Energy: 6.815657823639491, Test Loss Force: 6.639779555972036, time: 17.929211854934692


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0168445313503276, Training Loss Force: 3.4843919190967454, time: 1.7267541885375977
Validation Loss Energy: 1.6279560031216442, Validation Loss Force: 3.1575911088439983, time: 0.12862777709960938
Test Loss Energy: 7.008595112660518, Test Loss Force: 6.6839535215067905, time: 17.57916808128357


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0960886026265393, Training Loss Force: 3.4978779090833516, time: 2.048518180847168
Validation Loss Energy: 1.8183274904381848, Validation Loss Force: 3.035522881035228, time: 0.13134527206420898
Test Loss Energy: 6.810455528605721, Test Loss Force: 6.6762128238572, time: 17.887056589126587


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0429207536194247, Training Loss Force: 3.494296020038468, time: 1.7089691162109375
Validation Loss Energy: 1.4188180715208827, Validation Loss Force: 3.0322812636088115, time: 0.12880849838256836
Test Loss Energy: 6.902042468025479, Test Loss Force: 6.675827601571518, time: 17.06346821784973


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8436069456514552, Training Loss Force: 3.464274524522437, time: 1.7302932739257812
Validation Loss Energy: 1.8716072626702076, Validation Loss Force: 3.1750559406356986, time: 0.12720298767089844
Test Loss Energy: 6.827331856337, Test Loss Force: 6.646926400838472, time: 17.288026094436646


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1245876452337034, Training Loss Force: 3.48639095741134, time: 1.7273969650268555
Validation Loss Energy: 2.0689983948121213, Validation Loss Force: 2.867313598145594, time: 0.12252330780029297
Test Loss Energy: 6.718175523891519, Test Loss Force: 6.6150915515949364, time: 17.125699520111084


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0095492931869163, Training Loss Force: 3.501901706367716, time: 1.7061707973480225
Validation Loss Energy: 2.132672752447059, Validation Loss Force: 3.0179729896297838, time: 0.12077736854553223
Test Loss Energy: 7.478789667492638, Test Loss Force: 6.669068124075731, time: 17.114384412765503


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.556054279404285, Training Loss Force: 3.5048262760938216, time: 1.7212672233581543
Validation Loss Energy: 1.7855111240514987, Validation Loss Force: 2.9998066386938382, time: 0.12767672538757324
Test Loss Energy: 6.803800150684366, Test Loss Force: 6.640928239644877, time: 17.208423376083374


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3514444587243344, Training Loss Force: 3.493273997084507, time: 1.6624512672424316
Validation Loss Energy: 1.5138137392294604, Validation Loss Force: 2.943118748181531, time: 0.12279915809631348
Test Loss Energy: 6.9093074394567315, Test Loss Force: 6.601044681866771, time: 18.304564714431763


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.312292431461279, Training Loss Force: 3.4986137074319674, time: 1.8731634616851807
Validation Loss Energy: 1.7374915207210146, Validation Loss Force: 2.9780146773893232, time: 0.13248920440673828
Test Loss Energy: 7.273090857644761, Test Loss Force: 6.632229637982416, time: 18.036844730377197


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0666841920096735, Training Loss Force: 3.468079177466075, time: 1.7322108745574951
Validation Loss Energy: 1.52900144500033, Validation Loss Force: 3.128042356506516, time: 0.134660005569458
Test Loss Energy: 6.916537548594062, Test Loss Force: 6.601916640252537, time: 17.502106189727783


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.987053403647503, Training Loss Force: 3.456603108156367, time: 1.6767792701721191
Validation Loss Energy: 1.6886125814891089, Validation Loss Force: 3.0034104274861066, time: 0.13056206703186035
Test Loss Energy: 7.092264184402176, Test Loss Force: 6.611195895430769, time: 17.598567485809326


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2996423864560787, Training Loss Force: 3.472665498602391, time: 1.6942269802093506
Validation Loss Energy: 1.810230739286672, Validation Loss Force: 3.041972047508735, time: 0.12638068199157715
Test Loss Energy: 6.714345973650132, Test Loss Force: 6.602729065535659, time: 17.59667992591858


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1896859815321323, Training Loss Force: 3.4742187864503293, time: 1.9010746479034424
Validation Loss Energy: 1.6385277774974307, Validation Loss Force: 2.930061540798899, time: 0.12889337539672852
Test Loss Energy: 6.905492634342873, Test Loss Force: 6.613796780641069, time: 18.206544876098633


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.093122609332829, Training Loss Force: 3.4581927479267853, time: 1.724947214126587
Validation Loss Energy: 1.951163330136585, Validation Loss Force: 2.979768196913505, time: 0.1286611557006836
Test Loss Energy: 7.224358344069377, Test Loss Force: 6.593548288410281, time: 18.134157419204712


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9388894443834779, Training Loss Force: 3.4563111604802073, time: 1.7196674346923828
Validation Loss Energy: 1.8678591842713783, Validation Loss Force: 2.8839170343462723, time: 0.13370680809020996
Test Loss Energy: 7.422756578738793, Test Loss Force: 6.616461412180683, time: 18.124778509140015

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–â–†â–‚â–‚â–…â–‚â–„â–â–‚â–…â–†
wandb:   test_error_force â–‡â–ˆâ–ˆâ–†â–„â–‡â–‡â–‡â–…â–ƒâ–†â–„â–‚â–„â–‚â–‚â–‚â–‚â–â–ƒ
wandb:          test_loss â–ˆâ–†â–â–‚â–‚â–ƒâ–â–†â–…â–‚â–ƒâ–…â–‚â–…â–‚â–â–â–„â–‚â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–‚â–â–â–
wandb: valid_error_energy â–ˆâ–†â–…â–†â–„â–ƒâ–„â–â–„â–†â–†â–„â–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–…â–„
wandb:  valid_error_force â–ˆâ–‡â–…â–…â–„â–‡â–…â–…â–ˆâ–â–„â–„â–ƒâ–ƒâ–‡â–„â–…â–‚â–ƒâ–
wandb:         valid_loss â–ˆâ–…â–„â–„â–ƒâ–…â–ƒâ–„â–†â–â–„â–‚â–â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1502
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.42276
wandb:   test_error_force 6.61646
wandb:          test_loss 3.52743
wandb: train_error_energy 1.93889
wandb:  train_error_force 3.45631
wandb:         train_loss 1.5624
wandb: valid_error_energy 1.86786
wandb:  valid_error_force 2.88392
wandb:         valid_loss 1.42474
wandb: 
wandb: ğŸš€ View run al_55_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4mayk4wz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_013732-4mayk4wz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7468673586845398, Uncertainty Bias: 0.026643171906471252
0.00038146973 0.0037193298
0.42326146 5.283343
Found uncertainty sample 2 after 2816 steps.
Found uncertainty sample 6 after 1580 steps.
Found uncertainty sample 9 after 749 steps.
Found uncertainty sample 13 after 3583 steps.
Found uncertainty sample 14 after 1069 steps.
Found uncertainty sample 18 after 3872 steps.
Found uncertainty sample 23 after 2842 steps.
Found uncertainty sample 24 after 1668 steps.
Found uncertainty sample 33 after 3576 steps.
Found uncertainty sample 35 after 633 steps.
Found uncertainty sample 37 after 1224 steps.
Found uncertainty sample 44 after 2850 steps.
Found uncertainty sample 53 after 1764 steps.
Found uncertainty sample 54 after 1147 steps.
Found uncertainty sample 55 after 1134 steps.
Found uncertainty sample 65 after 2603 steps.
Found uncertainty sample 69 after 553 steps.
Found uncertainty sample 75 after 2083 steps.
Found uncertainty sample 81 after 3862 steps.
Found uncertainty sample 82 after 3307 steps.
Found uncertainty sample 91 after 3852 steps.
Found uncertainty sample 93 after 1513 steps.
Found uncertainty sample 96 after 986 steps.
Found uncertainty sample 99 after 716 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_042749-3p012mn2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3p012mn2
Training model 22. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.575549988270616, Training Loss Force: 3.8346959868374952, time: 1.7647175788879395
Validation Loss Energy: 1.5893745098777419, Validation Loss Force: 2.988369683351549, time: 0.13116955757141113
Test Loss Energy: 6.8777796801106055, Test Loss Force: 6.671829951280446, time: 17.601895093917847


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0645007007335265, Training Loss Force: 3.529946776923774, time: 1.7366724014282227
Validation Loss Energy: 1.8217848742670055, Validation Loss Force: 3.2386418986197025, time: 0.13189029693603516
Test Loss Energy: 6.744911713684516, Test Loss Force: 6.565113991067842, time: 17.731607913970947


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.262206782146063, Training Loss Force: 3.5133791208714817, time: 1.7702505588531494
Validation Loss Energy: 1.881310070704011, Validation Loss Force: 3.079122724488192, time: 0.12510156631469727
Test Loss Energy: 6.684318351495612, Test Loss Force: 6.591680873035054, time: 17.780762195587158


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.3930287139488224, Training Loss Force: 3.5040797197459916, time: 1.7343263626098633
Validation Loss Energy: 1.6669623490959768, Validation Loss Force: 2.958931263575874, time: 0.13726568222045898
Test Loss Energy: 6.899509957398472, Test Loss Force: 6.588828555887371, time: 17.58800220489502


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.4994906295897295, Training Loss Force: 3.51151008708891, time: 1.7656118869781494
Validation Loss Energy: 2.112199660493874, Validation Loss Force: 3.0480472411516555, time: 0.12854528427124023
Test Loss Energy: 6.636353549839879, Test Loss Force: 6.573782034595992, time: 17.820929527282715


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.185719385444355, Training Loss Force: 3.5060000091825914, time: 1.737320899963379
Validation Loss Energy: 1.529423848370155, Validation Loss Force: 2.9313075973395106, time: 0.12362074851989746
Test Loss Energy: 6.966181653331575, Test Loss Force: 6.554942828213658, time: 17.669639348983765


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0113456672931584, Training Loss Force: 3.491229000884683, time: 1.9696903228759766
Validation Loss Energy: 1.7229772777820038, Validation Loss Force: 3.0088942118774433, time: 0.1345503330230713
Test Loss Energy: 7.114229789168881, Test Loss Force: 6.57570201154773, time: 17.624647855758667


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2480428812745266, Training Loss Force: 3.487718821273574, time: 1.7668631076812744
Validation Loss Energy: 2.314690417083113, Validation Loss Force: 2.9585506106709105, time: 0.12790775299072266
Test Loss Energy: 7.516936091164604, Test Loss Force: 6.533060291862263, time: 18.10724711418152


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.158714210594449, Training Loss Force: 3.4921169497713564, time: 1.7775623798370361
Validation Loss Energy: 1.5735542010632915, Validation Loss Force: 2.972222273561731, time: 0.13386154174804688
Test Loss Energy: 6.823723830419018, Test Loss Force: 6.597045483383942, time: 17.682272911071777


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0436076107011867, Training Loss Force: 3.491326970669951, time: 1.8027501106262207
Validation Loss Energy: 1.5679663745135202, Validation Loss Force: 2.9655780489163917, time: 0.12762689590454102
Test Loss Energy: 6.802823045829439, Test Loss Force: 6.557150090332698, time: 17.762048959732056


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.521662884281316, Training Loss Force: 3.4869979206357526, time: 1.7479310035705566
Validation Loss Energy: 1.5561016160746173, Validation Loss Force: 2.9983214354904995, time: 0.13805365562438965
Test Loss Energy: 6.956105340538715, Test Loss Force: 6.548725283118393, time: 17.82758378982544


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.129597568609872, Training Loss Force: 3.4824912548461526, time: 1.8262462615966797
Validation Loss Energy: 1.5751690533768463, Validation Loss Force: 3.037120977495552, time: 0.12462639808654785
Test Loss Energy: 6.571223754970024, Test Loss Force: 6.531088982094644, time: 17.870853424072266


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.062201495675195, Training Loss Force: 3.467453173463465, time: 1.7479653358459473
Validation Loss Energy: 1.6980217445867198, Validation Loss Force: 3.0660571670125867, time: 0.13567376136779785
Test Loss Energy: 6.7811897636878635, Test Loss Force: 6.566708495676655, time: 18.311903715133667


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.437536147562706, Training Loss Force: 3.48098119156046, time: 1.7773442268371582
Validation Loss Energy: 2.251748974941997, Validation Loss Force: 3.109000247819637, time: 0.13408517837524414
Test Loss Energy: 7.510418670185932, Test Loss Force: 6.489418643151504, time: 18.219279766082764


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.213653758640217, Training Loss Force: 3.4848572304951486, time: 1.7757031917572021
Validation Loss Energy: 1.6976307375664708, Validation Loss Force: 2.9210494524557635, time: 0.12628793716430664
Test Loss Energy: 6.898249426197568, Test Loss Force: 6.52224808202406, time: 18.19990301132202


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.369036637675384, Training Loss Force: 3.4751511334525023, time: 1.7265925407409668
Validation Loss Energy: 1.763836398052315, Validation Loss Force: 3.045601331918212, time: 0.12600421905517578
Test Loss Energy: 6.515509078431627, Test Loss Force: 6.535547464253222, time: 18.3570773601532


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.085277685042556, Training Loss Force: 3.4809754392741894, time: 1.7656610012054443
Validation Loss Energy: 2.9140133301135913, Validation Loss Force: 3.016048126197811, time: 0.136796236038208
Test Loss Energy: 6.561464674595881, Test Loss Force: 6.503366314358065, time: 18.59176015853882


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.294001011332541, Training Loss Force: 3.4900252282870947, time: 1.7579426765441895
Validation Loss Energy: 1.5858139188997835, Validation Loss Force: 2.9790716878250425, time: 0.1368541717529297
Test Loss Energy: 6.595617787110604, Test Loss Force: 6.511145866024908, time: 18.19354510307312


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2206423457586744, Training Loss Force: 3.478805291861155, time: 1.744236946105957
Validation Loss Energy: 1.7756870170004513, Validation Loss Force: 3.0090222466363516, time: 0.13480567932128906
Test Loss Energy: 6.678509407780546, Test Loss Force: 6.506044191797344, time: 18.365267753601074


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.056910672654567, Training Loss Force: 3.4756676330922436, time: 1.7584805488586426
Validation Loss Energy: 2.848478349095281, Validation Loss Force: 3.2029789855387616, time: 0.13739776611328125
Test Loss Energy: 7.4540234794317515, Test Loss Force: 6.529619218839833, time: 18.27976417541504

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–‚â–„â–‚â–„â–…â–ˆâ–ƒâ–ƒâ–„â–â–ƒâ–ˆâ–„â–â–â–‚â–‚â–ˆ
wandb:   test_error_force â–ˆâ–„â–…â–…â–„â–„â–„â–ƒâ–…â–„â–ƒâ–ƒâ–„â–â–‚â–ƒâ–‚â–‚â–‚â–ƒ
wandb:          test_loss â–‡â–‡â–ƒâ–‡â–ƒâ–†â–…â–†â–ˆâ–†â–ƒâ–ˆâ–ƒâ–„â–‡â–â–â–â–ƒâ–ˆ
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–â–‚â–â–‚â–â–
wandb: valid_error_energy â–â–‚â–ƒâ–‚â–„â–â–‚â–…â–â–â–â–â–‚â–…â–‚â–‚â–ˆâ–â–‚â–ˆ
wandb:  valid_error_force â–‚â–ˆâ–„â–‚â–„â–â–ƒâ–‚â–‚â–‚â–ƒâ–„â–„â–…â–â–„â–ƒâ–‚â–ƒâ–‡
wandb:         valid_loss â–„â–‡â–…â–‚â–ƒâ–â–‚â–„â–ƒâ–‚â–‚â–†â–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1523
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.45402
wandb:   test_error_force 6.52962
wandb:          test_loss 3.53415
wandb: train_error_energy 2.05691
wandb:  train_error_force 3.47567
wandb:         train_loss 1.56573
wandb: valid_error_energy 2.84848
wandb:  valid_error_force 3.20298
wandb:         valid_loss 1.60106
wandb: 
wandb: ğŸš€ View run al_55_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3p012mn2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_042749-3p012mn2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.738845705986023, Uncertainty Bias: 0.027316942811012268
0.00016403198 0.029224396
0.49297068 6.3389826
Found uncertainty sample 0 after 1484 steps.
Found uncertainty sample 2 after 2852 steps.
Found uncertainty sample 9 after 265 steps.
Found uncertainty sample 10 after 2422 steps.
Found uncertainty sample 12 after 464 steps.
Found uncertainty sample 18 after 627 steps.
Found uncertainty sample 20 after 1017 steps.
Found uncertainty sample 21 after 2698 steps.
Found uncertainty sample 22 after 1032 steps.
Found uncertainty sample 28 after 1573 steps.
Found uncertainty sample 30 after 1394 steps.
Found uncertainty sample 31 after 1838 steps.
Found uncertainty sample 32 after 100 steps.
Found uncertainty sample 36 after 2036 steps.
Found uncertainty sample 39 after 2369 steps.
Found uncertainty sample 43 after 1857 steps.
Found uncertainty sample 50 after 2025 steps.
Found uncertainty sample 51 after 2149 steps.
Found uncertainty sample 52 after 2209 steps.
Found uncertainty sample 54 after 1365 steps.
Found uncertainty sample 55 after 1170 steps.
Found uncertainty sample 57 after 3068 steps.
Found uncertainty sample 59 after 2178 steps.
Found uncertainty sample 66 after 3761 steps.
Found uncertainty sample 67 after 1741 steps.
Found uncertainty sample 68 after 706 steps.
Found uncertainty sample 70 after 1282 steps.
Found uncertainty sample 71 after 1086 steps.
Found uncertainty sample 72 after 3761 steps.
Found uncertainty sample 73 after 440 steps.
Found uncertainty sample 75 after 2544 steps.
Found uncertainty sample 82 after 1025 steps.
Found uncertainty sample 90 after 2690 steps.
Found uncertainty sample 98 after 1399 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_070423-qp5kutln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qp5kutln
Training model 23. Added 34 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.753521552778586, Training Loss Force: 3.7709616797952696, time: 1.74458909034729
Validation Loss Energy: 2.0717769717495815, Validation Loss Force: 3.217644420827858, time: 0.12950754165649414
Test Loss Energy: 7.078860432131347, Test Loss Force: 6.587378056428199, time: 17.65701198577881


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.044031082873445, Training Loss Force: 3.519676708448083, time: 1.7799792289733887
Validation Loss Energy: 1.71135684306347, Validation Loss Force: 3.0618664223516534, time: 0.13194632530212402
Test Loss Energy: 6.681137542564754, Test Loss Force: 6.500610889765649, time: 17.789796590805054


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.023395933224708, Training Loss Force: 3.4944855981128096, time: 1.7216377258300781
Validation Loss Energy: 2.8194656727266203, Validation Loss Force: 3.0759603772777253, time: 0.13106298446655273
Test Loss Energy: 6.435256299317814, Test Loss Force: 6.479396167328066, time: 17.792301416397095


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1681651782147795, Training Loss Force: 3.5139935692792506, time: 1.80418062210083
Validation Loss Energy: 1.6666692608326494, Validation Loss Force: 3.1410674995321353, time: 0.12964081764221191
Test Loss Energy: 6.606356266647942, Test Loss Force: 6.495028026347928, time: 17.731712579727173


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.339878201014002, Training Loss Force: 3.509317862579157, time: 1.791264295578003
Validation Loss Energy: 1.7210858147219201, Validation Loss Force: 3.1418848066322633, time: 0.12792134284973145
Test Loss Energy: 6.59671716414021, Test Loss Force: 6.490821995042093, time: 17.817672967910767


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.3302672008323446, Training Loss Force: 3.5011047520300247, time: 1.7988860607147217
Validation Loss Energy: 1.6780061263938437, Validation Loss Force: 3.054296228062973, time: 0.13262152671813965
Test Loss Energy: 6.732440735289855, Test Loss Force: 6.467614957325521, time: 17.660998821258545


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0897353019884135, Training Loss Force: 3.5171312456572013, time: 2.042884588241577
Validation Loss Energy: 1.712182889927576, Validation Loss Force: 3.1903500822583215, time: 0.12785053253173828
Test Loss Energy: 6.880668769144159, Test Loss Force: 6.46780839502556, time: 18.088375091552734


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2239190057419314, Training Loss Force: 3.520111531303128, time: 1.789682388305664
Validation Loss Energy: 1.576828940525165, Validation Loss Force: 3.0344585225176934, time: 0.1281754970550537
Test Loss Energy: 6.823128490066074, Test Loss Force: 6.486781706524093, time: 17.82041621208191


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0659913547866715, Training Loss Force: 3.5155370754446755, time: 1.7849349975585938
Validation Loss Energy: 1.7634288578479806, Validation Loss Force: 3.1815131231984584, time: 0.12853574752807617
Test Loss Energy: 6.688082628200453, Test Loss Force: 6.487291772754799, time: 17.70622205734253


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2411278248191686, Training Loss Force: 3.4945658680677827, time: 1.7635407447814941
Validation Loss Energy: 2.5651739453707516, Validation Loss Force: 3.130331061322935, time: 0.12876534461975098
Test Loss Energy: 7.49113606075144, Test Loss Force: 6.486565910976514, time: 17.845120429992676


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.3340109076450855, Training Loss Force: 3.4953406203675628, time: 1.766855239868164
Validation Loss Energy: 1.8155732957722042, Validation Loss Force: 3.041386761658664, time: 0.12974858283996582
Test Loss Energy: 6.859956677419936, Test Loss Force: 6.45531204633795, time: 17.8486008644104


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.032292149542998, Training Loss Force: 3.5095125935636724, time: 1.7818431854248047
Validation Loss Energy: 1.7547438148129266, Validation Loss Force: 3.1411606865697057, time: 0.13449597358703613
Test Loss Energy: 6.499888721264087, Test Loss Force: 6.461568035086389, time: 17.95828628540039


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.278094833835247, Training Loss Force: 3.5056429900702524, time: 1.789736032485962
Validation Loss Energy: 2.046169574629594, Validation Loss Force: 3.0412490407919073, time: 0.1389772891998291
Test Loss Energy: 7.4898271065890425, Test Loss Force: 6.462601441426833, time: 18.22908306121826


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.311815338064369, Training Loss Force: 3.520088550938415, time: 1.7996554374694824
Validation Loss Energy: 2.8108026182697268, Validation Loss Force: 3.1586067028185747, time: 0.1344470977783203
Test Loss Energy: 7.64364550699522, Test Loss Force: 6.4962325125408675, time: 18.2621910572052


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.8948942051678306, Training Loss Force: 3.5404589924153274, time: 1.7689597606658936
Validation Loss Energy: 1.8432354281035268, Validation Loss Force: 3.092146308829789, time: 0.12723112106323242
Test Loss Energy: 6.477090625343374, Test Loss Force: 6.492942346245796, time: 18.37618637084961


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3172202066926815, Training Loss Force: 3.5120535620732203, time: 1.7886674404144287
Validation Loss Energy: 1.6240992621796022, Validation Loss Force: 2.9233839157816703, time: 0.13463759422302246
Test Loss Energy: 6.55410198055474, Test Loss Force: 6.441078635824235, time: 18.619882106781006


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.494916260829753, Training Loss Force: 3.4744286702490954, time: 1.7999804019927979
Validation Loss Energy: 2.046423751459671, Validation Loss Force: 3.0882946892781034, time: 0.13230538368225098
Test Loss Energy: 7.272420635173589, Test Loss Force: 6.43982828911369, time: 18.443068981170654


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2755777590883377, Training Loss Force: 3.492014215983499, time: 1.7542088031768799
Validation Loss Energy: 1.4763012805551572, Validation Loss Force: 2.9446936870506786, time: 0.13291096687316895
Test Loss Energy: 6.722939179360723, Test Loss Force: 6.380585178636008, time: 18.359241008758545


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2397161501488028, Training Loss Force: 3.464800619972836, time: 1.7218902111053467
Validation Loss Energy: 1.633161562415144, Validation Loss Force: 3.040410802792062, time: 0.1396331787109375
Test Loss Energy: 6.573261828175594, Test Loss Force: 6.471062444618323, time: 18.3408260345459


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.3747284807747446, Training Loss Force: 3.476008903190795, time: 1.7635412216186523
Validation Loss Energy: 1.7325641308580653, Validation Loss Force: 2.8994061228061554, time: 0.14374399185180664
Test Loss Energy: 6.865135751908947, Test Loss Force: 6.426177740154294, time: 18.496861219406128

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–â–‚â–‚â–ƒâ–„â–ƒâ–‚â–‡â–ƒâ–â–‡â–ˆâ–â–‚â–†â–ƒâ–‚â–ƒ
wandb:   test_error_force â–ˆâ–…â–„â–…â–…â–„â–„â–…â–…â–…â–„â–„â–„â–…â–…â–ƒâ–ƒâ–â–„â–ƒ
wandb:          test_loss â–†â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–†â–‚â–„â–…â–‚â–‚â–‡â–ˆâ–‡â–â–ƒâ–‚â–‚â–„
wandb: train_error_energy â–ˆâ–â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–ƒâ–‚â–‚â–â–â–
wandb: valid_error_energy â–„â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‡â–ƒâ–‚â–„â–ˆâ–ƒâ–‚â–„â–â–‚â–‚
wandb:  valid_error_force â–ˆâ–…â–…â–†â–†â–„â–‡â–„â–‡â–†â–„â–†â–„â–‡â–…â–‚â–…â–‚â–„â–
wandb:         valid_loss â–†â–ƒâ–…â–„â–…â–„â–‡â–ƒâ–†â–‡â–ƒâ–…â–„â–ˆâ–†â–‚â–…â–â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1553
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.86514
wandb:   test_error_force 6.42618
wandb:          test_loss 3.44355
wandb: train_error_energy 2.37473
wandb:  train_error_force 3.47601
wandb:         train_loss 1.58779
wandb: valid_error_energy 1.73256
wandb:  valid_error_force 2.89941
wandb:         valid_loss 1.47897
wandb: 
wandb: ğŸš€ View run al_55_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qp5kutln
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_070423-qp5kutln/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7386441230773926, Uncertainty Bias: 0.025814294815063477
2.2888184e-05 0.0026474
0.6105012 6.851897
Found uncertainty sample 9 after 2956 steps.
Found uncertainty sample 19 after 512 steps.
Found uncertainty sample 27 after 3625 steps.
Found uncertainty sample 29 after 1922 steps.
Found uncertainty sample 35 after 2250 steps.
Found uncertainty sample 38 after 646 steps.
Found uncertainty sample 40 after 2242 steps.
Found uncertainty sample 41 after 2149 steps.
Found uncertainty sample 42 after 1443 steps.
Found uncertainty sample 43 after 2447 steps.
Found uncertainty sample 46 after 490 steps.
Found uncertainty sample 48 after 3393 steps.
Found uncertainty sample 53 after 1503 steps.
Found uncertainty sample 54 after 3008 steps.
Found uncertainty sample 57 after 1463 steps.
Found uncertainty sample 58 after 3488 steps.
Found uncertainty sample 59 after 1459 steps.
Found uncertainty sample 61 after 3951 steps.
Found uncertainty sample 64 after 1414 steps.
Found uncertainty sample 66 after 3544 steps.
Found uncertainty sample 68 after 2580 steps.
Found uncertainty sample 70 after 1798 steps.
Found uncertainty sample 73 after 940 steps.
Found uncertainty sample 74 after 1850 steps.
Found uncertainty sample 83 after 517 steps.
Found uncertainty sample 84 after 1179 steps.
Found uncertainty sample 92 after 1237 steps.
Found uncertainty sample 96 after 2845 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_095113-bwbstxo9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/bwbstxo9
Training model 24. Added 28 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2743406480729886, Training Loss Force: 3.66206665627047, time: 1.7688627243041992
Validation Loss Energy: 1.9689296559518712, Validation Loss Force: 3.1196937108836726, time: 0.13354849815368652
Test Loss Energy: 6.42542002153265, Test Loss Force: 6.46774587046203, time: 17.646159172058105


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.256930699730117, Training Loss Force: 3.5467659984537345, time: 1.7557713985443115
Validation Loss Energy: 2.534919888513543, Validation Loss Force: 3.1370820558237464, time: 0.1286754608154297
Test Loss Energy: 6.468043957997426, Test Loss Force: 6.437821205391034, time: 17.80830454826355


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.364166942408711, Training Loss Force: 3.5405343262952043, time: 1.8226699829101562
Validation Loss Energy: 1.8637944703470393, Validation Loss Force: 3.1479508708402006, time: 0.12694287300109863
Test Loss Energy: 6.912436640441247, Test Loss Force: 6.406588269320574, time: 17.838979959487915


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.238228021209215, Training Loss Force: 3.5345622819074434, time: 1.8075335025787354
Validation Loss Energy: 2.474620749792579, Validation Loss Force: 3.0331567986906, time: 0.13829374313354492
Test Loss Energy: 6.40885507620033, Test Loss Force: 6.4177982525231245, time: 17.737902641296387


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1146222829880372, Training Loss Force: 3.533909055247566, time: 1.816948413848877
Validation Loss Energy: 1.752101567060061, Validation Loss Force: 3.0952618955196107, time: 0.13386011123657227
Test Loss Energy: 6.456657131192339, Test Loss Force: 6.4591427926973655, time: 17.89620876312256


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1076948142823118, Training Loss Force: 3.547213216073181, time: 1.842440128326416
Validation Loss Energy: 1.7084342548558815, Validation Loss Force: 3.19457066458481, time: 0.1318988800048828
Test Loss Energy: 6.583474346868954, Test Loss Force: 6.367439598998909, time: 18.05504870414734


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.4713745387016823, Training Loss Force: 3.549881130898498, time: 1.974501371383667
Validation Loss Energy: 1.732010297024856, Validation Loss Force: 3.0736142238216573, time: 0.13134241104125977
Test Loss Energy: 7.043566859546691, Test Loss Force: 6.387225074639784, time: 17.725177764892578


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.225796903797645, Training Loss Force: 3.511191444943281, time: 1.8278489112854004
Validation Loss Energy: 1.5225372483594735, Validation Loss Force: 3.109374999992233, time: 0.1402912139892578
Test Loss Energy: 6.838351554181767, Test Loss Force: 6.4141817581827585, time: 17.919373750686646


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.105192789084057, Training Loss Force: 3.5371423493013077, time: 1.8142461776733398
Validation Loss Energy: 2.47521728043452, Validation Loss Force: 3.054165187270595, time: 0.12888622283935547
Test Loss Energy: 7.494767983382263, Test Loss Force: 6.397196122051165, time: 17.79640507698059


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.68466232400142, Training Loss Force: 3.543196117719008, time: 1.9472148418426514
Validation Loss Energy: 3.4310095591621987, Validation Loss Force: 3.0380944870015485, time: 0.17023229598999023
Test Loss Energy: 8.21785908365545, Test Loss Force: 6.425966080890115, time: 17.868284940719604


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2060222670612584, Training Loss Force: 3.53679127576569, time: 1.8465805053710938
Validation Loss Energy: 2.052338790319383, Validation Loss Force: 3.1082478487755463, time: 0.13295197486877441
Test Loss Energy: 6.25506463651036, Test Loss Force: 6.404298971691272, time: 17.89783525466919


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.370376312025585, Training Loss Force: 3.5465513765707404, time: 1.8180079460144043
Validation Loss Energy: 2.6371105529999124, Validation Loss Force: 3.1034060195319197, time: 0.12663626670837402
Test Loss Energy: 7.590013726611728, Test Loss Force: 6.426973086364177, time: 17.889594793319702


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1144315134239546, Training Loss Force: 3.5035295376867763, time: 1.85117506980896
Validation Loss Energy: 1.4622464040641954, Validation Loss Force: 3.0048359553583364, time: 0.13198447227478027
Test Loss Energy: 6.777461093061845, Test Loss Force: 6.3441452679822925, time: 18.295286893844604


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.008433569492928, Training Loss Force: 3.5058836537915026, time: 1.8280549049377441
Validation Loss Energy: 2.425075640143344, Validation Loss Force: 3.095692648982408, time: 0.1321423053741455
Test Loss Energy: 6.317933171410388, Test Loss Force: 6.378627007513807, time: 18.24519920349121


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2529686964027205, Training Loss Force: 3.5223055389307403, time: 1.8197417259216309
Validation Loss Energy: 1.7895933731710794, Validation Loss Force: 3.1255528041204705, time: 0.13193726539611816
Test Loss Energy: 6.7110521373944785, Test Loss Force: 6.405170204945056, time: 18.49265766143799


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1560866959311813, Training Loss Force: 3.5225374176725435, time: 1.8067655563354492
Validation Loss Energy: 1.8357052585938272, Validation Loss Force: 3.0376564967915085, time: 0.1304471492767334
Test Loss Energy: 6.474515865868992, Test Loss Force: 6.391413224797135, time: 18.272875785827637


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.072872503947546, Training Loss Force: 3.506220338446911, time: 1.8064260482788086
Validation Loss Energy: 1.6522778199276176, Validation Loss Force: 2.9445659862954887, time: 0.13468360900878906
Test Loss Energy: 6.387250519544385, Test Loss Force: 6.365388256577531, time: 18.49568772315979


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.156287213950472, Training Loss Force: 3.4992373627764892, time: 1.8102288246154785
Validation Loss Energy: 1.7153749634690234, Validation Loss Force: 3.054611193569888, time: 0.12998032569885254
Test Loss Energy: 6.666330879078402, Test Loss Force: 6.315710014678074, time: 18.17017436027527


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1933499856044993, Training Loss Force: 3.491947370887662, time: 1.8574044704437256
Validation Loss Energy: 1.6243516019892248, Validation Loss Force: 3.0329048485519827, time: 0.13325715065002441
Test Loss Energy: 6.630979783242446, Test Loss Force: 6.3685804414535525, time: 18.465555429458618


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2167462803321154, Training Loss Force: 3.5245807232766184, time: 1.8671088218688965
Validation Loss Energy: 1.6617074685866542, Validation Loss Force: 3.047175380110775, time: 0.13263344764709473
Test Loss Energy: 6.752363253880689, Test Loss Force: 6.335444043253977, time: 18.40433692932129

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ƒâ–‚â–‚â–‚â–„â–ƒâ–…â–ˆâ–â–†â–ƒâ–â–ƒâ–‚â–â–‚â–‚â–ƒ
wandb:   test_error_force â–ˆâ–‡â–…â–†â–ˆâ–ƒâ–„â–†â–…â–†â–…â–†â–‚â–„â–…â–„â–ƒâ–â–ƒâ–‚
wandb:          test_loss â–„â–…â–„â–„â–ƒâ–‚â–…â–„â–„â–ˆâ–„â–†â–‚â–â–„â–â–„â–â–‡â–
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–„â–‚â–‚â–…â–‚â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–‚â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–â–â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–ƒ
wandb: valid_error_energy â–ƒâ–…â–‚â–…â–‚â–‚â–‚â–â–…â–ˆâ–ƒâ–…â–â–„â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  valid_error_force â–†â–†â–‡â–ƒâ–…â–ˆâ–…â–†â–„â–„â–†â–…â–ƒâ–…â–†â–„â–â–„â–ƒâ–„
wandb:         valid_loss â–…â–‡â–„â–„â–ƒâ–ˆâ–ƒâ–ƒâ–…â–†â–„â–…â–â–…â–„â–…â–‚â–„â–‡â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1578
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.75236
wandb:   test_error_force 6.33544
wandb:          test_loss 3.34864
wandb: train_error_energy 2.21675
wandb:  train_error_force 3.52458
wandb:         train_loss 1.63381
wandb: valid_error_energy 1.66171
wandb:  valid_error_force 3.04718
wandb:         valid_loss 1.50615
wandb: 
wandb: ğŸš€ View run al_55_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/bwbstxo9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_095113-bwbstxo9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7293946146965027, Uncertainty Bias: 0.03295743465423584
9.381771e-05 0.018522263
0.78240037 5.9708214
Found uncertainty sample 1 after 1039 steps.
Found uncertainty sample 2 after 1735 steps.
Found uncertainty sample 6 after 3452 steps.
Found uncertainty sample 7 after 962 steps.
Found uncertainty sample 12 after 2078 steps.
Found uncertainty sample 16 after 3624 steps.
Found uncertainty sample 22 after 3355 steps.
Found uncertainty sample 23 after 1823 steps.
Found uncertainty sample 33 after 1050 steps.
Found uncertainty sample 38 after 3822 steps.
Found uncertainty sample 47 after 3868 steps.
Found uncertainty sample 49 after 2421 steps.
Found uncertainty sample 50 after 3127 steps.
Found uncertainty sample 51 after 402 steps.
Found uncertainty sample 52 after 3197 steps.
Found uncertainty sample 53 after 1443 steps.
Found uncertainty sample 56 after 3755 steps.
Found uncertainty sample 58 after 2398 steps.
Found uncertainty sample 61 after 3018 steps.
Found uncertainty sample 68 after 498 steps.
Found uncertainty sample 71 after 2975 steps.
Found uncertainty sample 73 after 3601 steps.
Found uncertainty sample 74 after 3967 steps.
Found uncertainty sample 75 after 2474 steps.
Found uncertainty sample 78 after 3827 steps.
Found uncertainty sample 86 after 2524 steps.
Found uncertainty sample 90 after 1304 steps.
Found uncertainty sample 91 after 1957 steps.
Found uncertainty sample 92 after 2123 steps.
Found uncertainty sample 93 after 531 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_124144-jdlvzbba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jdlvzbba
Training model 25. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8977596986259435, Training Loss Force: 3.7810831880657623, time: 1.8242332935333252
Validation Loss Energy: 1.6839006796921308, Validation Loss Force: 3.1274551779687045, time: 0.13124585151672363
Test Loss Energy: 6.572483281245255, Test Loss Force: 6.3540931088386, time: 17.815959692001343


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1625888368353046, Training Loss Force: 3.5550071387143545, time: 1.8330330848693848
Validation Loss Energy: 1.5431807378765792, Validation Loss Force: 3.097863116482339, time: 0.126969575881958
Test Loss Energy: 6.308829463457256, Test Loss Force: 6.34355609241701, time: 17.810606241226196


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2226294632269386, Training Loss Force: 3.5542847738085936, time: 1.8762125968933105
Validation Loss Energy: 2.951632725645226, Validation Loss Force: 3.1406867352925985, time: 0.12833881378173828
Test Loss Energy: 7.609754829304789, Test Loss Force: 6.3733268406468495, time: 17.857823610305786


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.418941236154884, Training Loss Force: 3.583006600612056, time: 1.8235771656036377
Validation Loss Energy: 2.3292172408288687, Validation Loss Force: 3.045841925930387, time: 0.13094782829284668
Test Loss Energy: 6.207319701400414, Test Loss Force: 6.349249462684692, time: 18.142478227615356


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9966294859512965, Training Loss Force: 3.58342057748283, time: 1.8790256977081299
Validation Loss Energy: 2.7654635061179214, Validation Loss Force: 3.139174255118884, time: 0.1314091682434082
Test Loss Energy: 7.640754699562081, Test Loss Force: 6.346473163151298, time: 17.840229988098145


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.40306370136993, Training Loss Force: 3.5461223210693316, time: 1.8655385971069336
Validation Loss Energy: 1.8249953180129923, Validation Loss Force: 3.1757886334603738, time: 0.13417696952819824
Test Loss Energy: 6.447611930431655, Test Loss Force: 6.305025085321621, time: 17.88050103187561


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.599928145667161, Training Loss Force: 3.5379298385578015, time: 1.8262789249420166
Validation Loss Energy: 1.9702046594814537, Validation Loss Force: 3.0879000082169465, time: 0.12668752670288086
Test Loss Energy: 6.2212002407739915, Test Loss Force: 6.308952775531817, time: 17.718100547790527


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0782304824544644, Training Loss Force: 3.5193674006888367, time: 1.881131649017334
Validation Loss Energy: 1.5692306342568116, Validation Loss Force: 3.0652671368828353, time: 0.12667441368103027
Test Loss Energy: 6.462879111017611, Test Loss Force: 6.30171371299637, time: 17.84295654296875


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.3126242744441106, Training Loss Force: 3.547602953006086, time: 1.8745231628417969
Validation Loss Energy: 2.1025328135271386, Validation Loss Force: 3.149709066416446, time: 0.1395115852355957
Test Loss Energy: 6.323595873957897, Test Loss Force: 6.327670152746154, time: 17.717479705810547


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1582945270081746, Training Loss Force: 3.5735605999604947, time: 2.0728161334991455
Validation Loss Energy: 1.8524533740720723, Validation Loss Force: 3.110755771366131, time: 0.13610005378723145
Test Loss Energy: 6.331597891920243, Test Loss Force: 6.283741540630839, time: 17.81078839302063


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1424875303158015, Training Loss Force: 3.5374526498459553, time: 1.879244327545166
Validation Loss Energy: 2.951353053197941, Validation Loss Force: 3.084881616609322, time: 0.12779569625854492
Test Loss Energy: 6.162838002442757, Test Loss Force: 6.285745877712093, time: 17.91284155845642


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.128529135055951, Training Loss Force: 3.5266880723691956, time: 1.8831555843353271
Validation Loss Energy: 1.6406510948057118, Validation Loss Force: 2.9984328813980365, time: 0.12983441352844238
Test Loss Energy: 6.373659093323557, Test Loss Force: 6.271496919995604, time: 18.07904624938965


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.151169926425959, Training Loss Force: 3.5203976558985515, time: 1.890488624572754
Validation Loss Energy: 3.129371802642278, Validation Loss Force: 3.1426849682081546, time: 0.13875651359558105
Test Loss Energy: 6.223091373327778, Test Loss Force: 6.293859262889999, time: 17.8429958820343


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3305630400486717, Training Loss Force: 3.5422218954971014, time: 1.833343505859375
Validation Loss Energy: 3.4021686720396214, Validation Loss Force: 3.097342070680868, time: 0.1336052417755127
Test Loss Energy: 6.3617466554166056, Test Loss Force: 6.284542886083787, time: 18.140157222747803


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2993723778218578, Training Loss Force: 3.5391443328384935, time: 1.8239619731903076
Validation Loss Energy: 2.4341696707321807, Validation Loss Force: 3.080772702859517, time: 0.13807249069213867
Test Loss Energy: 6.210434693528641, Test Loss Force: 6.3086995016193, time: 18.133662939071655


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.464137082541593, Training Loss Force: 3.553876905058117, time: 1.848315715789795
Validation Loss Energy: 3.1238911356189845, Validation Loss Force: 3.102844893284182, time: 0.13182973861694336
Test Loss Energy: 6.218779948401688, Test Loss Force: 6.320719408283048, time: 18.30409860610962


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.486607793978667, Training Loss Force: 3.536401599084436, time: 1.874035120010376
Validation Loss Energy: 2.5397902194078488, Validation Loss Force: 3.1784694586427715, time: 0.1302013397216797
Test Loss Energy: 7.237541721502546, Test Loss Force: 6.27060850274595, time: 18.334778785705566


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.243749138353219, Training Loss Force: 3.527046735604483, time: 1.8871262073516846
Validation Loss Energy: 1.807442197904932, Validation Loss Force: 3.2558128071387777, time: 0.13361120223999023
Test Loss Energy: 6.453800628797357, Test Loss Force: 6.279988061630868, time: 18.197718858718872


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.4532347907471705, Training Loss Force: 3.532136886789468, time: 1.8804287910461426
Validation Loss Energy: 1.8271247030555, Validation Loss Force: 3.1989014681385326, time: 0.13061261177062988
Test Loss Energy: 6.2405395970322886, Test Loss Force: 6.330456811640964, time: 18.37682318687439


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.297861622242509, Training Loss Force: 3.513069177699899, time: 1.8384301662445068
Validation Loss Energy: 2.217729694161723, Validation Loss Force: 3.067459648628213, time: 0.144575834274292
Test Loss Energy: 6.139496006239229, Test Loss Force: 6.29899684630622, time: 18.39454412460327

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–ˆâ–â–ˆâ–‚â–â–ƒâ–‚â–‚â–â–‚â–â–‚â–â–â–†â–‚â–â–
wandb:   test_error_force â–‡â–†â–ˆâ–†â–†â–ƒâ–„â–ƒâ–…â–‚â–‚â–â–ƒâ–‚â–„â–„â–â–‚â–…â–ƒ
wandb:          test_loss â–ƒâ–‚â–‡â–ƒâ–ˆâ–‡â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–â–‚â–
wandb: valid_error_energy â–‚â–â–†â–„â–†â–‚â–ƒâ–â–ƒâ–‚â–†â–â–‡â–ˆâ–„â–‡â–…â–‚â–‚â–„
wandb:  valid_error_force â–…â–„â–…â–‚â–…â–†â–ƒâ–ƒâ–…â–„â–ƒâ–â–…â–„â–ƒâ–„â–†â–ˆâ–†â–ƒ
wandb:         valid_loss â–‚â–‚â–†â–ƒâ–‡â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–…â–â–†â–…â–„â–‡â–…â–…â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1605
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.1395
wandb:   test_error_force 6.299
wandb:          test_loss 3.34523
wandb: train_error_energy 2.29786
wandb:  train_error_force 3.51307
wandb:         train_loss 1.59591
wandb: valid_error_energy 2.21773
wandb:  valid_error_force 3.06746
wandb:         valid_loss 1.52187
wandb: 
wandb: ğŸš€ View run al_55_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jdlvzbba
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_124144-jdlvzbba/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7419105768203735, Uncertainty Bias: 0.030758947134017944
9.1552734e-05 0.02577591
0.6190288 6.141699
Found uncertainty sample 0 after 3774 steps.
Found uncertainty sample 2 after 2914 steps.
Found uncertainty sample 5 after 3274 steps.
Found uncertainty sample 8 after 183 steps.
Found uncertainty sample 9 after 3044 steps.
Found uncertainty sample 13 after 3688 steps.
Found uncertainty sample 18 after 3107 steps.
Found uncertainty sample 23 after 2071 steps.
Found uncertainty sample 30 after 3132 steps.
Found uncertainty sample 36 after 2785 steps.
Found uncertainty sample 37 after 1971 steps.
Found uncertainty sample 38 after 1502 steps.
Found uncertainty sample 42 after 2379 steps.
Found uncertainty sample 44 after 3722 steps.
Found uncertainty sample 47 after 2531 steps.
Found uncertainty sample 52 after 1940 steps.
Found uncertainty sample 53 after 778 steps.
Found uncertainty sample 54 after 1826 steps.
Found uncertainty sample 56 after 1071 steps.
Found uncertainty sample 57 after 3185 steps.
Found uncertainty sample 59 after 1250 steps.
Found uncertainty sample 66 after 563 steps.
Found uncertainty sample 67 after 1646 steps.
Found uncertainty sample 78 after 2831 steps.
Found uncertainty sample 79 after 1620 steps.
Found uncertainty sample 81 after 2543 steps.
Found uncertainty sample 82 after 2685 steps.
Found uncertainty sample 84 after 3031 steps.
Found uncertainty sample 89 after 3701 steps.
Found uncertainty sample 93 after 3910 steps.
Found uncertainty sample 99 after 2140 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_153409-1m8px957
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/1m8px957
Training model 26. Added 31 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.21896836812583, Training Loss Force: 3.829147956121345, time: 1.765058994293213
Validation Loss Energy: 1.825585836587993, Validation Loss Force: 3.275195488284354, time: 0.12598872184753418
Test Loss Energy: 6.630909802177044, Test Loss Force: 6.2699459023212505, time: 17.084487438201904


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0686309121322304, Training Loss Force: 3.5557352973839698, time: 1.8227057456970215
Validation Loss Energy: 1.6448695061080272, Validation Loss Force: 3.1381127913002462, time: 0.1259779930114746
Test Loss Energy: 6.429305835953727, Test Loss Force: 6.256566893139179, time: 17.4959819316864


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2332384298991874, Training Loss Force: 3.55294093931655, time: 1.8183653354644775
Validation Loss Energy: 1.9966623187351664, Validation Loss Force: 3.2809097352417256, time: 0.12836265563964844
Test Loss Energy: 6.184526163785252, Test Loss Force: 6.250594850686657, time: 16.95669913291931


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.367899388167339, Training Loss Force: 3.5572759277403962, time: 2.09342622756958
Validation Loss Energy: 1.9762446713993178, Validation Loss Force: 3.1832116434435953, time: 0.12775754928588867
Test Loss Energy: 6.271705734690588, Test Loss Force: 6.237814031089956, time: 17.378266096115112


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.443347106197383, Training Loss Force: 3.533403778176439, time: 1.8319895267486572
Validation Loss Energy: 1.5731686494371175, Validation Loss Force: 3.0724660303706806, time: 0.12857890129089355
Test Loss Energy: 6.347747427559213, Test Loss Force: 6.251239821777199, time: 17.70418643951416


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.057452235534971, Training Loss Force: 3.536885550825832, time: 1.87835693359375
Validation Loss Energy: 2.8660670962666903, Validation Loss Force: 3.0893457989814554, time: 0.13603854179382324
Test Loss Energy: 6.137537100658588, Test Loss Force: 6.268151286932862, time: 18.2730393409729


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1576909255293355, Training Loss Force: 3.532244427254828, time: 1.9100513458251953
Validation Loss Energy: 1.7241290339393152, Validation Loss Force: 3.0105368421669523, time: 0.13911223411560059
Test Loss Energy: 6.470180110549839, Test Loss Force: 6.2506621900332915, time: 18.429495096206665


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.3456331263007817, Training Loss Force: 3.55736795558859, time: 1.9153401851654053
Validation Loss Energy: 1.388756289471183, Validation Loss Force: 2.9062811440212486, time: 0.1328258514404297
Test Loss Energy: 6.343107058516815, Test Loss Force: 6.3051680505713765, time: 18.39295530319214


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.240396836897029, Training Loss Force: 3.5500198999693438, time: 1.8846731185913086
Validation Loss Energy: 1.6487524663420023, Validation Loss Force: 3.154743170467582, time: 0.12832164764404297
Test Loss Energy: 6.374394908762407, Test Loss Force: 6.234356256715776, time: 18.36255693435669


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.165157314518427, Training Loss Force: 3.538672453257657, time: 1.8958661556243896
Validation Loss Energy: 1.8542254308026522, Validation Loss Force: 3.17009008467779, time: 0.13451147079467773
Test Loss Energy: 6.645718396239866, Test Loss Force: 6.214407714980043, time: 18.40770387649536


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0534038332170867, Training Loss Force: 3.5326874384358047, time: 1.8965213298797607
Validation Loss Energy: 1.8617572146636596, Validation Loss Force: 3.0898580493516623, time: 0.1384425163269043
Test Loss Energy: 6.187931255338992, Test Loss Force: 6.236520792006549, time: 18.271884202957153


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.030328094782034, Training Loss Force: 3.5213804389195658, time: 1.8773245811462402
Validation Loss Energy: 1.5810516382085396, Validation Loss Force: 3.038396983036291, time: 0.1337909698486328
Test Loss Energy: 6.333543031651278, Test Loss Force: 6.2234526965690025, time: 18.34615206718445


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.410262153885545, Training Loss Force: 3.5373936206919763, time: 1.874072790145874
Validation Loss Energy: 1.6665751274512086, Validation Loss Force: 3.122065693960668, time: 0.13115525245666504
Test Loss Energy: 6.600508895601002, Test Loss Force: 6.203456368402426, time: 18.445964336395264


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0196266287269298, Training Loss Force: 3.5235982105148214, time: 1.936323881149292
Validation Loss Energy: 1.5104102970012407, Validation Loss Force: 3.161215605866838, time: 0.13383173942565918
Test Loss Energy: 6.359244507068322, Test Loss Force: 6.2276971971757655, time: 18.180336713790894


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.067636720592033, Training Loss Force: 3.538719091528573, time: 1.915794849395752
Validation Loss Energy: 1.758303014108723, Validation Loss Force: 3.0465522405058967, time: 0.13991022109985352
Test Loss Energy: 6.665365527890118, Test Loss Force: 6.180945671898102, time: 18.812209367752075


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1198375047253304, Training Loss Force: 3.5400416633002125, time: 1.8833928108215332
Validation Loss Energy: 1.6825440679205657, Validation Loss Force: 3.1850557893101694, time: 0.13620996475219727
Test Loss Energy: 6.492802248881374, Test Loss Force: 6.211534483253941, time: 18.795791149139404


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0933671249508987, Training Loss Force: 3.5303657240100175, time: 1.9459185600280762
Validation Loss Energy: 1.9808423439244347, Validation Loss Force: 3.023449314604732, time: 0.13408446311950684
Test Loss Energy: 6.1797037026769965, Test Loss Force: 6.193990183059092, time: 18.397372722625732


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1679432133413328, Training Loss Force: 3.5054241862254645, time: 2.1172244548797607
Validation Loss Energy: 1.8778480108231257, Validation Loss Force: 3.0565223628493863, time: 0.15798115730285645
Test Loss Energy: 6.166092583643534, Test Loss Force: 6.224571670815063, time: 18.62417721748352


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.3161365614986185, Training Loss Force: 3.522699321369081, time: 1.940532922744751
Validation Loss Energy: 2.142539333637692, Validation Loss Force: 3.1017185214095058, time: 0.13412952423095703
Test Loss Energy: 6.062444421358293, Test Loss Force: 6.240431508066145, time: 18.815056324005127


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1805056629798987, Training Loss Force: 3.4995364909185693, time: 1.9898731708526611
Validation Loss Energy: 1.9724812288294193, Validation Loss Force: 3.1065566766122252, time: 0.14284777641296387
Test Loss Energy: 6.083388655576506, Test Loss Force: 6.220874318429549, time: 17.35792565345764

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–…â–‚â–ƒâ–„â–‚â–†â–„â–…â–ˆâ–‚â–„â–‡â–„â–ˆâ–†â–‚â–‚â–â–
wandb:   test_error_force â–†â–…â–…â–„â–…â–†â–…â–ˆâ–„â–ƒâ–„â–ƒâ–‚â–„â–â–ƒâ–‚â–ƒâ–„â–ƒ
wandb:          test_loss â–‡â–…â–„â–…â–ˆâ–‚â–…â–…â–…â–„â–…â–…â–†â–ƒâ–ƒâ–„â–„â–„â–ƒâ–
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–‚â–â–â–‚â–â–â–â–
wandb: valid_error_energy â–ƒâ–‚â–„â–„â–‚â–ˆâ–ƒâ–â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–ƒâ–…â–„
wandb:  valid_error_force â–ˆâ–…â–ˆâ–†â–„â–„â–ƒâ–â–†â–†â–„â–ƒâ–…â–†â–„â–†â–ƒâ–„â–…â–…
wandb:         valid_loss â–‡â–…â–ˆâ–‡â–‡â–†â–‚â–â–…â–†â–†â–ƒâ–…â–„â–‚â–†â–„â–„â–…â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1632
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.08339
wandb:   test_error_force 6.22087
wandb:          test_loss 3.25779
wandb: train_error_energy 2.18051
wandb:  train_error_force 3.49954
wandb:         train_loss 1.57882
wandb: valid_error_energy 1.97248
wandb:  valid_error_force 3.10656
wandb:         valid_loss 1.59122
wandb: 
wandb: ğŸš€ View run al_55_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/1m8px957
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_153409-1m8px957/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7682812809944153, Uncertainty Bias: 0.019921332597732544
0.0002822876 0.018967628
0.466108 5.744565
Found uncertainty sample 0 after 2738 steps.
Found uncertainty sample 3 after 668 steps.
Found uncertainty sample 4 after 1109 steps.
Found uncertainty sample 13 after 3594 steps.
Found uncertainty sample 15 after 3421 steps.
Found uncertainty sample 17 after 3457 steps.
Found uncertainty sample 18 after 615 steps.
Found uncertainty sample 19 after 1777 steps.
Found uncertainty sample 24 after 332 steps.
Found uncertainty sample 36 after 3294 steps.
Found uncertainty sample 39 after 1642 steps.
Found uncertainty sample 40 after 1964 steps.
Found uncertainty sample 43 after 3657 steps.
Found uncertainty sample 48 after 1239 steps.
Found uncertainty sample 50 after 988 steps.
Found uncertainty sample 55 after 2326 steps.
Found uncertainty sample 59 after 3051 steps.
Found uncertainty sample 62 after 1319 steps.
Found uncertainty sample 71 after 2633 steps.
Found uncertainty sample 77 after 3010 steps.
Found uncertainty sample 81 after 2920 steps.
Found uncertainty sample 83 after 2736 steps.
Found uncertainty sample 85 after 3212 steps.
Found uncertainty sample 87 after 2342 steps.
Found uncertainty sample 93 after 2983 steps.
Found uncertainty sample 95 after 1086 steps.
Found uncertainty sample 96 after 1600 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_182831-zlxqdy3j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/zlxqdy3j
Training model 27. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.6839388125530257, Training Loss Force: 3.742139919760069, time: 1.9227566719055176
Validation Loss Energy: 1.5142201104207786, Validation Loss Force: 3.082544592588237, time: 0.13246703147888184
Test Loss Energy: 6.339197501269425, Test Loss Force: 6.190361345153714, time: 17.057300329208374


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.341668693928401, Training Loss Force: 3.550962601368613, time: 1.8814992904663086
Validation Loss Energy: 1.7448714442244992, Validation Loss Force: 3.2306975088312906, time: 0.13169384002685547
Test Loss Energy: 6.276380779497783, Test Loss Force: 6.188280162735169, time: 17.13971495628357


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.117520718701577, Training Loss Force: 3.541321023067842, time: 1.8736920356750488
Validation Loss Energy: 1.6660544713207428, Validation Loss Force: 3.097569081875142, time: 0.12491869926452637
Test Loss Energy: 6.233266415987813, Test Loss Force: 6.1831286409299, time: 16.96953511238098


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1961564945878345, Training Loss Force: 3.5467895032374943, time: 2.1099274158477783
Validation Loss Energy: 2.2131676486999545, Validation Loss Force: 3.085804914222912, time: 0.12813997268676758
Test Loss Energy: 6.139960836824906, Test Loss Force: 6.214466723469521, time: 17.085038661956787


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2466852858691455, Training Loss Force: 3.540090626163126, time: 1.9091033935546875
Validation Loss Energy: 1.5149710064481337, Validation Loss Force: 3.1645910474499575, time: 0.12837648391723633
Test Loss Energy: 6.27301706709936, Test Loss Force: 6.202299822526864, time: 17.082814931869507


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.301817791717207, Training Loss Force: 3.538658311164045, time: 1.8791978359222412
Validation Loss Energy: 1.6235234954355193, Validation Loss Force: 3.060574607301553, time: 0.12533855438232422
Test Loss Energy: 6.133768379897285, Test Loss Force: 6.176080176188523, time: 17.401598691940308


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0174626015877974, Training Loss Force: 3.5411588471339233, time: 1.8755748271942139
Validation Loss Energy: 1.5898266952458346, Validation Loss Force: 3.10577855928178, time: 0.12450170516967773
Test Loss Energy: 6.2851665462215145, Test Loss Force: 6.183535673133813, time: 17.184235095977783


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.013796285586513, Training Loss Force: 3.545172963776949, time: 1.890949010848999
Validation Loss Energy: 1.5025728997374475, Validation Loss Force: 3.0314063965344613, time: 0.13082575798034668
Test Loss Energy: 6.355170279575581, Test Loss Force: 6.157316486123451, time: 17.175126314163208


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.4640641361881612, Training Loss Force: 3.5372427605823926, time: 1.8709299564361572
Validation Loss Energy: 2.095220136105724, Validation Loss Force: 3.1456976817525573, time: 0.12950801849365234
Test Loss Energy: 6.063214457897193, Test Loss Force: 6.165859007206878, time: 17.036869287490845


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.395066857632474, Training Loss Force: 3.525577094052542, time: 1.862091302871704
Validation Loss Energy: 2.2972835906039273, Validation Loss Force: 3.0027329566096213, time: 0.12825298309326172
Test Loss Energy: 6.018921060093726, Test Loss Force: 6.145376164443555, time: 17.666401624679565


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.3490887449812408, Training Loss Force: 3.5279090009653697, time: 1.8476696014404297
Validation Loss Energy: 1.4390368753094176, Validation Loss Force: 3.029331899436425, time: 0.1262352466583252
Test Loss Energy: 6.127684953907904, Test Loss Force: 6.158852590794063, time: 17.734578132629395


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.266126867285919, Training Loss Force: 3.535165856944741, time: 2.0016417503356934
Validation Loss Energy: 1.8219326709126151, Validation Loss Force: 3.08988989103953, time: 0.1415724754333496
Test Loss Energy: 6.119291868303341, Test Loss Force: 6.151429633855063, time: 18.80098843574524


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.202152047613245, Training Loss Force: 3.5270982326303555, time: 1.9855923652648926
Validation Loss Energy: 1.9069618346513244, Validation Loss Force: 3.076072157188981, time: 0.13988280296325684
Test Loss Energy: 6.078483776573272, Test Loss Force: 6.139662215349882, time: 18.748777627944946


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0990386935713383, Training Loss Force: 3.51684880610009, time: 2.1298091411590576
Validation Loss Energy: 1.6204640213704715, Validation Loss Force: 3.088508562992767, time: 0.1402270793914795
Test Loss Energy: 6.261467997259195, Test Loss Force: 6.171373267543127, time: 18.60459327697754


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9729409763842762, Training Loss Force: 3.528268337581711, time: 2.069157600402832
Validation Loss Energy: 1.6438862548268967, Validation Loss Force: 3.127986689220034, time: 0.1403648853302002
Test Loss Energy: 6.302908168585478, Test Loss Force: 6.187491662144263, time: 19.16793727874756


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9539220017370285, Training Loss Force: 3.5166007612357246, time: 2.076542377471924
Validation Loss Energy: 1.5543067914238664, Validation Loss Force: 3.171184614864598, time: 0.13385605812072754
Test Loss Energy: 6.328186113297285, Test Loss Force: 6.141485887313102, time: 18.70175313949585


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2976810871451505, Training Loss Force: 3.528174889336104, time: 2.058009386062622
Validation Loss Energy: 2.2173834436398048, Validation Loss Force: 3.1386794842766323, time: 0.13170933723449707
Test Loss Energy: 7.071789052286659, Test Loss Force: 6.1338996287862235, time: 18.73644256591797


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.6590130245733414, Training Loss Force: 3.537723597474628, time: 2.0359184741973877
Validation Loss Energy: 1.6440932814653229, Validation Loss Force: 3.075940114385446, time: 0.13374638557434082
Test Loss Energy: 6.48057897883639, Test Loss Force: 6.144822033038096, time: 19.012657642364502


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.4034115316085316, Training Loss Force: 3.5292342121052624, time: 2.052600383758545
Validation Loss Energy: 2.227837648706542, Validation Loss Force: 3.1706590043456355, time: 0.13700556755065918
Test Loss Energy: 6.776262449893823, Test Loss Force: 6.12163500756529, time: 19.210033416748047


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.344585261504852, Training Loss Force: 3.513213389724903, time: 2.008136510848999
Validation Loss Energy: 1.6078006600396988, Validation Loss Force: 3.0550131113782877, time: 0.13781213760375977
Test Loss Energy: 6.35484852382552, Test Loss Force: 6.13514735243091, time: 19.02182412147522

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–â–â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–ˆâ–„â–†â–ƒ
wandb:   test_error_force â–†â–†â–†â–ˆâ–‡â–…â–†â–„â–„â–ƒâ–„â–ƒâ–‚â–…â–†â–‚â–‚â–ƒâ–â–‚
wandb:          test_loss â–†â–…â–„â–†â–†â–‡â–†â–ƒâ–ˆâ–ˆâ–„â–‚â–â–„â–ƒâ–…â–…â–‚â–†â–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–„â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–ƒâ–‚â–‚
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–‡â–‚â–ƒâ–‚â–‚â–†â–ˆâ–â–„â–…â–‚â–ƒâ–‚â–‡â–ƒâ–‡â–‚
wandb:  valid_error_force â–ƒâ–ˆâ–„â–„â–†â–ƒâ–„â–‚â–…â–â–‚â–„â–ƒâ–„â–…â–†â–…â–ƒâ–†â–ƒ
wandb:         valid_loss â–‚â–ˆâ–‚â–„â–„â–„â–ƒâ–‚â–…â–…â–â–†â–„â–ƒâ–„â–…â–‡â–ƒâ–†â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1656
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.35485
wandb:   test_error_force 6.13515
wandb:          test_loss 3.24782
wandb: train_error_energy 2.34459
wandb:  train_error_force 3.51321
wandb:         train_loss 1.59942
wandb: valid_error_energy 1.6078
wandb:  valid_error_force 3.05501
wandb:         valid_loss 1.46209
wandb: 
wandb: ğŸš€ View run al_55_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/zlxqdy3j
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_182831-zlxqdy3j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7768140435218811, Uncertainty Bias: 0.0220186710357666
5.340576e-05 0.008831769
0.36360818 5.6032767
Found uncertainty sample 8 after 2968 steps.
Found uncertainty sample 12 after 1971 steps.
Found uncertainty sample 24 after 1279 steps.
Found uncertainty sample 26 after 3354 steps.
Found uncertainty sample 27 after 3955 steps.
Found uncertainty sample 37 after 3487 steps.
Found uncertainty sample 43 after 709 steps.
Found uncertainty sample 44 after 3151 steps.
Found uncertainty sample 47 after 1744 steps.
Found uncertainty sample 54 after 3889 steps.
Found uncertainty sample 60 after 1734 steps.
Found uncertainty sample 62 after 413 steps.
Found uncertainty sample 65 after 3518 steps.
Found uncertainty sample 66 after 1599 steps.
Found uncertainty sample 69 after 1937 steps.
Found uncertainty sample 72 after 3626 steps.
Found uncertainty sample 80 after 1869 steps.
Found uncertainty sample 93 after 3476 steps.
Found uncertainty sample 95 after 761 steps.
Found uncertainty sample 97 after 3343 steps.
Found uncertainty sample 98 after 3275 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_213102-3i2mht4b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3i2mht4b
Training model 28. Added 21 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.85500105520521, Training Loss Force: 3.8133120811848777, time: 1.9074232578277588
Validation Loss Energy: 1.447740789554589, Validation Loss Force: 3.0660554969939926, time: 0.13289308547973633
Test Loss Energy: 6.348339422045934, Test Loss Force: 6.134063576231204, time: 17.041306972503662


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0938644801309643, Training Loss Force: 3.5438051400160093, time: 1.90875244140625
Validation Loss Energy: 1.4538775512163589, Validation Loss Force: 3.045537091869612, time: 0.1322484016418457
Test Loss Energy: 6.445589374117875, Test Loss Force: 6.12353519843983, time: 17.19223189353943


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2091398726460114, Training Loss Force: 3.5349091253174714, time: 1.8969066143035889
Validation Loss Energy: 3.338883762740912, Validation Loss Force: 3.0970167510586677, time: 0.12823772430419922
Test Loss Energy: 6.242513627793555, Test Loss Force: 6.156831673604992, time: 17.490297555923462


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2476059886115602, Training Loss Force: 3.5279363208375303, time: 1.9507555961608887
Validation Loss Energy: 1.61924897150843, Validation Loss Force: 3.0919850963681377, time: 0.13069748878479004
Test Loss Energy: 5.988056605319757, Test Loss Force: 6.104979066329745, time: 17.092193126678467


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.4238131501996323, Training Loss Force: 3.531888866229934, time: 2.0018672943115234
Validation Loss Energy: 2.7289499968995368, Validation Loss Force: 3.2326169168691883, time: 0.12853002548217773
Test Loss Energy: 7.276013890316286, Test Loss Force: 6.157596436032813, time: 17.158989906311035


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.44566724459847, Training Loss Force: 3.5451418859185826, time: 1.9481983184814453
Validation Loss Energy: 2.715133933067582, Validation Loss Force: 3.156145429414062, time: 0.13027334213256836
Test Loss Energy: 7.396292537274401, Test Loss Force: 6.0731151488533035, time: 17.05461573600769


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.586915123405429, Training Loss Force: 3.5498386630188565, time: 1.8856685161590576
Validation Loss Energy: 1.8223277416447776, Validation Loss Force: 3.3061223399659836, time: 0.13106131553649902
Test Loss Energy: 6.003506306988566, Test Loss Force: 6.172037203982703, time: 17.184743642807007


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.3314222409522896, Training Loss Force: 3.557900857389378, time: 1.9377374649047852
Validation Loss Energy: 1.6994270095666701, Validation Loss Force: 3.231779012873062, time: 0.1244356632232666
Test Loss Energy: 6.530088980789317, Test Loss Force: 6.057675333228252, time: 17.14453411102295


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.090760823045669, Training Loss Force: 3.5300874644367695, time: 1.948946475982666
Validation Loss Energy: 1.6022226865996347, Validation Loss Force: 3.1211642179233796, time: 0.13126015663146973
Test Loss Energy: 6.182957125065569, Test Loss Force: 6.112771705346497, time: 17.111331701278687


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.209570834073389, Training Loss Force: 3.5424218604632407, time: 1.887575626373291
Validation Loss Energy: 2.9378774504901104, Validation Loss Force: 3.1757399802519886, time: 0.1366138458251953
Test Loss Energy: 5.979990502944051, Test Loss Force: 6.133558515975959, time: 17.239375114440918


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.4921490548947824, Training Loss Force: 3.5446277932762915, time: 1.9265506267547607
Validation Loss Energy: 1.5784946170712777, Validation Loss Force: 3.0383724894302393, time: 0.12888360023498535
Test Loss Energy: 6.080237873171944, Test Loss Force: 6.117652023126867, time: 17.224717617034912


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.153066975408886, Training Loss Force: 3.505841096760177, time: 1.8780508041381836
Validation Loss Energy: 2.247728238173979, Validation Loss Force: 3.133321507952745, time: 0.13771367073059082
Test Loss Energy: 6.008456493916864, Test Loss Force: 6.0752385568030824, time: 17.332192420959473


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1920870312905856, Training Loss Force: 3.525448875405762, time: 1.9386699199676514
Validation Loss Energy: 1.7321975061092951, Validation Loss Force: 3.1486103055158656, time: 0.1291522979736328
Test Loss Energy: 6.402057096761018, Test Loss Force: 6.099921289400719, time: 17.205111980438232


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.5918289966210253, Training Loss Force: 3.5048511265425994, time: 1.8772022724151611
Validation Loss Energy: 1.4946471028227206, Validation Loss Force: 3.1186852423217655, time: 0.12637925148010254
Test Loss Energy: 6.225086521517888, Test Loss Force: 6.096454708520104, time: 17.05692768096924


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.240004837009639, Training Loss Force: 3.5196616664913574, time: 1.9376022815704346
Validation Loss Energy: 2.6656305738832082, Validation Loss Force: 3.0969355881549774, time: 0.13178610801696777
Test Loss Energy: 7.3447108892045705, Test Loss Force: 6.057266312157516, time: 17.1990749835968


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.031854234056162, Training Loss Force: 3.5256463619316776, time: 1.8524036407470703
Validation Loss Energy: 1.6897060539974738, Validation Loss Force: 3.0866749939106244, time: 0.13051843643188477
Test Loss Energy: 6.02950462952231, Test Loss Force: 6.052642693430765, time: 17.198850393295288


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1270054487670835, Training Loss Force: 3.515779501354285, time: 1.9026424884796143
Validation Loss Energy: 2.3740883024359345, Validation Loss Force: 3.264772345563474, time: 0.13243341445922852
Test Loss Energy: 5.919503061320187, Test Loss Force: 6.125137777428248, time: 17.074311017990112


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1474670774605578, Training Loss Force: 3.513648326556, time: 1.9078409671783447
Validation Loss Energy: 1.642156839237762, Validation Loss Force: 3.1606431234926573, time: 0.12824797630310059
Test Loss Energy: 6.292238294461226, Test Loss Force: 6.081560271421204, time: 17.173893690109253


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.079371651241704, Training Loss Force: 3.4953599466261296, time: 1.9373791217803955
Validation Loss Energy: 1.9762823024849798, Validation Loss Force: 3.126012615906811, time: 0.1314692497253418
Test Loss Energy: 6.650878489058543, Test Loss Force: 6.024156002388033, time: 17.232592582702637


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.022664804442861, Training Loss Force: 3.5103585243666666, time: 1.9235620498657227
Validation Loss Energy: 1.7614065766646645, Validation Loss Force: 3.174481231570059, time: 0.13185429573059082
Test Loss Energy: 6.1999667231952005, Test Loss Force: 6.040687241907017, time: 17.39793562889099

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ƒâ–â–‡â–ˆâ–â–„â–‚â–â–‚â–â–ƒâ–‚â–ˆâ–‚â–â–ƒâ–„â–‚
wandb:   test_error_force â–†â–†â–‡â–…â–‡â–ƒâ–ˆâ–ƒâ–…â–†â–…â–ƒâ–…â–„â–ƒâ–‚â–†â–„â–â–‚
wandb:          test_loss â–…â–„â–ƒâ–‚â–‡â–ˆâ–†â–ƒâ–ƒâ–„â–‚â–‚â–„â–ƒâ–‡â–â–‚â–ƒâ–„â–„
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–„â–…â–†â–„â–‚â–ƒâ–…â–‚â–‚â–†â–ƒâ–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–â–â–ˆâ–‚â–†â–†â–‚â–‚â–‚â–‡â–â–„â–‚â–â–†â–‚â–„â–‚â–ƒâ–‚
wandb:  valid_error_force â–‚â–â–ƒâ–‚â–†â–„â–ˆâ–†â–ƒâ–…â–â–ƒâ–„â–ƒâ–ƒâ–‚â–‡â–„â–ƒâ–…
wandb:         valid_loss â–‚â–â–…â–‚â–‡â–†â–‡â–„â–ƒâ–‡â–„â–…â–ƒâ–ƒâ–†â–ƒâ–ˆâ–ƒâ–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1674
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.19997
wandb:   test_error_force 6.04069
wandb:          test_loss 3.25397
wandb: train_error_energy 2.02266
wandb:  train_error_force 3.51036
wandb:         train_loss 1.58282
wandb: valid_error_energy 1.76141
wandb:  valid_error_force 3.17448
wandb:         valid_loss 1.59537
wandb: 
wandb: ğŸš€ View run al_55_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3i2mht4b
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_213102-3i2mht4b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7882540822029114, Uncertainty Bias: 0.011996835470199585
7.6293945e-05 0.006252289
0.464474 6.5613422
Found uncertainty sample 0 after 2487 steps.
Found uncertainty sample 3 after 2326 steps.
Found uncertainty sample 12 after 2466 steps.
Found uncertainty sample 27 after 1454 steps.
Found uncertainty sample 28 after 3165 steps.
Found uncertainty sample 31 after 1866 steps.
Found uncertainty sample 36 after 3149 steps.
Found uncertainty sample 50 after 2607 steps.
Found uncertainty sample 52 after 1035 steps.
Found uncertainty sample 54 after 2306 steps.
Found uncertainty sample 55 after 2178 steps.
Found uncertainty sample 63 after 762 steps.
Found uncertainty sample 66 after 213 steps.
Found uncertainty sample 84 after 2715 steps.
Found uncertainty sample 87 after 2768 steps.
Found uncertainty sample 90 after 2498 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241127_003343-a78n3td1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/a78n3td1
Training model 29. Added 16 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.156539583211487, Training Loss Force: 3.784343110988389, time: 1.8876726627349854
Validation Loss Energy: 1.8599304926577545, Validation Loss Force: 3.2053979518055487, time: 0.1262497901916504
Test Loss Energy: 6.503890629082494, Test Loss Force: 6.123631522081259, time: 16.944891452789307


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9987681428612518, Training Loss Force: 3.5229652951742625, time: 1.9028613567352295
Validation Loss Energy: 1.5674221711208727, Validation Loss Force: 3.178387182393351, time: 0.12790942192077637
Test Loss Energy: 6.068069967303608, Test Loss Force: 6.071698418161049, time: 17.003968715667725


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.979285829876787, Training Loss Force: 3.5219020121907154, time: 1.9360454082489014
Validation Loss Energy: 1.986391927048393, Validation Loss Force: 3.0622903844054994, time: 0.1278824806213379
Test Loss Energy: 5.9095807446433595, Test Loss Force: 6.030366820776641, time: 16.93174147605896


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.3653832118254634, Training Loss Force: 3.522586459333555, time: 2.074338674545288
Validation Loss Energy: 2.505226067227489, Validation Loss Force: 3.106406374938724, time: 0.12844562530517578
Test Loss Energy: 5.821783759994456, Test Loss Force: 6.095469573586238, time: 16.919983863830566


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9539592395563377, Training Loss Force: 3.531338663374261, time: 1.930119276046753
Validation Loss Energy: 1.6907013850797707, Validation Loss Force: 3.2058731277629584, time: 0.14109206199645996
Test Loss Energy: 6.0060904139038485, Test Loss Force: 6.039557339385702, time: 17.135123014450073


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.334055236382012, Training Loss Force: 3.5269888384137804, time: 1.9140050411224365
Validation Loss Energy: 1.529637777752105, Validation Loss Force: 3.0809664250164737, time: 0.13661932945251465
Test Loss Energy: 6.139326019913743, Test Loss Force: 6.0609882863878575, time: 16.9722101688385


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.41961386008506, Training Loss Force: 3.5104733502237866, time: 1.962846040725708
Validation Loss Energy: 2.602369601517686, Validation Loss Force: 3.1550582473090696, time: 0.12435722351074219
Test Loss Energy: 5.912827167526424, Test Loss Force: 6.0231725042472615, time: 17.07288932800293


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.267031842363618, Training Loss Force: 3.5083199127122153, time: 1.8925104141235352
Validation Loss Energy: 1.5450524390499618, Validation Loss Force: 3.0887806646890907, time: 0.12797236442565918
Test Loss Energy: 6.3074066099463915, Test Loss Force: 6.0306520797712935, time: 17.131107807159424


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9683393495427548, Training Loss Force: 3.5022577158051975, time: 1.8573148250579834
Validation Loss Energy: 1.4575358939493794, Validation Loss Force: 3.0755899671534745, time: 0.13341379165649414
Test Loss Energy: 6.107131325672316, Test Loss Force: 6.037922905885537, time: 17.28101396560669


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2646595756985595, Training Loss Force: 3.5116759568718097, time: 1.8815295696258545
Validation Loss Energy: 1.7511925202718108, Validation Loss Force: 3.0739627010350343, time: 0.12932586669921875
Test Loss Energy: 6.296026017877392, Test Loss Force: 6.003767251911452, time: 17.106343269348145


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.170540001845287, Training Loss Force: 3.505002373509646, time: 1.8905224800109863
Validation Loss Energy: 1.574159861140215, Validation Loss Force: 3.087789898324285, time: 0.12974262237548828
Test Loss Energy: 5.933743800096999, Test Loss Force: 6.008558963693044, time: 17.023569345474243


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3117194729094424, Training Loss Force: 3.4923608789191984, time: 2.1156585216522217
Validation Loss Energy: 2.562194186859946, Validation Loss Force: 2.964436758208939, time: 0.13477230072021484
Test Loss Energy: 5.818171026547622, Test Loss Force: 6.0239433008923555, time: 17.004277229309082


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.217373833155441, Training Loss Force: 3.4942006008119866, time: 1.9168767929077148
Validation Loss Energy: 1.630625639179459, Validation Loss Force: 3.132779085913265, time: 0.12592792510986328
Test Loss Energy: 6.305959111274558, Test Loss Force: 6.062089332853154, time: 17.18593668937683


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.934558553719726, Training Loss Force: 3.494056113744106, time: 1.8739466667175293
Validation Loss Energy: 1.7123064713035658, Validation Loss Force: 3.111897396077303, time: 0.1305253505706787
Test Loss Energy: 5.9214586396875175, Test Loss Force: 6.026850814340475, time: 17.01926302909851


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0570450319086846, Training Loss Force: 3.5100949555200662, time: 1.957939624786377
Validation Loss Energy: 1.9993322331294137, Validation Loss Force: 3.0596913901342306, time: 0.12396717071533203
Test Loss Energy: 5.922671944044959, Test Loss Force: 6.018392063488198, time: 17.160687923431396


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9718259828544804, Training Loss Force: 3.486921210327236, time: 1.8536975383758545
Validation Loss Energy: 1.7822054892456278, Validation Loss Force: 3.022340310923439, time: 0.12723398208618164
Test Loss Energy: 5.808709115052922, Test Loss Force: 6.038098977723807, time: 17.200018167495728


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2743462801316774, Training Loss Force: 3.50383130185425, time: 1.902907133102417
Validation Loss Energy: 1.9142558078644811, Validation Loss Force: 3.1715929900782296, time: 0.12514710426330566
Test Loss Energy: 6.4882232572483725, Test Loss Force: 6.022324796979676, time: 16.9698703289032


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2557624035405937, Training Loss Force: 3.4933030340886653, time: 1.948422908782959
Validation Loss Energy: 1.7577391044966608, Validation Loss Force: 3.05494219125531, time: 0.1292877197265625
Test Loss Energy: 6.376741694668799, Test Loss Force: 6.003120823562104, time: 17.164505004882812


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.040766530910832, Training Loss Force: 3.486506944884498, time: 1.9048855304718018
Validation Loss Energy: 2.483471291670344, Validation Loss Force: 3.006572774696573, time: 0.13070416450500488
Test Loss Energy: 7.050720715576707, Test Loss Force: 6.001868285134312, time: 17.157472610473633


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.320853575541937, Training Loss Force: 3.4918436899153873, time: 1.9492151737213135
Validation Loss Energy: 2.3647075853217157, Validation Loss Force: 3.0597064203015805, time: 0.13556146621704102
Test Loss Energy: 7.018401403556825, Test Loss Force: 5.989314019152618, time: 16.987353324890137

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–‚â–â–‚â–ƒâ–‚â–„â–ƒâ–„â–‚â–â–„â–‚â–‚â–â–…â–„â–ˆâ–ˆ
wandb:   test_error_force â–ˆâ–…â–ƒâ–‡â–„â–…â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–
wandb:          test_loss â–ˆâ–‡â–„â–ƒâ–…â–ƒâ–‚â–ˆâ–ƒâ–ˆâ–„â–â–„â–â–…â–‚â–„â–„â–†â–„
wandb: train_error_energy â–ˆâ–â–â–ƒâ–â–ƒâ–„â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–â–ƒâ–ƒâ–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–‚
wandb: valid_error_energy â–ƒâ–‚â–„â–‡â–‚â–â–ˆâ–‚â–â–ƒâ–‚â–ˆâ–‚â–ƒâ–„â–ƒâ–„â–ƒâ–‡â–‡
wandb:  valid_error_force â–ˆâ–‡â–„â–…â–ˆâ–„â–‡â–…â–„â–„â–…â–â–†â–…â–„â–ƒâ–‡â–„â–‚â–„
wandb:         valid_loss â–†â–†â–‚â–†â–‡â–â–ˆâ–…â–â–†â–ƒâ–…â–‚â–ƒâ–…â–â–‡â–‚â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1688
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.0184
wandb:   test_error_force 5.98931
wandb:          test_loss 3.19345
wandb: train_error_energy 2.32085
wandb:  train_error_force 3.49184
wandb:         train_loss 1.592
wandb: valid_error_energy 2.36471
wandb:  valid_error_force 3.05971
wandb:         valid_loss 1.52974
wandb: 
wandb: ğŸš€ View run al_55_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/a78n3td1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_003343-a78n3td1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7556558847427368, Uncertainty Bias: 0.02561125159263611
0.00031280518 0.0017795563
0.49716476 5.2651157
Found uncertainty sample 3 after 2553 steps.
Found uncertainty sample 4 after 2773 steps.
Found uncertainty sample 9 after 1875 steps.
Found uncertainty sample 18 after 2395 steps.
Found uncertainty sample 21 after 3870 steps.
Found uncertainty sample 25 after 1940 steps.
Found uncertainty sample 29 after 3407 steps.
Found uncertainty sample 31 after 2961 steps.
Found uncertainty sample 32 after 2702 steps.
Found uncertainty sample 34 after 1889 steps.
Found uncertainty sample 35 after 1135 steps.
Found uncertainty sample 36 after 1304 steps.
Found uncertainty sample 38 after 2803 steps.
Found uncertainty sample 41 after 2960 steps.
Found uncertainty sample 56 after 1913 steps.
Found uncertainty sample 58 after 1771 steps.
Found uncertainty sample 61 after 2864 steps.
Found uncertainty sample 66 after 3054 steps.
Found uncertainty sample 69 after 2751 steps.
Found uncertainty sample 70 after 330 steps.
Found uncertainty sample 76 after 3996 steps.
Found uncertainty sample 81 after 2058 steps.
Found uncertainty sample 82 after 3089 steps.
Found uncertainty sample 86 after 2128 steps.
Found uncertainty sample 90 after 3601 steps.
Found uncertainty sample 94 after 1082 steps.
Found uncertainty sample 95 after 2631 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241127_032939-8qoilliw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_30
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/8qoilliw
Training model 30. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.695456692972254, Training Loss Force: 3.837260125655859, time: 1.8992247581481934
Validation Loss Energy: 1.7305561005000882, Validation Loss Force: 3.1911341003211335, time: 0.1313610076904297
Test Loss Energy: 6.490641705313929, Test Loss Force: 5.963493873904672, time: 16.921390295028687


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1552439939097803, Training Loss Force: 3.5354713252319505, time: 1.9542725086212158
Validation Loss Energy: 2.3735819527980944, Validation Loss Force: 3.1080300783508292, time: 0.12773728370666504
Test Loss Energy: 5.901862994739678, Test Loss Force: 5.987925053320988, time: 17.10179352760315


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.338959605624096, Training Loss Force: 3.519583349738155, time: 1.9610631465911865
Validation Loss Energy: 1.6854782905910293, Validation Loss Force: 3.0768507198577177, time: 0.12746882438659668
Test Loss Energy: 6.474292173144478, Test Loss Force: 5.980326183093477, time: 17.01625919342041


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2646874130762935, Training Loss Force: 3.5207903690786826, time: 2.144660234451294
Validation Loss Energy: 1.76182580699916, Validation Loss Force: 3.131912012259022, time: 0.1247255802154541
Test Loss Energy: 5.9020666985365695, Test Loss Force: 5.966627092260268, time: 17.035767078399658


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2077224561704094, Training Loss Force: 3.524463651261994, time: 1.9278838634490967
Validation Loss Energy: 1.5003206013263877, Validation Loss Force: 3.1476249945451356, time: 0.12846636772155762
Test Loss Energy: 6.1782187489563665, Test Loss Force: 6.008142511768193, time: 17.12062406539917


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0288437543609965, Training Loss Force: 3.511384861466217, time: 1.9414794445037842
Validation Loss Energy: 1.6324440667596782, Validation Loss Force: 3.1085156084235246, time: 0.13146448135375977
Test Loss Energy: 6.137141945696865, Test Loss Force: 5.946792979149402, time: 17.037654399871826


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.5124223443528697, Training Loss Force: 3.5204346303770473, time: 1.9587204456329346
Validation Loss Energy: 2.3058714942240703, Validation Loss Force: 3.081921341648785, time: 0.1253650188446045
Test Loss Energy: 7.037228000570139, Test Loss Force: 5.963135779948964, time: 17.1796817779541


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.70681240359851, Training Loss Force: 3.516521785057237, time: 1.950028419494629
Validation Loss Energy: 2.034146888098942, Validation Loss Force: 3.061360629386678, time: 0.12733101844787598
Test Loss Energy: 5.808903483066983, Test Loss Force: 5.9804175613814134, time: 17.17307734489441


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9978761913371859, Training Loss Force: 3.5067359379260132, time: 1.9247164726257324
Validation Loss Energy: 2.6756548048291586, Validation Loss Force: 3.1710099309196176, time: 0.12640023231506348
Test Loss Energy: 6.960198631308287, Test Loss Force: 5.954991272386139, time: 17.051734924316406


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.4502730476983916, Training Loss Force: 3.5206947120629937, time: 1.9645161628723145
Validation Loss Energy: 2.459444177479006, Validation Loss Force: 3.0859492038294727, time: 0.1304011344909668
Test Loss Energy: 5.811154201809495, Test Loss Force: 5.978335175849996, time: 17.4812912940979


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.424811727723388, Training Loss Force: 3.519371261500161, time: 1.926945686340332
Validation Loss Energy: 2.4940025402615715, Validation Loss Force: 3.1660608864822266, time: 0.1264057159423828
Test Loss Energy: 7.196615960204022, Test Loss Force: 5.952496193491789, time: 17.167809009552002


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3033642746906966, Training Loss Force: 3.5073053276731665, time: 1.9205524921417236
Validation Loss Energy: 1.5398067436429081, Validation Loss Force: 3.0389213688749512, time: 0.14102673530578613
Test Loss Energy: 5.944011640997952, Test Loss Force: 5.969386566866364, time: 17.04776692390442


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.992387598941699, Training Loss Force: 3.5084112057394115, time: 1.974531650543213
Validation Loss Energy: 1.5875138308270829, Validation Loss Force: 3.1236722518485376, time: 0.13058900833129883
Test Loss Energy: 6.064519380698825, Test Loss Force: 6.021098589469844, time: 17.151860237121582


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2655590823742977, Training Loss Force: 3.5177459251809857, time: 1.943047285079956
Validation Loss Energy: 1.629093118782611, Validation Loss Force: 2.9900497220575746, time: 0.13608026504516602
Test Loss Energy: 6.304447598137789, Test Loss Force: 5.941298796342111, time: 17.104538202285767


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.097323982234244, Training Loss Force: 3.5022054166424046, time: 1.8947277069091797
Validation Loss Energy: 1.5476682448417485, Validation Loss Force: 3.1288857158967174, time: 0.13144350051879883
Test Loss Energy: 5.998110772441956, Test Loss Force: 5.925426153866431, time: 17.20348024368286


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.177417173039129, Training Loss Force: 3.5094387372543117, time: 1.9278538227081299
Validation Loss Energy: 2.2064424838200702, Validation Loss Force: 3.083750680017155, time: 0.14023923873901367
Test Loss Energy: 5.622178674875411, Test Loss Force: 5.943909756456909, time: 17.178526163101196


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.054082963924689, Training Loss Force: 3.504693183551779, time: 1.9327974319458008
Validation Loss Energy: 1.5535497719949984, Validation Loss Force: 3.0279511280625266, time: 0.12363648414611816
Test Loss Energy: 5.945881998870164, Test Loss Force: 5.992911790631815, time: 17.15069031715393


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9466469545289966, Training Loss Force: 3.4996889501542197, time: 1.9499995708465576
Validation Loss Energy: 1.6555340221830925, Validation Loss Force: 3.1518426821727266, time: 0.12720370292663574
Test Loss Energy: 6.255665185689192, Test Loss Force: 5.953652690403455, time: 17.525225162506104


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.34196258564037, Training Loss Force: 3.4941806267983018, time: 1.9889824390411377
Validation Loss Energy: 1.4849525335473168, Validation Loss Force: 3.0240113315290538, time: 0.14293670654296875
Test Loss Energy: 6.0308001792352846, Test Loss Force: 5.912037109417303, time: 17.620742082595825


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1054623560220347, Training Loss Force: 3.4921007897642657, time: 2.071784734725952
Validation Loss Energy: 1.6569996861688758, Validation Loss Force: 3.1996441810747744, time: 0.1315147876739502
Test Loss Energy: 6.053215988372458, Test Loss Force: 5.934657648261569, time: 17.46654748916626

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–…â–‚â–ƒâ–ƒâ–‡â–‚â–‡â–‚â–ˆâ–‚â–ƒâ–„â–ƒâ–â–‚â–„â–ƒâ–ƒ
wandb:   test_error_force â–„â–†â–…â–…â–‡â–ƒâ–„â–…â–„â–…â–„â–…â–ˆâ–ƒâ–‚â–ƒâ–†â–„â–â–‚
wandb:          test_loss â–…â–ƒâ–ƒâ–â–…â–„â–ˆâ–„â–†â–‚â–‡â–‚â–„â–ƒâ–‚â–â–‚â–ƒâ–â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–â–â–‚â–
wandb: valid_error_energy â–‚â–†â–‚â–ƒâ–â–‚â–†â–„â–ˆâ–‡â–‡â–â–‚â–‚â–â–…â–â–‚â–â–‚
wandb:  valid_error_force â–ˆâ–…â–„â–†â–†â–…â–„â–ƒâ–‡â–„â–‡â–ƒâ–…â–â–†â–„â–‚â–†â–‚â–ˆ
wandb:         valid_loss â–†â–…â–†â–„â–„â–…â–ˆâ–…â–ˆâ–ˆâ–‡â–ƒâ–ƒâ–„â–„â–†â–â–†â–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1712
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.05322
wandb:   test_error_force 5.93466
wandb:          test_loss 3.13237
wandb: train_error_energy 2.10546
wandb:  train_error_force 3.4921
wandb:         train_loss 1.56811
wandb: valid_error_energy 1.657
wandb:  valid_error_force 3.19964
wandb:         valid_loss 1.54058
wandb: 
wandb: ğŸš€ View run al_55_30 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/8qoilliw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_032939-8qoilliw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7521175146102905, Uncertainty Bias: 0.025270357728004456
6.1035156e-05 0.0042619705
0.40175715 5.1309543
Found uncertainty sample 17 after 2053 steps.
Found uncertainty sample 22 after 1796 steps.
Found uncertainty sample 28 after 1437 steps.
Found uncertainty sample 33 after 1883 steps.
Found uncertainty sample 40 after 2917 steps.
Found uncertainty sample 41 after 3480 steps.
Found uncertainty sample 53 after 1273 steps.
Found uncertainty sample 54 after 2108 steps.
Found uncertainty sample 64 after 2627 steps.
Found uncertainty sample 90 after 1385 steps.
Found uncertainty sample 94 after 2116 steps.
Found uncertainty sample 95 after 3413 steps.
Found uncertainty sample 97 after 3855 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241127_063616-54d67o3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_31
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/54d67o3y
Training model 31. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0174294831090935, Training Loss Force: 3.7413434076426646, time: 1.8919928073883057
Validation Loss Energy: 1.5417181355915526, Validation Loss Force: 3.1143714729577066, time: 0.13381624221801758
Test Loss Energy: 5.840566413076952, Test Loss Force: 5.921897953088557, time: 16.966583013534546


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.025955418028605, Training Loss Force: 3.493031270519563, time: 1.9169261455535889
Validation Loss Energy: 2.533084983416525, Validation Loss Force: 3.078953273268141, time: 0.12896227836608887
Test Loss Energy: 5.73594970062889, Test Loss Force: 5.960051581448069, time: 17.004630088806152


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.996731375034923, Training Loss Force: 3.5061979445284353, time: 1.965592384338379
Validation Loss Energy: 1.6323514363949725, Validation Loss Force: 3.2392612528491007, time: 0.14236974716186523
Test Loss Energy: 6.052563260001831, Test Loss Force: 5.935000299937134, time: 16.986202239990234


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1856285555040165, Training Loss Force: 3.4971714321728467, time: 2.1624088287353516
Validation Loss Energy: 2.3750848581985338, Validation Loss Force: 3.0568337656499662, time: 0.1254899501800537
Test Loss Energy: 5.759984496322859, Test Loss Force: 5.93334309356212, time: 16.95603632926941


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.20615589213525, Training Loss Force: 3.5038703138465057, time: 1.9879260063171387
Validation Loss Energy: 1.9556022395606554, Validation Loss Force: 3.0240701161835783, time: 0.1282193660736084
Test Loss Energy: 5.80307448747071, Test Loss Force: 5.8970768065518735, time: 17.338322162628174


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.171577264398654, Training Loss Force: 3.4972229347215995, time: 1.9799833297729492
Validation Loss Energy: 2.330072401683805, Validation Loss Force: 3.0898210862734383, time: 0.1267397403717041
Test Loss Energy: 7.175677743881788, Test Loss Force: 5.932806556516611, time: 16.9932918548584


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.3177415389934373, Training Loss Force: 3.5080524362632883, time: 1.9503920078277588
Validation Loss Energy: 1.5769394957561182, Validation Loss Force: 3.155645091843162, time: 0.13419365882873535
Test Loss Energy: 6.252430297301048, Test Loss Force: 5.923171054021037, time: 17.024306535720825


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.80389649347375, Training Loss Force: 3.5119983809392923, time: 1.9829504489898682
Validation Loss Energy: 1.6533870462780569, Validation Loss Force: 3.0829280288575247, time: 0.12668466567993164
Test Loss Energy: 6.355514076073663, Test Loss Force: 5.917514737764529, time: 17.083959817886353


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.07418010170424, Training Loss Force: 3.496491322254631, time: 1.9310626983642578
Validation Loss Energy: 2.3725337377936393, Validation Loss Force: 3.1113189016361824, time: 0.12911105155944824
Test Loss Energy: 5.81030952330862, Test Loss Force: 5.980330379998846, time: 17.006842851638794


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.142446150723624, Training Loss Force: 3.497693636678577, time: 1.9226086139678955
Validation Loss Energy: 1.7557398139026617, Validation Loss Force: 3.0838286142182296, time: 0.12403368949890137
Test Loss Energy: 6.371051940734574, Test Loss Force: 5.915709986849679, time: 17.13973832130432


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2709096157758077, Training Loss Force: 3.4854588825274457, time: 1.9400243759155273
Validation Loss Energy: 1.9378191022248514, Validation Loss Force: 3.136143282704515, time: 0.14217257499694824
Test Loss Energy: 5.759741684362779, Test Loss Force: 5.8947661560007045, time: 17.19609808921814


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3420253515367544, Training Loss Force: 3.509521759857721, time: 1.897582769393921
Validation Loss Energy: 1.5959776520656574, Validation Loss Force: 3.125086312259752, time: 0.13010144233703613
Test Loss Energy: 6.056981265339745, Test Loss Force: 5.89457821158347, time: 16.993901252746582


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.069698916068713, Training Loss Force: 3.4877034782354572, time: 1.8966796398162842
Validation Loss Energy: 1.7843531888253876, Validation Loss Force: 3.1118769105158774, time: 0.13042998313903809
Test Loss Energy: 5.854039582162572, Test Loss Force: 5.917171675724884, time: 17.42482328414917


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1497236299259708, Training Loss Force: 3.4895189904992656, time: 1.9408483505249023
Validation Loss Energy: 1.602611967934003, Validation Loss Force: 3.18062066526158, time: 0.13103127479553223
Test Loss Energy: 5.801021491934941, Test Loss Force: 5.898935331482563, time: 17.02886438369751


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9118151169237068, Training Loss Force: 3.4927242056438264, time: 1.9548051357269287
Validation Loss Energy: 1.4996642283514792, Validation Loss Force: 3.0666230806469628, time: 0.13045239448547363
Test Loss Energy: 6.006374066416392, Test Loss Force: 5.879350073875509, time: 17.037428855895996


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.121390426394357, Training Loss Force: 3.4795933236384107, time: 1.980902910232544
Validation Loss Energy: 1.6859224042025822, Validation Loss Force: 2.9872833919231407, time: 0.13277935981750488
Test Loss Energy: 6.386418977357313, Test Loss Force: 5.830665533260099, time: 17.104005336761475


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.527625061735327, Training Loss Force: 3.4939011605261516, time: 1.936899185180664
Validation Loss Energy: 2.1929518509448895, Validation Loss Force: 3.0430155864611255, time: 0.13281583786010742
Test Loss Energy: 6.725533680611635, Test Loss Force: 5.858894280167284, time: 17.027684450149536


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.411704168249256, Training Loss Force: 3.488060363270844, time: 1.9314582347869873
Validation Loss Energy: 1.958796038787984, Validation Loss Force: 3.1075901954530485, time: 0.1286923885345459
Test Loss Energy: 5.73710668951113, Test Loss Force: 5.848501068376523, time: 17.06931710243225


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.198191936326516, Training Loss Force: 3.496569487371858, time: 1.945033073425293
Validation Loss Energy: 1.611619157555928, Validation Loss Force: 3.086281426195197, time: 0.13905072212219238
Test Loss Energy: 6.2806837453279405, Test Loss Force: 5.888187427561059, time: 17.11739468574524


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.077472232038761, Training Loss Force: 3.4784293784071103, time: 1.9996886253356934
Validation Loss Energy: 1.4960201921110845, Validation Loss Force: 3.102724540610808, time: 0.12744569778442383
Test Loss Energy: 6.00063983461172, Test Loss Force: 5.885751909748724, time: 17.167329788208008

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ƒâ–â–â–ˆâ–„â–„â–â–„â–â–ƒâ–‚â–â–‚â–„â–†â–â–„â–‚
wandb:   test_error_force â–…â–‡â–†â–†â–„â–†â–…â–…â–ˆâ–…â–„â–„â–…â–„â–ƒâ–â–‚â–‚â–„â–„
wandb:          test_loss â–„â–…â–…â–‚â–ƒâ–ˆâ–†â–†â–ƒâ–†â–‚â–†â–‚â–‚â–„â–‚â–†â–â–ƒâ–…
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–‡â–‚â–‚â–ƒâ–„â–‚â–ƒâ–â–‚â–…â–„â–ƒâ–‚
wandb:  train_error_force â–ˆâ–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–‚â–‚â–
wandb: valid_error_energy â–â–ˆâ–‚â–‡â–„â–‡â–‚â–‚â–‡â–ƒâ–„â–‚â–ƒâ–‚â–â–‚â–†â–„â–‚â–
wandb:  valid_error_force â–…â–„â–ˆâ–ƒâ–‚â–„â–†â–„â–„â–„â–…â–…â–„â–†â–ƒâ–â–ƒâ–„â–„â–„
wandb:         valid_loss â–ƒâ–…â–†â–†â–‚â–„â–„â–„â–„â–ƒâ–…â–…â–†â–„â–â–â–ˆâ–ˆâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1723
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.00064
wandb:   test_error_force 5.88575
wandb:          test_loss 3.13449
wandb: train_error_energy 2.07747
wandb:  train_error_force 3.47843
wandb:         train_loss 1.55646
wandb: valid_error_energy 1.49602
wandb:  valid_error_force 3.10272
wandb:         valid_loss 1.51374
wandb: 
wandb: ğŸš€ View run al_55_31 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/54d67o3y
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_063616-54d67o3y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7478978633880615, Uncertainty Bias: 0.02628268301486969
1.7166138e-05 0.004055023
0.4920702 6.3384395
Found uncertainty sample 9 after 3923 steps.
Found uncertainty sample 11 after 3614 steps.
Found uncertainty sample 19 after 1553 steps.
Found uncertainty sample 24 after 2548 steps.
Found uncertainty sample 26 after 1406 steps.
Found uncertainty sample 37 after 2295 steps.
Found uncertainty sample 46 after 828 steps.
Found uncertainty sample 49 after 2709 steps.
Found uncertainty sample 51 after 1146 steps.
Found uncertainty sample 54 after 2843 steps.
Found uncertainty sample 63 after 3553 steps.
Found uncertainty sample 67 after 779 steps.
Found uncertainty sample 68 after 3107 steps.
Found uncertainty sample 71 after 3358 steps.
Found uncertainty sample 74 after 3596 steps.
Found uncertainty sample 91 after 545 steps.
Found uncertainty sample 94 after 3863 steps.
Found uncertainty sample 95 after 934 steps.
Found uncertainty sample 97 after 3313 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241127_093906-rzpdt3mh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_32
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/rzpdt3mh
Training model 32. Added 19 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.422211848575703, Training Loss Force: 3.7738079886797022, time: 2.099411725997925
Validation Loss Energy: 1.6830206912274241, Validation Loss Force: 3.1896834108354133, time: 0.1369619369506836
Test Loss Energy: 6.261619097510522, Test Loss Force: 5.9090089349398465, time: 18.51984477043152


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.010579308369645, Training Loss Force: 3.484249104188745, time: 2.1416704654693604
Validation Loss Energy: 1.7003660053550476, Validation Loss Force: 3.121518150530832, time: 0.13399195671081543
Test Loss Energy: 5.892871353486337, Test Loss Force: 5.893172280927697, time: 18.855107307434082


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0636987233919633, Training Loss Force: 3.4906258100736367, time: 2.238380193710327
Validation Loss Energy: 2.161864120805327, Validation Loss Force: 3.113270708034813, time: 0.1391587257385254
Test Loss Energy: 5.809868971820498, Test Loss Force: 5.899425592983156, time: 17.80524230003357


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0305939771822534, Training Loss Force: 3.490543952847063, time: 1.8914554119110107
Validation Loss Energy: 3.35959177064305, Validation Loss Force: 3.0507296250180747, time: 0.12906742095947266
Test Loss Energy: 7.634333261809181, Test Loss Force: 5.8835111936306745, time: 17.071250438690186


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.489487670294766, Training Loss Force: 3.4935672573457537, time: 1.9830873012542725
Validation Loss Energy: 1.5875594223347114, Validation Loss Force: 3.0837182816564224, time: 0.13358163833618164
Test Loss Energy: 5.964601029198893, Test Loss Force: 5.875039248174243, time: 17.116329431533813


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.088672513432948, Training Loss Force: 3.484323487829074, time: 1.9652860164642334
Validation Loss Energy: 1.6324733477523679, Validation Loss Force: 3.1569788800272702, time: 0.1278674602508545
Test Loss Energy: 5.966014912990341, Test Loss Force: 5.878070619294623, time: 17.16595959663391


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.988959192990633, Training Loss Force: 3.481132286745826, time: 2.000082492828369
Validation Loss Energy: 2.250972082291855, Validation Loss Force: 3.0716156569023827, time: 0.13347983360290527
Test Loss Energy: 6.8963318578031885, Test Loss Force: 5.877225264625659, time: 16.9656183719635


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1846224196450743, Training Loss Force: 3.488019864476485, time: 1.9554145336151123
Validation Loss Energy: 1.8202396617288397, Validation Loss Force: 3.1089544893101486, time: 0.13237857818603516
Test Loss Energy: 6.43572220011436, Test Loss Force: 5.848842906318769, time: 17.098240852355957


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.145152066595265, Training Loss Force: 3.4925843835900383, time: 1.9844286441802979
Validation Loss Energy: 1.8059895600641855, Validation Loss Force: 3.0689457425081352, time: 0.13300490379333496
Test Loss Energy: 6.4049253318381165, Test Loss Force: 5.861494104493169, time: 17.06618905067444


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.5099083459309988, Training Loss Force: 3.4837290057432764, time: 1.9599430561065674
Validation Loss Energy: 1.5406874001150528, Validation Loss Force: 3.0970181984081164, time: 0.13389825820922852
Test Loss Energy: 5.869612306785795, Test Loss Force: 5.834863033189966, time: 17.139278888702393


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0799278183458325, Training Loss Force: 3.4857433477594086, time: 1.9857783317565918
Validation Loss Energy: 1.4680882404421838, Validation Loss Force: 3.0065746673843137, time: 0.13603949546813965
Test Loss Energy: 6.160634918576176, Test Loss Force: 5.838993261390006, time: 17.13317108154297


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.5608488623898142, Training Loss Force: 3.4975496504868424, time: 1.9975626468658447
Validation Loss Energy: 1.4491156601961201, Validation Loss Force: 3.0731634301357262, time: 0.12838530540466309
Test Loss Energy: 6.037654203682561, Test Loss Force: 5.809239648192138, time: 17.074063062667847


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2032580822428316, Training Loss Force: 3.4624089167957517, time: 1.993194341659546
Validation Loss Energy: 1.5279725465442842, Validation Loss Force: 3.0291122363239675, time: 0.1254558563232422
Test Loss Energy: 5.870412034098561, Test Loss Force: 5.825190311138619, time: 17.19813561439514


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.220991382175247, Training Loss Force: 3.482428658416357, time: 1.9992332458496094
Validation Loss Energy: 1.776591387736637, Validation Loss Force: 3.014929659077816, time: 0.13090777397155762
Test Loss Energy: 5.751024807509054, Test Loss Force: 5.803527648327851, time: 17.5341899394989


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1207337348601216, Training Loss Force: 3.4733051059473006, time: 1.9754040241241455
Validation Loss Energy: 1.5998193628403494, Validation Loss Force: 3.0912250152385132, time: 0.1446516513824463
Test Loss Energy: 6.458233561128699, Test Loss Force: 5.85369501856345, time: 17.03796887397766


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8939182667660126, Training Loss Force: 3.46035523521433, time: 1.9785676002502441
Validation Loss Energy: 1.702424136270858, Validation Loss Force: 3.1287204953904393, time: 0.12989282608032227
Test Loss Energy: 5.754847516794691, Test Loss Force: 5.812315963505785, time: 17.174623727798462


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9608165193876155, Training Loss Force: 3.462659593671708, time: 1.9050688743591309
Validation Loss Energy: 1.9419093117663988, Validation Loss Force: 3.1368079501051094, time: 0.12459087371826172
Test Loss Energy: 6.354701035244425, Test Loss Force: 5.797750750316881, time: 17.119595289230347


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.282619548009125, Training Loss Force: 3.477583329218609, time: 2.2130579948425293
Validation Loss Energy: 1.6543355055051363, Validation Loss Force: 3.0381302253994695, time: 0.1462242603302002
Test Loss Energy: 5.844314741541393, Test Loss Force: 5.82754956651718, time: 17.26756238937378


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0275228818120534, Training Loss Force: 3.451080551123137, time: 2.0591962337493896
Validation Loss Energy: 1.9138395835634556, Validation Loss Force: 3.153976297929007, time: 0.13433313369750977
Test Loss Energy: 5.7114627140292455, Test Loss Force: 5.811981726625484, time: 17.44767999649048


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.338408517106527, Training Loss Force: 3.446545319075068, time: 1.969590187072754
Validation Loss Energy: 1.6648369164308097, Validation Loss Force: 3.0304177455265418, time: 0.13349485397338867
Test Loss Energy: 5.729565580359556, Test Loss Force: 5.7643620831304645, time: 17.312164783477783

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.039 MB uploadedwandb: - 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: \ 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: | 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 5.3%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–â–ˆâ–‚â–‚â–…â–„â–„â–‚â–ƒâ–‚â–‚â–â–„â–â–ƒâ–â–â–
wandb:   test_error_force â–ˆâ–‡â–ˆâ–‡â–†â–‡â–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–
wandb:          test_loss â–†â–ƒâ–ƒâ–ˆâ–„â–„â–…â–…â–ƒâ–‚â–„â–ƒâ–ƒâ–â–„â–‚â–ƒâ–â–‚â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–„â–‚â–â–‚â–‚â–„â–‚â–„â–‚â–‚â–‚â–â–â–ƒâ–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–â–â–‚â–â–‚
wandb: valid_error_energy â–‚â–‚â–„â–ˆâ–‚â–‚â–„â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚
wandb:  valid_error_force â–ˆâ–…â–…â–ƒâ–„â–‡â–ƒâ–…â–ƒâ–„â–â–„â–‚â–â–„â–†â–†â–‚â–‡â–‚
wandb:         valid_loss â–†â–ƒâ–…â–ˆâ–ƒâ–…â–„â–†â–…â–ƒâ–„â–„â–…â–‚â–ƒâ–‡â–„â–ƒâ–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1740
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.72957
wandb:   test_error_force 5.76436
wandb:          test_loss 3.03463
wandb: train_error_energy 2.33841
wandb:  train_error_force 3.44655
wandb:         train_loss 1.57378
wandb: valid_error_energy 1.66484
wandb:  valid_error_force 3.03042
wandb:         valid_loss 1.46069
wandb: 
wandb: ğŸš€ View run al_55_32 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/rzpdt3mh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_093906-rzpdt3mh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7371222972869873, Uncertainty Bias: 0.031650930643081665
5.531311e-05 0.0016872883
0.51320434 4.749996
Found uncertainty sample 0 after 1791 steps.
Found uncertainty sample 2 after 2606 steps.
Found uncertainty sample 3 after 190 steps.
Found uncertainty sample 17 after 2485 steps.
Found uncertainty sample 19 after 1069 steps.
Found uncertainty sample 21 after 1491 steps.
Found uncertainty sample 31 after 2910 steps.
Found uncertainty sample 36 after 723 steps.
Found uncertainty sample 46 after 910 steps.
Found uncertainty sample 47 after 2704 steps.
Found uncertainty sample 48 after 2229 steps.
Found uncertainty sample 60 after 2286 steps.
Found uncertainty sample 64 after 2308 steps.
Found uncertainty sample 66 after 2825 steps.
Found uncertainty sample 69 after 1677 steps.
Found uncertainty sample 70 after 2075 steps.
Found uncertainty sample 82 after 1111 steps.
Found uncertainty sample 84 after 3922 steps.
Found uncertainty sample 94 after 33 steps.
Found uncertainty sample 95 after 2620 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241127_123541-x3b82cih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_33
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/x3b82cih
Training model 33. Added 20 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.659015441653585, Training Loss Force: 3.721410448810097, time: 2.02189564704895
Validation Loss Energy: 2.3785931219271994, Validation Loss Force: 3.107429985002554, time: 0.13913917541503906
Test Loss Energy: 6.711255649999014, Test Loss Force: 5.770790900441971, time: 16.921547412872314


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.206132121491681, Training Loss Force: 3.4903929305352346, time: 2.018904209136963
Validation Loss Energy: 1.5376072178194335, Validation Loss Force: 3.0192576792672146, time: 0.131591796875
Test Loss Energy: 5.761897273250274, Test Loss Force: 5.786492626278141, time: 17.438148498535156


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1451497832243867, Training Loss Force: 3.476474663589565, time: 2.0081913471221924
Validation Loss Energy: 1.6322379307978356, Validation Loss Force: 3.0990963695470604, time: 0.13303494453430176
Test Loss Energy: 5.793937640286468, Test Loss Force: 5.778992206124114, time: 17.09608221054077


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1859177852559193, Training Loss Force: 3.480195877968071, time: 2.058544397354126
Validation Loss Energy: 1.531998794373664, Validation Loss Force: 3.0787809273491926, time: 0.13489890098571777
Test Loss Energy: 5.800750213298391, Test Loss Force: 5.830250816056133, time: 17.013856887817383


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.4530249154717985, Training Loss Force: 3.484414348986203, time: 1.979381799697876
Validation Loss Energy: 1.52234536322297, Validation Loss Force: 3.1016369131675234, time: 0.13569259643554688
Test Loss Energy: 5.812086115320063, Test Loss Force: 5.8012058853039115, time: 17.124056100845337


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.275768520406638, Training Loss Force: 3.4892841717900027, time: 2.031313180923462
Validation Loss Energy: 1.941041291768286, Validation Loss Force: 3.0237519219740476, time: 0.13272809982299805
Test Loss Energy: 6.2016997070282525, Test Loss Force: 5.810742110002998, time: 17.06151556968689


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.4287947249951087, Training Loss Force: 3.481091303477385, time: 1.9767837524414062
Validation Loss Energy: 1.5499933560635264, Validation Loss Force: 3.0750966436606717, time: 0.13675522804260254
Test Loss Energy: 5.90417018983876, Test Loss Force: 5.778447998068239, time: 17.181533098220825


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2455258500398467, Training Loss Force: 3.4878927163456304, time: 2.035341739654541
Validation Loss Energy: 1.56127216064492, Validation Loss Force: 3.0064102262200456, time: 0.12769436836242676
Test Loss Energy: 5.785483324164198, Test Loss Force: 5.770584076945421, time: 17.157344579696655


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0235279888348177, Training Loss Force: 3.484682151143745, time: 2.0053558349609375
Validation Loss Energy: 1.5077239607574815, Validation Loss Force: 3.117364591617268, time: 0.12652802467346191
Test Loss Energy: 5.895660752027707, Test Loss Force: 5.795454567431163, time: 17.06340193748474


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0887153570008894, Training Loss Force: 3.478526754098727, time: 1.987067699432373
Validation Loss Energy: 1.9383988213462744, Validation Loss Force: 3.0769191906200906, time: 0.12545037269592285
Test Loss Energy: 5.4921321760109345, Test Loss Force: 5.769325140568557, time: 17.255029678344727


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9703186640599035, Training Loss Force: 3.4829610279560312, time: 1.9687411785125732
Validation Loss Energy: 2.302818477564254, Validation Loss Force: 3.053889968206228, time: 0.1304161548614502
Test Loss Energy: 6.640345329126662, Test Loss Force: 5.762922679822764, time: 17.18177628517151


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.113086986919072, Training Loss Force: 3.4577514515321583, time: 2.0299503803253174
Validation Loss Energy: 1.4521730745715682, Validation Loss Force: 2.960995183889479, time: 0.12963390350341797
Test Loss Energy: 5.8125732851003695, Test Loss Force: 5.78174950533426, time: 17.050615310668945


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.327194664102868, Training Loss Force: 3.4787364517547714, time: 2.020387649536133
Validation Loss Energy: 2.122841464316055, Validation Loss Force: 3.0474622893053036, time: 0.13068413734436035
Test Loss Energy: 6.6633346920146925, Test Loss Force: 5.769059791226646, time: 17.167253732681274


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1750842369836505, Training Loss Force: 3.475038443549801, time: 1.9534049034118652
Validation Loss Energy: 2.0991127267802607, Validation Loss Force: 3.0367105982596074, time: 0.1283564567565918
Test Loss Energy: 6.608446288215519, Test Loss Force: 5.733888693667094, time: 17.335965633392334


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.097379522779248, Training Loss Force: 3.4744580665422657, time: 2.1555070877075195
Validation Loss Energy: 1.5621386219590114, Validation Loss Force: 3.104466592673974, time: 0.13228273391723633
Test Loss Energy: 5.817802001985046, Test Loss Force: 5.793242338974107, time: 17.1193630695343


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2046754745941755, Training Loss Force: 3.4566746761733413, time: 1.999955654144287
Validation Loss Energy: 1.5653542427626412, Validation Loss Force: 3.055610755365958, time: 0.13083982467651367
Test Loss Energy: 5.757746323995784, Test Loss Force: 5.765282797898541, time: 17.177992582321167


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3070774541242955, Training Loss Force: 3.4533297564573338, time: 1.9917149543762207
Validation Loss Energy: 1.7732435571276128, Validation Loss Force: 3.049175505714072, time: 0.12502169609069824
Test Loss Energy: 5.613056910902741, Test Loss Force: 5.772201508315615, time: 17.019158601760864


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0514987719785025, Training Loss Force: 3.455254338516476, time: 1.9835104942321777
Validation Loss Energy: 1.5071286547958436, Validation Loss Force: 3.076220677509315, time: 0.13530302047729492
Test Loss Energy: 5.873769008132254, Test Loss Force: 5.742893102839214, time: 17.105860710144043


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0458400931186294, Training Loss Force: 3.4611103589190604, time: 1.9894845485687256
Validation Loss Energy: 1.5134770634808175, Validation Loss Force: 3.0972958668330883, time: 0.12877440452575684
Test Loss Energy: 5.819852523678262, Test Loss Force: 5.767035003558179, time: 17.127946615219116


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.019048503019564, Training Loss Force: 3.4641652459997023, time: 2.0063748359680176
Validation Loss Energy: 1.3797129161130446, Validation Loss Force: 2.9951486228301745, time: 0.1315474510192871
Test Loss Energy: 5.833977957143306, Test Loss Force: 5.78080852883971, time: 17.170340299606323

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–â–ˆâ–ƒâ–ˆâ–‡â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒ
wandb:   test_error_force â–„â–…â–„â–ˆâ–†â–‡â–„â–„â–…â–„â–ƒâ–„â–„â–â–…â–ƒâ–„â–‚â–ƒâ–„
wandb:          test_loss â–‡â–…â–‚â–ƒâ–…â–…â–ƒâ–â–„â–„â–ˆâ–â–…â–…â–‚â–„â–ƒâ–â–…â–
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–â–‚â–‚â–â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–‚
wandb: valid_error_energy â–ˆâ–‚â–ƒâ–‚â–‚â–…â–‚â–‚â–‚â–…â–‡â–‚â–†â–†â–‚â–‚â–„â–‚â–‚â–
wandb:  valid_error_force â–ˆâ–„â–‡â–†â–‡â–„â–†â–ƒâ–ˆâ–†â–…â–â–…â–„â–‡â–…â–…â–†â–‡â–ƒ
wandb:         valid_loss â–ˆâ–ƒâ–…â–†â–‡â–ƒâ–„â–ƒâ–„â–‡â–‡â–â–…â–†â–…â–…â–„â–„â–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1758
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.83398
wandb:   test_error_force 5.78081
wandb:          test_loss 3.0264
wandb: train_error_energy 2.01905
wandb:  train_error_force 3.46417
wandb:         train_loss 1.57625
wandb: valid_error_energy 1.37971
wandb:  valid_error_force 2.99515
wandb:         valid_loss 1.48386
wandb: 
wandb: ğŸš€ View run al_55_33 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/x3b82cih
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_123541-x3b82cih/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7331656217575073, Uncertainty Bias: 0.03150677680969238
0.00012207031 0.0259552
0.7507793 4.8917956
Found uncertainty sample 3 after 2430 steps.
Found uncertainty sample 4 after 3016 steps.
Found uncertainty sample 6 after 1209 steps.
Found uncertainty sample 11 after 1604 steps.
Found uncertainty sample 18 after 3965 steps.
Found uncertainty sample 29 after 3517 steps.
Found uncertainty sample 31 after 3046 steps.
Found uncertainty sample 33 after 1881 steps.
Found uncertainty sample 36 after 3273 steps.
Found uncertainty sample 38 after 3521 steps.
Found uncertainty sample 46 after 3071 steps.
Found uncertainty sample 59 after 3088 steps.
Found uncertainty sample 65 after 1717 steps.
Found uncertainty sample 68 after 2246 steps.
Found uncertainty sample 76 after 222 steps.
Found uncertainty sample 79 after 2802 steps.
Found uncertainty sample 85 after 3758 steps.
Found uncertainty sample 88 after 2514 steps.
Found uncertainty sample 89 after 1130 steps.
Found uncertainty sample 90 after 1554 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241127_153607-j9rd9w5h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_34
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/j9rd9w5h
Training model 34. Added 20 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8950109469965244, Training Loss Force: 3.6728751831385154, time: 2.0083858966827393
Validation Loss Energy: 1.5581045807095242, Validation Loss Force: 3.145811243016981, time: 0.13344049453735352
Test Loss Energy: 5.799833320045813, Test Loss Force: 5.763322651899202, time: 17.908388137817383


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9625061560736674, Training Loss Force: 3.476701474670788, time: 2.0201921463012695
Validation Loss Energy: 1.603464957764766, Validation Loss Force: 3.1124667610834402, time: 0.13635969161987305
Test Loss Energy: 5.641396327872872, Test Loss Force: 5.735643081717526, time: 18.10605025291443


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0211481810700502, Training Loss Force: 3.4788374960490915, time: 1.999443531036377
Validation Loss Energy: 2.9168320988318914, Validation Loss Force: 2.9826412969034113, time: 0.1354515552520752
Test Loss Energy: 5.499365747595193, Test Loss Force: 5.752802698229546, time: 18.07551407814026


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1889879783100126, Training Loss Force: 3.4850379808489436, time: 2.0206081867218018
Validation Loss Energy: 1.6032826474015374, Validation Loss Force: 3.107222902696841, time: 0.13988423347473145
Test Loss Energy: 5.9459472630802574, Test Loss Force: 5.754653414584636, time: 18.3791561126709


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0001614033259143, Training Loss Force: 3.471337255658345, time: 2.017760992050171
Validation Loss Energy: 3.2041979877781435, Validation Loss Force: 3.0305889780997606, time: 0.13326644897460938
Test Loss Energy: 5.51258041762111, Test Loss Force: 5.775324514201483, time: 18.08092188835144


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.4767884021183084, Training Loss Force: 3.5116954180651363, time: 1.9817612171173096
Validation Loss Energy: 1.4843896259464113, Validation Loss Force: 3.123932552080127, time: 0.13586211204528809
Test Loss Energy: 5.705569508112452, Test Loss Force: 5.800758959182856, time: 18.0223867893219


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.319941027116316, Training Loss Force: 3.511919188628089, time: 2.0582480430603027
Validation Loss Energy: 1.555180433817914, Validation Loss Force: 3.0389205895329408, time: 0.13959360122680664
Test Loss Energy: 5.804103682916101, Test Loss Force: 5.745390047024838, time: 17.953617095947266


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0278362596084327, Training Loss Force: 3.4897577237808464, time: 2.0142931938171387
Validation Loss Energy: 2.0713502263314107, Validation Loss Force: 2.988879039022859, time: 0.13623571395874023
Test Loss Energy: 5.511959776923637, Test Loss Force: 5.748543601718558, time: 18.099015474319458


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.185428528511427, Training Loss Force: 3.468382141850512, time: 2.0217576026916504
Validation Loss Energy: 1.8754943422833823, Validation Loss Force: 3.0205946961539376, time: 0.13817954063415527
Test Loss Energy: 6.247339376477685, Test Loss Force: 5.673728414806373, time: 18.13371443748474


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.297731121789247, Training Loss Force: 3.457305198778606, time: 2.075530767440796
Validation Loss Energy: 1.4409240519884423, Validation Loss Force: 2.948326979504782, time: 0.13092637062072754
Test Loss Energy: 5.943833909050448, Test Loss Force: 5.745289433213477, time: 17.99315857887268


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1288995183990918, Training Loss Force: 3.467522213490113, time: 1.9838621616363525
Validation Loss Energy: 2.3187914260782385, Validation Loss Force: 3.050512856604514, time: 0.1338491439819336
Test Loss Energy: 5.46723661601046, Test Loss Force: 5.700662393091304, time: 18.116745471954346


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2633376335805364, Training Loss Force: 3.4749125308712303, time: 2.0060503482818604
Validation Loss Energy: 1.6680620563404278, Validation Loss Force: 3.03252987371024, time: 0.13278746604919434
Test Loss Energy: 5.5410541472210975, Test Loss Force: 5.688863626034636, time: 18.540254592895508


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0854104767036357, Training Loss Force: 3.467382806699823, time: 2.030635118484497
Validation Loss Energy: 2.067524102396934, Validation Loss Force: 3.070080464475783, time: 0.1362476348876953
Test Loss Energy: 6.303679695025784, Test Loss Force: 5.726666647251301, time: 18.00853395462036


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.090264767466965, Training Loss Force: 3.46387632034809, time: 2.0387635231018066
Validation Loss Energy: 1.5713574586041408, Validation Loss Force: 3.1233714258323886, time: 0.13610267639160156
Test Loss Energy: 5.604154157773484, Test Loss Force: 5.691840110959255, time: 18.306620836257935


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0355802392130395, Training Loss Force: 3.4542280622788044, time: 2.037782907485962
Validation Loss Energy: 3.4741876672527754, Validation Loss Force: 3.1317661639684395, time: 0.13315272331237793
Test Loss Energy: 5.507538649554452, Test Loss Force: 5.686530699242418, time: 18.49845790863037


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3407458583227023, Training Loss Force: 3.4734205044490634, time: 1.9851293563842773
Validation Loss Energy: 2.1275224151017493, Validation Loss Force: 2.966329668618471, time: 0.13808250427246094
Test Loss Energy: 6.5758637509541655, Test Loss Force: 5.673502271555446, time: 18.386082410812378


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.258971175129822, Training Loss Force: 3.4762423945116407, time: 2.0687785148620605
Validation Loss Energy: 1.5116529578373772, Validation Loss Force: 3.0718827485429228, time: 0.1359097957611084
Test Loss Energy: 5.812075842228366, Test Loss Force: 5.7150931001263805, time: 18.52134370803833


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.034058792629967, Training Loss Force: 3.461668480217756, time: 2.01570987701416
Validation Loss Energy: 1.468055007072154, Validation Loss Force: 2.9770891530842745, time: 0.13689923286437988
Test Loss Energy: 5.693820427752118, Test Loss Force: 5.706715862502811, time: 18.666251182556152


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.139100648052777, Training Loss Force: 3.4482128580895375, time: 1.9996976852416992
Validation Loss Energy: 1.800202221959663, Validation Loss Force: 3.076836580366951, time: 0.14200592041015625
Test Loss Energy: 5.460479822202495, Test Loss Force: 5.657124897582105, time: 18.526893138885498


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9930219187614493, Training Loss Force: 3.4613721950616907, time: 2.0297794342041016
Validation Loss Energy: 1.8589357739156085, Validation Loss Force: 3.0305879760886034, time: 0.14110255241394043
Test Loss Energy: 5.452556123157548, Test Loss Force: 5.698645358039699, time: 18.692551612854004

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–â–„â–â–ƒâ–ƒâ–â–†â–„â–â–‚â–†â–‚â–â–ˆâ–ƒâ–ƒâ–â–
wandb:   test_error_force â–†â–…â–†â–†â–‡â–ˆâ–…â–…â–‚â–…â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–„â–ƒâ–â–ƒ
wandb:          test_loss â–ˆâ–‡â–‡â–ˆâ–†â–‡â–„â–ƒâ–†â–…â–ƒâ–ƒâ–…â–ƒâ–â–…â–ƒâ–„â–‚â–
wandb: train_error_energy â–ˆâ–â–â–‚â–â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–
wandb: valid_error_energy â–â–‚â–†â–‚â–‡â–â–â–ƒâ–‚â–â–„â–‚â–ƒâ–â–ˆâ–ƒâ–â–â–‚â–‚
wandb:  valid_error_force â–ˆâ–‡â–‚â–‡â–„â–‡â–„â–‚â–„â–â–…â–„â–…â–‡â–ˆâ–‚â–…â–‚â–†â–„
wandb:         valid_loss â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–‚â–ƒâ–â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1776
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.45256
wandb:   test_error_force 5.69865
wandb:          test_loss 2.9857
wandb: train_error_energy 1.99302
wandb:  train_error_force 3.46137
wandb:         train_loss 1.57288
wandb: valid_error_energy 1.85894
wandb:  valid_error_force 3.03059
wandb:         valid_loss 1.51374
wandb: 
wandb: ğŸš€ View run al_55_34 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/j9rd9w5h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_153607-j9rd9w5h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7262491583824158, Uncertainty Bias: 0.027152568101882935
1.1444092e-05 0.010143518
0.5464826 4.6461234
Found uncertainty sample 12 after 1819 steps.
Found uncertainty sample 13 after 2545 steps.
Found uncertainty sample 15 after 2381 steps.
Found uncertainty sample 22 after 2595 steps.
Found uncertainty sample 23 after 676 steps.
Found uncertainty sample 24 after 3744 steps.
Found uncertainty sample 35 after 3455 steps.
Found uncertainty sample 37 after 3012 steps.
Found uncertainty sample 38 after 2773 steps.
Found uncertainty sample 39 after 2169 steps.
Found uncertainty sample 50 after 2730 steps.
Found uncertainty sample 52 after 3753 steps.
Found uncertainty sample 63 after 2121 steps.
Found uncertainty sample 64 after 2409 steps.
Found uncertainty sample 65 after 483 steps.
Found uncertainty sample 73 after 2172 steps.
Found uncertainty sample 75 after 3702 steps.
Found uncertainty sample 85 after 3124 steps.
Found uncertainty sample 89 after 2147 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241127_183600-984b0vny
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_35
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/984b0vny
Training model 35. Added 19 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8353824257626643, Training Loss Force: 3.671110034941415, time: 2.059225082397461
Validation Loss Energy: 1.5736573525451425, Validation Loss Force: 3.1022839897055894, time: 0.14023995399475098
Test Loss Energy: 5.594588860178265, Test Loss Force: 5.649849783629543, time: 18.060004949569702


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.423181719909702, Training Loss Force: 3.4883527747371623, time: 2.0280814170837402
Validation Loss Energy: 2.0202821710586027, Validation Loss Force: 3.0849117882785952, time: 0.13819646835327148
Test Loss Energy: 6.409168608347481, Test Loss Force: 5.657418743911464, time: 18.252806901931763


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.5232194257226688, Training Loss Force: 3.5001996405382467, time: 2.061262369155884
Validation Loss Energy: 2.6815446264080944, Validation Loss Force: 3.179923376831107, time: 0.13607454299926758
Test Loss Energy: 5.402126490637099, Test Loss Force: 5.785272287440983, time: 18.218263149261475


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.4816273919117733, Training Loss Force: 3.53816433927131, time: 2.0714359283447266
Validation Loss Energy: 2.283358418890468, Validation Loss Force: 2.996229013526216, time: 0.14782166481018066
Test Loss Energy: 5.342146750987248, Test Loss Force: 5.661876060262995, time: 18.090147733688354


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.042450734252215, Training Loss Force: 3.5063983042225844, time: 2.111163377761841
Validation Loss Energy: 2.109105338707489, Validation Loss Force: 3.103570683365333, time: 0.14434218406677246
Test Loss Energy: 6.500134023388021, Test Loss Force: 5.663117360310856, time: 18.27146005630493


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.437676580866827, Training Loss Force: 3.4879646116316185, time: 2.093074321746826
Validation Loss Energy: 1.5812542114640473, Validation Loss Force: 3.0793019731506637, time: 0.13395404815673828
Test Loss Energy: 5.786824263408729, Test Loss Force: 5.68317715034983, time: 18.327491998672485


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.196362683249544, Training Loss Force: 3.497359538553176, time: 2.105724334716797
Validation Loss Energy: 3.249050790515243, Validation Loss Force: 3.084975248985185, time: 0.14135265350341797
Test Loss Energy: 5.332271346385982, Test Loss Force: 5.702172292751122, time: 18.120315313339233


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.3821314635697077, Training Loss Force: 3.4755822265345784, time: 2.000704288482666
Validation Loss Energy: 1.5365375709096831, Validation Loss Force: 3.0579563521491613, time: 0.13382649421691895
Test Loss Energy: 5.4903053307209335, Test Loss Force: 5.6985419253068965, time: 18.194018840789795


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.197783433501327, Training Loss Force: 3.513468940282376, time: 2.0552902221679688
Validation Loss Energy: 4.234365101282893, Validation Loss Force: 2.9920359308392506, time: 0.14174580574035645
Test Loss Energy: 5.6010395876674055, Test Loss Force: 5.708985173536106, time: 18.58547067642212


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.5763897375137055, Training Loss Force: 3.5176846141214626, time: 2.0777370929718018
Validation Loss Energy: 3.237252109145394, Validation Loss Force: 3.076340362175251, time: 0.13310956954956055
Test Loss Energy: 7.235080101270439, Test Loss Force: 5.706353284853206, time: 18.111958503723145


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1257820506363205, Training Loss Force: 3.4642454566820513, time: 2.0461738109588623
Validation Loss Energy: 1.463271238808328, Validation Loss Force: 3.0476749383396644, time: 0.1400907039642334
Test Loss Energy: 5.736729826061972, Test Loss Force: 5.744482797328151, time: 18.15377688407898


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.190130396524171, Training Loss Force: 3.4723024526014443, time: 2.053903818130493
Validation Loss Energy: 2.913134788998333, Validation Loss Force: 3.0955641688852076, time: 0.1342470645904541
Test Loss Energy: 5.418555113488213, Test Loss Force: 5.752209188193665, time: 18.22279119491577


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2839135369777424, Training Loss Force: 3.532958498711521, time: 2.0480234622955322
Validation Loss Energy: 1.8144941854237515, Validation Loss Force: 3.1355262665011487, time: 0.13470196723937988
Test Loss Energy: 5.483269396073697, Test Loss Force: 5.70266344026507, time: 18.195449829101562


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.220364497147486, Training Loss Force: 3.5338729305772736, time: 2.0878970623016357
Validation Loss Energy: 1.7889500263412077, Validation Loss Force: 3.044129043525337, time: 0.1404409408569336
Test Loss Energy: 5.454609284237918, Test Loss Force: 5.677797197980208, time: 18.435631275177002


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2144981417713496, Training Loss Force: 3.4579671360406152, time: 2.1118385791778564
Validation Loss Energy: 4.554594284138336, Validation Loss Force: 2.991127774727584, time: 0.14419341087341309
Test Loss Energy: 5.673163723520685, Test Loss Force: 5.657485197244743, time: 18.630011558532715


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.4569060148558144, Training Loss Force: 3.4955509884981413, time: 2.1348934173583984
Validation Loss Energy: 2.8361808888385545, Validation Loss Force: 3.111067285501284, time: 0.13631343841552734
Test Loss Energy: 7.050380777899948, Test Loss Force: 5.6551898047761995, time: 18.46942949295044


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.561609158837307, Training Loss Force: 3.4905266350117117, time: 2.1188924312591553
Validation Loss Energy: 2.852817502741976, Validation Loss Force: 3.050884268739922, time: 0.1432967185974121
Test Loss Energy: 7.034292628996833, Test Loss Force: 5.637355260595766, time: 18.77017593383789


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1419031210100616, Training Loss Force: 3.478660229016453, time: 2.13559889793396
Validation Loss Energy: 2.125296614319055, Validation Loss Force: 3.1972666312691302, time: 0.1349191665649414
Test Loss Energy: 6.095942804977495, Test Loss Force: 5.715537561731339, time: 19.015508890151978


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1052730933247368, Training Loss Force: 3.468305269931941, time: 2.0637521743774414
Validation Loss Energy: 2.4595050774904177, Validation Loss Force: 3.0298805562119915, time: 0.13519930839538574
Test Loss Energy: 6.751262827624742, Test Loss Force: 5.666202447156722, time: 18.77050232887268


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.116709911940357, Training Loss Force: 3.465151700573596, time: 2.11700439453125
Validation Loss Energy: 1.507850993505233, Validation Loss Force: 3.02936362978972, time: 0.1372697353363037
Test Loss Energy: 5.75069062658749, Test Loss Force: 5.696494005695009, time: 18.764660596847534

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–â–â–…â–ƒâ–â–‚â–‚â–ˆâ–‚â–â–‚â–â–‚â–‡â–‡â–„â–†â–ƒ
wandb:   test_error_force â–‚â–‚â–ˆâ–‚â–‚â–ƒâ–„â–„â–„â–„â–†â–†â–„â–ƒâ–‚â–‚â–â–…â–‚â–„
wandb:          test_loss â–ƒâ–†â–ƒâ–â–ˆâ–„â–ƒâ–…â–‚â–†â–ƒâ–ƒâ–‚â–â–‚â–†â–…â–ƒâ–„â–‚
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–â–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–â–â–ƒâ–ƒâ–â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–â–‚â–ƒâ–â–â–
wandb: valid_error_energy â–â–‚â–„â–ƒâ–‚â–â–…â–â–‡â–…â–â–„â–‚â–‚â–ˆâ–„â–„â–‚â–ƒâ–
wandb:  valid_error_force â–…â–„â–‡â–â–…â–„â–„â–ƒâ–â–„â–ƒâ–…â–†â–ƒâ–â–…â–ƒâ–ˆâ–‚â–‚
wandb:         valid_loss â–‡â–…â–‡â–ƒâ–ˆâ–„â–ˆâ–†â–‡â–…â–ƒâ–…â–ƒâ–ƒâ–‡â–†â–…â–…â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1793
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.75069
wandb:   test_error_force 5.69649
wandb:          test_loss 2.99882
wandb: train_error_energy 2.11671
wandb:  train_error_force 3.46515
wandb:         train_loss 1.56632
wandb: valid_error_energy 1.50785
wandb:  valid_error_force 3.02936
wandb:         valid_loss 1.4622
wandb: 
wandb: ğŸš€ View run al_55_35 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/984b0vny
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241127_183600-984b0vny/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7155843377113342, Uncertainty Bias: 0.03797203302383423
7.6293945e-06 0.0075130463
0.58345014 5.5393877
Found uncertainty sample 8 after 3036 steps.
Found uncertainty sample 19 after 3343 steps.
Found uncertainty sample 20 after 1240 steps.
Found uncertainty sample 31 after 3409 steps.
Found uncertainty sample 36 after 2778 steps.
Found uncertainty sample 42 after 3485 steps.
Found uncertainty sample 44 after 1823 steps.
Found uncertainty sample 54 after 2711 steps.
Found uncertainty sample 57 after 2481 steps.
Found uncertainty sample 63 after 3777 steps.
Found uncertainty sample 67 after 2340 steps.
Found uncertainty sample 69 after 1980 steps.
slurmstepd: error: *** JOB 5122848 ON aimat01 CANCELLED AT 2024-11-27T20:48:34 DUE TO TIME LIMIT ***
