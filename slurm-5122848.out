wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_164835-fl9zr4hd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/fl9zr4hd
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
54
Uncertainty Slope: 0.6569392085075378, Uncertainty Bias: 0.02670060098171234
0.0004043579 0.0067281723
0.4407349 2.8812606

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 12.431827418372507, Test Loss Force: 10.721727356400123, time: 14.565014839172363

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.047 MB uploadedwandb: | 0.039 MB of 0.050 MB uploadedwandb: / 0.039 MB of 0.050 MB uploadedwandb: - 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.43183
wandb:   test_error_force 10.72173
wandb:          test_loss 6.0442
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_55 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/fl9zr4hd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_164835-fl9zr4hd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 520 steps.
Found uncertainty sample 1 after 251 steps.
Found uncertainty sample 2 after 268 steps.
Found uncertainty sample 6 after 69 steps.
Found uncertainty sample 7 after 3085 steps.
Found uncertainty sample 8 after 3286 steps.
Found uncertainty sample 9 after 846 steps.
Found uncertainty sample 10 after 3583 steps.
Found uncertainty sample 11 after 1274 steps.
Found uncertainty sample 12 after 1155 steps.
Found uncertainty sample 13 after 1457 steps.
Found uncertainty sample 14 after 3351 steps.
Found uncertainty sample 15 after 1272 steps.
Found uncertainty sample 16 after 1093 steps.
Found uncertainty sample 17 after 658 steps.
Found uncertainty sample 21 after 134 steps.
Found uncertainty sample 23 after 460 steps.
Found uncertainty sample 24 after 45 steps.
Found uncertainty sample 25 after 226 steps.
Found uncertainty sample 26 after 3470 steps.
Found uncertainty sample 28 after 3094 steps.
Found uncertainty sample 29 after 2080 steps.
Found uncertainty sample 30 after 2503 steps.
Found uncertainty sample 31 after 1879 steps.
Found uncertainty sample 35 after 3618 steps.
Found uncertainty sample 37 after 2586 steps.
Found uncertainty sample 39 after 50 steps.
Found uncertainty sample 40 after 1893 steps.
Found uncertainty sample 41 after 1318 steps.
Found uncertainty sample 42 after 569 steps.
Found uncertainty sample 43 after 884 steps.
Found uncertainty sample 44 after 1218 steps.
Found uncertainty sample 46 after 2203 steps.
Found uncertainty sample 47 after 2959 steps.
Found uncertainty sample 49 after 1326 steps.
Found uncertainty sample 50 after 2173 steps.
Found uncertainty sample 51 after 1005 steps.
Found uncertainty sample 52 after 919 steps.
Found uncertainty sample 53 after 908 steps.
Found uncertainty sample 56 after 3103 steps.
Found uncertainty sample 57 after 1178 steps.
Found uncertainty sample 59 after 852 steps.
Found uncertainty sample 61 after 633 steps.
Found uncertainty sample 63 after 451 steps.
Found uncertainty sample 64 after 969 steps.
Found uncertainty sample 65 after 120 steps.
Found uncertainty sample 66 after 3652 steps.
Found uncertainty sample 67 after 313 steps.
Found uncertainty sample 68 after 559 steps.
Found uncertainty sample 70 after 2428 steps.
Found uncertainty sample 71 after 1263 steps.
Found uncertainty sample 72 after 3949 steps.
Found uncertainty sample 73 after 13 steps.
Found uncertainty sample 74 after 840 steps.
Found uncertainty sample 76 after 918 steps.
Found uncertainty sample 79 after 84 steps.
Found uncertainty sample 81 after 976 steps.
Found uncertainty sample 83 after 3850 steps.
Found uncertainty sample 84 after 841 steps.
Found uncertainty sample 86 after 68 steps.
Found uncertainty sample 87 after 2893 steps.
Found uncertainty sample 88 after 3292 steps.
Found uncertainty sample 91 after 978 steps.
Found uncertainty sample 92 after 1436 steps.
Found uncertainty sample 93 after 1574 steps.
Found uncertainty sample 94 after 894 steps.
Found uncertainty sample 95 after 726 steps.
Found uncertainty sample 96 after 3859 steps.
Found uncertainty sample 99 after 2399 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_183550-qgol9mdl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qgol9mdl
Training model 0. Added 69 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.384761372059645, Training Loss Force: 3.035181306565375, time: 1.0143578052520752
Validation Loss Energy: 1.23124592503966, Validation Loss Force: 2.776435750952659, time: 0.07066679000854492
Test Loss Energy: 11.938175937414961, Test Loss Force: 10.360448131385938, time: 15.990667819976807


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.408830849011686, Training Loss Force: 2.630320529546023, time: 0.9684827327728271
Validation Loss Energy: 1.8398712869795633, Validation Loss Force: 2.6912329609474126, time: 0.06943774223327637
Test Loss Energy: 11.549434164195695, Test Loss Force: 10.370537874275977, time: 16.124412298202515


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4683700055670903, Training Loss Force: 2.5440805796470665, time: 0.9457859992980957
Validation Loss Energy: 1.1201001755115128, Validation Loss Force: 2.660498384073292, time: 0.07200145721435547
Test Loss Energy: 11.874220313091604, Test Loss Force: 10.18820005629165, time: 16.02809190750122


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3513870730337545, Training Loss Force: 2.534016363095412, time: 0.975085973739624
Validation Loss Energy: 1.1878970297141571, Validation Loss Force: 2.655480312200663, time: 0.06613516807556152
Test Loss Energy: 11.69157352359729, Test Loss Force: 10.26547744633947, time: 16.214299201965332


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4907043456143072, Training Loss Force: 2.516585797611168, time: 0.9612009525299072
Validation Loss Energy: 1.420920958935025, Validation Loss Force: 2.6584587346965933, time: 0.07127046585083008
Test Loss Energy: 11.470890898887468, Test Loss Force: 10.189008888557453, time: 16.117172718048096


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3720119964799429, Training Loss Force: 2.488577606500803, time: 0.9681093692779541
Validation Loss Energy: 1.1251696839568506, Validation Loss Force: 2.636795030820133, time: 0.07240176200866699
Test Loss Energy: 11.823122519246837, Test Loss Force: 10.166487133207484, time: 16.289467334747314


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4264660763055563, Training Loss Force: 2.4894016885158714, time: 0.9687294960021973
Validation Loss Energy: 1.830544233129513, Validation Loss Force: 2.6306259821322033, time: 0.06982016563415527
Test Loss Energy: 12.363232749363558, Test Loss Force: 10.20959926069954, time: 16.28991389274597


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5525817364388392, Training Loss Force: 2.4956354926902384, time: 0.9885938167572021
Validation Loss Energy: 1.1241348291011513, Validation Loss Force: 2.630725737909579, time: 0.07001948356628418
Test Loss Energy: 11.6209272533578, Test Loss Force: 10.186498989923923, time: 16.29477596282959


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3325915498084766, Training Loss Force: 2.5142683643514223, time: 0.9870195388793945
Validation Loss Energy: 1.3514064349406936, Validation Loss Force: 2.6477913239226307, time: 0.07340407371520996
Test Loss Energy: 11.422407753770997, Test Loss Force: 10.186573009344933, time: 16.4256374835968


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4927432218342491, Training Loss Force: 2.5268648486536165, time: 0.9593238830566406
Validation Loss Energy: 1.1297556663518065, Validation Loss Force: 2.6272055613816065, time: 0.06815958023071289
Test Loss Energy: 11.556505879792812, Test Loss Force: 10.113127006850407, time: 16.37386655807495


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.19493788377568, Training Loss Force: 2.4800906627208255, time: 0.9686410427093506
Validation Loss Energy: 1.3417948099221475, Validation Loss Force: 2.6476615078105548, time: 0.0684194564819336
Test Loss Energy: 11.35192139961572, Test Loss Force: 10.18818443914045, time: 16.50856113433838


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.636143265157474, Training Loss Force: 2.4701622743481866, time: 0.983985185623169
Validation Loss Energy: 1.2714954885229939, Validation Loss Force: 2.707210362844315, time: 0.07079243659973145
Test Loss Energy: 11.393385374390284, Test Loss Force: 10.091116462553664, time: 16.569475650787354


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6951746535901084, Training Loss Force: 2.5387485772667016, time: 0.9829151630401611
Validation Loss Energy: 1.1525549828724986, Validation Loss Force: 2.6067182186030826, time: 0.0775139331817627
Test Loss Energy: 11.647920545573657, Test Loss Force: 10.059459307951803, time: 17.218719244003296


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.403195756812189, Training Loss Force: 2.4968713064501378, time: 0.9435489177703857
Validation Loss Energy: 2.590349587016785, Validation Loss Force: 2.6290439178503866, time: 0.0749976634979248
Test Loss Energy: 10.944148325323798, Test Loss Force: 10.199874634586854, time: 16.936707973480225


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5188402354181099, Training Loss Force: 2.501972310209116, time: 0.9847970008850098
Validation Loss Energy: 1.299055137379903, Validation Loss Force: 2.6208830936521332, time: 0.07159709930419922
Test Loss Energy: 11.674081544822702, Test Loss Force: 10.00309157195358, time: 16.808595180511475


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2161258612071197, Training Loss Force: 2.4745492688732345, time: 0.9664373397827148
Validation Loss Energy: 1.2181379490917559, Validation Loss Force: 2.6342708533818953, time: 0.06904792785644531
Test Loss Energy: 11.613059193619966, Test Loss Force: 10.130868645535672, time: 17.007864713668823


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.159925634680157, Training Loss Force: 2.476292677568789, time: 0.9657096862792969
Validation Loss Energy: 1.1164990587489956, Validation Loss Force: 2.623014260047808, time: 0.07314133644104004
Test Loss Energy: 11.546414849851793, Test Loss Force: 9.977235543164731, time: 16.832149028778076


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4638421006459463, Training Loss Force: 2.4521272528498086, time: 0.9978258609771729
Validation Loss Energy: 1.1928982900662681, Validation Loss Force: 2.614040916136064, time: 0.07172369956970215
Test Loss Energy: 11.536346585790783, Test Loss Force: 10.04971202787659, time: 17.09766411781311


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3875452311597574, Training Loss Force: 2.4652446716189007, time: 0.9824037551879883
Validation Loss Energy: 1.1194770359066337, Validation Loss Force: 2.640970077306279, time: 0.0737605094909668
Test Loss Energy: 11.318794875801833, Test Loss Force: 10.019996613512417, time: 16.962181568145752


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3446203947904143, Training Loss Force: 2.4591652720032235, time: 0.9775345325469971
Validation Loss Energy: 1.6618331653195304, Validation Loss Force: 2.609844493411909, time: 0.07019400596618652
Test Loss Energy: 11.029138121215802, Test Loss Force: 10.050450939698957, time: 17.00000500679016

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–„â–†â–…â–„â–…â–ˆâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–â–…â–„â–„â–„â–ƒâ–
wandb:   test_error_force â–ˆâ–ˆâ–…â–†â–…â–„â–…â–…â–…â–ƒâ–…â–ƒâ–‚â–…â–â–„â–â–‚â–‚â–‚
wandb:          test_loss â–ˆâ–‡â–…â–…â–„â–„â–†â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–â–‚â–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–
wandb: valid_error_energy â–‚â–„â–â–â–‚â–â–„â–â–‚â–â–‚â–‚â–â–ˆâ–‚â–â–â–â–â–„
wandb:  valid_error_force â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–…â–â–‚â–‚â–‚â–‚â–â–‚â–
wandb:         valid_loss â–ˆâ–…â–‚â–‚â–ƒâ–‚â–„â–â–‚â–â–ƒâ–„â–ƒâ–…â–‚â–ƒâ–â–„â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 862
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.02914
wandb:   test_error_force 10.05045
wandb:          test_loss 5.59375
wandb: train_error_energy 1.34462
wandb:  train_error_force 2.45917
wandb:         train_loss 1.10551
wandb: valid_error_energy 1.66183
wandb:  valid_error_force 2.60984
wandb:         valid_loss 1.30574
wandb: 
wandb: ğŸš€ View run al_55_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qgol9mdl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_183550-qgol9mdl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.734303891658783, Uncertainty Bias: 0.014710575342178345
9.536743e-06 0.026553392
0.26015446 3.3277085
Found uncertainty sample 0 after 1723 steps.
Found uncertainty sample 1 after 1377 steps.
Found uncertainty sample 2 after 2881 steps.
Found uncertainty sample 3 after 2169 steps.
Found uncertainty sample 5 after 536 steps.
Found uncertainty sample 14 after 1021 steps.
Found uncertainty sample 15 after 2023 steps.
Found uncertainty sample 16 after 1147 steps.
Found uncertainty sample 19 after 31 steps.
Found uncertainty sample 20 after 38 steps.
Found uncertainty sample 21 after 1316 steps.
Found uncertainty sample 22 after 1359 steps.
Found uncertainty sample 23 after 2058 steps.
Found uncertainty sample 27 after 3092 steps.
Found uncertainty sample 28 after 1605 steps.
Found uncertainty sample 29 after 142 steps.
Found uncertainty sample 30 after 119 steps.
Found uncertainty sample 31 after 1270 steps.
Found uncertainty sample 32 after 1077 steps.
Found uncertainty sample 33 after 41 steps.
Found uncertainty sample 35 after 1580 steps.
Found uncertainty sample 36 after 1392 steps.
Found uncertainty sample 39 after 187 steps.
Found uncertainty sample 40 after 2683 steps.
Found uncertainty sample 41 after 642 steps.
Found uncertainty sample 42 after 248 steps.
Found uncertainty sample 43 after 1053 steps.
Found uncertainty sample 44 after 1791 steps.
Found uncertainty sample 47 after 1646 steps.
Found uncertainty sample 49 after 917 steps.
Found uncertainty sample 50 after 177 steps.
Found uncertainty sample 51 after 3208 steps.
Found uncertainty sample 52 after 1538 steps.
Found uncertainty sample 53 after 2201 steps.
Found uncertainty sample 54 after 656 steps.
Found uncertainty sample 55 after 2438 steps.
Found uncertainty sample 57 after 1950 steps.
Found uncertainty sample 58 after 2661 steps.
Found uncertainty sample 61 after 697 steps.
Found uncertainty sample 62 after 405 steps.
Found uncertainty sample 63 after 86 steps.
Found uncertainty sample 64 after 1103 steps.
Found uncertainty sample 66 after 94 steps.
Found uncertainty sample 68 after 79 steps.
Found uncertainty sample 70 after 3365 steps.
Found uncertainty sample 71 after 3852 steps.
Found uncertainty sample 73 after 37 steps.
Found uncertainty sample 74 after 3337 steps.
Found uncertainty sample 78 after 364 steps.
Found uncertainty sample 79 after 1078 steps.
Found uncertainty sample 81 after 2327 steps.
Found uncertainty sample 82 after 2886 steps.
Found uncertainty sample 83 after 3981 steps.
Found uncertainty sample 84 after 948 steps.
Found uncertainty sample 85 after 370 steps.
Found uncertainty sample 86 after 3060 steps.
Found uncertainty sample 87 after 571 steps.
Found uncertainty sample 89 after 624 steps.
Found uncertainty sample 90 after 3578 steps.
Found uncertainty sample 92 after 181 steps.
Found uncertainty sample 94 after 1268 steps.
Found uncertainty sample 95 after 3862 steps.
Found uncertainty sample 99 after 7 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_203319-afxxun9s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/afxxun9s
Training model 1. Added 63 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.1617748509174195, Training Loss Force: 3.157047984244972, time: 1.0437922477722168
Validation Loss Energy: 1.58618265900544, Validation Loss Force: 2.8828653679700555, time: 0.07887816429138184
Test Loss Energy: 10.94842160970655, Test Loss Force: 9.768370172879722, time: 16.235610485076904


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.875188988021413, Training Loss Force: 2.7624023581951556, time: 1.0567450523376465
Validation Loss Energy: 2.584766603520938, Validation Loss Force: 2.7106937989632094, time: 0.07277655601501465
Test Loss Energy: 12.297342085861414, Test Loss Force: 9.771189280847873, time: 16.33895754814148


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7266163270013544, Training Loss Force: 2.676794387126785, time: 1.0218281745910645
Validation Loss Energy: 1.443553384930844, Validation Loss Force: 2.6861997475728607, time: 0.07135725021362305
Test Loss Energy: 11.541231830271736, Test Loss Force: 9.77622425692268, time: 16.211690187454224


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5026454860398966, Training Loss Force: 2.670908581270722, time: 1.0536072254180908
Validation Loss Energy: 1.261581256135132, Validation Loss Force: 2.686286143201481, time: 0.07363343238830566
Test Loss Energy: 10.999834232075898, Test Loss Force: 9.808460770994488, time: 16.33811593055725


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.339796644191248, Training Loss Force: 2.655376617482878, time: 1.0120429992675781
Validation Loss Energy: 2.2685855457384623, Validation Loss Force: 2.6803419903509385, time: 0.07648444175720215
Test Loss Energy: 12.002296849861409, Test Loss Force: 9.719064121874782, time: 16.28484869003296


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6285299846734365, Training Loss Force: 2.6514505842060974, time: 1.0818908214569092
Validation Loss Energy: 1.1714670527781563, Validation Loss Force: 2.7040295340947367, time: 0.07486724853515625
Test Loss Energy: 11.247994905561299, Test Loss Force: 9.75358753434499, time: 16.569846153259277


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6990836998131278, Training Loss Force: 2.681029239474229, time: 1.0745525360107422
Validation Loss Energy: 1.5431095394171688, Validation Loss Force: 2.6746127132262165, time: 0.07333827018737793
Test Loss Energy: 10.862998180225441, Test Loss Force: 9.703626929315584, time: 16.47455334663391


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3277487902884213, Training Loss Force: 2.648004740781633, time: 1.0515751838684082
Validation Loss Energy: 1.6069139358333278, Validation Loss Force: 2.6668678349925563, time: 0.07212305068969727
Test Loss Energy: 11.553817584701761, Test Loss Force: 9.705313395115857, time: 16.657240867614746


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.451560114401869, Training Loss Force: 2.6600616530956636, time: 1.05928635597229
Validation Loss Energy: 1.1535622267541028, Validation Loss Force: 2.6699622681135144, time: 0.07344222068786621
Test Loss Energy: 11.146958629041647, Test Loss Force: 9.711858259192411, time: 16.43461847305298


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6709928276391297, Training Loss Force: 2.650577260459276, time: 1.0608186721801758
Validation Loss Energy: 1.1609568464212188, Validation Loss Force: 2.672243068175253, time: 0.0764927864074707
Test Loss Energy: 10.977697146419072, Test Loss Force: 9.685623884047844, time: 16.30374312400818


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7742601588720306, Training Loss Force: 2.6687412964039283, time: 1.0687003135681152
Validation Loss Energy: 1.371827422313731, Validation Loss Force: 2.696720864717949, time: 0.07450127601623535
Test Loss Energy: 11.368397876514491, Test Loss Force: 9.696691393971212, time: 16.600988149642944


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7119483425344493, Training Loss Force: 2.6395058280373975, time: 1.0591349601745605
Validation Loss Energy: 1.6382557314683937, Validation Loss Force: 2.6747106876504247, time: 0.07994604110717773
Test Loss Energy: 10.770766791996705, Test Loss Force: 9.718809071272323, time: 16.644575119018555


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3918779131822452, Training Loss Force: 2.673663720361011, time: 1.1151492595672607
Validation Loss Energy: 1.353011322809968, Validation Loss Force: 2.6709616072404385, time: 0.0747992992401123
Test Loss Energy: 10.792344994418547, Test Loss Force: 9.702451604620114, time: 16.802378177642822


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3836116321086562, Training Loss Force: 2.650885948999749, time: 1.0657289028167725
Validation Loss Energy: 1.596046790835468, Validation Loss Force: 2.6834655931300135, time: 0.07274937629699707
Test Loss Energy: 10.677351480079714, Test Loss Force: 9.65018017883171, time: 16.87101435661316


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4305107930902559, Training Loss Force: 2.6459325817096286, time: 1.089782476425171
Validation Loss Energy: 1.2569639887251733, Validation Loss Force: 2.6613316120173534, time: 0.07447600364685059
Test Loss Energy: 11.290856641015854, Test Loss Force: 9.62970856512186, time: 16.944418907165527


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5006747239704388, Training Loss Force: 2.6119000905064036, time: 1.0732877254486084
Validation Loss Energy: 1.5877299869004922, Validation Loss Force: 2.655043880674645, time: 0.07546448707580566
Test Loss Energy: 11.450919402410987, Test Loss Force: 9.665656155459736, time: 17.231143951416016


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5362044962586077, Training Loss Force: 2.6310162827537824, time: 1.0546760559082031
Validation Loss Energy: 1.1538691761717643, Validation Loss Force: 2.6753922779061097, time: 0.0793619155883789
Test Loss Energy: 10.979961176346444, Test Loss Force: 9.644999476876059, time: 16.777384996414185


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3982177836572105, Training Loss Force: 2.6408216951943806, time: 1.1461429595947266
Validation Loss Energy: 1.137126571754881, Validation Loss Force: 2.6688055019004198, time: 0.09805130958557129
Test Loss Energy: 11.019458900955975, Test Loss Force: 9.582291643814196, time: 16.996574640274048


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4207250542365253, Training Loss Force: 2.6480240285366183, time: 1.1001029014587402
Validation Loss Energy: 1.1989666923002382, Validation Loss Force: 2.690420886572214, time: 0.07393527030944824
Test Loss Energy: 11.22696941692354, Test Loss Force: 9.626217210841505, time: 17.08795738220215


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.584503426515288, Training Loss Force: 2.6270003756027576, time: 1.044532060623169
Validation Loss Energy: 1.217412493014323, Validation Loss Force: 2.6627595892501885, time: 0.07345318794250488
Test Loss Energy: 11.180429560236512, Test Loss Force: 9.656248834045806, time: 16.939852237701416

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–…â–‚â–‡â–ƒâ–‚â–…â–ƒâ–‚â–„â–â–â–â–„â–„â–‚â–‚â–ƒâ–ƒ
wandb:   test_error_force â–‡â–‡â–‡â–ˆâ–…â–†â–…â–…â–…â–„â–…â–…â–…â–ƒâ–‚â–„â–ƒâ–â–‚â–ƒ
wandb:          test_loss â–…â–ˆâ–‡â–†â–†â–…â–ƒâ–„â–…â–‚â–…â–‚â–‚â–â–ƒâ–ƒâ–‚â–â–â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–ˆâ–‚â–‚â–†â–â–ƒâ–ƒâ–â–â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–â–â–
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–‚â–
wandb:         valid_loss â–ˆâ–…â–ƒâ–‚â–„â–„â–ƒâ–‚â–„â–‚â–„â–ƒâ–‚â–‚â–â–‚â–â–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 918
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.18043
wandb:   test_error_force 9.65625
wandb:          test_loss 5.39924
wandb: train_error_energy 1.5845
wandb:  train_error_force 2.627
wandb:         train_loss 1.20472
wandb: valid_error_energy 1.21741
wandb:  valid_error_force 2.66276
wandb:         valid_loss 1.3676
wandb: 
wandb: ğŸš€ View run al_55_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/afxxun9s
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_203319-afxxun9s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6627286672592163, Uncertainty Bias: 0.03025926649570465
6.389618e-05 0.013895988
1.0295689 5.5197115
Found uncertainty sample 2 after 91 steps.
Found uncertainty sample 6 after 84 steps.
Found uncertainty sample 7 after 498 steps.
Found uncertainty sample 9 after 1403 steps.
Found uncertainty sample 12 after 1734 steps.
Found uncertainty sample 14 after 2521 steps.
Found uncertainty sample 19 after 1397 steps.
Found uncertainty sample 20 after 1112 steps.
Found uncertainty sample 21 after 3278 steps.
Found uncertainty sample 23 after 3672 steps.
Found uncertainty sample 24 after 2126 steps.
Found uncertainty sample 26 after 2777 steps.
Found uncertainty sample 27 after 3532 steps.
Found uncertainty sample 28 after 1519 steps.
Found uncertainty sample 30 after 3023 steps.
Found uncertainty sample 33 after 1074 steps.
Found uncertainty sample 34 after 272 steps.
Found uncertainty sample 37 after 2069 steps.
Found uncertainty sample 39 after 271 steps.
Found uncertainty sample 40 after 3730 steps.
Found uncertainty sample 41 after 1046 steps.
Found uncertainty sample 45 after 741 steps.
Found uncertainty sample 47 after 39 steps.
Found uncertainty sample 48 after 1715 steps.
Found uncertainty sample 55 after 781 steps.
Found uncertainty sample 62 after 1418 steps.
Found uncertainty sample 64 after 2353 steps.
Found uncertainty sample 67 after 906 steps.
Found uncertainty sample 70 after 3961 steps.
Found uncertainty sample 72 after 1398 steps.
Found uncertainty sample 73 after 3180 steps.
Found uncertainty sample 74 after 1004 steps.
Found uncertainty sample 75 after 1992 steps.
Found uncertainty sample 79 after 1300 steps.
Found uncertainty sample 85 after 3442 steps.
Found uncertainty sample 91 after 3064 steps.
Found uncertainty sample 93 after 1721 steps.
Found uncertainty sample 95 after 1441 steps.
Found uncertainty sample 96 after 746 steps.
Found uncertainty sample 98 after 1479 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_230331-4m22u2wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4m22u2wh
Training model 2. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.108862662081089, Training Loss Force: 3.049117841827581, time: 1.0607233047485352
Validation Loss Energy: 1.9796389285252682, Validation Loss Force: 2.798964079122757, time: 0.07607054710388184
Test Loss Energy: 10.55717490419177, Test Loss Force: 9.569179704705236, time: 16.47830295562744


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.754302568066628, Training Loss Force: 2.8412105320844665, time: 1.0830836296081543
Validation Loss Energy: 1.2871673883516834, Validation Loss Force: 2.715899580925855, time: 0.0790410041809082
Test Loss Energy: 10.666536759093132, Test Loss Force: 9.441373546568942, time: 16.62801766395569


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6706390843004513, Training Loss Force: 2.7935470954751986, time: 1.1046695709228516
Validation Loss Energy: 1.214107637550463, Validation Loss Force: 2.713287894513268, time: 0.0749349594116211
Test Loss Energy: 10.750645988280128, Test Loss Force: 9.489744741566328, time: 16.55025577545166


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4663948694210462, Training Loss Force: 2.7786358111820832, time: 1.0929434299468994
Validation Loss Energy: 1.3278581707476733, Validation Loss Force: 2.711310369828283, time: 0.07599663734436035
Test Loss Energy: 10.669454275165714, Test Loss Force: 9.478511868908221, time: 16.68919062614441


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3521869904982864, Training Loss Force: 2.7812383607373827, time: 1.0706181526184082
Validation Loss Energy: 1.6484810326531165, Validation Loss Force: 2.7072854023464927, time: 0.07523584365844727
Test Loss Energy: 11.183833637538122, Test Loss Force: 9.413530227129481, time: 16.63750696182251


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5383073044588402, Training Loss Force: 2.777397214057861, time: 1.0648999214172363
Validation Loss Energy: 1.5431203388707462, Validation Loss Force: 2.725815928670603, time: 0.0754537582397461
Test Loss Energy: 11.178970781215694, Test Loss Force: 9.423285887025747, time: 16.55730628967285


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4091389517730535, Training Loss Force: 2.7658899175323723, time: 1.1002135276794434
Validation Loss Energy: 1.2010950753315888, Validation Loss Force: 2.6994432176960617, time: 0.07905983924865723
Test Loss Energy: 10.606103821280316, Test Loss Force: 9.403895046396652, time: 16.628926038742065


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3108794498240244, Training Loss Force: 2.7525900156252887, time: 1.109224557876587
Validation Loss Energy: 1.3619637358219947, Validation Loss Force: 2.6959161384245656, time: 0.07782244682312012
Test Loss Energy: 11.070279955523983, Test Loss Force: 9.418001983167093, time: 16.534295320510864


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5582424073441246, Training Loss Force: 2.7455410601180064, time: 1.0982439517974854
Validation Loss Energy: 1.2545494758413054, Validation Loss Force: 2.6974465434645274, time: 0.07464933395385742
Test Loss Energy: 10.596338895549643, Test Loss Force: 9.3925246038438, time: 16.988696098327637


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5567297379016367, Training Loss Force: 2.7610830621892664, time: 1.0956311225891113
Validation Loss Energy: 1.1716977380133375, Validation Loss Force: 2.687615032664378, time: 0.07360124588012695
Test Loss Energy: 10.606055123188362, Test Loss Force: 9.411624081312548, time: 16.58610510826111


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4793359678331113, Training Loss Force: 2.7655681531942027, time: 1.076812744140625
Validation Loss Energy: 1.852930387049936, Validation Loss Force: 2.6982100759659136, time: 0.0775444507598877
Test Loss Energy: 11.295251369850273, Test Loss Force: 9.364981558993753, time: 16.686506032943726


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4571148080386676, Training Loss Force: 2.7582439118218094, time: 1.1076858043670654
Validation Loss Energy: 1.916615098800159, Validation Loss Force: 2.6875876443594287, time: 0.0759432315826416
Test Loss Energy: 10.319666629382992, Test Loss Force: 9.376229148800022, time: 16.864549160003662


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8379815644499706, Training Loss Force: 2.774088068501789, time: 1.0939664840698242
Validation Loss Energy: 1.1564308733610906, Validation Loss Force: 2.6853335645952017, time: 0.0773916244506836
Test Loss Energy: 10.596523144358539, Test Loss Force: 9.399307521056068, time: 17.10445737838745


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6906249390508215, Training Loss Force: 2.7614685544370015, time: 1.1346302032470703
Validation Loss Energy: 1.5322996203898125, Validation Loss Force: 2.700709759798099, time: 0.07488870620727539
Test Loss Energy: 11.031554839223697, Test Loss Force: 9.368841308300881, time: 17.180537939071655


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4004562634642181, Training Loss Force: 2.7653402810125645, time: 1.10341477394104
Validation Loss Energy: 1.5784741871771388, Validation Loss Force: 2.6796673028387774, time: 0.0812840461730957
Test Loss Energy: 10.995151427657001, Test Loss Force: 9.31178452437929, time: 17.089200973510742


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4450613523432012, Training Loss Force: 2.739037228369175, time: 1.1187491416931152
Validation Loss Energy: 1.2054563845583035, Validation Loss Force: 2.680715629177805, time: 0.07497501373291016
Test Loss Energy: 10.780886356230997, Test Loss Force: 9.362527008215576, time: 17.239914655685425


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3929759588541728, Training Loss Force: 2.744289310669564, time: 1.0900726318359375
Validation Loss Energy: 1.4050350740570987, Validation Loss Force: 2.68382832116873, time: 0.07762622833251953
Test Loss Energy: 10.413601103157264, Test Loss Force: 9.342965801207898, time: 17.52904224395752


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4462750327899947, Training Loss Force: 2.7358746510672574, time: 1.1361477375030518
Validation Loss Energy: 1.1538561500267275, Validation Loss Force: 2.683875081689375, time: 0.08203554153442383
Test Loss Energy: 10.646210265044463, Test Loss Force: 9.318630320560432, time: 17.230084896087646


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.2984486014710055, Training Loss Force: 2.742756471113606, time: 1.0720350742340088
Validation Loss Energy: 1.1767449795440827, Validation Loss Force: 2.675501163118468, time: 0.07706451416015625
Test Loss Energy: 10.67922544495893, Test Loss Force: 9.320290756220967, time: 17.22734522819519


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3938291732096582, Training Loss Force: 2.7456198107726166, time: 1.079038143157959
Validation Loss Energy: 1.1388548183309994, Validation Loss Force: 2.6738781277138006, time: 0.07835626602172852
Test Loss Energy: 10.639621655224285, Test Loss Force: 9.315789169512641, time: 17.175182819366455

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–„â–„â–‡â–‡â–ƒâ–†â–ƒâ–ƒâ–ˆâ–â–ƒâ–†â–†â–„â–‚â–ƒâ–„â–ƒ
wandb:   test_error_force â–ˆâ–…â–†â–†â–„â–„â–„â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–â–â–
wandb:          test_loss â–ˆâ–…â–ˆâ–‡â–…â–†â–ƒâ–…â–‚â–ƒâ–…â–â–„â–ƒâ–ƒâ–ƒâ–â–â–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–‚â–ƒâ–…â–„â–‚â–ƒâ–‚â–â–‡â–‡â–â–„â–…â–‚â–ƒâ–â–â–
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–‚â–â–
wandb:         valid_loss â–ˆâ–ƒâ–…â–‚â–ƒâ–ƒâ–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–†â–‚â–„â–â–‚â–…â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 954
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.63962
wandb:   test_error_force 9.31579
wandb:          test_loss 5.15501
wandb: train_error_energy 1.39383
wandb:  train_error_force 2.74562
wandb:         train_loss 1.23224
wandb: valid_error_energy 1.13885
wandb:  valid_error_force 2.67388
wandb:         valid_loss 1.33425
wandb: 
wandb: ğŸš€ View run al_55_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4m22u2wh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_230331-4m22u2wh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6801798939704895, Uncertainty Bias: 0.027707546949386597
0.00019073486 0.0008176565
0.50942403 5.327008
Found uncertainty sample 1 after 2204 steps.
Found uncertainty sample 2 after 1460 steps.
Found uncertainty sample 3 after 45 steps.
Found uncertainty sample 5 after 3690 steps.
Found uncertainty sample 8 after 399 steps.
Found uncertainty sample 9 after 1357 steps.
Found uncertainty sample 10 after 2574 steps.
Found uncertainty sample 13 after 880 steps.
Found uncertainty sample 14 after 1456 steps.
Found uncertainty sample 15 after 3047 steps.
Found uncertainty sample 16 after 2864 steps.
Found uncertainty sample 22 after 1141 steps.
Found uncertainty sample 25 after 994 steps.
Found uncertainty sample 26 after 236 steps.
Found uncertainty sample 27 after 1890 steps.
Found uncertainty sample 28 after 813 steps.
Found uncertainty sample 29 after 1299 steps.
Found uncertainty sample 31 after 1368 steps.
Found uncertainty sample 32 after 225 steps.
Found uncertainty sample 34 after 3580 steps.
Found uncertainty sample 36 after 3791 steps.
Found uncertainty sample 43 after 17 steps.
Found uncertainty sample 44 after 1457 steps.
Found uncertainty sample 47 after 2337 steps.
Found uncertainty sample 48 after 2149 steps.
Found uncertainty sample 49 after 1906 steps.
Found uncertainty sample 53 after 659 steps.
Found uncertainty sample 57 after 1858 steps.
Found uncertainty sample 59 after 2206 steps.
Found uncertainty sample 61 after 2000 steps.
Found uncertainty sample 62 after 2187 steps.
Found uncertainty sample 64 after 1249 steps.
Found uncertainty sample 65 after 2230 steps.
Found uncertainty sample 68 after 596 steps.
Found uncertainty sample 69 after 732 steps.
Found uncertainty sample 70 after 1389 steps.
Found uncertainty sample 72 after 3349 steps.
Found uncertainty sample 73 after 1360 steps.
Found uncertainty sample 74 after 3756 steps.
Found uncertainty sample 77 after 2235 steps.
Found uncertainty sample 79 after 1113 steps.
Found uncertainty sample 83 after 1107 steps.
Found uncertainty sample 85 after 3722 steps.
Found uncertainty sample 86 after 3748 steps.
Found uncertainty sample 90 after 2191 steps.
Found uncertainty sample 97 after 1065 steps.
Found uncertainty sample 98 after 1184 steps.
Found uncertainty sample 99 after 478 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_012545-nyysy38s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nyysy38s
Training model 3. Added 48 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.689346306651223, Training Loss Force: 3.2106886542137225, time: 1.1687016487121582
Validation Loss Energy: 1.516457601333634, Validation Loss Force: 2.878809004138689, time: 0.07903242111206055
Test Loss Energy: 10.710576146194027, Test Loss Force: 9.412506555277876, time: 16.60508942604065


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2479131301076185, Training Loss Force: 3.0333354280545093, time: 1.1699035167694092
Validation Loss Energy: 2.6722878246735844, Validation Loss Force: 2.773919144265383, time: 0.07724642753601074
Test Loss Energy: 10.210417741184457, Test Loss Force: 9.217192488798375, time: 16.804198265075684


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1230891106775864, Training Loss Force: 2.9077890664358828, time: 1.155165195465088
Validation Loss Energy: 3.2489038288789303, Validation Loss Force: 2.777893788520194, time: 0.0766298770904541
Test Loss Energy: 10.163661939726548, Test Loss Force: 9.229836426326491, time: 16.659226417541504


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1667639936327276, Training Loss Force: 2.9084649786283467, time: 1.1619155406951904
Validation Loss Energy: 1.2576429069511073, Validation Loss Force: 2.7389019717076333, time: 0.08240032196044922
Test Loss Energy: 10.364835441024313, Test Loss Force: 9.177634459321931, time: 16.7433180809021


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8697433375209056, Training Loss Force: 2.8754288795450944, time: 1.146892786026001
Validation Loss Energy: 1.2537454175553602, Validation Loss Force: 2.7334957875136525, time: 0.08170437812805176
Test Loss Energy: 10.318383831267496, Test Loss Force: 9.1678475371439, time: 16.733916997909546


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7323329533153191, Training Loss Force: 2.901252662366048, time: 1.144270658493042
Validation Loss Energy: 1.3654274657214744, Validation Loss Force: 2.7260524033035782, time: 0.08226561546325684
Test Loss Energy: 10.223142128725257, Test Loss Force: 9.144497004901172, time: 16.957878589630127


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.484636701718256, Training Loss Force: 2.9062597747416508, time: 1.1755871772766113
Validation Loss Energy: 1.3100971889918893, Validation Loss Force: 2.750695197683407, time: 0.0785055160522461
Test Loss Energy: 10.426472069949662, Test Loss Force: 9.167252597828575, time: 16.770692348480225


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4904312974452538, Training Loss Force: 2.9034707184375104, time: 1.1681561470031738
Validation Loss Energy: 1.4157188510132868, Validation Loss Force: 2.756281966554735, time: 0.07693886756896973
Test Loss Energy: 10.519872217048587, Test Loss Force: 9.116234824979502, time: 16.684993505477905


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.625211134465752, Training Loss Force: 2.853992444324107, time: 1.1672136783599854
Validation Loss Energy: 1.372172002817054, Validation Loss Force: 2.744600965828509, time: 0.07585382461547852
Test Loss Energy: 10.4602240445809, Test Loss Force: 9.117359427741983, time: 16.7909255027771


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6047102784534344, Training Loss Force: 2.8707553325085025, time: 1.1534950733184814
Validation Loss Energy: 1.330899608611901, Validation Loss Force: 2.7457552826809986, time: 0.07843589782714844
Test Loss Energy: 10.177591300767629, Test Loss Force: 9.070921476580525, time: 16.77046227455139


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6046393165799917, Training Loss Force: 2.8903075692502918, time: 1.2622478008270264
Validation Loss Energy: 1.920259302042413, Validation Loss Force: 2.7341197064605423, time: 0.07914590835571289
Test Loss Energy: 9.916680797168445, Test Loss Force: 9.083207082328297, time: 16.649051904678345


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9248663162340427, Training Loss Force: 2.868766695241454, time: 1.1387171745300293
Validation Loss Energy: 2.027974388039251, Validation Loss Force: 2.763534077968457, time: 0.0814361572265625
Test Loss Energy: 9.886333086367944, Test Loss Force: 9.094951455159775, time: 17.044336557388306


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8664188175880956, Training Loss Force: 2.922169874889196, time: 1.1725358963012695
Validation Loss Energy: 3.6581545775922812, Validation Loss Force: 2.8185086407374227, time: 0.07884788513183594
Test Loss Energy: 9.984605570132196, Test Loss Force: 9.096451154007934, time: 16.986225605010986


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.332294563217645, Training Loss Force: 2.9311664251009923, time: 1.1572351455688477
Validation Loss Energy: 1.390263536919968, Validation Loss Force: 2.7298043784124615, time: 0.07910680770874023
Test Loss Energy: 9.953950240157885, Test Loss Force: 9.003238981637228, time: 17.579962968826294


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.62952581712123, Training Loss Force: 2.8637391738469447, time: 1.1390409469604492
Validation Loss Energy: 1.2643142972322496, Validation Loss Force: 2.755297546260588, time: 0.07752275466918945
Test Loss Energy: 10.013157252586172, Test Loss Force: 9.006154380604212, time: 17.239928483963013


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4193729839077673, Training Loss Force: 2.879952396286207, time: 1.2228772640228271
Validation Loss Energy: 1.445415901001957, Validation Loss Force: 2.75375600776333, time: 0.07868075370788574
Test Loss Energy: 9.947331431271973, Test Loss Force: 8.985029318054979, time: 17.20814871788025


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6235468861334579, Training Loss Force: 2.918678805393643, time: 1.1915764808654785
Validation Loss Energy: 1.473488690905657, Validation Loss Force: 2.721233842985701, time: 0.08037543296813965
Test Loss Energy: 9.954273863530833, Test Loss Force: 9.03174056703079, time: 17.218148946762085


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8732076867189473, Training Loss Force: 2.8505390685399132, time: 1.1687369346618652
Validation Loss Energy: 1.265398695972918, Validation Loss Force: 2.723481688013842, time: 0.08029866218566895
Test Loss Energy: 9.997536841791508, Test Loss Force: 8.944005514715437, time: 17.336868047714233


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8436365596115047, Training Loss Force: 2.8493964766096394, time: 1.1498494148254395
Validation Loss Energy: 1.4217647636635182, Validation Loss Force: 2.737212803566625, time: 0.07879781723022461
Test Loss Energy: 9.920418374560303, Test Loss Force: 8.967678835613265, time: 17.35649871826172


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7526615764828641, Training Loss Force: 2.865235461798704, time: 1.1604595184326172
Validation Loss Energy: 2.8258137474078757, Validation Loss Force: 2.7408095782807966, time: 0.08035063743591309
Test Loss Energy: 9.835522608001463, Test Loss Force: 9.021007816269279, time: 17.356937646865845

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–„â–…â–…â–„â–†â–†â–†â–„â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:   test_error_force â–ˆâ–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚
wandb:          test_loss â–ˆâ–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–‚â–‚â–ƒâ–â–â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–…â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–ƒâ–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–ƒâ–â–â–‚â–â–â–
wandb: valid_error_energy â–‚â–…â–‡â–â–â–â–â–â–â–â–ƒâ–ƒâ–ˆâ–â–â–‚â–‚â–â–â–†
wandb:  valid_error_force â–ˆâ–ƒâ–„â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–…â–â–ƒâ–‚â–â–â–‚â–‚
wandb:         valid_loss â–‡â–†â–†â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ˆâ–‚â–â–ƒâ–â–â–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 997
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.83552
wandb:   test_error_force 9.02101
wandb:          test_loss 4.89948
wandb: train_error_energy 1.75266
wandb:  train_error_force 2.86524
wandb:         train_loss 1.30558
wandb: valid_error_energy 2.82581
wandb:  valid_error_force 2.74081
wandb:         valid_loss 1.44637
wandb: 
wandb: ğŸš€ View run al_55_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nyysy38s
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_012545-nyysy38s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6743947863578796, Uncertainty Bias: 0.03226761519908905
5.722046e-06 0.02125454
0.9220463 4.588394
Found uncertainty sample 5 after 2962 steps.
Found uncertainty sample 6 after 3491 steps.
Found uncertainty sample 11 after 455 steps.
Found uncertainty sample 12 after 1364 steps.
Found uncertainty sample 13 after 1887 steps.
Found uncertainty sample 14 after 1594 steps.
Found uncertainty sample 21 after 1514 steps.
Found uncertainty sample 25 after 2874 steps.
Found uncertainty sample 26 after 2986 steps.
Found uncertainty sample 27 after 3764 steps.
Found uncertainty sample 30 after 1890 steps.
Found uncertainty sample 31 after 592 steps.
Found uncertainty sample 33 after 927 steps.
Found uncertainty sample 35 after 763 steps.
Found uncertainty sample 36 after 1942 steps.
Found uncertainty sample 37 after 3161 steps.
Found uncertainty sample 41 after 3365 steps.
Found uncertainty sample 44 after 17 steps.
Found uncertainty sample 45 after 3823 steps.
Found uncertainty sample 46 after 3722 steps.
Found uncertainty sample 48 after 603 steps.
Found uncertainty sample 49 after 3442 steps.
Found uncertainty sample 51 after 1064 steps.
Found uncertainty sample 52 after 391 steps.
Found uncertainty sample 53 after 3871 steps.
Found uncertainty sample 56 after 1725 steps.
Found uncertainty sample 58 after 3111 steps.
Found uncertainty sample 59 after 3868 steps.
Found uncertainty sample 68 after 1952 steps.
Found uncertainty sample 69 after 1905 steps.
Found uncertainty sample 72 after 2797 steps.
Found uncertainty sample 73 after 978 steps.
Found uncertainty sample 74 after 1717 steps.
Found uncertainty sample 77 after 2692 steps.
Found uncertainty sample 78 after 2852 steps.
Found uncertainty sample 82 after 1494 steps.
Found uncertainty sample 83 after 2242 steps.
Found uncertainty sample 86 after 1178 steps.
Found uncertainty sample 88 after 379 steps.
Found uncertainty sample 90 after 2004 steps.
Found uncertainty sample 92 after 650 steps.
Found uncertainty sample 93 after 3328 steps.
Found uncertainty sample 98 after 3550 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_035944-2boaekla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2boaekla
Training model 4. Added 43 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.668087543380077, Training Loss Force: 3.304896009887436, time: 1.208698034286499
Validation Loss Energy: 2.1831554105352233, Validation Loss Force: 2.904255411466171, time: 0.08023619651794434
Test Loss Energy: 9.67760476835935, Test Loss Force: 8.92576201941269, time: 16.760206699371338


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7963758433051777, Training Loss Force: 3.051261986460689, time: 1.2080409526824951
Validation Loss Energy: 1.3500609566264248, Validation Loss Force: 2.7751017400994056, time: 0.07841253280639648
Test Loss Energy: 9.998681225967958, Test Loss Force: 8.89068968436291, time: 16.839357376098633


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6111929536286347, Training Loss Force: 3.041065217290619, time: 1.1777691841125488
Validation Loss Energy: 1.3215142154456176, Validation Loss Force: 2.78633116779769, time: 0.07790589332580566
Test Loss Energy: 10.012535415770667, Test Loss Force: 8.907666180567256, time: 17.185216426849365


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6655776843858, Training Loss Force: 3.0118826915964645, time: 1.1718659400939941
Validation Loss Energy: 2.101324722075907, Validation Loss Force: 2.77219635308334, time: 0.0800318717956543
Test Loss Energy: 9.62730393886465, Test Loss Force: 8.904048415497208, time: 16.8670973777771


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7450045413327027, Training Loss Force: 3.003054926073308, time: 1.1936390399932861
Validation Loss Energy: 1.434081150797649, Validation Loss Force: 2.8044793711982425, time: 0.07950353622436523
Test Loss Energy: 9.820657915303553, Test Loss Force: 8.892963521059158, time: 16.910732984542847


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7704864222167733, Training Loss Force: 3.0199115337191316, time: 1.213770866394043
Validation Loss Energy: 1.3707959074952205, Validation Loss Force: 2.807051199833708, time: 0.08036303520202637
Test Loss Energy: 9.876029002857521, Test Loss Force: 8.888797504914397, time: 16.800141096115112


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9469784356013942, Training Loss Force: 3.0039615133796285, time: 1.219970703125
Validation Loss Energy: 1.7413563334195967, Validation Loss Force: 2.7814600575613735, time: 0.08018922805786133
Test Loss Energy: 9.622197456848825, Test Loss Force: 8.874845387319763, time: 16.835575103759766


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7683093168146509, Training Loss Force: 3.000063096195773, time: 1.2175569534301758
Validation Loss Energy: 1.317310333305074, Validation Loss Force: 2.804578904306472, time: 0.07977414131164551
Test Loss Energy: 9.773782627949808, Test Loss Force: 8.824279723769871, time: 16.727147102355957


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5871918765453834, Training Loss Force: 2.9893006934146475, time: 1.2281157970428467
Validation Loss Energy: 1.3516378995178855, Validation Loss Force: 2.7815584773238737, time: 0.08006072044372559
Test Loss Energy: 9.7661610104952, Test Loss Force: 8.812461228926358, time: 16.86644434928894


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6892073375254317, Training Loss Force: 3.005148724537767, time: 1.2593967914581299
Validation Loss Energy: 2.434797375054551, Validation Loss Force: 2.7701072711562453, time: 0.07830619812011719
Test Loss Energy: 10.530498874705614, Test Loss Force: 8.816226412629081, time: 16.90912938117981


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8501215844628038, Training Loss Force: 2.9946957104135823, time: 1.2072198390960693
Validation Loss Energy: 1.888191159653331, Validation Loss Force: 2.7809018260125327, time: 0.07944178581237793
Test Loss Energy: 10.278514083639664, Test Loss Force: 8.786575453404907, time: 17.12247633934021


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9855243186508227, Training Loss Force: 2.9755022170714467, time: 1.194756031036377
Validation Loss Energy: 2.525090159066561, Validation Loss Force: 2.7720157684059923, time: 0.08457708358764648
Test Loss Energy: 9.55232049801625, Test Loss Force: 8.816840583097445, time: 17.21944808959961


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.51122674261646, Training Loss Force: 2.987330833946323, time: 1.216064214706421
Validation Loss Energy: 1.4107586731185995, Validation Loss Force: 2.764902379870183, time: 0.0882570743560791
Test Loss Energy: 9.660576841411329, Test Loss Force: 8.806082552975933, time: 17.223122596740723


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.716956504815725, Training Loss Force: 2.988021405190894, time: 1.2202653884887695
Validation Loss Energy: 1.6940104155901172, Validation Loss Force: 2.764804850784267, time: 0.08141922950744629
Test Loss Energy: 9.511465097836226, Test Loss Force: 8.762718942250983, time: 17.508665323257446


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7192217585225475, Training Loss Force: 2.965187790874179, time: 1.2508811950683594
Validation Loss Energy: 1.330813546987, Validation Loss Force: 2.77920196975252, time: 0.07982325553894043
Test Loss Energy: 9.62631210287188, Test Loss Force: 8.755553281258813, time: 17.52270221710205


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6928585784622072, Training Loss Force: 2.990965685084448, time: 1.1831300258636475
Validation Loss Energy: 1.9585902368298602, Validation Loss Force: 2.7721783168825196, time: 0.08138561248779297
Test Loss Energy: 10.229300956782806, Test Loss Force: 8.781353057526038, time: 17.305357217788696


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7574308679838604, Training Loss Force: 2.9681780958054413, time: 1.2287521362304688
Validation Loss Energy: 1.605947997078293, Validation Loss Force: 2.7684352485394736, time: 0.08046817779541016
Test Loss Energy: 9.484379140281453, Test Loss Force: 8.7558954736064, time: 17.52184224128723


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.491056931100692, Training Loss Force: 2.9901412491978756, time: 1.2338409423828125
Validation Loss Energy: 1.3457509726378467, Validation Loss Force: 2.7766931564853516, time: 0.08290386199951172
Test Loss Energy: 9.693766066991419, Test Loss Force: 8.769632975450186, time: 17.411518812179565


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2710372612385745, Training Loss Force: 2.998087393349255, time: 1.1840779781341553
Validation Loss Energy: 1.43593420343006, Validation Loss Force: 2.7673875902078833, time: 0.08064770698547363
Test Loss Energy: 9.581163249847199, Test Loss Force: 8.729865865474748, time: 17.40601086616516


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8136871025485741, Training Loss Force: 2.9496249381990447, time: 1.2121226787567139
Validation Loss Energy: 1.3101341520701133, Validation Loss Force: 2.7556665090353905, time: 0.07985997200012207
Test Loss Energy: 9.67761379636912, Test Loss Force: 8.719494943914722, time: 17.399455785751343

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–…â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–ˆâ–†â–â–‚â–â–‚â–†â–â–‚â–‚â–‚
wandb:   test_error_force â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–…â–„â–„â–ƒâ–„â–„â–‚â–‚â–ƒâ–‚â–ƒâ–â–
wandb:          test_loss â–‡â–‡â–‡â–†â–‡â–ˆâ–…â–…â–„â–‡â–…â–ƒâ–„â–ƒâ–‚â–„â–â–…â–ƒâ–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–â–â–â–‚â–‚â–ƒâ–â–â–â–â–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–‚â–‚â–
wandb: valid_error_energy â–†â–â–â–†â–‚â–â–ƒâ–â–â–‡â–„â–ˆâ–‚â–ƒâ–â–…â–ƒâ–â–‚â–
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–
wandb:         valid_loss â–ˆâ–ƒâ–‚â–„â–„â–…â–„â–ƒâ–ƒâ–…â–„â–…â–„â–ƒâ–‚â–…â–†â–…â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1035
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.67761
wandb:   test_error_force 8.71949
wandb:          test_loss 4.76557
wandb: train_error_energy 1.81369
wandb:  train_error_force 2.94962
wandb:         train_loss 1.35403
wandb: valid_error_energy 1.31013
wandb:  valid_error_force 2.75567
wandb:         valid_loss 1.35305
wandb: 
wandb: ğŸš€ View run al_55_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2boaekla
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_035944-2boaekla/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.693762481212616, Uncertainty Bias: 0.02676767110824585
0.00018310547 0.008595467
0.4106724 5.933535
Found uncertainty sample 4 after 470 steps.
Found uncertainty sample 5 after 20 steps.
Found uncertainty sample 6 after 1781 steps.
Found uncertainty sample 9 after 1145 steps.
Found uncertainty sample 11 after 1977 steps.
Found uncertainty sample 15 after 1412 steps.
Found uncertainty sample 16 after 1196 steps.
Found uncertainty sample 20 after 3963 steps.
Found uncertainty sample 30 after 473 steps.
Found uncertainty sample 31 after 1398 steps.
Found uncertainty sample 33 after 591 steps.
Found uncertainty sample 35 after 387 steps.
Found uncertainty sample 38 after 1102 steps.
Found uncertainty sample 40 after 235 steps.
Found uncertainty sample 41 after 391 steps.
Found uncertainty sample 42 after 2306 steps.
Found uncertainty sample 45 after 3588 steps.
Found uncertainty sample 46 after 1191 steps.
Found uncertainty sample 48 after 2685 steps.
Found uncertainty sample 52 after 801 steps.
Found uncertainty sample 54 after 359 steps.
Found uncertainty sample 56 after 3354 steps.
Found uncertainty sample 63 after 719 steps.
Found uncertainty sample 68 after 1360 steps.
Found uncertainty sample 69 after 1396 steps.
Found uncertainty sample 75 after 675 steps.
Found uncertainty sample 76 after 529 steps.
Found uncertainty sample 78 after 2408 steps.
Found uncertainty sample 82 after 3491 steps.
Found uncertainty sample 85 after 1633 steps.
Found uncertainty sample 88 after 2684 steps.
Found uncertainty sample 89 after 3510 steps.
Found uncertainty sample 90 after 727 steps.
Found uncertainty sample 91 after 200 steps.
Found uncertainty sample 92 after 1246 steps.
Found uncertainty sample 94 after 631 steps.
Found uncertainty sample 97 after 3317 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_062857-5xv2vy7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/5xv2vy7x
Training model 5. Added 37 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2379244946515326, Training Loss Force: 3.26963376314285, time: 1.2067523002624512
Validation Loss Energy: 2.188565157435539, Validation Loss Force: 2.8651838790993676, time: 0.08972430229187012
Test Loss Energy: 9.441670165187457, Test Loss Force: 8.738438590287144, time: 16.90186357498169


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1090001602815005, Training Loss Force: 3.1220981774596037, time: 1.204756498336792
Validation Loss Energy: 1.572325401381489, Validation Loss Force: 2.8144691997611466, time: 0.08193349838256836
Test Loss Energy: 9.711081938953528, Test Loss Force: 8.696169910203723, time: 16.77688455581665


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8339991708722745, Training Loss Force: 3.046928420380664, time: 1.2390780448913574
Validation Loss Energy: 1.4316403629545615, Validation Loss Force: 2.8097644233768384, time: 0.07900500297546387
Test Loss Energy: 9.390158379270712, Test Loss Force: 8.670993248476522, time: 16.69223189353943


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6730023020720084, Training Loss Force: 3.040214591979945, time: 1.196638822555542
Validation Loss Energy: 1.4610616372060001, Validation Loss Force: 2.814450050214597, time: 0.07698535919189453
Test Loss Energy: 9.53659308478761, Test Loss Force: 8.632715941979033, time: 16.78432583808899


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8965314879286648, Training Loss Force: 3.047443192151494, time: 1.2295136451721191
Validation Loss Energy: 1.4782135075130987, Validation Loss Force: 2.814885591064032, time: 0.08174395561218262
Test Loss Energy: 9.630336534082428, Test Loss Force: 8.631955117647417, time: 16.832950115203857


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.793401552592032, Training Loss Force: 3.0535643735221414, time: 1.213280439376831
Validation Loss Energy: 1.5840718668366176, Validation Loss Force: 2.8294583959884214, time: 0.08265209197998047
Test Loss Energy: 9.333687893702614, Test Loss Force: 8.645534382169133, time: 16.671433210372925


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8646392410666806, Training Loss Force: 3.0441821239202707, time: 1.2130582332611084
Validation Loss Energy: 1.504986466277445, Validation Loss Force: 2.7956509849004973, time: 0.0833280086517334
Test Loss Energy: 9.290025575232917, Test Loss Force: 8.58300253001259, time: 16.814658880233765


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8334618342031421, Training Loss Force: 3.053135185292458, time: 1.252533197402954
Validation Loss Energy: 1.6816415898721204, Validation Loss Force: 2.7893409866431957, time: 0.08263874053955078
Test Loss Energy: 9.302438617680584, Test Loss Force: 8.572200730831314, time: 16.72480034828186


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.031046370871026, Training Loss Force: 3.0582992953793524, time: 1.2330737113952637
Validation Loss Energy: 1.401241014479635, Validation Loss Force: 2.8151485633253723, time: 0.08175516128540039
Test Loss Energy: 9.428853814123586, Test Loss Force: 8.573355929033934, time: 17.177000284194946


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8173830654521022, Training Loss Force: 3.050552557203414, time: 1.2004072666168213
Validation Loss Energy: 1.386766740652318, Validation Loss Force: 2.797542113956862, time: 0.07874202728271484
Test Loss Energy: 9.45181682277752, Test Loss Force: 8.561394058576584, time: 16.822192192077637


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.673504827039812, Training Loss Force: 3.033619983259592, time: 1.2337706089019775
Validation Loss Energy: 1.3368094704139704, Validation Loss Force: 2.819047500070568, time: 0.08060169219970703
Test Loss Energy: 9.448206304364072, Test Loss Force: 8.5862180729986, time: 16.69240713119507


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7935758403169142, Training Loss Force: 3.0763231118655345, time: 1.2516276836395264
Validation Loss Energy: 1.469603114309217, Validation Loss Force: 2.832251112416648, time: 0.08274388313293457
Test Loss Energy: 9.259614267326402, Test Loss Force: 8.58982634373606, time: 16.971100330352783


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.933388759013807, Training Loss Force: 3.05271927862242, time: 1.2546062469482422
Validation Loss Energy: 1.491588909105262, Validation Loss Force: 2.8041827758958666, time: 0.08702397346496582
Test Loss Energy: 9.191117526109378, Test Loss Force: 8.554431569773293, time: 17.139833211898804


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7323982488934415, Training Loss Force: 3.0454953479538425, time: 1.2567105293273926
Validation Loss Energy: 1.5340489092002212, Validation Loss Force: 2.818587688284227, time: 0.0892336368560791
Test Loss Energy: 9.253531240043031, Test Loss Force: 8.53444559397329, time: 17.32358455657959


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9482053473584329, Training Loss Force: 3.0333360342548863, time: 1.2551696300506592
Validation Loss Energy: 1.5236456953679018, Validation Loss Force: 2.799379802418204, time: 0.08489537239074707
Test Loss Energy: 9.590414824102913, Test Loss Force: 8.50909375341602, time: 17.453214406967163


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8363807156243603, Training Loss Force: 3.0224148985382318, time: 1.2454619407653809
Validation Loss Energy: 1.514521493109792, Validation Loss Force: 2.81617885346358, time: 0.08180975914001465
Test Loss Energy: 9.212769654687671, Test Loss Force: 8.526639424599953, time: 17.237600326538086


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8768645172255716, Training Loss Force: 3.0245628371598685, time: 1.2433750629425049
Validation Loss Energy: 1.4117462107807892, Validation Loss Force: 2.793955582023403, time: 0.08230352401733398
Test Loss Energy: 9.402099447067119, Test Loss Force: 8.463755265553887, time: 17.435400009155273


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.807600938084155, Training Loss Force: 3.0390963016854475, time: 1.2391550540924072
Validation Loss Energy: 1.3387573801025467, Validation Loss Force: 2.7925035565228082, time: 0.0834665298461914
Test Loss Energy: 9.322445564017743, Test Loss Force: 8.479726374424349, time: 17.496631622314453


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5969716487703522, Training Loss Force: 3.020716247311244, time: 1.240842580795288
Validation Loss Energy: 1.6153149087054643, Validation Loss Force: 2.810286582524039, time: 0.08396649360656738
Test Loss Energy: 9.611103702277221, Test Loss Force: 8.466287860119001, time: 17.33651638031006


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9731793751910132, Training Loss Force: 3.010817274308971, time: 1.2398219108581543
Validation Loss Energy: 1.407484991335169, Validation Loss Force: 2.788954878344157, time: 0.0827186107635498
Test Loss Energy: 9.372092310474024, Test Loss Force: 8.45127442909484, time: 17.49536681175232

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–„â–†â–‡â–ƒâ–‚â–‚â–„â–…â–„â–‚â–â–‚â–†â–â–„â–ƒâ–‡â–ƒ
wandb:   test_error_force â–ˆâ–‡â–†â–…â–…â–†â–„â–„â–„â–„â–„â–„â–„â–ƒâ–‚â–ƒâ–â–‚â–â–
wandb:          test_loss â–†â–‡â–‡â–†â–ˆâ–…â–ƒâ–…â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–â–â–‚
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒ
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–‚â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–â–ƒâ–‚â–„â–…â–‚â–„â–‚â–ƒâ–â–â–ƒâ–
wandb:         valid_loss â–ˆâ–ƒâ–‚â–„â–†â–‚â–„â–…â–…â–‚â–â–‚â–ƒâ–„â–‡â–„â–â–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1068
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.37209
wandb:   test_error_force 8.45127
wandb:          test_loss 4.60501
wandb: train_error_energy 1.97318
wandb:  train_error_force 3.01082
wandb:         train_loss 1.37981
wandb: valid_error_energy 1.40748
wandb:  valid_error_force 2.78895
wandb:         valid_loss 1.38693
wandb: 
wandb: ğŸš€ View run al_55_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/5xv2vy7x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_062857-5xv2vy7x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7013411521911621, Uncertainty Bias: 0.026312917470932007
0.00023627281 0.0066337585
0.61287206 5.9209566
Found uncertainty sample 4 after 902 steps.
Found uncertainty sample 6 after 3730 steps.
Found uncertainty sample 7 after 2545 steps.
Found uncertainty sample 9 after 3882 steps.
Found uncertainty sample 11 after 989 steps.
Found uncertainty sample 12 after 1796 steps.
Found uncertainty sample 14 after 1932 steps.
Found uncertainty sample 16 after 2766 steps.
Found uncertainty sample 17 after 532 steps.
Found uncertainty sample 19 after 882 steps.
Found uncertainty sample 26 after 175 steps.
Found uncertainty sample 34 after 2642 steps.
Found uncertainty sample 35 after 875 steps.
Found uncertainty sample 37 after 1655 steps.
Found uncertainty sample 39 after 1942 steps.
Found uncertainty sample 41 after 1492 steps.
Found uncertainty sample 54 after 1075 steps.
Found uncertainty sample 63 after 761 steps.
Found uncertainty sample 64 after 2871 steps.
Found uncertainty sample 65 after 1142 steps.
Found uncertainty sample 66 after 2395 steps.
Found uncertainty sample 67 after 3502 steps.
Found uncertainty sample 71 after 875 steps.
Found uncertainty sample 81 after 3650 steps.
Found uncertainty sample 83 after 531 steps.
Found uncertainty sample 91 after 551 steps.
Found uncertainty sample 94 after 473 steps.
Found uncertainty sample 96 after 1384 steps.
Found uncertainty sample 97 after 2609 steps.
Found uncertainty sample 99 after 982 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_090846-gg1k1x9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gg1k1x9v
Training model 6. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2404736036429944, Training Loss Force: 3.3417968541094267, time: 1.2586638927459717
Validation Loss Energy: 1.374969395297345, Validation Loss Force: 2.8969454060745075, time: 0.08450913429260254
Test Loss Energy: 9.177162661873343, Test Loss Force: 8.533548883172305, time: 16.867761373519897


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.942192483300263, Training Loss Force: 3.1279739970787164, time: 1.2731573581695557
Validation Loss Energy: 1.4812297837638364, Validation Loss Force: 2.8348567867622947, time: 0.0818624496459961
Test Loss Energy: 9.033563712049224, Test Loss Force: 8.43183032507339, time: 16.973822355270386


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.866075386514832, Training Loss Force: 3.068088434486436, time: 1.2513148784637451
Validation Loss Energy: 1.4207856874288736, Validation Loss Force: 2.822381302523399, time: 0.0798943042755127
Test Loss Energy: 9.263335131708438, Test Loss Force: 8.432020892556478, time: 16.89547848701477


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.010409068842981, Training Loss Force: 3.1230238711054734, time: 1.2551145553588867
Validation Loss Energy: 1.8288348020962253, Validation Loss Force: 2.848190215220451, time: 0.08014035224914551
Test Loss Energy: 9.50986811472163, Test Loss Force: 8.422313958731538, time: 16.937979221343994


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8464503999856452, Training Loss Force: 3.0837655638590666, time: 1.2758383750915527
Validation Loss Energy: 1.576669787753113, Validation Loss Force: 2.829842945603439, time: 0.08106637001037598
Test Loss Energy: 8.997076642168851, Test Loss Force: 8.410536253144977, time: 16.96798849105835


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7895513682271942, Training Loss Force: 3.1223353208484848, time: 1.2940032482147217
Validation Loss Energy: 1.5585396205533808, Validation Loss Force: 2.8263503800495617, time: 0.08333826065063477
Test Loss Energy: 9.351647440377828, Test Loss Force: 8.412093580167069, time: 16.84211301803589


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2566724951332895, Training Loss Force: 3.073882788259548, time: 1.2833666801452637
Validation Loss Energy: 2.39568910227867, Validation Loss Force: 2.831606485239187, time: 0.08345746994018555
Test Loss Energy: 10.139921832074627, Test Loss Force: 8.42858746955989, time: 16.876213312149048


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9198929985734108, Training Loss Force: 3.0908657131236557, time: 1.243494987487793
Validation Loss Energy: 1.568097916311477, Validation Loss Force: 2.8608453934601106, time: 0.08191156387329102
Test Loss Energy: 9.494990159802757, Test Loss Force: 8.396391422982289, time: 16.808918714523315


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8382746521831328, Training Loss Force: 3.084798774144074, time: 1.2493467330932617
Validation Loss Energy: 1.6693419029239343, Validation Loss Force: 2.868686464764812, time: 0.08089184761047363
Test Loss Energy: 9.50804863966378, Test Loss Force: 8.399468992704316, time: 16.924083471298218


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8474056378977244, Training Loss Force: 3.126349549315466, time: 1.2786953449249268
Validation Loss Energy: 2.597922119331497, Validation Loss Force: 2.879287742802434, time: 0.08480381965637207
Test Loss Energy: 9.067185125617682, Test Loss Force: 8.395187204924971, time: 17.272210597991943


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9926385441238008, Training Loss Force: 3.092515882354249, time: 1.2826342582702637
Validation Loss Energy: 1.725404538474476, Validation Loss Force: 2.851338088936432, time: 0.08982014656066895
Test Loss Energy: 9.478102614676077, Test Loss Force: 8.357615001845492, time: 16.882765531539917


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3147052945630486, Training Loss Force: 3.1268773388110707, time: 1.2346618175506592
Validation Loss Energy: 3.2189258817626722, Validation Loss Force: 3.0125509959264423, time: 0.08943843841552734
Test Loss Energy: 9.001657200646523, Test Loss Force: 8.407428262853871, time: 17.036727905273438


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3166880837828407, Training Loss Force: 3.0994296511817216, time: 1.2744276523590088
Validation Loss Energy: 1.8686530554438971, Validation Loss Force: 2.8305136250709735, time: 0.08427929878234863
Test Loss Energy: 8.875576595489164, Test Loss Force: 8.345996853274576, time: 17.17044186592102


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1787896670115168, Training Loss Force: 3.1103297003173735, time: 1.2980921268463135
Validation Loss Energy: 1.4428791427569747, Validation Loss Force: 2.826117468122921, time: 0.08621025085449219
Test Loss Energy: 8.99533307513943, Test Loss Force: 8.345711580290239, time: 17.422032594680786


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.168455464709496, Training Loss Force: 3.081996572010231, time: 1.283959150314331
Validation Loss Energy: 1.4913251575019106, Validation Loss Force: 2.813277474492141, time: 0.08265852928161621
Test Loss Energy: 9.361202380943242, Test Loss Force: 8.343358389439933, time: 17.45618510246277


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2442418055645783, Training Loss Force: 3.0907132738263536, time: 1.3111722469329834
Validation Loss Energy: 1.669842685833126, Validation Loss Force: 2.8364731420925846, time: 0.082733154296875
Test Loss Energy: 9.00679515945261, Test Loss Force: 8.325042614100289, time: 17.486942768096924


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7642250050172699, Training Loss Force: 3.0478312552610936, time: 1.2814998626708984
Validation Loss Energy: 1.6218650556366492, Validation Loss Force: 2.8246816974699787, time: 0.08736848831176758
Test Loss Energy: 9.2876747812819, Test Loss Force: 8.306572737721979, time: 17.492707014083862


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7860583636970004, Training Loss Force: 3.0632483834149884, time: 1.2718815803527832
Validation Loss Energy: 2.3927906180061282, Validation Loss Force: 2.806213518506728, time: 0.09007072448730469
Test Loss Energy: 8.937268432373017, Test Loss Force: 8.314408094240536, time: 17.814218759536743


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.329954517456963, Training Loss Force: 3.084385869203816, time: 1.489088773727417
Validation Loss Energy: 3.3829887311514124, Validation Loss Force: 2.8487533454905023, time: 0.08579826354980469
Test Loss Energy: 9.034170258139504, Test Loss Force: 8.37165614979267, time: 17.470380306243896


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.207767069406475, Training Loss Force: 3.0804993510349887, time: 1.2819762229919434
Validation Loss Energy: 1.550059154796148, Validation Loss Force: 2.842654660252686, time: 0.08360505104064941
Test Loss Energy: 9.23702027857182, Test Loss Force: 8.312931585626153, time: 17.620190858840942

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–ƒâ–…â–‚â–„â–ˆâ–„â–…â–‚â–„â–‚â–â–‚â–„â–‚â–ƒâ–â–‚â–ƒ
wandb:   test_error_force â–ˆâ–…â–…â–…â–„â–„â–…â–„â–„â–„â–ƒâ–„â–‚â–‚â–‚â–‚â–â–â–ƒâ–
wandb:          test_loss â–‡â–…â–…â–†â–„â–†â–ˆâ–„â–„â–ƒâ–„â–„â–‚â–‚â–…â–â–‚â–â–â–‚
wandb: train_error_energy â–ˆâ–‚â–â–‚â–â–â–ƒâ–‚â–â–â–‚â–„â–„â–ƒâ–ƒâ–ƒâ–â–â–„â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚
wandb: valid_error_energy â–â–â–â–ƒâ–‚â–‚â–…â–‚â–‚â–…â–‚â–‡â–ƒâ–â–â–‚â–‚â–…â–ˆâ–‚
wandb:  valid_error_force â–„â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–‚â–‚â–â–‚â–‚â–â–‚â–‚
wandb:         valid_loss â–ƒâ–‚â–â–ƒâ–â–‚â–„â–â–‚â–„â–‚â–ˆâ–‚â–ƒâ–„â–‚â–‚â–ƒâ–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1095
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.23702
wandb:   test_error_force 8.31293
wandb:          test_loss 4.49051
wandb: train_error_energy 2.20777
wandb:  train_error_force 3.0805
wandb:         train_loss 1.45817
wandb: valid_error_energy 1.55006
wandb:  valid_error_force 2.84265
wandb:         valid_loss 1.41783
wandb: 
wandb: ğŸš€ View run al_55_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gg1k1x9v
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_090846-gg1k1x9v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7349976301193237, Uncertainty Bias: 0.0207635760307312
0.00017547607 0.008922577
0.5351896 5.4854546
Found uncertainty sample 4 after 994 steps.
Found uncertainty sample 8 after 3547 steps.
Found uncertainty sample 9 after 3853 steps.
Found uncertainty sample 10 after 1268 steps.
Found uncertainty sample 14 after 1900 steps.
Found uncertainty sample 15 after 1044 steps.
Found uncertainty sample 18 after 1425 steps.
Found uncertainty sample 19 after 1739 steps.
Found uncertainty sample 21 after 1171 steps.
Found uncertainty sample 25 after 1272 steps.
Found uncertainty sample 29 after 10 steps.
Found uncertainty sample 31 after 279 steps.
Found uncertainty sample 32 after 1322 steps.
Found uncertainty sample 34 after 3561 steps.
Found uncertainty sample 35 after 696 steps.
Found uncertainty sample 36 after 708 steps.
Found uncertainty sample 39 after 3739 steps.
Found uncertainty sample 40 after 1705 steps.
Found uncertainty sample 41 after 392 steps.
Found uncertainty sample 42 after 3670 steps.
Found uncertainty sample 45 after 2738 steps.
Found uncertainty sample 47 after 3620 steps.
Found uncertainty sample 52 after 501 steps.
Found uncertainty sample 53 after 2026 steps.
Found uncertainty sample 54 after 749 steps.
Found uncertainty sample 55 after 3465 steps.
Found uncertainty sample 60 after 2687 steps.
Found uncertainty sample 63 after 749 steps.
Found uncertainty sample 65 after 3369 steps.
Found uncertainty sample 68 after 2277 steps.
Found uncertainty sample 69 after 662 steps.
Found uncertainty sample 71 after 206 steps.
Found uncertainty sample 72 after 1275 steps.
Found uncertainty sample 73 after 903 steps.
Found uncertainty sample 74 after 1312 steps.
Found uncertainty sample 75 after 336 steps.
Found uncertainty sample 80 after 1197 steps.
Found uncertainty sample 81 after 1769 steps.
Found uncertainty sample 85 after 1893 steps.
Found uncertainty sample 88 after 2119 steps.
Found uncertainty sample 89 after 3745 steps.
Found uncertainty sample 91 after 940 steps.
Found uncertainty sample 92 after 575 steps.
Found uncertainty sample 93 after 326 steps.
Found uncertainty sample 94 after 1599 steps.
Found uncertainty sample 96 after 683 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_113054-rvivxedx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/rvivxedx
Training model 7. Added 46 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.837874939251071, Training Loss Force: 3.6075253660945723, time: 1.2949409484863281
Validation Loss Energy: 2.4844822095928563, Validation Loss Force: 2.9149749268202805, time: 0.09065890312194824
Test Loss Energy: 9.619704028737255, Test Loss Force: 8.273145211855075, time: 17.149376153945923


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.3410654970099567, Training Loss Force: 3.2406080733634983, time: 1.3341064453125
Validation Loss Energy: 1.9124556391542278, Validation Loss Force: 2.8864672640745836, time: 0.08963823318481445
Test Loss Energy: 8.89316081291729, Test Loss Force: 8.277900713669796, time: 17.278129816055298


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.031808797121533, Training Loss Force: 3.1843614821721506, time: 1.375830888748169
Validation Loss Energy: 1.6426305121784368, Validation Loss Force: 2.8626492362112717, time: 0.0848684310913086
Test Loss Energy: 8.924510287723374, Test Loss Force: 8.209741177477815, time: 17.158632516860962


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8784283701183435, Training Loss Force: 3.1752830384235278, time: 1.3105254173278809
Validation Loss Energy: 1.481644059709835, Validation Loss Force: 2.8690200231454117, time: 0.08692693710327148
Test Loss Energy: 8.963898668958377, Test Loss Force: 8.256088536105285, time: 17.24276900291443


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0578926598244003, Training Loss Force: 3.1760551746133037, time: 1.337193250656128
Validation Loss Energy: 1.790837203020232, Validation Loss Force: 2.865781300417892, time: 0.08536171913146973
Test Loss Energy: 9.391006350010686, Test Loss Force: 8.224243010400814, time: 17.304837942123413


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2000255177791668, Training Loss Force: 3.1934525871358197, time: 1.3662402629852295
Validation Loss Energy: 1.9400167353605857, Validation Loss Force: 2.8621206196588393, time: 0.08865475654602051
Test Loss Energy: 9.403424843772104, Test Loss Force: 8.207426593493668, time: 17.179970502853394


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.173455500292944, Training Loss Force: 3.174843303971845, time: 1.3114535808563232
Validation Loss Energy: 1.5469675050395135, Validation Loss Force: 2.8571139039126527, time: 0.08695507049560547
Test Loss Energy: 9.202817838429333, Test Loss Force: 8.2114844903613, time: 17.261626482009888


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9952674109631288, Training Loss Force: 3.1567421456136247, time: 1.3180365562438965
Validation Loss Energy: 1.5060555008470444, Validation Loss Force: 2.874277019011621, time: 0.0870053768157959
Test Loss Energy: 8.9451774632337, Test Loss Force: 8.197659830451089, time: 17.11960220336914


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0912887700735254, Training Loss Force: 3.1599912348269377, time: 1.5463104248046875
Validation Loss Energy: 1.3922113352739713, Validation Loss Force: 2.8533336498222366, time: 0.08535027503967285
Test Loss Energy: 8.988658591972191, Test Loss Force: 8.193814791297278, time: 17.142930269241333


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9525863034988906, Training Loss Force: 3.156341693710436, time: 1.3834497928619385
Validation Loss Energy: 2.446996081545059, Validation Loss Force: 2.860045120549646, time: 0.08372735977172852
Test Loss Energy: 8.802224258596, Test Loss Force: 8.206893073556797, time: 17.712308645248413


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.013121381828354, Training Loss Force: 3.1547511803715818, time: 1.3430914878845215
Validation Loss Energy: 1.384451092869242, Validation Loss Force: 2.8547320120586632, time: 0.08817458152770996
Test Loss Energy: 8.953306106494235, Test Loss Force: 8.163538350944771, time: 17.190807104110718


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0700318425225235, Training Loss Force: 3.1762863113720305, time: 1.3219213485717773
Validation Loss Energy: 1.3635434620777795, Validation Loss Force: 2.8445671655470597, time: 0.09075784683227539
Test Loss Energy: 8.989596600322, Test Loss Force: 8.160757430152243, time: 17.303595542907715


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9385781596949303, Training Loss Force: 3.1461779914708314, time: 1.3468363285064697
Validation Loss Energy: 1.4453152545479977, Validation Loss Force: 2.849940840045735, time: 0.09181046485900879
Test Loss Energy: 8.923280300667095, Test Loss Force: 8.165374366473, time: 17.55783176422119


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9631739770702221, Training Loss Force: 3.162897871264322, time: 1.369873046875
Validation Loss Energy: 1.4196079903160617, Validation Loss Force: 2.881025898155546, time: 0.08781743049621582
Test Loss Energy: 8.880562955078506, Test Loss Force: 8.198416707360046, time: 17.53501534461975


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.584640374856213, Training Loss Force: 3.15648472152517, time: 1.3329360485076904
Validation Loss Energy: 1.983882334439214, Validation Loss Force: 2.8695383969171315, time: 0.08673381805419922
Test Loss Energy: 9.518652825224176, Test Loss Force: 8.112091327941085, time: 17.7060284614563


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9312444060203282, Training Loss Force: 3.1550711311932633, time: 1.4172227382659912
Validation Loss Energy: 1.6162055852891755, Validation Loss Force: 2.853650730686038, time: 0.08689713478088379
Test Loss Energy: 9.225204106015944, Test Loss Force: 8.112271172330958, time: 17.837932348251343


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0366801887869084, Training Loss Force: 3.1509236709401964, time: 1.3709845542907715
Validation Loss Energy: 2.427498948458476, Validation Loss Force: 2.8724132782602054, time: 0.08730769157409668
Test Loss Energy: 9.706378131354876, Test Loss Force: 8.188421914790734, time: 17.907349348068237


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3421403549962476, Training Loss Force: 3.142706066109731, time: 1.3464205265045166
Validation Loss Energy: 2.5603676318559003, Validation Loss Force: 2.8559718338631894, time: 0.09385466575622559
Test Loss Energy: 9.83627280949927, Test Loss Force: 8.134568973815632, time: 17.800292491912842


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1878401559742797, Training Loss Force: 3.156307464514503, time: 1.393665075302124
Validation Loss Energy: 1.4097935137055755, Validation Loss Force: 2.8924951405239945, time: 0.08845186233520508
Test Loss Energy: 8.800041490083016, Test Loss Force: 8.156719139827523, time: 17.836645126342773


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0550957312381635, Training Loss Force: 3.136200156115537, time: 1.4094023704528809
Validation Loss Energy: 1.4060727122771222, Validation Loss Force: 2.8504670072375626, time: 0.08643937110900879
Test Loss Energy: 8.992770048347166, Test Loss Force: 8.106712007438881, time: 17.642178297042847

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–‚â–‚â–‚â–…â–…â–„â–‚â–‚â–â–‚â–‚â–‚â–‚â–†â–„â–‡â–ˆâ–â–‚
wandb:   test_error_force â–ˆâ–ˆâ–…â–‡â–†â–…â–…â–…â–…â–…â–ƒâ–ƒâ–ƒâ–…â–â–â–„â–‚â–ƒâ–
wandb:          test_loss â–ˆâ–„â–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–„â–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–
wandb: valid_error_energy â–ˆâ–„â–ƒâ–‚â–ƒâ–„â–‚â–‚â–â–‡â–â–â–â–â–…â–‚â–‡â–ˆâ–â–
wandb:  valid_error_force â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–‚â–â–‚â–…â–ƒâ–‚â–„â–‚â–†â–‚
wandb:         valid_loss â–ˆâ–‚â–â–‚â–ƒâ–ƒâ–â–â–â–ƒâ–‚â–â–â–‚â–‚â–â–ƒâ–ƒâ–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1136
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.99277
wandb:   test_error_force 8.10671
wandb:          test_loss 4.36528
wandb: train_error_energy 2.0551
wandb:  train_error_force 3.1362
wandb:         train_loss 1.45704
wandb: valid_error_energy 1.40607
wandb:  valid_error_force 2.85047
wandb:         valid_loss 1.41241
wandb: 
wandb: ğŸš€ View run al_55_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/rvivxedx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_113054-rvivxedx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7228235006332397, Uncertainty Bias: 0.02268126606941223
0.00028800964 6.888062e-05
0.40040186 5.002351
Found uncertainty sample 5 after 2929 steps.
Found uncertainty sample 6 after 3834 steps.
Found uncertainty sample 10 after 1645 steps.
Found uncertainty sample 12 after 1312 steps.
Found uncertainty sample 13 after 938 steps.
Found uncertainty sample 17 after 2171 steps.
Found uncertainty sample 22 after 3210 steps.
Found uncertainty sample 26 after 3370 steps.
Found uncertainty sample 27 after 69 steps.
Found uncertainty sample 33 after 435 steps.
Found uncertainty sample 35 after 142 steps.
Found uncertainty sample 40 after 3110 steps.
Found uncertainty sample 45 after 2010 steps.
Found uncertainty sample 47 after 2902 steps.
Found uncertainty sample 50 after 629 steps.
Found uncertainty sample 52 after 3439 steps.
Found uncertainty sample 53 after 104 steps.
Found uncertainty sample 58 after 4 steps.
Found uncertainty sample 60 after 1298 steps.
Found uncertainty sample 61 after 2373 steps.
Found uncertainty sample 63 after 1613 steps.
Found uncertainty sample 65 after 2292 steps.
Found uncertainty sample 66 after 2981 steps.
Found uncertainty sample 69 after 1962 steps.
Found uncertainty sample 77 after 3158 steps.
Found uncertainty sample 80 after 838 steps.
Found uncertainty sample 82 after 2560 steps.
Found uncertainty sample 83 after 670 steps.
Found uncertainty sample 84 after 1526 steps.
Found uncertainty sample 88 after 1682 steps.
Found uncertainty sample 91 after 1145 steps.
Found uncertainty sample 96 after 3725 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_141146-wjafaucq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/wjafaucq
Training model 8. Added 32 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.850399655760903, Training Loss Force: 3.3932439572639224, time: 1.3668975830078125
Validation Loss Energy: 2.8099018102398756, Validation Loss Force: 2.9162978042162373, time: 0.09058785438537598
Test Loss Energy: 8.77243856938305, Test Loss Force: 8.08734350833603, time: 17.319905281066895


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9582425600217916, Training Loss Force: 3.224060541996492, time: 1.3038625717163086
Validation Loss Energy: 1.4740658493319019, Validation Loss Force: 2.8966142970545126, time: 0.09952759742736816
Test Loss Energy: 8.739861308564391, Test Loss Force: 8.054000305292817, time: 17.146854877471924


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.13421460689378, Training Loss Force: 3.2076586364180906, time: 1.3120524883270264
Validation Loss Energy: 1.6383294349556956, Validation Loss Force: 2.9117025810517254, time: 0.08710932731628418
Test Loss Energy: 8.712763172989206, Test Loss Force: 8.098314030107952, time: 17.06348443031311


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.03897150862844, Training Loss Force: 3.2009618618543128, time: 1.333343267440796
Validation Loss Energy: 1.9276683952040143, Validation Loss Force: 2.9125603026018396, time: 0.0848841667175293
Test Loss Energy: 8.572431490678147, Test Loss Force: 8.046809089810184, time: 17.175369262695312


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.433843565749885, Training Loss Force: 3.2311630859430855, time: 1.3509585857391357
Validation Loss Energy: 2.212857247910531, Validation Loss Force: 2.8839600094914366, time: 0.09075784683227539
Test Loss Energy: 8.668624048763851, Test Loss Force: 8.069862275970797, time: 17.170491456985474


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.138816642530541, Training Loss Force: 3.2043548341191097, time: 1.371927261352539
Validation Loss Energy: 1.7177770068807197, Validation Loss Force: 2.8938948387752967, time: 0.08896017074584961
Test Loss Energy: 8.68403895342393, Test Loss Force: 8.070336864361455, time: 17.143784284591675


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8811364293922612, Training Loss Force: 3.1935725621743587, time: 1.3470401763916016
Validation Loss Energy: 1.723384929320911, Validation Loss Force: 2.8840379436925114, time: 0.09184670448303223
Test Loss Energy: 9.034500848375362, Test Loss Force: 8.031062335842638, time: 17.179425716400146


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.877093194013377, Training Loss Force: 3.199383757472442, time: 1.335073709487915
Validation Loss Energy: 2.395696005022194, Validation Loss Force: 2.879669397718554, time: 0.08921146392822266
Test Loss Energy: 8.619704929117724, Test Loss Force: 8.009579496437215, time: 17.09114980697632


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0398080585554355, Training Loss Force: 3.201212791927518, time: 1.5736029148101807
Validation Loss Energy: 1.4162033790748256, Validation Loss Force: 2.8733489340113936, time: 0.08961677551269531
Test Loss Energy: 8.763266708349965, Test Loss Force: 8.03379677590821, time: 17.454695224761963


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.343994645598899, Training Loss Force: 3.1851469663073417, time: 1.3751025199890137
Validation Loss Energy: 1.7539384761793924, Validation Loss Force: 2.878171279704752, time: 0.08467602729797363
Test Loss Energy: 9.1269640503405, Test Loss Force: 8.026645022994106, time: 17.31222701072693


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.211725929169964, Training Loss Force: 3.212306451627636, time: 1.3506131172180176
Validation Loss Energy: 1.5274878514808858, Validation Loss Force: 2.8871212433561735, time: 0.08524417877197266
Test Loss Energy: 8.67925737017396, Test Loss Force: 8.021059193763259, time: 17.164071798324585


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3401101281854237, Training Loss Force: 3.1964031564297324, time: 1.3323228359222412
Validation Loss Energy: 1.8240568788974798, Validation Loss Force: 2.893143998415228, time: 0.08844280242919922
Test Loss Energy: 8.64620940310211, Test Loss Force: 7.978833823411623, time: 17.254358291625977


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0757988609808815, Training Loss Force: 3.2028349246194314, time: 1.3454911708831787
Validation Loss Energy: 2.5403303034212965, Validation Loss Force: 2.9085965691351787, time: 0.09878015518188477
Test Loss Energy: 8.588042787193318, Test Loss Force: 8.02247216822521, time: 17.344789266586304


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.099141583497956, Training Loss Force: 3.196255382351942, time: 1.326221227645874
Validation Loss Energy: 2.126364535542925, Validation Loss Force: 2.881758256976503, time: 0.08833718299865723
Test Loss Energy: 9.36370436141531, Test Loss Force: 7.977836044134529, time: 17.53235936164856


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.310748451029988, Training Loss Force: 3.189313731908493, time: 1.308469533920288
Validation Loss Energy: 1.6694923159320085, Validation Loss Force: 2.8662382175053356, time: 0.08616423606872559
Test Loss Energy: 8.99804986721793, Test Loss Force: 7.977300920047162, time: 17.544330596923828


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.780752421111802, Training Loss Force: 3.1521687751188523, time: 1.4281537532806396
Validation Loss Energy: 1.4132110397572752, Validation Loss Force: 2.875575402801526, time: 0.08564162254333496
Test Loss Energy: 8.665982073518382, Test Loss Force: 7.963661439259866, time: 17.686551332473755


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.215830952227801, Training Loss Force: 3.181072800980472, time: 1.3743116855621338
Validation Loss Energy: 1.9817756616495912, Validation Loss Force: 2.891476206512229, time: 0.08793377876281738
Test Loss Energy: 9.145371667959289, Test Loss Force: 7.998623118236384, time: 18.0356867313385


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.049511823464757, Training Loss Force: 3.1676588023999996, time: 1.348681926727295
Validation Loss Energy: 1.5430599955321997, Validation Loss Force: 2.8961484732012317, time: 0.08812260627746582
Test Loss Energy: 8.471921338215465, Test Loss Force: 7.9936966508182605, time: 17.716877222061157


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8689094499383057, Training Loss Force: 3.1690361073569235, time: 1.2997379302978516
Validation Loss Energy: 1.4332708577756177, Validation Loss Force: 2.8956748559278433, time: 0.09047603607177734
Test Loss Energy: 8.618872486927613, Test Loss Force: 7.9460170078977725, time: 17.61336922645569


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0896735409609803, Training Loss Force: 3.18046288009935, time: 1.3629145622253418
Validation Loss Energy: 1.5680247694970397, Validation Loss Force: 2.865790207183729, time: 0.0926668643951416
Test Loss Energy: 8.573664895880688, Test Loss Force: 7.950375449822055, time: 17.707309246063232

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–†â–ƒâ–‚â–‚â–ˆâ–…â–ƒâ–†â–â–‚â–‚
wandb:   test_error_force â–‡â–†â–ˆâ–†â–‡â–‡â–…â–„â–…â–…â–„â–ƒâ–…â–‚â–‚â–‚â–ƒâ–ƒâ–â–
wandb:          test_loss â–†â–…â–†â–„â–‡â–‡â–†â–„â–…â–ˆâ–‚â–ƒâ–†â–†â–ƒâ–‚â–ˆâ–‚â–‚â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–
wandb: valid_error_energy â–ˆâ–â–‚â–„â–…â–ƒâ–ƒâ–†â–â–ƒâ–‚â–ƒâ–‡â–…â–‚â–â–„â–‚â–â–‚
wandb:  valid_error_force â–ˆâ–…â–‡â–‡â–„â–…â–„â–ƒâ–‚â–ƒâ–„â–…â–‡â–ƒâ–â–‚â–…â–…â–…â–
wandb:         valid_loss â–ˆâ–ƒâ–„â–…â–…â–„â–‚â–…â–â–ƒâ–‡â–„â–†â–†â–â–â–ˆâ–ƒâ–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1164
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.57366
wandb:   test_error_force 7.95038
wandb:          test_loss 4.28101
wandb: train_error_energy 2.08967
wandb:  train_error_force 3.18046
wandb:         train_loss 1.45303
wandb: valid_error_energy 1.56802
wandb:  valid_error_force 2.86579
wandb:         valid_loss 1.45683
wandb: 
wandb: ğŸš€ View run al_55_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/wjafaucq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_141146-wjafaucq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7066308259963989, Uncertainty Bias: 0.027644142508506775
3.8146973e-06 0.010543346
0.8193185 5.896148
Found uncertainty sample 0 after 703 steps.
Found uncertainty sample 2 after 1403 steps.
Found uncertainty sample 8 after 1513 steps.
Found uncertainty sample 17 after 1355 steps.
Found uncertainty sample 19 after 2183 steps.
Found uncertainty sample 30 after 668 steps.
Found uncertainty sample 33 after 2667 steps.
Found uncertainty sample 34 after 1278 steps.
Found uncertainty sample 37 after 1256 steps.
Found uncertainty sample 39 after 408 steps.
Found uncertainty sample 46 after 664 steps.
Found uncertainty sample 47 after 2967 steps.
Found uncertainty sample 51 after 1996 steps.
Found uncertainty sample 52 after 1070 steps.
Found uncertainty sample 59 after 577 steps.
Found uncertainty sample 60 after 2270 steps.
Found uncertainty sample 61 after 291 steps.
Found uncertainty sample 63 after 3967 steps.
Found uncertainty sample 67 after 2530 steps.
Found uncertainty sample 68 after 1939 steps.
Found uncertainty sample 69 after 1902 steps.
Found uncertainty sample 70 after 1677 steps.
Found uncertainty sample 71 after 519 steps.
Found uncertainty sample 75 after 1283 steps.
Found uncertainty sample 80 after 2019 steps.
Found uncertainty sample 85 after 2849 steps.
Found uncertainty sample 89 after 3371 steps.
Found uncertainty sample 95 after 1311 steps.
Found uncertainty sample 97 after 3776 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_165241-m31rlafz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/m31rlafz
Training model 9. Added 29 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.298919810684827, Training Loss Force: 3.3761418717235645, time: 1.3524844646453857
Validation Loss Energy: 1.5748695077082868, Validation Loss Force: 2.9753899648316997, time: 0.08774423599243164
Test Loss Energy: 8.77619696808876, Test Loss Force: 8.006312191618331, time: 16.896591901779175


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.06386553406491, Training Loss Force: 3.266338828864791, time: 1.3734922409057617
Validation Loss Energy: 1.480349238626265, Validation Loss Force: 2.91844767482017, time: 0.08783769607543945
Test Loss Energy: 8.680450501406265, Test Loss Force: 7.949181416255098, time: 17.09204649925232


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8963242000159155, Training Loss Force: 3.29312845851651, time: 1.3643543720245361
Validation Loss Energy: 1.6128736755240851, Validation Loss Force: 2.907668261465806, time: 0.0853126049041748
Test Loss Energy: 8.78044322673255, Test Loss Force: 7.929969065348086, time: 17.096622228622437


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.917270440465339, Training Loss Force: 3.2296850732427576, time: 1.3355107307434082
Validation Loss Energy: 1.4446799794746656, Validation Loss Force: 2.9076731601870165, time: 0.09110212326049805
Test Loss Energy: 8.567486897292062, Test Loss Force: 7.922964446609739, time: 17.13961887359619


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0060056904247987, Training Loss Force: 3.257986204495893, time: 1.365955114364624
Validation Loss Energy: 1.8252938060031088, Validation Loss Force: 2.9123959727721447, time: 0.0888373851776123
Test Loss Energy: 8.937089369073867, Test Loss Force: 7.947676958582576, time: 17.08279800415039


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.063196228700395, Training Loss Force: 3.2146910310317014, time: 1.3546011447906494
Validation Loss Energy: 1.5038504082949216, Validation Loss Force: 2.8912619987938464, time: 0.08823728561401367
Test Loss Energy: 8.739596313627825, Test Loss Force: 7.927381869044131, time: 17.36110806465149


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.029798602087407, Training Loss Force: 3.240126586168176, time: 1.3368501663208008
Validation Loss Energy: 1.4818245330526096, Validation Loss Force: 2.8930547080877114, time: 0.08796930313110352
Test Loss Energy: 8.733637449458158, Test Loss Force: 7.917820215761738, time: 17.131927013397217


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9000899747521316, Training Loss Force: 3.250306761692563, time: 1.4039487838745117
Validation Loss Energy: 1.4621458132775225, Validation Loss Force: 2.898768175703072, time: 0.09000468254089355
Test Loss Energy: 8.64450670693613, Test Loss Force: 7.906793548722446, time: 17.03885245323181


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8859210565001687, Training Loss Force: 3.217684214148121, time: 1.5887172222137451
Validation Loss Energy: 1.4533047348384596, Validation Loss Force: 2.9099007423228778, time: 0.08582258224487305
Test Loss Energy: 8.605720782140288, Test Loss Force: 7.936957470042028, time: 17.022624492645264


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0046038636322536, Training Loss Force: 3.2317370573181976, time: 1.3576459884643555
Validation Loss Energy: 1.4345483106658055, Validation Loss Force: 2.90362882048953, time: 0.08797001838684082
Test Loss Energy: 8.631426717935096, Test Loss Force: 7.921123637282931, time: 17.139811754226685


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0905728552387797, Training Loss Force: 3.231911360381744, time: 1.377748727798462
Validation Loss Energy: 1.5166215971596098, Validation Loss Force: 2.877767803212331, time: 0.08641934394836426
Test Loss Energy: 8.436814446313203, Test Loss Force: 7.889550187627029, time: 17.10577082633972


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3100650632673285, Training Loss Force: 3.238734300455548, time: 1.3780229091644287
Validation Loss Energy: 1.8533044712150948, Validation Loss Force: 2.927745002339239, time: 0.08936643600463867
Test Loss Energy: 8.323742268257124, Test Loss Force: 7.832547984459754, time: 17.184097290039062


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0455384570236053, Training Loss Force: 3.222792888924285, time: 1.389714002609253
Validation Loss Energy: 1.943025663529508, Validation Loss Force: 2.9185752642407867, time: 0.09141373634338379
Test Loss Energy: 8.34227977543383, Test Loss Force: 7.871559012606639, time: 17.312607288360596


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.14753401353057, Training Loss Force: 3.224777908183944, time: 1.4110524654388428
Validation Loss Energy: 1.6422896057160215, Validation Loss Force: 2.8843516845191237, time: 0.09242010116577148
Test Loss Energy: 8.378230574072703, Test Loss Force: 7.857385067578764, time: 17.35990047454834


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9105763760194552, Training Loss Force: 3.22143548609128, time: 1.3820011615753174
Validation Loss Energy: 1.608103323076301, Validation Loss Force: 2.8969022082601974, time: 0.08779144287109375
Test Loss Energy: 8.388317530683898, Test Loss Force: 7.860149874586291, time: 17.589815616607666


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9457646434471358, Training Loss Force: 3.2225441733479974, time: 1.4063096046447754
Validation Loss Energy: 3.1485408327423365, Validation Loss Force: 2.895508744744981, time: 0.08700847625732422
Test Loss Energy: 8.50185416160417, Test Loss Force: 7.905987029417824, time: 17.725289821624756


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2106295925282393, Training Loss Force: 3.239158760585116, time: 1.3632540702819824
Validation Loss Energy: 1.9817204397014012, Validation Loss Force: 2.9181081043726302, time: 0.09270119667053223
Test Loss Energy: 8.354471820502875, Test Loss Force: 7.889423557665612, time: 17.938647270202637


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8211919356299717, Training Loss Force: 3.213696309359699, time: 1.3658418655395508
Validation Loss Energy: 2.149790220371112, Validation Loss Force: 2.872050550221489, time: 0.0957174301147461
Test Loss Energy: 8.990653963997254, Test Loss Force: 7.833654493896872, time: 17.70850110054016


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.873469403719601, Training Loss Force: 3.200167723114566, time: 1.4058406352996826
Validation Loss Energy: 2.0101058570859838, Validation Loss Force: 2.9047675505018047, time: 0.0904085636138916
Test Loss Energy: 8.774983819949464, Test Loss Force: 7.85420514466126, time: 17.59657597541809


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.3066263455586227, Training Loss Force: 3.2070788577492997, time: 1.378448486328125
Validation Loss Energy: 3.5297243582806357, Validation Loss Force: 2.926532791508808, time: 0.09392356872558594
Test Loss Energy: 8.512502176846297, Test Loss Force: 7.835631450833824, time: 17.72642469406128

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–†â–„â–‡â–…â–…â–„â–„â–„â–‚â–â–â–‚â–‚â–ƒâ–â–ˆâ–†â–ƒ
wandb:   test_error_force â–ˆâ–†â–…â–…â–†â–…â–„â–„â–…â–…â–ƒâ–â–ƒâ–‚â–‚â–„â–ƒâ–â–‚â–
wandb:          test_loss â–ˆâ–†â–‡â–†â–†â–…â–ˆâ–…â–„â–„â–„â–ƒâ–â–â–‚â–‡â–„â–‚â–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–„â–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–‚â–â–‚â–â–â–‚â–‚â–â–‚â–â–â–‚â–â–â–‚
wandb: valid_error_energy â–â–â–‚â–â–‚â–â–â–â–â–â–â–‚â–ƒâ–‚â–‚â–‡â–ƒâ–ƒâ–ƒâ–ˆ
wandb:  valid_error_force â–ˆâ–„â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–„â–ƒâ–â–…â–„â–‚â–ƒâ–ƒâ–„â–â–ƒâ–…
wandb:         valid_loss â–ƒâ–â–‚â–â–ƒâ–‚â–…â–‚â–â–ƒâ–â–„â–„â–ƒâ–â–‡â–ƒâ–ƒâ–ƒâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1190
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.5125
wandb:   test_error_force 7.83563
wandb:          test_loss 4.22684
wandb: train_error_energy 2.30663
wandb:  train_error_force 3.20708
wandb:         train_loss 1.49769
wandb: valid_error_energy 3.52972
wandb:  valid_error_force 2.92653
wandb:         valid_loss 1.57083
wandb: 
wandb: ğŸš€ View run al_55_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/m31rlafz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_165241-m31rlafz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6967669129371643, Uncertainty Bias: 0.030797362327575684
0.00012207031 0.099824905
0.60038584 6.974499
Found uncertainty sample 0 after 2593 steps.
Found uncertainty sample 6 after 2455 steps.
Found uncertainty sample 7 after 1817 steps.
Found uncertainty sample 9 after 467 steps.
Found uncertainty sample 10 after 622 steps.
Found uncertainty sample 11 after 1453 steps.
Found uncertainty sample 13 after 536 steps.
Found uncertainty sample 15 after 2051 steps.
Found uncertainty sample 30 after 3654 steps.
Found uncertainty sample 33 after 2540 steps.
Found uncertainty sample 35 after 2278 steps.
Found uncertainty sample 39 after 734 steps.
Found uncertainty sample 40 after 1505 steps.
Found uncertainty sample 54 after 419 steps.
Found uncertainty sample 56 after 2141 steps.
Found uncertainty sample 60 after 1588 steps.
Found uncertainty sample 61 after 1564 steps.
Found uncertainty sample 62 after 2190 steps.
Found uncertainty sample 73 after 109 steps.
Found uncertainty sample 75 after 3604 steps.
Found uncertainty sample 79 after 1922 steps.
Found uncertainty sample 81 after 675 steps.
Found uncertainty sample 83 after 10 steps.
Found uncertainty sample 84 after 1024 steps.
Found uncertainty sample 86 after 213 steps.
Found uncertainty sample 97 after 90 steps.
Found uncertainty sample 98 after 842 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_193332-9hfblxen
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9hfblxen
Training model 10. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.7872844088706, Training Loss Force: 3.45617754802127, time: 1.3848252296447754
Validation Loss Energy: 1.612485229199014, Validation Loss Force: 2.9468954395656124, time: 0.08851432800292969
Test Loss Energy: 8.33091471657792, Test Loss Force: 7.9047594858931145, time: 16.975186824798584


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.029409317823182, Training Loss Force: 3.304637646557795, time: 1.388270616531372
Validation Loss Energy: 1.6983288610062408, Validation Loss Force: 2.89897280864818, time: 0.08791542053222656
Test Loss Energy: 8.68871224718894, Test Loss Force: 7.827813984790204, time: 17.00164818763733


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.882052317792961, Training Loss Force: 3.275436357703104, time: 1.4141349792480469
Validation Loss Energy: 1.8766263922212794, Validation Loss Force: 2.9138669251501437, time: 0.09196662902832031
Test Loss Energy: 8.297503586621326, Test Loss Force: 7.781045147277899, time: 17.318180561065674


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1101280756738783, Training Loss Force: 3.255565304523364, time: 1.41953444480896
Validation Loss Energy: 1.8955991394692024, Validation Loss Force: 2.963891107466843, time: 0.0846867561340332
Test Loss Energy: 8.306988571769095, Test Loss Force: 7.8282303994092315, time: 17.099120140075684


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.241916465060548, Training Loss Force: 3.288251687796116, time: 1.3643929958343506
Validation Loss Energy: 2.5150181655888093, Validation Loss Force: 2.9238794659659324, time: 0.08703160285949707
Test Loss Energy: 8.327579195725503, Test Loss Force: 7.789880861838739, time: 17.074275493621826


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0297995367118484, Training Loss Force: 3.2648986517066447, time: 1.416541337966919
Validation Loss Energy: 1.508905888584066, Validation Loss Force: 2.9155108914545287, time: 0.09089112281799316
Test Loss Energy: 8.388721368576501, Test Loss Force: 7.79556736783453, time: 16.901188135147095


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9222814308731553, Training Loss Force: 3.2626112829051017, time: 1.4208111763000488
Validation Loss Energy: 1.501058471208706, Validation Loss Force: 2.9002507068766596, time: 0.08895730972290039
Test Loss Energy: 8.3572775403429, Test Loss Force: 7.790225343831366, time: 17.059775352478027


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.115253951641565, Training Loss Force: 3.2534671693375734, time: 1.3763296604156494
Validation Loss Energy: 1.5905362861466201, Validation Loss Force: 2.9113667959796663, time: 0.08793759346008301
Test Loss Energy: 8.60328979465414, Test Loss Force: 7.825446305289923, time: 16.863240242004395


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.323043070750583, Training Loss Force: 3.2661341021642536, time: 1.5937304496765137
Validation Loss Energy: 1.459224171413804, Validation Loss Force: 2.9062692312219416, time: 0.08565807342529297
Test Loss Energy: 8.383477085836137, Test Loss Force: 7.757195943402541, time: 17.00751495361328


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.268416560365703, Training Loss Force: 3.2426465153134982, time: 1.3537161350250244
Validation Loss Energy: 1.4534407856866216, Validation Loss Force: 2.8929803365929714, time: 0.08619856834411621
Test Loss Energy: 8.465387882726672, Test Loss Force: 7.766448440977435, time: 17.062624216079712


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9485313603227183, Training Loss Force: 3.237526572306608, time: 1.3608744144439697
Validation Loss Energy: 1.863263460101288, Validation Loss Force: 2.9007973596299124, time: 0.08503937721252441
Test Loss Energy: 8.243435654505504, Test Loss Force: 7.7900634598648555, time: 16.94657063484192


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1341077115295617, Training Loss Force: 3.242219090168461, time: 1.3650751113891602
Validation Loss Energy: 1.8561823585916384, Validation Loss Force: 2.895849873876543, time: 0.0903475284576416
Test Loss Energy: 8.188646798970051, Test Loss Force: 7.751686017536892, time: 17.555971384048462


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.981614903315803, Training Loss Force: 3.2581735805821905, time: 1.421252727508545
Validation Loss Energy: 1.4546502131527284, Validation Loss Force: 2.905356065054492, time: 0.08949518203735352
Test Loss Energy: 8.435995324634407, Test Loss Force: 7.786670474051489, time: 17.429370164871216


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.04541656617521, Training Loss Force: 3.2468944332075065, time: 1.4446773529052734
Validation Loss Energy: 1.4698292348269066, Validation Loss Force: 2.8907903855427715, time: 0.0891561508178711
Test Loss Energy: 8.260555433059126, Test Loss Force: 7.76287863720929, time: 17.446479082107544


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0751036927376005, Training Loss Force: 3.24769106723535, time: 1.3977899551391602
Validation Loss Energy: 1.9696588974047846, Validation Loss Force: 2.890815547156261, time: 0.08802103996276855
Test Loss Energy: 8.193629376681335, Test Loss Force: 7.761662686469853, time: 17.619057178497314


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9473018897036203, Training Loss Force: 3.2459805052771884, time: 1.4026942253112793
Validation Loss Energy: 1.5198397229911311, Validation Loss Force: 2.882164405498675, time: 0.08816146850585938
Test Loss Energy: 8.28365029215843, Test Loss Force: 7.726215728652058, time: 17.49991273880005


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8372462316286489, Training Loss Force: 3.23897247440569, time: 1.3606796264648438
Validation Loss Energy: 1.5631964117367414, Validation Loss Force: 2.8979503119300793, time: 0.08687210083007812
Test Loss Energy: 8.214304682530006, Test Loss Force: 7.726535241389359, time: 17.574824333190918


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.949499666402357, Training Loss Force: 3.235351053732893, time: 1.3730394840240479
Validation Loss Energy: 1.9275501578875267, Validation Loss Force: 2.8889257541147724, time: 0.0912470817565918
Test Loss Energy: 8.13723691624726, Test Loss Force: 7.727372202247586, time: 17.58546805381775


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1231131001650865, Training Loss Force: 3.2371754289231935, time: 1.364311933517456
Validation Loss Energy: 2.076385109724557, Validation Loss Force: 2.8837333323008822, time: 0.08986043930053711
Test Loss Energy: 8.17507056787827, Test Loss Force: 7.710379391739427, time: 17.572818756103516


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.3495462687744957, Training Loss Force: 3.2521318576277314, time: 1.3742263317108154
Validation Loss Energy: 1.5849654381192257, Validation Loss Force: 2.8869482294297875, time: 0.09090495109558105
Test Loss Energy: 8.1748471969165, Test Loss Force: 7.725079129735065, time: 17.828248262405396

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–„â–„â–‡â–„â–…â–‚â–‚â–…â–ƒâ–‚â–ƒâ–‚â–â–â–
wandb:   test_error_force â–ˆâ–…â–„â–…â–„â–„â–„â–…â–ƒâ–ƒâ–„â–‚â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚
wandb:          test_loss â–‡â–…â–ƒâ–…â–…â–„â–„â–ˆâ–‚â–‚â–„â–…â–ƒâ–â–â–â–â–â–‚â–ƒ
wandb: train_error_energy â–ˆâ–â–â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–‚â–ƒâ–„â–„â–ˆâ–â–â–‚â–â–â–„â–„â–â–â–„â–â–‚â–„â–…â–‚
wandb:  valid_error_force â–‡â–‚â–„â–ˆâ–…â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–
wandb:         valid_loss â–…â–ƒâ–ƒâ–†â–†â–‚â–ƒâ–ˆâ–ˆâ–‚â–„â–‡â–‚â–ƒâ–…â–â–‚â–ƒâ–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1214
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.17485
wandb:   test_error_force 7.72508
wandb:          test_loss 4.17668
wandb: train_error_energy 2.34955
wandb:  train_error_force 3.25213
wandb:         train_loss 1.51135
wandb: valid_error_energy 1.58497
wandb:  valid_error_force 2.88695
wandb:         valid_loss 1.47543
wandb: 
wandb: ğŸš€ View run al_55_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9hfblxen
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_193332-9hfblxen/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6945311427116394, Uncertainty Bias: 0.030136778950691223
6.1035156e-05 0.044727325
0.6725656 7.1867685
Found uncertainty sample 0 after 1714 steps.
Found uncertainty sample 4 after 2405 steps.
Found uncertainty sample 11 after 714 steps.
Found uncertainty sample 12 after 3558 steps.
Found uncertainty sample 14 after 3011 steps.
Found uncertainty sample 15 after 2345 steps.
Found uncertainty sample 20 after 2543 steps.
Found uncertainty sample 22 after 3632 steps.
Found uncertainty sample 23 after 476 steps.
Found uncertainty sample 28 after 1334 steps.
Found uncertainty sample 32 after 1183 steps.
Found uncertainty sample 33 after 2964 steps.
Found uncertainty sample 37 after 366 steps.
Found uncertainty sample 43 after 2717 steps.
Found uncertainty sample 44 after 236 steps.
Found uncertainty sample 47 after 2641 steps.
Found uncertainty sample 48 after 2565 steps.
Found uncertainty sample 50 after 2720 steps.
Found uncertainty sample 55 after 1417 steps.
Found uncertainty sample 58 after 2020 steps.
Found uncertainty sample 62 after 829 steps.
Found uncertainty sample 64 after 656 steps.
Found uncertainty sample 72 after 522 steps.
Found uncertainty sample 80 after 2252 steps.
Found uncertainty sample 81 after 3373 steps.
Found uncertainty sample 82 after 866 steps.
Found uncertainty sample 88 after 1808 steps.
Found uncertainty sample 90 after 481 steps.
Found uncertainty sample 91 after 1750 steps.
Found uncertainty sample 92 after 2713 steps.
Found uncertainty sample 93 after 3671 steps.
Found uncertainty sample 94 after 1362 steps.
Found uncertainty sample 96 after 198 steps.
Found uncertainty sample 99 after 1967 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_221131-3yj02wru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3yj02wru
Training model 11. Added 34 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4404789813837433, Training Loss Force: 3.494898287235279, time: 1.4436283111572266
Validation Loss Energy: 2.1357449186534248, Validation Loss Force: 3.016986119975032, time: 0.09117770195007324
Test Loss Energy: 8.141233214202158, Test Loss Force: 7.79789149511516, time: 17.109164237976074


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0082248708946895, Training Loss Force: 3.344689369706965, time: 1.4090750217437744
Validation Loss Energy: 1.6210504205662724, Validation Loss Force: 2.9653803187148076, time: 0.08888888359069824
Test Loss Energy: 8.510783998762738, Test Loss Force: 7.699250450779536, time: 17.209733724594116


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.019441680674704, Training Loss Force: 3.3106823614223098, time: 1.3995602130889893
Validation Loss Energy: 1.9794340729110147, Validation Loss Force: 2.9426052731310217, time: 0.08754467964172363
Test Loss Energy: 8.750815012403857, Test Loss Force: 7.691756428574578, time: 17.110152006149292


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9368948311474317, Training Loss Force: 3.3114455456463143, time: 1.4086928367614746
Validation Loss Energy: 1.5705099798347397, Validation Loss Force: 2.946743133869798, time: 0.0917959213256836
Test Loss Energy: 8.220603454065447, Test Loss Force: 7.668091286978991, time: 17.226264715194702


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9684443885145788, Training Loss Force: 3.3024188696193884, time: 1.387847661972046
Validation Loss Energy: 1.5061557019627119, Validation Loss Force: 2.9422819575311348, time: 0.08954715728759766
Test Loss Energy: 8.140439542091192, Test Loss Force: 7.6573361550537955, time: 17.25306510925293


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2656085677372477, Training Loss Force: 3.300720572043396, time: 1.4232850074768066
Validation Loss Energy: 3.0507672561037364, Validation Loss Force: 2.981943785803792, time: 0.09181857109069824
Test Loss Energy: 8.166445482008177, Test Loss Force: 7.701962381442651, time: 17.070513010025024


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.268973672333477, Training Loss Force: 3.3002542971423585, time: 1.3702824115753174
Validation Loss Energy: 1.4625763440711739, Validation Loss Force: 2.926880378045601, time: 0.09135150909423828
Test Loss Energy: 8.299518304048522, Test Loss Force: 7.655781973379117, time: 17.233105421066284


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.862837097217291, Training Loss Force: 3.2873557301072687, time: 1.451629877090454
Validation Loss Energy: 1.5272838865432161, Validation Loss Force: 2.9569910359728326, time: 0.09169650077819824
Test Loss Energy: 8.347573854456389, Test Loss Force: 7.648955949285488, time: 17.224767208099365


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1133973378804347, Training Loss Force: 3.291834468761134, time: 1.5256712436676025
Validation Loss Energy: 1.463587595997405, Validation Loss Force: 2.9444594391091625, time: 0.09049391746520996
Test Loss Energy: 8.189514870555126, Test Loss Force: 7.641554263661862, time: 17.07161283493042


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9559580163253925, Training Loss Force: 3.2760984801846744, time: 1.397711992263794
Validation Loss Energy: 1.891915746457265, Validation Loss Force: 2.9432380988437488, time: 0.08884429931640625
Test Loss Energy: 8.149075327738359, Test Loss Force: 7.64993771503699, time: 17.267152070999146


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0626138594855874, Training Loss Force: 3.303630047036603, time: 1.4058971405029297
Validation Loss Energy: 1.8205899202953841, Validation Loss Force: 2.9808106225201656, time: 0.08906412124633789
Test Loss Energy: 8.08723565719452, Test Loss Force: 7.6222222892937825, time: 17.188493251800537


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9985267018014259, Training Loss Force: 3.286993435987914, time: 1.3994617462158203
Validation Loss Energy: 2.7404853720043256, Validation Loss Force: 2.938083530784666, time: 0.09065556526184082
Test Loss Energy: 8.201596851780886, Test Loss Force: 7.608676462449782, time: 17.99122452735901


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.915971536437973, Training Loss Force: 3.2893227665045344, time: 1.4094021320343018
Validation Loss Energy: 2.433120008378277, Validation Loss Force: 2.9361788189104, time: 0.09174418449401855
Test Loss Energy: 8.019982424063905, Test Loss Force: 7.625055890575138, time: 17.6797297000885


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0466823388516753, Training Loss Force: 3.2932997801874366, time: 1.4549305438995361
Validation Loss Energy: 1.8437318132970861, Validation Loss Force: 2.9370670461335058, time: 0.09137606620788574
Test Loss Energy: 8.572219292811113, Test Loss Force: 7.64024149731042, time: 17.588143587112427


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1108149895551898, Training Loss Force: 3.2727139377138985, time: 1.4069373607635498
Validation Loss Energy: 1.4558696607304018, Validation Loss Force: 2.9623161685976953, time: 0.0908362865447998
Test Loss Energy: 8.22554320935229, Test Loss Force: 7.625608347881676, time: 17.70403742790222


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2228063765501855, Training Loss Force: 3.3033999612952765, time: 1.421445608139038
Validation Loss Energy: 1.926423897347424, Validation Loss Force: 2.9406110482600925, time: 0.0927436351776123
Test Loss Energy: 8.128818765791193, Test Loss Force: 7.576633215870182, time: 17.737497806549072


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9664276512220498, Training Loss Force: 3.280162506118447, time: 1.666935920715332
Validation Loss Energy: 1.787223728120116, Validation Loss Force: 2.9432962154908355, time: 0.08933019638061523
Test Loss Energy: 8.549446853971885, Test Loss Force: 7.588990854503758, time: 17.624290466308594


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.922936810025483, Training Loss Force: 3.266614241900728, time: 1.4080150127410889
Validation Loss Energy: 1.6699893134657193, Validation Loss Force: 2.9361394064715705, time: 0.09120798110961914
Test Loss Energy: 8.109045692005681, Test Loss Force: 7.61496061709647, time: 17.768954038619995


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.064293498529042, Training Loss Force: 3.2848841882294506, time: 1.4100782871246338
Validation Loss Energy: 1.512128579133079, Validation Loss Force: 2.9429143379055693, time: 0.0924997329711914
Test Loss Energy: 8.033526809970397, Test Loss Force: 7.594539233349038, time: 17.635295152664185


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9898591054649024, Training Loss Force: 3.2666039934105493, time: 1.4787702560424805
Validation Loss Energy: 1.4685903036989645, Validation Loss Force: 2.9297352191655417, time: 0.09344649314880371
Test Loss Energy: 8.157921735081432, Test Loss Force: 7.61631411907774, time: 17.734976291656494

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–ˆâ–ƒâ–‚â–‚â–„â–„â–ƒâ–‚â–‚â–ƒâ–â–†â–ƒâ–‚â–†â–‚â–â–‚
wandb:   test_error_force â–ˆâ–…â–…â–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–â–â–‚â–‚â–‚
wandb:          test_loss â–†â–ˆâ–†â–ƒâ–‚â–‚â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–…â–ƒâ–„â–â–â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–ƒâ–ƒâ–â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–â–
wandb: valid_error_energy â–„â–‚â–ƒâ–‚â–â–ˆâ–â–â–â–ƒâ–ƒâ–‡â–…â–ƒâ–â–ƒâ–‚â–‚â–â–
wandb:  valid_error_force â–ˆâ–„â–‚â–ƒâ–‚â–…â–â–ƒâ–‚â–‚â–…â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–
wandb:         valid_loss â–†â–†â–ƒâ–‚â–‚â–ˆâ–â–…â–â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–ƒâ–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1244
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.15792
wandb:   test_error_force 7.61631
wandb:          test_loss 4.07834
wandb: train_error_energy 1.98986
wandb:  train_error_force 3.2666
wandb:         train_loss 1.48722
wandb: valid_error_energy 1.46859
wandb:  valid_error_force 2.92974
wandb:         valid_loss 1.43782
wandb: 
wandb: ğŸš€ View run al_55_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3yj02wru
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_221131-3yj02wru/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7291700839996338, Uncertainty Bias: 0.02417983114719391
0.00037384033 0.0047664642
0.43821144 7.097926
Found uncertainty sample 0 after 1027 steps.
Found uncertainty sample 2 after 905 steps.
Found uncertainty sample 10 after 3105 steps.
Found uncertainty sample 13 after 2237 steps.
Found uncertainty sample 16 after 995 steps.
Found uncertainty sample 21 after 503 steps.
Found uncertainty sample 22 after 3999 steps.
Found uncertainty sample 28 after 2080 steps.
Found uncertainty sample 31 after 2971 steps.
Found uncertainty sample 33 after 345 steps.
Found uncertainty sample 35 after 865 steps.
Found uncertainty sample 37 after 1655 steps.
Found uncertainty sample 44 after 1429 steps.
Found uncertainty sample 47 after 3258 steps.
Found uncertainty sample 49 after 2035 steps.
Found uncertainty sample 51 after 2196 steps.
Found uncertainty sample 59 after 646 steps.
Found uncertainty sample 60 after 3949 steps.
Found uncertainty sample 62 after 2711 steps.
Found uncertainty sample 74 after 2036 steps.
Found uncertainty sample 78 after 477 steps.
Found uncertainty sample 79 after 1649 steps.
Found uncertainty sample 81 after 875 steps.
Found uncertainty sample 84 after 398 steps.
Found uncertainty sample 87 after 775 steps.
Found uncertainty sample 88 after 1187 steps.
Found uncertainty sample 91 after 1891 steps.
Found uncertainty sample 92 after 1644 steps.
Found uncertainty sample 93 after 1209 steps.
Found uncertainty sample 97 after 1529 steps.
Found uncertainty sample 99 after 2824 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_005049-o0taf200
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/o0taf200
Training model 12. Added 31 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.976452018723574, Training Loss Force: 3.6043158724036077, time: 1.427475929260254
Validation Loss Energy: 1.215964726061144, Validation Loss Force: 2.609887579891646, time: 0.11854982376098633
Test Loss Energy: 8.06849834001646, Test Loss Force: 7.667935689044077, time: 17.072226524353027


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.094737024776626, Training Loss Force: 3.3332125298958046, time: 1.4343864917755127
Validation Loss Energy: 1.3407929657673319, Validation Loss Force: 2.755828278169907, time: 0.1244814395904541
Test Loss Energy: 8.430453161872302, Test Loss Force: 7.578712327815414, time: 17.21040916442871


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8308180521616246, Training Loss Force: 3.3084530234831377, time: 1.4808769226074219
Validation Loss Energy: 2.714619010667624, Validation Loss Force: 3.47584777707024, time: 0.11766481399536133
Test Loss Energy: 8.451840619608387, Test Loss Force: 7.560200545337, time: 17.194530963897705


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.958902599891132, Training Loss Force: 3.3148281969994526, time: 1.4466040134429932
Validation Loss Energy: 1.1460522644693962, Validation Loss Force: 2.5956824017271827, time: 0.14661216735839844
Test Loss Energy: 8.234194050231656, Test Loss Force: 7.577985799195497, time: 17.295031309127808


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0560577769942965, Training Loss Force: 3.3160596408773637, time: 1.4606468677520752
Validation Loss Energy: 1.8642743780238002, Validation Loss Force: 3.5236773322846746, time: 0.11700010299682617
Test Loss Energy: 8.12090668284766, Test Loss Force: 7.574595914428875, time: 17.697012186050415


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8631561892402373, Training Loss Force: 3.3065491187845253, time: 1.441502332687378
Validation Loss Energy: 1.6200162337180108, Validation Loss Force: 3.110217023367559, time: 0.11728429794311523
Test Loss Energy: 7.947071624931627, Test Loss Force: 7.570110313266776, time: 17.118408679962158


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0519783140224046, Training Loss Force: 3.3264468559315477, time: 1.4331202507019043
Validation Loss Energy: 1.8382207519353733, Validation Loss Force: 2.590847252557934, time: 0.12032938003540039
Test Loss Energy: 8.594652582059148, Test Loss Force: 7.521378942182299, time: 17.288960218429565


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.250047657415714, Training Loss Force: 3.3222594179074307, time: 1.495973825454712
Validation Loss Energy: 2.1720495642129287, Validation Loss Force: 2.642486231520901, time: 0.1253657341003418
Test Loss Energy: 8.039436710244098, Test Loss Force: 7.536881911906687, time: 17.253774166107178


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.372636070966379, Training Loss Force: 3.3227523851295997, time: 1.4655535221099854
Validation Loss Energy: 3.6956928102202258, Validation Loss Force: 3.7689267996281344, time: 0.11919760704040527
Test Loss Energy: 8.294335606231208, Test Loss Force: 7.537618995743604, time: 17.117713451385498


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9806660901619757, Training Loss Force: 3.2980057100264673, time: 1.4716589450836182
Validation Loss Energy: 2.1338554596156545, Validation Loss Force: 3.6400510193554876, time: 0.11767911911010742
Test Loss Energy: 7.90781422444994, Test Loss Force: 7.550596477662635, time: 17.24785852432251


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2331682979594953, Training Loss Force: 3.319566913728329, time: 1.441502571105957
Validation Loss Energy: 1.6934378218813637, Validation Loss Force: 2.498183153476366, time: 0.11962366104125977
Test Loss Energy: 8.51024256999086, Test Loss Force: 7.514867219668471, time: 17.201420068740845


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0219179626219677, Training Loss Force: 3.2854071955177178, time: 1.508378267288208
Validation Loss Energy: 2.406087194720633, Validation Loss Force: 2.4471827896239198, time: 0.1347954273223877
Test Loss Energy: 7.986411904967878, Test Loss Force: 7.51434739330117, time: 17.31596851348877


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9244676152989606, Training Loss Force: 3.2893305869018645, time: 1.443941593170166
Validation Loss Energy: 1.8355428771191593, Validation Loss Force: 3.9099590905881367, time: 0.1288135051727295
Test Loss Energy: 8.056979807326075, Test Loss Force: 7.497231524864387, time: 17.59939479827881


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9497596989914925, Training Loss Force: 3.294255260201234, time: 1.4765937328338623
Validation Loss Energy: 3.364208592714717, Validation Loss Force: 3.381244897735079, time: 0.11851811408996582
Test Loss Energy: 8.041805343374547, Test Loss Force: 7.52028564133902, time: 17.643874883651733


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9345595571488232, Training Loss Force: 3.3037211037299414, time: 1.4474513530731201
Validation Loss Energy: 1.9953946632873996, Validation Loss Force: 2.5563898702330463, time: 0.12551569938659668
Test Loss Energy: 8.057789492962636, Test Loss Force: 7.486310333051841, time: 18.039623498916626


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2019691427876285, Training Loss Force: 3.2883920698521516, time: 1.4177088737487793
Validation Loss Energy: 2.4170492524419442, Validation Loss Force: 3.028588741161891, time: 0.12063026428222656
Test Loss Energy: 8.017695730847544, Test Loss Force: 7.465374359742361, time: 17.68119764328003


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1140492074789194, Training Loss Force: 3.310366296986065, time: 1.4902617931365967
Validation Loss Energy: 1.6746631388387434, Validation Loss Force: 3.170299616344108, time: 0.11618924140930176
Test Loss Energy: 8.038552282386158, Test Loss Force: 7.484362490980071, time: 17.71561622619629


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8709091503638953, Training Loss Force: 3.306087503378103, time: 1.4553523063659668
Validation Loss Energy: 2.460277294088495, Validation Loss Force: 3.3268054089237777, time: 0.11768054962158203
Test Loss Energy: 8.054944070397825, Test Loss Force: 7.489717600001527, time: 17.768181562423706


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.885036021356464, Training Loss Force: 3.2889744832702403, time: 1.4497671127319336
Validation Loss Energy: 1.609246562138781, Validation Loss Force: 2.550700005547154, time: 0.12365078926086426
Test Loss Energy: 8.472832770827836, Test Loss Force: 7.50171584130712, time: 17.777833700180054


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.023875488834283, Training Loss Force: 3.298598588894415, time: 1.486227035522461
Validation Loss Energy: 1.1215479146310487, Validation Loss Force: 3.242265504965958, time: 0.12797856330871582
Test Loss Energy: 8.29021894103035, Test Loss Force: 7.473619686298591, time: 17.841459274291992

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–‡â–„â–ƒâ–â–ˆâ–‚â–…â–â–‡â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‡â–…
wandb:   test_error_force â–ˆâ–…â–„â–…â–…â–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–
wandb:          test_loss â–ˆâ–†â–„â–„â–„â–ƒâ–…â–…â–…â–‚â–„â–‚â–ƒâ–‚â–„â–‚â–â–‚â–ƒâ–‚
wandb: train_error_energy â–ˆâ–ƒâ–â–‚â–‚â–â–‚â–„â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–‚â–‚â–â–â–
wandb: valid_error_energy â–â–‚â–…â–â–ƒâ–‚â–ƒâ–„â–ˆâ–„â–ƒâ–„â–ƒâ–‡â–ƒâ–…â–ƒâ–…â–‚â–
wandb:  valid_error_force â–‚â–‚â–†â–‚â–†â–„â–‚â–‚â–‡â–‡â–â–â–ˆâ–…â–‚â–„â–„â–…â–â–…
wandb:         valid_loss â–â–‚â–†â–â–…â–„â–‚â–‚â–ˆâ–†â–â–â–ˆâ–‡â–‚â–„â–†â–†â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1271
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.29022
wandb:   test_error_force 7.47362
wandb:          test_loss 4.00459
wandb: train_error_energy 2.02388
wandb:  train_error_force 3.2986
wandb:         train_loss 1.49575
wandb: valid_error_energy 1.12155
wandb:  valid_error_force 3.24227
wandb:         valid_loss 1.48002
wandb: 
wandb: ğŸš€ View run al_55_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/o0taf200
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_005049-o0taf200/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7097359299659729, Uncertainty Bias: 0.02840001881122589
0.00013542175 0.0036239624
0.5393374 5.8714423
Found uncertainty sample 1 after 3553 steps.
Found uncertainty sample 2 after 838 steps.
Found uncertainty sample 4 after 3986 steps.
Found uncertainty sample 6 after 1380 steps.
Found uncertainty sample 8 after 1792 steps.
Found uncertainty sample 17 after 2558 steps.
Found uncertainty sample 18 after 221 steps.
Found uncertainty sample 19 after 590 steps.
Found uncertainty sample 20 after 1047 steps.
Found uncertainty sample 22 after 1607 steps.
Found uncertainty sample 26 after 2825 steps.
Found uncertainty sample 36 after 389 steps.
Found uncertainty sample 39 after 1569 steps.
Found uncertainty sample 40 after 3013 steps.
Found uncertainty sample 42 after 1342 steps.
Found uncertainty sample 49 after 3560 steps.
Found uncertainty sample 50 after 2010 steps.
Found uncertainty sample 51 after 2289 steps.
Found uncertainty sample 66 after 3584 steps.
Found uncertainty sample 67 after 448 steps.
Found uncertainty sample 69 after 1048 steps.
Found uncertainty sample 79 after 1039 steps.
Found uncertainty sample 83 after 1064 steps.
Found uncertainty sample 88 after 1415 steps.
Found uncertainty sample 91 after 1784 steps.
Found uncertainty sample 92 after 210 steps.
Found uncertainty sample 93 after 1847 steps.
Found uncertainty sample 95 after 2129 steps.
Found uncertainty sample 96 after 2103 steps.
Found uncertainty sample 98 after 492 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_033207-7u3rvixy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7u3rvixy
Training model 13. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.434859984706427, Training Loss Force: 3.6210189036254, time: 1.4845235347747803
Validation Loss Energy: 3.0276775790167547, Validation Loss Force: 3.318031353897639, time: 0.12394404411315918
Test Loss Energy: 8.930883885418304, Test Loss Force: 7.472560028315067, time: 17.56012272834778


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1981210309878034, Training Loss Force: 3.3780029571668524, time: 1.458512306213379
Validation Loss Energy: 1.3946925375670447, Validation Loss Force: 2.7972841517513047, time: 0.1215662956237793
Test Loss Energy: 8.01445045745023, Test Loss Force: 7.421518759790772, time: 17.297654390335083


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1334871458399483, Training Loss Force: 3.326508447031954, time: 1.4883270263671875
Validation Loss Energy: 1.913918408441114, Validation Loss Force: 3.2960699413730734, time: 0.12392258644104004
Test Loss Energy: 7.891763691476995, Test Loss Force: 7.442393106208146, time: 17.225019216537476


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.059781176591516, Training Loss Force: 3.3443846736481433, time: 1.691908597946167
Validation Loss Energy: 1.393701659867666, Validation Loss Force: 3.0789104094575497, time: 0.11706233024597168
Test Loss Energy: 8.172946845160588, Test Loss Force: 7.471158506741543, time: 17.183001041412354


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8885743433832216, Training Loss Force: 3.3458648695111752, time: 1.5180518627166748
Validation Loss Energy: 2.692476902131138, Validation Loss Force: 3.0516923350704936, time: 0.1295926570892334
Test Loss Energy: 8.952759016563341, Test Loss Force: 7.397321984534115, time: 17.348424196243286


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.469694433900937, Training Loss Force: 3.355374275814354, time: 1.498166799545288
Validation Loss Energy: 1.1508391222676222, Validation Loss Force: 2.6456181843929487, time: 0.1198275089263916
Test Loss Energy: 8.127810585183626, Test Loss Force: 7.433908350863885, time: 17.22165822982788


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0755639222072397, Training Loss Force: 3.3575803568002454, time: 1.5073299407958984
Validation Loss Energy: 1.9329224963713265, Validation Loss Force: 2.6174644542547036, time: 0.1276257038116455
Test Loss Energy: 7.749646731891993, Test Loss Force: 7.42602422164172, time: 17.339527368545532


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0945891623485764, Training Loss Force: 3.3349377776344675, time: 1.4708921909332275
Validation Loss Energy: 1.3113341717648046, Validation Loss Force: 2.7015379776863777, time: 0.12524938583374023
Test Loss Energy: 8.059734436838085, Test Loss Force: 7.406797127938795, time: 17.322150945663452


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1025555312109776, Training Loss Force: 3.3544278667727028, time: 1.4800043106079102
Validation Loss Energy: 2.884334984333179, Validation Loss Force: 2.901898792560244, time: 0.12588214874267578
Test Loss Energy: 7.759202292666756, Test Loss Force: 7.452404227070953, time: 17.18337368965149


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0533637893498975, Training Loss Force: 3.3575395105893557, time: 1.5433387756347656
Validation Loss Energy: 1.885948881353838, Validation Loss Force: 3.402554446334941, time: 0.12251424789428711
Test Loss Energy: 7.980784323523459, Test Loss Force: 7.41741218581571, time: 17.68227481842041


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9255865228693887, Training Loss Force: 3.340835327462054, time: 1.496213436126709
Validation Loss Energy: 2.039168968016197, Validation Loss Force: 3.209318710127045, time: 0.12950873374938965
Test Loss Energy: 7.7296646685404395, Test Loss Force: 7.42060929739231, time: 17.263039350509644


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8887439738247802, Training Loss Force: 3.315744191472378, time: 1.5195395946502686
Validation Loss Energy: 1.1082768613673957, Validation Loss Force: 2.9342471640694763, time: 0.1350407600402832
Test Loss Energy: 7.885180696183555, Test Loss Force: 7.371310775169276, time: 17.696170806884766


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9123086367857545, Training Loss Force: 3.3393618496900834, time: 1.4909827709197998
Validation Loss Energy: 1.7211254498298953, Validation Loss Force: 3.2618542664060906, time: 0.12772130966186523
Test Loss Energy: 7.8946536385445345, Test Loss Force: 7.380197421508375, time: 17.800406455993652


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.880920124077682, Training Loss Force: 3.3378220925459923, time: 1.4679198265075684
Validation Loss Energy: 1.5572245365775312, Validation Loss Force: 2.529789925395086, time: 0.12465071678161621
Test Loss Energy: 7.827753374481845, Test Loss Force: 7.420866586344297, time: 17.672964096069336


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9621990519707764, Training Loss Force: 3.3185261546101423, time: 1.5262806415557861
Validation Loss Energy: 2.454412411453903, Validation Loss Force: 2.9182795596149944, time: 0.12310624122619629
Test Loss Energy: 8.211985405006686, Test Loss Force: 7.405182869895382, time: 17.86974549293518


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1497797766450724, Training Loss Force: 3.3477261663329405, time: 1.5439393520355225
Validation Loss Energy: 1.5809293371801387, Validation Loss Force: 2.947738353617522, time: 0.12787365913391113
Test Loss Energy: 8.388237239220974, Test Loss Force: 7.435687281484263, time: 17.971173763275146


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.129885317622355, Training Loss Force: 3.353539791616331, time: 1.5242550373077393
Validation Loss Energy: 1.692574756271748, Validation Loss Force: 3.180751149381093, time: 0.12804651260375977
Test Loss Energy: 7.928933124543123, Test Loss Force: 7.366872960438021, time: 17.848848819732666


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3243641559314634, Training Loss Force: 3.324945499710959, time: 1.4921989440917969
Validation Loss Energy: 2.3403722970324132, Validation Loss Force: 3.1122865104098114, time: 0.12007355690002441
Test Loss Energy: 8.649487855367974, Test Loss Force: 7.387569500296243, time: 18.035012006759644


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.450493211816428, Training Loss Force: 3.333633924873101, time: 1.531010627746582
Validation Loss Energy: 2.3487623591163995, Validation Loss Force: 2.9622721914413748, time: 0.1253974437713623
Test Loss Energy: 7.79194443590765, Test Loss Force: 7.379631981774565, time: 17.919437170028687


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.524233909305192, Training Loss Force: 3.328886759886745, time: 1.453352689743042
Validation Loss Energy: 1.218503989334018, Validation Loss Force: 2.5753509273508084, time: 0.125962495803833
Test Loss Energy: 7.7384821172364715, Test Loss Force: 7.332444295438116, time: 17.896960020065308

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–ƒâ–‚â–„â–ˆâ–ƒâ–â–ƒâ–â–‚â–â–‚â–‚â–‚â–„â–…â–‚â–†â–â–
wandb:   test_error_force â–ˆâ–…â–†â–ˆâ–„â–†â–†â–…â–‡â–…â–…â–ƒâ–ƒâ–…â–…â–†â–ƒâ–„â–ƒâ–
wandb:          test_loss â–ˆâ–„â–ƒâ–…â–…â–…â–‚â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–ƒâ–‚â–…â–‚â–…â–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–ˆâ–‚â–„â–‚â–‡â–â–„â–‚â–‡â–„â–„â–â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–†â–
wandb:  valid_error_force â–‡â–ƒâ–‡â–…â–…â–‚â–‚â–‚â–„â–ˆâ–†â–„â–‡â–â–„â–„â–†â–†â–„â–
wandb:         valid_loss â–ˆâ–„â–ˆâ–…â–†â–ƒâ–‚â–‚â–…â–ˆâ–†â–„â–†â–â–…â–…â–†â–…â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1298
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.73848
wandb:   test_error_force 7.33244
wandb:          test_loss 3.91751
wandb: train_error_energy 2.52423
wandb:  train_error_force 3.32889
wandb:         train_loss 1.54785
wandb: valid_error_energy 1.2185
wandb:  valid_error_force 2.57535
wandb:         valid_loss 1.25285
wandb: 
wandb: ğŸš€ View run al_55_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7u3rvixy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_033207-7u3rvixy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.708260715007782, Uncertainty Bias: 0.028825029730796814
0.00011253357 0.013093233
0.4434499 5.057127
Found uncertainty sample 9 after 3468 steps.
Found uncertainty sample 11 after 939 steps.
Found uncertainty sample 19 after 3189 steps.
Found uncertainty sample 21 after 511 steps.
Found uncertainty sample 23 after 3495 steps.
Found uncertainty sample 24 after 2277 steps.
Found uncertainty sample 28 after 684 steps.
Found uncertainty sample 29 after 1356 steps.
Found uncertainty sample 39 after 2122 steps.
Found uncertainty sample 54 after 1538 steps.
Found uncertainty sample 55 after 77 steps.
Found uncertainty sample 60 after 2388 steps.
Found uncertainty sample 63 after 3494 steps.
Found uncertainty sample 73 after 1736 steps.
Found uncertainty sample 74 after 2405 steps.
Found uncertainty sample 77 after 3970 steps.
Found uncertainty sample 79 after 1844 steps.
Found uncertainty sample 82 after 3333 steps.
Found uncertainty sample 83 after 3163 steps.
Found uncertainty sample 85 after 1138 steps.
Found uncertainty sample 87 after 274 steps.
Found uncertainty sample 88 after 3439 steps.
Found uncertainty sample 89 after 1360 steps.
Found uncertainty sample 91 after 2749 steps.
Found uncertainty sample 93 after 2153 steps.
Found uncertainty sample 96 after 3786 steps.
Found uncertainty sample 97 after 1906 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_062054-asgskj77
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/asgskj77
Training model 14. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.916293688484417, Training Loss Force: 3.7080092927839896, time: 1.5020215511322021
Validation Loss Energy: 2.2123992174773575, Validation Loss Force: 3.1358324365767993, time: 0.12520217895507812
Test Loss Energy: 7.669782301758362, Test Loss Force: 7.381231580960171, time: 17.246744394302368


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.026354594591315, Training Loss Force: 3.381013571000692, time: 1.5047283172607422
Validation Loss Energy: 1.950829771755985, Validation Loss Force: 3.134330310518371, time: 0.11827826499938965
Test Loss Energy: 8.193274096983838, Test Loss Force: 7.3303712596792145, time: 17.32146978378296


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3793157575287833, Training Loss Force: 3.3737308266744654, time: 1.502830982208252
Validation Loss Energy: 2.506983817465443, Validation Loss Force: 3.206394507568148, time: 0.12089252471923828
Test Loss Energy: 7.7075748820071155, Test Loss Force: 7.344247749039111, time: 17.276413202285767


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.91176090876811, Training Loss Force: 3.364501572294294, time: 1.7370221614837646
Validation Loss Energy: 1.2982501327500877, Validation Loss Force: 2.6516281359761122, time: 0.12497591972351074
Test Loss Energy: 7.7386269174665205, Test Loss Force: 7.319891433088108, time: 17.294986486434937


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8907903580379841, Training Loss Force: 3.365654664466482, time: 1.5182898044586182
Validation Loss Energy: 1.8411219082376666, Validation Loss Force: 2.7549210127348243, time: 0.12456679344177246
Test Loss Energy: 7.823446365632851, Test Loss Force: 7.329815559097471, time: 17.355161905288696


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2333472839253914, Training Loss Force: 3.3585208274807714, time: 1.5071995258331299
Validation Loss Energy: 1.9808195203369774, Validation Loss Force: 3.130754132700198, time: 0.1255354881286621
Test Loss Energy: 8.402369210531937, Test Loss Force: 7.2985943044136175, time: 17.21858835220337


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1651848228900725, Training Loss Force: 3.365059072215942, time: 1.5193495750427246
Validation Loss Energy: 2.1446379903380617, Validation Loss Force: 2.8560301731794224, time: 0.12872052192687988
Test Loss Energy: 8.4951071605754, Test Loss Force: 7.305148837693817, time: 17.39068579673767


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.090163812854813, Training Loss Force: 3.3684370638909464, time: 1.5882606506347656
Validation Loss Energy: 1.5947956129044998, Validation Loss Force: 2.9390845399301844, time: 0.12620091438293457
Test Loss Energy: 7.845763263036949, Test Loss Force: 7.335287568254731, time: 17.761173009872437


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0586244990840163, Training Loss Force: 3.379314865197932, time: 1.5162479877471924
Validation Loss Energy: 1.7283393734850907, Validation Loss Force: 3.1158025675585845, time: 0.12327051162719727
Test Loss Energy: 8.128640534878274, Test Loss Force: 7.391003177438768, time: 17.206804275512695


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.98454327743326, Training Loss Force: 3.3853381398183275, time: 1.5363218784332275
Validation Loss Energy: 1.2063434706020364, Validation Loss Force: 2.8567604166434926, time: 0.1273031234741211
Test Loss Energy: 7.710738140878692, Test Loss Force: 7.33204226221482, time: 17.36840534210205


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.301608869842172, Training Loss Force: 3.35314372281692, time: 1.5556166172027588
Validation Loss Energy: 2.3660206652752516, Validation Loss Force: 2.8045620927859547, time: 0.13045144081115723
Test Loss Energy: 7.743858616485621, Test Loss Force: 7.305383920353178, time: 17.406752586364746


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.187045708247721, Training Loss Force: 3.349953828252114, time: 1.7254157066345215
Validation Loss Energy: 2.154270212252606, Validation Loss Force: 3.144826266049969, time: 0.1240699291229248
Test Loss Energy: 7.680928366092154, Test Loss Force: 7.273050108025249, time: 17.762781858444214


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.24870246340223, Training Loss Force: 3.3555201115620172, time: 1.5835635662078857
Validation Loss Energy: 1.4111490677986973, Validation Loss Force: 2.9395694019954424, time: 0.12519216537475586
Test Loss Energy: 7.757265180683048, Test Loss Force: 7.354687586116902, time: 17.883718013763428


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9204867665274477, Training Loss Force: 3.358480826559199, time: 1.554199457168579
Validation Loss Energy: 1.368690069714895, Validation Loss Force: 2.8149913589083475, time: 0.13126492500305176
Test Loss Energy: 7.729586832267157, Test Loss Force: 7.291186689495352, time: 17.79479217529297


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.4904920392381547, Training Loss Force: 3.3682076457492385, time: 1.5205883979797363
Validation Loss Energy: 1.7490299575265602, Validation Loss Force: 2.859296284211891, time: 0.12492513656616211
Test Loss Energy: 7.763302573615381, Test Loss Force: 7.324567883858602, time: 18.062706232070923


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.4555901032650684, Training Loss Force: 3.3868714501604793, time: 1.5316905975341797
Validation Loss Energy: 1.3107134815205308, Validation Loss Force: 3.1552029822539227, time: 0.12934017181396484
Test Loss Energy: 7.759254157090654, Test Loss Force: 7.2846688301732305, time: 17.95539951324463


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.15496769419317, Training Loss Force: 3.3515253104478533, time: 1.5680303573608398
Validation Loss Energy: 1.1787332480153583, Validation Loss Force: 2.756015876925351, time: 0.1307365894317627
Test Loss Energy: 7.772849759232322, Test Loss Force: 7.271141509350288, time: 18.160919427871704


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2005706215680823, Training Loss Force: 3.3529993801938955, time: 1.532958745956421
Validation Loss Energy: 1.4875861528707777, Validation Loss Force: 3.0099506656402975, time: 0.12399673461914062
Test Loss Energy: 7.720646826939528, Test Loss Force: 7.235202622927822, time: 18.211552381515503


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.093276730165706, Training Loss Force: 3.322643977065411, time: 1.5284533500671387
Validation Loss Energy: 1.822419258663754, Validation Loss Force: 3.315206907116118, time: 0.12925338745117188
Test Loss Energy: 7.989570568228078, Test Loss Force: 7.238760283649768, time: 17.94649624824524


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0494856536787385, Training Loss Force: 3.351293262689565, time: 1.507781982421875
Validation Loss Energy: 1.4377226820101519, Validation Loss Force: 2.9827147777215672, time: 0.12953734397888184
Test Loss Energy: 7.92379537325069, Test Loss Force: 7.2396000284552215, time: 18.06213927268982

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–â–‚â–‚â–‡â–ˆâ–‚â–…â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–„â–ƒ
wandb:   test_error_force â–ˆâ–…â–†â–…â–…â–„â–„â–…â–ˆâ–…â–„â–ƒâ–†â–„â–…â–ƒâ–ƒâ–â–â–
wandb:          test_loss â–…â–„â–„â–„â–†â–ˆâ–…â–…â–‡â–…â–…â–‚â–„â–‚â–ƒâ–‚â–â–ƒâ–‡â–
wandb: train_error_energy â–ˆâ–â–ƒâ–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–ƒâ–ƒâ–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–†â–…â–ˆâ–‚â–„â–…â–†â–ƒâ–„â–â–‡â–†â–‚â–‚â–„â–‚â–â–ƒâ–„â–‚
wandb:  valid_error_force â–†â–†â–‡â–â–‚â–†â–ƒâ–„â–†â–ƒâ–ƒâ–†â–„â–ƒâ–ƒâ–†â–‚â–…â–ˆâ–„
wandb:         valid_loss â–†â–†â–‡â–â–„â–†â–ƒâ–„â–…â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–†â–ƒâ–„â–ˆâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1322
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.9238
wandb:   test_error_force 7.2396
wandb:          test_loss 3.85702
wandb: train_error_energy 2.04949
wandb:  train_error_force 3.35129
wandb:         train_loss 1.5278
wandb: valid_error_energy 1.43772
wandb:  valid_error_force 2.98271
wandb:         valid_loss 1.47184
wandb: 
wandb: ğŸš€ View run al_55_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/asgskj77
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_062054-asgskj77/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7393958568572998, Uncertainty Bias: 0.02165307104587555
0.00019073486 0.0030751228
0.47563514 5.2920804
Found uncertainty sample 1 after 1879 steps.
Found uncertainty sample 7 after 2850 steps.
Found uncertainty sample 9 after 2857 steps.
Found uncertainty sample 10 after 2761 steps.
Found uncertainty sample 11 after 264 steps.
Found uncertainty sample 13 after 2153 steps.
Found uncertainty sample 15 after 2726 steps.
Found uncertainty sample 16 after 418 steps.
Found uncertainty sample 19 after 1030 steps.
Found uncertainty sample 22 after 1559 steps.
Found uncertainty sample 32 after 2481 steps.
Found uncertainty sample 38 after 2241 steps.
Found uncertainty sample 47 after 2320 steps.
Found uncertainty sample 49 after 932 steps.
Found uncertainty sample 60 after 2796 steps.
Found uncertainty sample 61 after 1134 steps.
Found uncertainty sample 67 after 2010 steps.
Found uncertainty sample 71 after 3772 steps.
Found uncertainty sample 73 after 1327 steps.
Found uncertainty sample 75 after 1255 steps.
Found uncertainty sample 76 after 996 steps.
Found uncertainty sample 79 after 486 steps.
Found uncertainty sample 80 after 1391 steps.
Found uncertainty sample 87 after 1432 steps.
Found uncertainty sample 88 after 1370 steps.
Found uncertainty sample 89 after 1617 steps.
Found uncertainty sample 90 after 2062 steps.
Found uncertainty sample 91 after 3370 steps.
Found uncertainty sample 92 after 833 steps.
Found uncertainty sample 93 after 240 steps.
Found uncertainty sample 96 after 1567 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_090112-9t2i0xdj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_55_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9t2i0xdj
Training model 15. Added 31 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5279318871909733, Training Loss Force: 3.584648033382228, time: 1.5449676513671875
Validation Loss Energy: 2.1010686525580904, Validation Loss Force: 2.9219708573816128, time: 0.1335735321044922
Test Loss Energy: 7.644914718795396, Test Loss Force: 7.192573549917198, time: 17.136078596115112


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1823226072160447, Training Loss Force: 3.3955411708828125, time: 1.664151906967163
Validation Loss Energy: 1.6168619025967979, Validation Loss Force: 3.0764418993057943, time: 0.127730131149292
Test Loss Energy: 8.280692800562218, Test Loss Force: 7.241362089847634, time: 17.730200052261353


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8751135379116164, Training Loss Force: 3.3682817499423683, time: 1.5368738174438477
Validation Loss Energy: 1.6216106561374266, Validation Loss Force: 2.8961993531010766, time: 0.12647223472595215
Test Loss Energy: 7.638747000293306, Test Loss Force: 7.229201621828259, time: 16.703452348709106


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1245540411983233, Training Loss Force: 3.389745900837259, time: 1.7329730987548828
Validation Loss Energy: 1.3949923615720365, Validation Loss Force: 2.6750413513321276, time: 0.12463974952697754
Test Loss Energy: 7.662888185206745, Test Loss Force: 7.2433849492712445, time: 16.718695878982544


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9694241031471087, Training Loss Force: 3.369406938563559, time: 1.5382235050201416
Validation Loss Energy: 2.081076080621818, Validation Loss Force: 2.9121346705293982, time: 0.12612271308898926
Test Loss Energy: 7.597550226162239, Test Loss Force: 7.227192954939634, time: 16.851991176605225


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9112152438471925, Training Loss Force: 3.3962168474602485, time: 1.5277090072631836
Validation Loss Energy: 1.7963377989320861, Validation Loss Force: 2.959083346602543, time: 0.12498736381530762
Test Loss Energy: 7.585795841379842, Test Loss Force: 7.230737089968226, time: 17.04685401916504


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9978160038286834, Training Loss Force: 3.3873713518867326, time: 1.563349723815918
Validation Loss Energy: 1.400316046847451, Validation Loss Force: 3.1186232289646245, time: 0.12095928192138672
Test Loss Energy: 7.900588123357237, Test Loss Force: 7.226826614064881, time: 17.435047149658203


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2173271109350616, Training Loss Force: 3.399545953147607, time: 1.583000659942627
Validation Loss Energy: 2.2538690078803754, Validation Loss Force: 3.283045132351173, time: 0.12713003158569336
Test Loss Energy: 8.41321614743045, Test Loss Force: 7.214045055346512, time: 17.432557582855225


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.39474260953085, Training Loss Force: 3.4119108174261465, time: 1.582047939300537
Validation Loss Energy: 3.1227870306589014, Validation Loss Force: 3.00156917631843, time: 0.13187932968139648
Test Loss Energy: 8.766757500711325, Test Loss Force: 7.21631160108549, time: 17.352760314941406


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.066975020996485, Training Loss Force: 3.389077996966521, time: 1.5283482074737549
Validation Loss Energy: 1.479711068854036, Validation Loss Force: 3.3148525291703743, time: 0.12224054336547852
Test Loss Energy: 7.546651419259056, Test Loss Force: 7.199006090816413, time: 17.478399753570557


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2640447496450733, Training Loss Force: 3.3839672274106074, time: 1.574833631515503
Validation Loss Energy: 1.9199699991545665, Validation Loss Force: 2.9542496447827427, time: 0.12053656578063965
Test Loss Energy: 7.473940038416963, Test Loss Force: 7.206762414943657, time: 17.694963455200195


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1287049358496644, Training Loss Force: 3.400839774809195, time: 1.5788969993591309
Validation Loss Energy: 2.505925693683994, Validation Loss Force: 3.2253197149534154, time: 0.13487982749938965
Test Loss Energy: 7.419711875449026, Test Loss Force: 7.186274465945469, time: 18.02801203727722


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.079890054129443, Training Loss Force: 3.3593338472751353, time: 1.613922119140625
Validation Loss Energy: 1.6135485300381056, Validation Loss Force: 2.810117131303988, time: 0.13406848907470703
Test Loss Energy: 7.629305504411609, Test Loss Force: 7.1886203868230325, time: 17.874050855636597


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1422060341747042, Training Loss Force: 3.3794815626442447, time: 1.5803942680358887
Validation Loss Energy: 1.6646888414487677, Validation Loss Force: 3.1887775927497795, time: 0.12833142280578613
Test Loss Energy: 7.993048501737712, Test Loss Force: 7.165691575953007, time: 17.804161548614502


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0736792705117084, Training Loss Force: 3.3662317490395597, time: 1.5662267208099365
Validation Loss Energy: 1.4946638586759518, Validation Loss Force: 3.042436646681713, time: 0.13389372825622559
Test Loss Energy: 7.596649768457406, Test Loss Force: 7.210626354161308, time: 17.87499237060547


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.066371849117808, Training Loss Force: 3.3867250262097404, time: 1.5804429054260254
Validation Loss Energy: 1.8697071711807194, Validation Loss Force: 2.9709191023851886, time: 0.1243295669555664
Test Loss Energy: 7.528802330469908, Test Loss Force: 7.167800658465796, time: 18.2634060382843


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.918397464335442, Training Loss Force: 3.3510375314907592, time: 1.5802185535430908
Validation Loss Energy: 1.549065939070737, Validation Loss Force: 2.890056690706939, time: 0.12186646461486816
Test Loss Energy: 7.892083542298338, Test Loss Force: 7.2073556335277775, time: 18.02380084991455


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1163969376461473, Training Loss Force: 3.3489891876606666, time: 1.5827152729034424
Validation Loss Energy: 1.9177081816375185, Validation Loss Force: 3.0381209846299138, time: 0.12304997444152832
Test Loss Energy: 8.028228590001207, Test Loss Force: 7.136839800775518, time: 17.897294998168945


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.937806513650578, Training Loss Force: 3.3546553406716932, time: 1.6352829933166504
Validation Loss Energy: 3.1451739639213354, Validation Loss Force: 3.5974733386169055, time: 0.13068795204162598
Test Loss Energy: 8.647708222931755, Test Loss Force: 7.141820375630294, time: 17.90469241142273


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1063988573789634, Training Loss Force: 3.3867486757443785, time: 1.5659301280975342
Validation Loss Energy: 1.169147341283167, Validation Loss Force: 2.730419501928087, time: 0.12231206893920898
Test Loss Energy: 7.577653551182018, Test Loss Force: 7.139919627499987, time: 17.874508142471313

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–‚â–‚â–‚â–‚â–ƒâ–†â–ˆâ–‚â–â–â–‚â–„â–‚â–‚â–ƒâ–„â–‡â–‚
wandb:   test_error_force â–…â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–†â–…â–†â–„â–„â–ƒâ–†â–ƒâ–†â–â–â–
wandb:          test_loss â–‡â–…â–…â–‡â–„â–„â–†â–ˆâ–‡â–‚â–„â–…â–‚â–ƒâ–ƒâ–„â–…â–„â–„â–
wandb: train_error_energy â–ˆâ–‚â–â–‚â–â–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–…â–ˆâ–‚â–„â–†â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–ˆâ–
wandb:  valid_error_force â–ƒâ–„â–ƒâ–â–ƒâ–ƒâ–„â–†â–ƒâ–†â–ƒâ–…â–‚â–…â–„â–ƒâ–ƒâ–„â–ˆâ–
wandb:         valid_loss â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–ƒâ–…â–„â–…â–‚â–†â–â–†â–ƒâ–„â–‚â–ƒâ–ˆâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1349
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.57765
wandb:   test_error_force 7.13992
wandb:          test_loss 3.79186
wandb: train_error_energy 2.1064
wandb:  train_error_force 3.38675
wandb:         train_loss 1.53857
wandb: valid_error_energy 1.16915
wandb:  valid_error_force 2.73042
wandb:         valid_loss 1.36186
wandb: 
wandb: ğŸš€ View run al_55_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9t2i0xdj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_090112-9t2i0xdj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7191523313522339, Uncertainty Bias: 0.02645242214202881
0.00010728836 0.0010108948
0.56201524 5.6404934
Found uncertainty sample 2 after 1135 steps.
Found uncertainty sample 3 after 906 steps.
Found uncertainty sample 5 after 3697 steps.
Found uncertainty sample 7 after 1053 steps.
Found uncertainty sample 10 after 2267 steps.
Found uncertainty sample 13 after 2796 steps.
Found uncertainty sample 16 after 2401 steps.
Found uncertainty sample 19 after 2233 steps.
Found uncertainty sample 24 after 2480 steps.
Found uncertainty sample 27 after 3146 steps.
Found uncertainty sample 33 after 2118 steps.
Found uncertainty sample 34 after 2623 steps.
Found uncertainty sample 39 after 678 steps.
Found uncertainty sample 40 after 1957 steps.
Found uncertainty sample 43 after 2648 steps.
Found uncertainty sample 45 after 1052 steps.
Found uncertainty sample 50 after 2697 steps.
Found uncertainty sample 55 after 303 steps.
Found uncertainty sample 57 after 2373 steps.
Found uncertainty sample 59 after 1556 steps.
Found uncertainty sample 60 after 809 steps.
Found uncertainty sample 61 after 3017 steps.
Found uncertainty sample 63 after 3221 steps.
Found uncertainty sample 71 after 2696 steps.
Found uncertainty sample 72 after 2142 steps.
Found uncertainty sample 74 after 2921 steps.
